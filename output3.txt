training...
(276480, 30, 30, 1)
(30720, 30, 30, 1)
('x_minibatch', TensorShape([Dimension(None), Dimension(30), Dimension(30), Dimension(1)]))
[2018-06-05 00:36] Train Step 0000, Epoch 0.0, Batch Size = 256, Examples/Sec = 188.08, Train LB = -1263.095, Loss = 0.000
[2018-06-05 00:36] Train Step 0025, Epoch 0.0, Batch Size = 256, Examples/Sec = 3902.98, Train LB = -585.271, Loss = 788.345
[2018-06-05 00:36] Train Step 0050, Epoch 0.0, Batch Size = 256, Examples/Sec = 3893.59, Train LB = -538.561, Loss = 660.950
[2018-06-05 00:36] Train Step 0075, Epoch 0.1, Batch Size = 256, Examples/Sec = 3907.98, Train LB = -519.146, Loss = 603.411
[2018-06-05 00:36] Train Step 0100, Epoch 0.1, Batch Size = 256, Examples/Sec = 3839.11, Train LB = -510.086, Loss = 571.859
[2018-06-05 00:36] Train Step 0125, Epoch 0.1, Batch Size = 256, Examples/Sec = 3818.05, Train LB = -503.683, Loss = 552.025
[2018-06-05 00:36] Train Step 0150, Epoch 0.1, Batch Size = 256, Examples/Sec = 3885.68, Train LB = -510.785, Loss = 538.834
[2018-06-05 00:36] Train Step 0175, Epoch 0.2, Batch Size = 256, Examples/Sec = 3910.19, Train LB = -502.363, Loss = 529.314
[2018-06-05 00:36] Train Step 0200, Epoch 0.2, Batch Size = 256, Examples/Sec = 3888.80, Train LB = -500.639, Loss = 522.375
Performance on test set:
  Test Lower Bound = -500.603, Test Loss = 500.603
[2018-06-05 00:36] Train Step 0225, Epoch 0.2, Batch Size = 256, Examples/Sec = 3874.74, Train LB = -499.770, Loss = 516.484
[2018-06-05 00:36] Train Step 0250, Epoch 0.2, Batch Size = 256, Examples/Sec = 3878.66, Train LB = -494.874, Loss = 511.818
[2018-06-05 00:36] Train Step 0275, Epoch 0.3, Batch Size = 256, Examples/Sec = 3788.77, Train LB = -502.267, Loss = 507.159
[2018-06-05 00:36] Train Step 0300, Epoch 0.3, Batch Size = 256, Examples/Sec = 3872.27, Train LB = -493.776, Loss = 503.258
[2018-06-05 00:36] Train Step 0325, Epoch 0.3, Batch Size = 256, Examples/Sec = 3839.92, Train LB = -479.639, Loss = 499.077
[2018-06-05 00:36] Train Step 0350, Epoch 0.3, Batch Size = 256, Examples/Sec = 3889.93, Train LB = -485.667, Loss = 495.857
[2018-06-05 00:36] Train Step 0375, Epoch 0.3, Batch Size = 256, Examples/Sec = 3869.35, Train LB = -479.866, Loss = 493.134
[2018-06-05 00:36] Train Step 0400, Epoch 0.4, Batch Size = 256, Examples/Sec = 3834.00, Train LB = -481.085, Loss = 490.625
Performance on test set:
  Test Lower Bound = -481.555, Test Loss = 481.555
[2018-06-05 00:36] Train Step 0425, Epoch 0.4, Batch Size = 256, Examples/Sec = 3871.75, Train LB = -475.799, Loss = 488.163
[2018-06-05 00:36] Train Step 0450, Epoch 0.4, Batch Size = 256, Examples/Sec = 3871.81, Train LB = -481.567, Loss = 486.499
[2018-06-05 00:36] Train Step 0475, Epoch 0.4, Batch Size = 256, Examples/Sec = 3805.06, Train LB = -475.920, Loss = 484.528
[2018-06-05 00:36] Train Step 0500, Epoch 0.5, Batch Size = 256, Examples/Sec = 3624.57, Train LB = -476.135, Loss = 482.267
[2018-06-05 00:36] Train Step 0525, Epoch 0.5, Batch Size = 256, Examples/Sec = 3813.15, Train LB = -474.426, Loss = 480.579
[2018-06-05 00:36] Train Step 0550, Epoch 0.5, Batch Size = 256, Examples/Sec = 3893.36, Train LB = -465.356, Loss = 479.142
[2018-06-05 00:36] Train Step 0575, Epoch 0.5, Batch Size = 256, Examples/Sec = 3896.51, Train LB = -478.802, Loss = 477.479
[2018-06-05 00:36] Train Step 0600, Epoch 0.6, Batch Size = 256, Examples/Sec = 3697.08, Train LB = -462.879, Loss = 476.446
Performance on test set:
  Test Lower Bound = -471.466, Test Loss = 471.466
[2018-06-05 00:36] Train Step 0625, Epoch 0.6, Batch Size = 256, Examples/Sec = 3587.49, Train LB = -462.748, Loss = 474.561
[2018-06-05 00:36] Train Step 0650, Epoch 0.6, Batch Size = 256, Examples/Sec = 3539.49, Train LB = -475.038, Loss = 473.649
[2018-06-05 00:36] Train Step 0675, Epoch 0.6, Batch Size = 256, Examples/Sec = 3826.03, Train LB = -471.134, Loss = 472.153
[2018-06-05 00:37] Train Step 0700, Epoch 0.6, Batch Size = 256, Examples/Sec = 3885.27, Train LB = -466.567, Loss = 471.474
[2018-06-05 00:37] Train Step 0725, Epoch 0.7, Batch Size = 256, Examples/Sec = 3890.28, Train LB = -457.739, Loss = 470.325
[2018-06-05 00:37] Train Step 0750, Epoch 0.7, Batch Size = 256, Examples/Sec = 3812.25, Train LB = -461.778, Loss = 469.061
[2018-06-05 00:37] Train Step 0775, Epoch 0.7, Batch Size = 256, Examples/Sec = 3872.44, Train LB = -459.608, Loss = 467.992
[2018-06-05 00:37] Train Step 0800, Epoch 0.7, Batch Size = 256, Examples/Sec = 3872.56, Train LB = -456.400, Loss = 467.576
Performance on test set:
  Test Lower Bound = -462.720, Test Loss = 462.720
[2018-06-05 00:37] Train Step 0825, Epoch 0.8, Batch Size = 256, Examples/Sec = 3883.45, Train LB = -461.293, Loss = 466.042
[2018-06-05 00:37] Train Step 0850, Epoch 0.8, Batch Size = 256, Examples/Sec = 3881.97, Train LB = -454.964, Loss = 465.378
[2018-06-05 00:37] Train Step 0875, Epoch 0.8, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -462.252, Loss = 464.452
[2018-06-05 00:37] Train Step 0900, Epoch 0.8, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -451.647, Loss = 463.566
[2018-06-05 00:37] Train Step 0925, Epoch 0.9, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -451.943, Loss = 463.752
[2018-06-05 00:37] Train Step 0950, Epoch 0.9, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -448.779, Loss = 462.734
[2018-06-05 00:37] Train Step 0975, Epoch 0.9, Batch Size = 256, Examples/Sec = 3848.30, Train LB = -451.328, Loss = 461.990
[2018-06-05 00:37] Train Step 1000, Epoch 0.9, Batch Size = 256, Examples/Sec = 3781.05, Train LB = -476.125, Loss = 461.792
Performance on test set:
  Test Lower Bound = -460.448, Test Loss = 460.448
[2018-06-05 00:37] Train Step 1025, Epoch 0.9, Batch Size = 256, Examples/Sec = 3833.08, Train LB = -456.706, Loss = 461.221
[2018-06-05 00:37] Train Step 1050, Epoch 1.0, Batch Size = 256, Examples/Sec = 3872.03, Train LB = -459.035, Loss = 460.354
[2018-06-05 00:37] Train Step 1075, Epoch 1.0, Batch Size = 256, Examples/Sec = 3877.79, Train LB = -449.383, Loss = 460.475
[2018-06-05 00:37] Train Step 1100, Epoch 1.0, Batch Size = 256, Examples/Sec = 3871.75, Train LB = -452.855, Loss = 459.800
[2018-06-05 00:37] Train Step 1125, Epoch 1.0, Batch Size = 256, Examples/Sec = 3880.85, Train LB = -451.794, Loss = 459.115
[2018-06-05 00:37] Train Step 1150, Epoch 1.1, Batch Size = 256, Examples/Sec = 3893.47, Train LB = -463.180, Loss = 458.776
[2018-06-05 00:37] Train Step 1175, Epoch 1.1, Batch Size = 256, Examples/Sec = 3880.32, Train LB = -447.345, Loss = 458.417
[2018-06-05 00:37] Train Step 1200, Epoch 1.1, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -458.804, Loss = 458.048
Performance on test set:
  Test Lower Bound = -457.358, Test Loss = 457.358
[2018-06-05 00:37] Train Step 1225, Epoch 1.1, Batch Size = 256, Examples/Sec = 3878.26, Train LB = -457.453, Loss = 457.547
[2018-06-05 00:37] Train Step 1250, Epoch 1.2, Batch Size = 256, Examples/Sec = 3854.67, Train LB = -456.658, Loss = 456.977
[2018-06-05 00:37] Train Step 1275, Epoch 1.2, Batch Size = 256, Examples/Sec = 3866.37, Train LB = -459.575, Loss = 456.732
[2018-06-05 00:37] Train Step 1300, Epoch 1.2, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -452.981, Loss = 456.713
[2018-06-05 00:37] Train Step 1325, Epoch 1.2, Batch Size = 256, Examples/Sec = 3878.42, Train LB = -455.630, Loss = 456.217
[2018-06-05 00:37] Train Step 1350, Epoch 1.2, Batch Size = 256, Examples/Sec = 3892.12, Train LB = -448.697, Loss = 455.716
[2018-06-05 00:37] Train Step 1375, Epoch 1.3, Batch Size = 256, Examples/Sec = 3847.71, Train LB = -458.402, Loss = 455.332
[2018-06-05 00:37] Train Step 1400, Epoch 1.3, Batch Size = 256, Examples/Sec = 3880.08, Train LB = -454.769, Loss = 455.813
Performance on test set:
  Test Lower Bound = -454.385, Test Loss = 454.385
[2018-06-05 00:38] Train Step 1425, Epoch 1.3, Batch Size = 256, Examples/Sec = 3890.51, Train LB = -462.708, Loss = 455.594
[2018-06-05 00:38] Train Step 1450, Epoch 1.3, Batch Size = 256, Examples/Sec = 3875.44, Train LB = -456.796, Loss = 455.562
[2018-06-05 00:38] Train Step 1475, Epoch 1.4, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -459.405, Loss = 454.979
[2018-06-05 00:38] Train Step 1500, Epoch 1.4, Batch Size = 256, Examples/Sec = 3867.58, Train LB = -439.511, Loss = 454.424
[2018-06-05 00:38] Train Step 1525, Epoch 1.4, Batch Size = 256, Examples/Sec = 3868.81, Train LB = -448.218, Loss = 454.521
[2018-06-05 00:38] Train Step 1550, Epoch 1.4, Batch Size = 256, Examples/Sec = 3866.02, Train LB = -443.763, Loss = 453.931
[2018-06-05 00:38] Train Step 1575, Epoch 1.5, Batch Size = 256, Examples/Sec = 3893.30, Train LB = -445.853, Loss = 453.602
[2018-06-05 00:38] Train Step 1600, Epoch 1.5, Batch Size = 256, Examples/Sec = 3863.17, Train LB = -449.174, Loss = 454.077
Performance on test set:
  Test Lower Bound = -454.348, Test Loss = 454.348
[2018-06-05 00:38] Train Step 1625, Epoch 1.5, Batch Size = 256, Examples/Sec = 3881.97, Train LB = -445.976, Loss = 453.629
[2018-06-05 00:38] Train Step 1650, Epoch 1.5, Batch Size = 256, Examples/Sec = 3872.03, Train LB = -457.109, Loss = 453.306
[2018-06-05 00:38] Train Step 1675, Epoch 1.6, Batch Size = 256, Examples/Sec = 3794.95, Train LB = -450.086, Loss = 453.134
[2018-06-05 00:38] Train Step 1700, Epoch 1.6, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -457.955, Loss = 453.350
[2018-06-05 00:38] Train Step 1725, Epoch 1.6, Batch Size = 256, Examples/Sec = 3878.97, Train LB = -454.889, Loss = 453.159
[2018-06-05 00:38] Train Step 1750, Epoch 1.6, Batch Size = 256, Examples/Sec = 3872.98, Train LB = -453.228, Loss = 452.754
[2018-06-05 00:38] Train Step 1775, Epoch 1.6, Batch Size = 256, Examples/Sec = 3789.72, Train LB = -444.758, Loss = 452.113
[2018-06-05 00:38] Train Step 1800, Epoch 1.7, Batch Size = 256, Examples/Sec = 3863.87, Train LB = -454.449, Loss = 452.264
Performance on test set:
  Test Lower Bound = -453.184, Test Loss = 453.184
[2018-06-05 00:38] Train Step 1825, Epoch 1.7, Batch Size = 256, Examples/Sec = 3879.90, Train LB = -469.518, Loss = 451.907
[2018-06-05 00:38] Train Step 1850, Epoch 1.7, Batch Size = 256, Examples/Sec = 3836.59, Train LB = -447.992, Loss = 451.776
[2018-06-05 00:38] Train Step 1875, Epoch 1.7, Batch Size = 256, Examples/Sec = 3836.01, Train LB = -454.711, Loss = 451.815
[2018-06-05 00:38] Train Step 1900, Epoch 1.8, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -449.230, Loss = 451.867
[2018-06-05 00:38] Train Step 1925, Epoch 1.8, Batch Size = 256, Examples/Sec = 3859.66, Train LB = -457.379, Loss = 451.384
[2018-06-05 00:38] Train Step 1950, Epoch 1.8, Batch Size = 256, Examples/Sec = 3882.21, Train LB = -445.439, Loss = 451.099
[2018-06-05 00:38] Train Step 1975, Epoch 1.8, Batch Size = 256, Examples/Sec = 3863.67, Train LB = -455.677, Loss = 450.989
[2018-06-05 00:38] Train Step 2000, Epoch 1.9, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -453.400, Loss = 450.832
Performance on test set:
  Test Lower Bound = -451.661, Test Loss = 451.661
[2018-06-05 00:38] Train Step 2025, Epoch 1.9, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -449.369, Loss = 450.963
[2018-06-05 00:38] Train Step 2050, Epoch 1.9, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -451.089, Loss = 450.515
[2018-06-05 00:38] Train Step 2075, Epoch 1.9, Batch Size = 256, Examples/Sec = 3857.63, Train LB = -446.132, Loss = 451.022
[2018-06-05 00:38] Train Step 2100, Epoch 1.9, Batch Size = 256, Examples/Sec = 3812.03, Train LB = -453.020, Loss = 450.560
[2018-06-05 00:39] Train Step 2125, Epoch 2.0, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -444.377, Loss = 449.989
[2018-06-05 00:39] Train Step 2150, Epoch 2.0, Batch Size = 256, Examples/Sec = 3802.34, Train LB = -465.943, Loss = 449.927
[2018-06-05 00:39] Train Step 2175, Epoch 2.0, Batch Size = 256, Examples/Sec = 3866.26, Train LB = -440.580, Loss = 450.149
[2018-06-05 00:39] Train Step 2200, Epoch 2.0, Batch Size = 256, Examples/Sec = 3850.66, Train LB = -450.908, Loss = 450.333
Performance on test set:
  Test Lower Bound = -451.060, Test Loss = 451.060
[2018-06-05 00:39] Train Step 2225, Epoch 2.1, Batch Size = 256, Examples/Sec = 3885.27, Train LB = -459.696, Loss = 449.766
[2018-06-05 00:39] Train Step 2250, Epoch 2.1, Batch Size = 256, Examples/Sec = 3821.92, Train LB = -452.734, Loss = 449.323
[2018-06-05 00:39] Train Step 2275, Epoch 2.1, Batch Size = 256, Examples/Sec = 3853.44, Train LB = -454.934, Loss = 449.335
[2018-06-05 00:39] Train Step 2300, Epoch 2.1, Batch Size = 256, Examples/Sec = 3888.16, Train LB = -445.607, Loss = 449.139
[2018-06-05 00:39] Train Step 2325, Epoch 2.2, Batch Size = 256, Examples/Sec = 3872.56, Train LB = -446.800, Loss = 449.425
[2018-06-05 00:39] Train Step 2350, Epoch 2.2, Batch Size = 256, Examples/Sec = 3874.56, Train LB = -456.482, Loss = 449.729
[2018-06-05 00:39] Train Step 2375, Epoch 2.2, Batch Size = 256, Examples/Sec = 3878.79, Train LB = -450.488, Loss = 449.762
[2018-06-05 00:39] Train Step 2400, Epoch 2.2, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -439.854, Loss = 449.205
Performance on test set:
  Test Lower Bound = -449.309, Test Loss = 449.309
[2018-06-05 00:39] Train Step 2425, Epoch 2.2, Batch Size = 256, Examples/Sec = 3789.78, Train LB = -439.668, Loss = 448.900
[2018-06-05 00:39] Train Step 2450, Epoch 2.3, Batch Size = 256, Examples/Sec = 3872.91, Train LB = -451.067, Loss = 448.820
[2018-06-05 00:39] Train Step 2475, Epoch 2.3, Batch Size = 256, Examples/Sec = 3881.90, Train LB = -448.386, Loss = 448.845
[2018-06-05 00:39] Train Step 2500, Epoch 2.3, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -459.716, Loss = 448.437
[2018-06-05 00:39] Train Step 2525, Epoch 2.3, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -448.038, Loss = 447.957
[2018-06-05 00:39] Train Step 2550, Epoch 2.4, Batch Size = 256, Examples/Sec = 3849.81, Train LB = -444.079, Loss = 448.167
[2018-06-05 00:39] Train Step 2575, Epoch 2.4, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -441.083, Loss = 448.396
[2018-06-05 00:39] Train Step 2600, Epoch 2.4, Batch Size = 256, Examples/Sec = 3875.96, Train LB = -447.790, Loss = 448.195
Performance on test set:
  Test Lower Bound = -448.589, Test Loss = 448.589
[2018-06-05 00:39] Train Step 2625, Epoch 2.4, Batch Size = 256, Examples/Sec = 3887.09, Train LB = -440.951, Loss = 447.949
[2018-06-05 00:39] Train Step 2650, Epoch 2.5, Batch Size = 256, Examples/Sec = 3776.87, Train LB = -451.109, Loss = 447.798
[2018-06-05 00:39] Train Step 2675, Epoch 2.5, Batch Size = 256, Examples/Sec = 3863.09, Train LB = -438.001, Loss = 448.019
[2018-06-05 00:39] Train Step 2700, Epoch 2.5, Batch Size = 256, Examples/Sec = 3853.68, Train LB = -445.187, Loss = 447.011
[2018-06-05 00:39] Train Step 2725, Epoch 2.5, Batch Size = 256, Examples/Sec = 3849.68, Train LB = -444.918, Loss = 447.044
[2018-06-05 00:39] Train Step 2750, Epoch 2.5, Batch Size = 256, Examples/Sec = 3877.08, Train LB = -445.573, Loss = 446.898
[2018-06-05 00:39] Train Step 2775, Epoch 2.6, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -440.802, Loss = 446.856
[2018-06-05 00:39] Train Step 2800, Epoch 2.6, Batch Size = 256, Examples/Sec = 3843.10, Train LB = -443.832, Loss = 446.991
Performance on test set:
  Test Lower Bound = -446.836, Test Loss = 446.836
[2018-06-05 00:40] Train Step 2825, Epoch 2.6, Batch Size = 256, Examples/Sec = 3864.22, Train LB = -436.378, Loss = 446.232
[2018-06-05 00:40] Train Step 2850, Epoch 2.6, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -443.766, Loss = 446.084
[2018-06-05 00:40] Train Step 2875, Epoch 2.7, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -453.593, Loss = 446.733
[2018-06-05 00:40] Train Step 2900, Epoch 2.7, Batch Size = 256, Examples/Sec = 3871.22, Train LB = -447.899, Loss = 446.514
[2018-06-05 00:40] Train Step 2925, Epoch 2.7, Batch Size = 256, Examples/Sec = 3863.09, Train LB = -445.017, Loss = 446.074
[2018-06-05 00:40] Train Step 2950, Epoch 2.7, Batch Size = 256, Examples/Sec = 3839.98, Train LB = -449.251, Loss = 446.261
[2018-06-05 00:40] Train Step 2975, Epoch 2.8, Batch Size = 256, Examples/Sec = 3882.49, Train LB = -450.263, Loss = 446.785
[2018-06-05 00:40] Train Step 3000, Epoch 2.8, Batch Size = 256, Examples/Sec = 3860.48, Train LB = -441.108, Loss = 446.268
Performance on test set:
  Test Lower Bound = -447.932, Test Loss = 447.932
[2018-06-05 00:40] Train Step 3025, Epoch 2.8, Batch Size = 256, Examples/Sec = 3883.61, Train LB = -447.617, Loss = 445.997
[2018-06-05 00:40] Train Step 3050, Epoch 2.8, Batch Size = 256, Examples/Sec = 3845.11, Train LB = -441.041, Loss = 445.802
[2018-06-05 00:40] Train Step 3075, Epoch 2.8, Batch Size = 256, Examples/Sec = 3888.80, Train LB = -459.929, Loss = 445.652
[2018-06-05 00:40] Train Step 3100, Epoch 2.9, Batch Size = 256, Examples/Sec = 3844.60, Train LB = -445.912, Loss = 445.857
[2018-06-05 00:40] Train Step 3125, Epoch 2.9, Batch Size = 256, Examples/Sec = 3864.20, Train LB = -444.806, Loss = 445.329
[2018-06-05 00:40] Train Step 3150, Epoch 2.9, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -447.318, Loss = 445.208
[2018-06-05 00:40] Train Step 3175, Epoch 2.9, Batch Size = 256, Examples/Sec = 3822.44, Train LB = -444.901, Loss = 444.452
[2018-06-05 00:40] Train Step 3200, Epoch 3.0, Batch Size = 256, Examples/Sec = 3811.79, Train LB = -457.077, Loss = 445.198
Performance on test set:
  Test Lower Bound = -446.521, Test Loss = 446.521
[2018-06-05 00:40] Train Step 3225, Epoch 3.0, Batch Size = 256, Examples/Sec = 3798.05, Train LB = -448.146, Loss = 445.016
[2018-06-05 00:40] Train Step 3250, Epoch 3.0, Batch Size = 256, Examples/Sec = 3883.84, Train LB = -446.743, Loss = 445.312
[2018-06-05 00:40] Train Step 3275, Epoch 3.0, Batch Size = 256, Examples/Sec = 3842.34, Train LB = -451.949, Loss = 445.281
[2018-06-05 00:40] Train Step 3300, Epoch 3.1, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -455.054, Loss = 444.728
[2018-06-05 00:40] Train Step 3325, Epoch 3.1, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -440.176, Loss = 444.760
[2018-06-05 00:40] Train Step 3350, Epoch 3.1, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -442.231, Loss = 444.989
[2018-06-05 00:40] Train Step 3375, Epoch 3.1, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -436.283, Loss = 444.520
[2018-06-05 00:40] Train Step 3400, Epoch 3.1, Batch Size = 256, Examples/Sec = 3802.11, Train LB = -444.450, Loss = 444.873
Performance on test set:
  Test Lower Bound = -444.247, Test Loss = 444.247
[2018-06-05 00:40] Train Step 3425, Epoch 3.2, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -442.537, Loss = 444.997
[2018-06-05 00:40] Train Step 3450, Epoch 3.2, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -437.180, Loss = 444.430
[2018-06-05 00:40] Train Step 3475, Epoch 3.2, Batch Size = 256, Examples/Sec = 3869.01, Train LB = -462.114, Loss = 444.014
[2018-06-05 00:40] Train Step 3500, Epoch 3.2, Batch Size = 256, Examples/Sec = 3869.87, Train LB = -457.699, Loss = 444.201
[2018-06-05 00:40] Train Step 3525, Epoch 3.3, Batch Size = 256, Examples/Sec = 3854.67, Train LB = -448.937, Loss = 443.679
[2018-06-05 00:40] Train Step 3550, Epoch 3.3, Batch Size = 256, Examples/Sec = 3879.03, Train LB = -436.527, Loss = 443.175
[2018-06-05 00:41] Train Step 3575, Epoch 3.3, Batch Size = 256, Examples/Sec = 3861.23, Train LB = -441.241, Loss = 443.300
[2018-06-05 00:41] Train Step 3600, Epoch 3.3, Batch Size = 256, Examples/Sec = 3865.68, Train LB = -438.457, Loss = 443.654
Performance on test set:
  Test Lower Bound = -443.858, Test Loss = 443.858
[2018-06-05 00:41] Train Step 3625, Epoch 3.4, Batch Size = 256, Examples/Sec = 3872.93, Train LB = -446.549, Loss = 442.839
[2018-06-05 00:41] Train Step 3650, Epoch 3.4, Batch Size = 256, Examples/Sec = 3801.54, Train LB = -444.641, Loss = 443.135
[2018-06-05 00:41] Train Step 3675, Epoch 3.4, Batch Size = 256, Examples/Sec = 3793.32, Train LB = -441.771, Loss = 443.080
[2018-06-05 00:41] Train Step 3700, Epoch 3.4, Batch Size = 256, Examples/Sec = 3850.50, Train LB = -437.594, Loss = 442.436
[2018-06-05 00:41] Train Step 3725, Epoch 3.4, Batch Size = 256, Examples/Sec = 3796.19, Train LB = -443.654, Loss = 442.502
[2018-06-05 00:41] Train Step 3750, Epoch 3.5, Batch Size = 256, Examples/Sec = 3868.02, Train LB = -438.543, Loss = 442.361
[2018-06-05 00:41] Train Step 3775, Epoch 3.5, Batch Size = 256, Examples/Sec = 3846.26, Train LB = -442.514, Loss = 442.777
[2018-06-05 00:41] Train Step 3800, Epoch 3.5, Batch Size = 256, Examples/Sec = 3872.68, Train LB = -450.136, Loss = 442.803
Performance on test set:
  Test Lower Bound = -444.125, Test Loss = 444.125
[2018-06-05 00:41] Train Step 3825, Epoch 3.5, Batch Size = 256, Examples/Sec = 3805.10, Train LB = -430.294, Loss = 442.130
[2018-06-05 00:41] Train Step 3850, Epoch 3.6, Batch Size = 256, Examples/Sec = 3850.21, Train LB = -447.484, Loss = 442.014
[2018-06-05 00:41] Train Step 3875, Epoch 3.6, Batch Size = 256, Examples/Sec = 3896.26, Train LB = -447.903, Loss = 442.709
[2018-06-05 00:41] Train Step 3900, Epoch 3.6, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -429.445, Loss = 442.357
[2018-06-05 00:41] Train Step 3925, Epoch 3.6, Batch Size = 256, Examples/Sec = 3865.62, Train LB = -433.856, Loss = 441.660
[2018-06-05 00:41] Train Step 3950, Epoch 3.7, Batch Size = 256, Examples/Sec = 3869.54, Train LB = -439.357, Loss = 441.720
[2018-06-05 00:41] Train Step 3975, Epoch 3.7, Batch Size = 256, Examples/Sec = 3869.70, Train LB = -439.746, Loss = 441.146
[2018-06-05 00:41] Train Step 4000, Epoch 3.7, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -444.202, Loss = 441.316
Performance on test set:
  Test Lower Bound = -442.707, Test Loss = 442.707
[2018-06-05 00:41] Train Step 4025, Epoch 3.7, Batch Size = 256, Examples/Sec = 3877.54, Train LB = -444.231, Loss = 441.362
[2018-06-05 00:41] Train Step 4050, Epoch 3.8, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -440.757, Loss = 441.670
[2018-06-05 00:41] Train Step 4075, Epoch 3.8, Batch Size = 256, Examples/Sec = 3836.81, Train LB = -442.074, Loss = 441.327
[2018-06-05 00:41] Train Step 4100, Epoch 3.8, Batch Size = 256, Examples/Sec = 3873.63, Train LB = -431.534, Loss = 441.018
[2018-06-05 00:41] Train Step 4125, Epoch 3.8, Batch Size = 256, Examples/Sec = 3847.76, Train LB = -435.232, Loss = 441.116
[2018-06-05 00:41] Train Step 4150, Epoch 3.8, Batch Size = 256, Examples/Sec = 3849.81, Train LB = -434.759, Loss = 441.157
[2018-06-05 00:41] Train Step 4175, Epoch 3.9, Batch Size = 256, Examples/Sec = 3873.74, Train LB = -435.383, Loss = 441.063
[2018-06-05 00:41] Train Step 4200, Epoch 3.9, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -445.307, Loss = 441.272
Performance on test set:
  Test Lower Bound = -441.771, Test Loss = 441.771
[2018-06-05 00:41] Train Step 4225, Epoch 3.9, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -448.626, Loss = 441.508
[2018-06-05 00:42] Train Step 4250, Epoch 3.9, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -438.249, Loss = 441.426
[2018-06-05 00:42] Train Step 4275, Epoch 4.0, Batch Size = 256, Examples/Sec = 3505.94, Train LB = -449.877, Loss = 441.084
[2018-06-05 00:42] Train Step 4300, Epoch 4.0, Batch Size = 256, Examples/Sec = 3550.72, Train LB = -442.695, Loss = 440.817
[2018-06-05 00:42] Train Step 4325, Epoch 4.0, Batch Size = 256, Examples/Sec = 3501.10, Train LB = -456.177, Loss = 440.432
[2018-06-05 00:42] Train Step 4350, Epoch 4.0, Batch Size = 256, Examples/Sec = 3543.60, Train LB = -437.710, Loss = 440.243
[2018-06-05 00:42] Train Step 4375, Epoch 4.1, Batch Size = 256, Examples/Sec = 3583.93, Train LB = -442.868, Loss = 440.361
[2018-06-05 00:42] Train Step 4400, Epoch 4.1, Batch Size = 256, Examples/Sec = 3567.39, Train LB = -446.505, Loss = 440.590
Performance on test set:
  Test Lower Bound = -441.255, Test Loss = 441.255
[2018-06-05 00:42] Train Step 4425, Epoch 4.1, Batch Size = 256, Examples/Sec = 3853.79, Train LB = -443.262, Loss = 440.481
[2018-06-05 00:42] Train Step 4450, Epoch 4.1, Batch Size = 256, Examples/Sec = 3854.44, Train LB = -439.860, Loss = 440.110
[2018-06-05 00:42] Train Step 4475, Epoch 4.1, Batch Size = 256, Examples/Sec = 3867.71, Train LB = -436.071, Loss = 440.318
[2018-06-05 00:42] Train Step 4500, Epoch 4.2, Batch Size = 256, Examples/Sec = 3865.38, Train LB = -440.699, Loss = 440.594
[2018-06-05 00:42] Train Step 4525, Epoch 4.2, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -431.599, Loss = 440.339
[2018-06-05 00:42] Train Step 4550, Epoch 4.2, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -439.689, Loss = 439.702
[2018-06-05 00:42] Train Step 4575, Epoch 4.2, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -447.101, Loss = 439.675
[2018-06-05 00:42] Train Step 4600, Epoch 4.3, Batch Size = 256, Examples/Sec = 3878.73, Train LB = -444.629, Loss = 440.312
Performance on test set:
  Test Lower Bound = -441.927, Test Loss = 441.927
[2018-06-05 00:42] Train Step 4625, Epoch 4.3, Batch Size = 256, Examples/Sec = 3803.52, Train LB = -432.931, Loss = 439.953
[2018-06-05 00:42] Train Step 4650, Epoch 4.3, Batch Size = 256, Examples/Sec = 3886.57, Train LB = -436.010, Loss = 440.443
[2018-06-05 00:42] Train Step 4675, Epoch 4.3, Batch Size = 256, Examples/Sec = 3852.57, Train LB = -431.678, Loss = 440.208
[2018-06-05 00:42] Train Step 4700, Epoch 4.4, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -433.930, Loss = 440.578
[2018-06-05 00:42] Train Step 4725, Epoch 4.4, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -429.503, Loss = 440.133
[2018-06-05 00:42] Train Step 4750, Epoch 4.4, Batch Size = 256, Examples/Sec = 3848.58, Train LB = -440.400, Loss = 439.339
[2018-06-05 00:42] Train Step 4775, Epoch 4.4, Batch Size = 256, Examples/Sec = 3874.67, Train LB = -449.238, Loss = 439.487
[2018-06-05 00:42] Train Step 4800, Epoch 4.4, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -438.867, Loss = 440.215
Performance on test set:
  Test Lower Bound = -441.272, Test Loss = 441.272
[2018-06-05 00:42] Train Step 4825, Epoch 4.5, Batch Size = 256, Examples/Sec = 3865.62, Train LB = -437.727, Loss = 439.430
[2018-06-05 00:42] Train Step 4850, Epoch 4.5, Batch Size = 256, Examples/Sec = 3876.32, Train LB = -434.481, Loss = 439.735
[2018-06-05 00:42] Train Step 4875, Epoch 4.5, Batch Size = 256, Examples/Sec = 3858.40, Train LB = -429.451, Loss = 439.793
[2018-06-05 00:42] Train Step 4900, Epoch 4.5, Batch Size = 256, Examples/Sec = 3837.51, Train LB = -442.291, Loss = 440.088
[2018-06-05 00:42] Train Step 4925, Epoch 4.6, Batch Size = 256, Examples/Sec = 3843.66, Train LB = -429.384, Loss = 439.389
[2018-06-05 00:42] Train Step 4950, Epoch 4.6, Batch Size = 256, Examples/Sec = 3886.79, Train LB = -438.440, Loss = 439.423
[2018-06-05 00:42] Train Step 4975, Epoch 4.6, Batch Size = 256, Examples/Sec = 3791.51, Train LB = -444.974, Loss = 439.051
[2018-06-05 00:43] Train Step 5000, Epoch 4.6, Batch Size = 256, Examples/Sec = 3881.96, Train LB = -439.227, Loss = 439.338
Performance on test set:
  Test Lower Bound = -441.471, Test Loss = 441.471
[2018-06-05 00:43] Train Step 5025, Epoch 4.7, Batch Size = 256, Examples/Sec = 3875.32, Train LB = -430.433, Loss = 439.140
[2018-06-05 00:43] Train Step 5050, Epoch 4.7, Batch Size = 256, Examples/Sec = 3869.35, Train LB = -446.435, Loss = 438.941
[2018-06-05 00:43] Train Step 5075, Epoch 4.7, Batch Size = 256, Examples/Sec = 3870.51, Train LB = -443.510, Loss = 438.509
[2018-06-05 00:43] Train Step 5100, Epoch 4.7, Batch Size = 256, Examples/Sec = 3871.11, Train LB = -444.556, Loss = 438.141
[2018-06-05 00:43] Train Step 5125, Epoch 4.7, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -437.158, Loss = 438.214
[2018-06-05 00:43] Train Step 5150, Epoch 4.8, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -436.581, Loss = 438.684
[2018-06-05 00:43] Train Step 5175, Epoch 4.8, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -439.671, Loss = 438.877
[2018-06-05 00:43] Train Step 5200, Epoch 4.8, Batch Size = 256, Examples/Sec = 3875.26, Train LB = -459.557, Loss = 438.479
Performance on test set:
  Test Lower Bound = -440.667, Test Loss = 440.667
[2018-06-05 00:43] Train Step 5225, Epoch 4.8, Batch Size = 256, Examples/Sec = 3895.90, Train LB = -429.450, Loss = 437.797
[2018-06-05 00:43] Train Step 5250, Epoch 4.9, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -437.465, Loss = 438.339
[2018-06-05 00:43] Train Step 5275, Epoch 4.9, Batch Size = 256, Examples/Sec = 3851.93, Train LB = -433.230, Loss = 438.042
[2018-06-05 00:43] Train Step 5300, Epoch 4.9, Batch Size = 256, Examples/Sec = 3886.20, Train LB = -434.036, Loss = 438.005
[2018-06-05 00:43] Train Step 5325, Epoch 4.9, Batch Size = 256, Examples/Sec = 3872.05, Train LB = -431.066, Loss = 437.628
[2018-06-05 00:43] Train Step 5350, Epoch 5.0, Batch Size = 256, Examples/Sec = 3859.91, Train LB = -435.310, Loss = 437.688
[2018-06-05 00:43] Train Step 5375, Epoch 5.0, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -444.397, Loss = 437.521
[2018-06-05 00:43] Train Step 5400, Epoch 5.0, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -446.188, Loss = 437.708
Performance on test set:
  Test Lower Bound = -439.231, Test Loss = 439.231
[2018-06-05 00:43] Train Step 5425, Epoch 5.0, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -433.803, Loss = 437.467
[2018-06-05 00:43] Train Step 5450, Epoch 5.0, Batch Size = 256, Examples/Sec = 3864.74, Train LB = -443.204, Loss = 437.210
[2018-06-05 00:43] Train Step 5475, Epoch 5.1, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -443.377, Loss = 437.799
[2018-06-05 00:43] Train Step 5500, Epoch 5.1, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -427.268, Loss = 437.050
[2018-06-05 00:43] Train Step 5525, Epoch 5.1, Batch Size = 256, Examples/Sec = 3849.81, Train LB = -436.404, Loss = 437.040
[2018-06-05 00:43] Train Step 5550, Epoch 5.1, Batch Size = 256, Examples/Sec = 3877.96, Train LB = -430.981, Loss = 437.593
[2018-06-05 00:43] Train Step 5575, Epoch 5.2, Batch Size = 256, Examples/Sec = 3877.67, Train LB = -439.142, Loss = 436.948
[2018-06-05 00:43] Train Step 5600, Epoch 5.2, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -438.964, Loss = 437.128
Performance on test set:
  Test Lower Bound = -438.409, Test Loss = 438.409
[2018-06-05 00:43] Train Step 5625, Epoch 5.2, Batch Size = 256, Examples/Sec = 3869.88, Train LB = -438.687, Loss = 437.111
[2018-06-05 00:43] Train Step 5650, Epoch 5.2, Batch Size = 256, Examples/Sec = 3790.00, Train LB = -441.956, Loss = 436.725
[2018-06-05 00:44] Train Step 5675, Epoch 5.3, Batch Size = 256, Examples/Sec = 3878.27, Train LB = -434.196, Loss = 437.292
[2018-06-05 00:44] Train Step 5700, Epoch 5.3, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -429.068, Loss = 437.128
[2018-06-05 00:44] Train Step 5725, Epoch 5.3, Batch Size = 256, Examples/Sec = 3808.32, Train LB = -437.655, Loss = 436.775
[2018-06-05 00:44] Train Step 5750, Epoch 5.3, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -440.990, Loss = 435.967
[2018-06-05 00:44] Train Step 5775, Epoch 5.3, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -439.340, Loss = 436.260
[2018-06-05 00:44] Train Step 5800, Epoch 5.4, Batch Size = 256, Examples/Sec = 3851.08, Train LB = -438.108, Loss = 436.984
Performance on test set:
  Test Lower Bound = -438.433, Test Loss = 438.433
[2018-06-05 00:44] Train Step 5825, Epoch 5.4, Batch Size = 256, Examples/Sec = 3869.23, Train LB = -419.776, Loss = 436.794
[2018-06-05 00:44] Train Step 5850, Epoch 5.4, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -439.757, Loss = 436.784
[2018-06-05 00:44] Train Step 5875, Epoch 5.4, Batch Size = 256, Examples/Sec = 3793.55, Train LB = -445.133, Loss = 436.757
[2018-06-05 00:44] Train Step 5900, Epoch 5.5, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -428.285, Loss = 436.702
[2018-06-05 00:44] Train Step 5925, Epoch 5.5, Batch Size = 256, Examples/Sec = 3854.38, Train LB = -430.369, Loss = 436.155
[2018-06-05 00:44] Train Step 5950, Epoch 5.5, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -449.841, Loss = 435.927
[2018-06-05 00:44] Train Step 5975, Epoch 5.5, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -435.598, Loss = 436.001
[2018-06-05 00:44] Train Step 6000, Epoch 5.6, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -437.438, Loss = 436.133
Performance on test set:
  Test Lower Bound = -438.138, Test Loss = 438.138
[2018-06-05 00:44] Train Step 6025, Epoch 5.6, Batch Size = 256, Examples/Sec = 3878.44, Train LB = -436.155, Loss = 435.831
[2018-06-05 00:44] Train Step 6050, Epoch 5.6, Batch Size = 256, Examples/Sec = 3882.27, Train LB = -435.528, Loss = 435.663
[2018-06-05 00:44] Train Step 6075, Epoch 5.6, Batch Size = 256, Examples/Sec = 3865.72, Train LB = -444.608, Loss = 435.803
[2018-06-05 00:44] Train Step 6100, Epoch 5.6, Batch Size = 256, Examples/Sec = 3848.65, Train LB = -446.818, Loss = 435.705
[2018-06-05 00:44] Train Step 6125, Epoch 5.7, Batch Size = 256, Examples/Sec = 3869.59, Train LB = -440.458, Loss = 435.590
[2018-06-05 00:44] Train Step 6150, Epoch 5.7, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -430.322, Loss = 435.221
[2018-06-05 00:44] Train Step 6175, Epoch 5.7, Batch Size = 256, Examples/Sec = 3857.04, Train LB = -434.094, Loss = 435.055
[2018-06-05 00:44] Train Step 6200, Epoch 5.7, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -426.656, Loss = 435.560
Performance on test set:
  Test Lower Bound = -438.474, Test Loss = 438.474
[2018-06-05 00:44] Train Step 6225, Epoch 5.8, Batch Size = 256, Examples/Sec = 3877.26, Train LB = -433.231, Loss = 435.143
[2018-06-05 00:44] Train Step 6250, Epoch 5.8, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -438.778, Loss = 435.183
[2018-06-05 00:44] Train Step 6275, Epoch 5.8, Batch Size = 256, Examples/Sec = 3800.69, Train LB = -442.957, Loss = 434.928
[2018-06-05 00:44] Train Step 6300, Epoch 5.8, Batch Size = 256, Examples/Sec = 3871.63, Train LB = -429.040, Loss = 434.842
[2018-06-05 00:44] Train Step 6325, Epoch 5.9, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -446.957, Loss = 434.593
[2018-06-05 00:44] Train Step 6350, Epoch 5.9, Batch Size = 256, Examples/Sec = 3803.58, Train LB = -437.725, Loss = 434.735
[2018-06-05 00:44] Train Step 6375, Epoch 5.9, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -424.917, Loss = 434.869
[2018-06-05 00:44] Train Step 6400, Epoch 5.9, Batch Size = 256, Examples/Sec = 3855.36, Train LB = -441.096, Loss = 435.227
Performance on test set:
  Test Lower Bound = -437.823, Test Loss = 437.823
[2018-06-05 00:45] Train Step 6425, Epoch 5.9, Batch Size = 256, Examples/Sec = 3866.90, Train LB = -428.629, Loss = 434.798
[2018-06-05 00:45] Train Step 6450, Epoch 6.0, Batch Size = 256, Examples/Sec = 3791.69, Train LB = -450.045, Loss = 435.272
[2018-06-05 00:45] Train Step 6475, Epoch 6.0, Batch Size = 256, Examples/Sec = 3874.03, Train LB = -440.241, Loss = 435.372
[2018-06-05 00:45] Train Step 6500, Epoch 6.0, Batch Size = 256, Examples/Sec = 3846.21, Train LB = -434.526, Loss = 435.149
[2018-06-05 00:45] Train Step 6525, Epoch 6.0, Batch Size = 256, Examples/Sec = 3848.76, Train LB = -434.388, Loss = 435.089
[2018-06-05 00:45] Train Step 6550, Epoch 6.1, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -424.895, Loss = 434.878
[2018-06-05 00:45] Train Step 6575, Epoch 6.1, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -450.943, Loss = 434.905
[2018-06-05 00:45] Train Step 6600, Epoch 6.1, Batch Size = 256, Examples/Sec = 3831.59, Train LB = -441.645, Loss = 435.594
Performance on test set:
  Test Lower Bound = -436.565, Test Loss = 436.565
[2018-06-05 00:45] Train Step 6625, Epoch 6.1, Batch Size = 256, Examples/Sec = 3852.17, Train LB = -435.948, Loss = 434.954
[2018-06-05 00:45] Train Step 6650, Epoch 6.2, Batch Size = 256, Examples/Sec = 3870.99, Train LB = -436.437, Loss = 435.240
[2018-06-05 00:45] Train Step 6675, Epoch 6.2, Batch Size = 256, Examples/Sec = 3846.61, Train LB = -422.337, Loss = 435.008
[2018-06-05 00:45] Train Step 6700, Epoch 6.2, Batch Size = 256, Examples/Sec = 3876.67, Train LB = -427.860, Loss = 434.041
[2018-06-05 00:45] Train Step 6725, Epoch 6.2, Batch Size = 256, Examples/Sec = 3871.33, Train LB = -432.814, Loss = 434.019
[2018-06-05 00:45] Train Step 6750, Epoch 6.2, Batch Size = 256, Examples/Sec = 3873.33, Train LB = -421.551, Loss = 434.013
[2018-06-05 00:45] Train Step 6775, Epoch 6.3, Batch Size = 256, Examples/Sec = 3872.80, Train LB = -434.178, Loss = 434.468
[2018-06-05 00:45] Train Step 6800, Epoch 6.3, Batch Size = 256, Examples/Sec = 3876.44, Train LB = -431.502, Loss = 434.300
Performance on test set:
  Test Lower Bound = -435.778, Test Loss = 435.778
[2018-06-05 00:45] Train Step 6825, Epoch 6.3, Batch Size = 256, Examples/Sec = 3807.43, Train LB = -444.493, Loss = 434.061
[2018-06-05 00:45] Train Step 6850, Epoch 6.3, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -435.960, Loss = 434.059
[2018-06-05 00:45] Train Step 6875, Epoch 6.4, Batch Size = 256, Examples/Sec = 3867.07, Train LB = -424.474, Loss = 434.806
[2018-06-05 00:45] Train Step 6900, Epoch 6.4, Batch Size = 256, Examples/Sec = 3854.96, Train LB = -445.926, Loss = 434.561
[2018-06-05 00:45] Train Step 6925, Epoch 6.4, Batch Size = 256, Examples/Sec = 3834.46, Train LB = -433.198, Loss = 433.993
[2018-06-05 00:45] Train Step 6950, Epoch 6.4, Batch Size = 256, Examples/Sec = 3853.09, Train LB = -432.025, Loss = 433.534
[2018-06-05 00:45] Train Step 6975, Epoch 6.5, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -438.425, Loss = 433.412
[2018-06-05 00:45] Train Step 7000, Epoch 6.5, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -430.852, Loss = 434.195
Performance on test set:
  Test Lower Bound = -437.074, Test Loss = 437.074
[2018-06-05 00:45] Train Step 7025, Epoch 6.5, Batch Size = 256, Examples/Sec = 3806.30, Train LB = -429.143, Loss = 434.652
[2018-06-05 00:45] Train Step 7050, Epoch 6.5, Batch Size = 256, Examples/Sec = 3885.26, Train LB = -424.184, Loss = 434.444
[2018-06-05 00:45] Train Step 7075, Epoch 6.6, Batch Size = 256, Examples/Sec = 3854.95, Train LB = -442.053, Loss = 434.068
[2018-06-05 00:45] Train Step 7100, Epoch 6.6, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -430.723, Loss = 433.548
[2018-06-05 00:46] Train Step 7125, Epoch 6.6, Batch Size = 256, Examples/Sec = 3886.22, Train LB = -428.567, Loss = 433.427
[2018-06-05 00:46] Train Step 7150, Epoch 6.6, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -442.014, Loss = 433.723
[2018-06-05 00:46] Train Step 7175, Epoch 6.6, Batch Size = 256, Examples/Sec = 3859.67, Train LB = -440.756, Loss = 433.805
[2018-06-05 00:46] Train Step 7200, Epoch 6.7, Batch Size = 256, Examples/Sec = 3844.20, Train LB = -444.821, Loss = 434.119
Performance on test set:
  Test Lower Bound = -436.877, Test Loss = 436.877
[2018-06-05 00:46] Train Step 7225, Epoch 6.7, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -421.825, Loss = 433.675
[2018-06-05 00:46] Train Step 7250, Epoch 6.7, Batch Size = 256, Examples/Sec = 3856.40, Train LB = -427.496, Loss = 433.489
[2018-06-05 00:46] Train Step 7275, Epoch 6.7, Batch Size = 256, Examples/Sec = 3766.26, Train LB = -425.645, Loss = 433.720
[2018-06-05 00:46] Train Step 7300, Epoch 6.8, Batch Size = 256, Examples/Sec = 3869.58, Train LB = -420.900, Loss = 433.638
[2018-06-05 00:46] Train Step 7325, Epoch 6.8, Batch Size = 256, Examples/Sec = 3858.49, Train LB = -433.216, Loss = 432.967
[2018-06-05 00:46] Train Step 7350, Epoch 6.8, Batch Size = 256, Examples/Sec = 3841.13, Train LB = -430.058, Loss = 432.808
[2018-06-05 00:46] Train Step 7375, Epoch 6.8, Batch Size = 256, Examples/Sec = 3873.56, Train LB = -445.271, Loss = 433.079
[2018-06-05 00:46] Train Step 7400, Epoch 6.9, Batch Size = 256, Examples/Sec = 3857.87, Train LB = -430.536, Loss = 433.533
Performance on test set:
  Test Lower Bound = -436.671, Test Loss = 436.671
[2018-06-05 00:46] Train Step 7425, Epoch 6.9, Batch Size = 256, Examples/Sec = 3872.75, Train LB = -437.459, Loss = 433.648
[2018-06-05 00:46] Train Step 7450, Epoch 6.9, Batch Size = 256, Examples/Sec = 3795.74, Train LB = -431.463, Loss = 433.386
[2018-06-05 00:46] Train Step 7475, Epoch 6.9, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -430.031, Loss = 433.026
[2018-06-05 00:46] Train Step 7500, Epoch 6.9, Batch Size = 256, Examples/Sec = 3845.59, Train LB = -435.337, Loss = 432.764
[2018-06-05 00:46] Train Step 7525, Epoch 7.0, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -424.246, Loss = 433.051
[2018-06-05 00:46] Train Step 7550, Epoch 7.0, Batch Size = 256, Examples/Sec = 3802.73, Train LB = -438.709, Loss = 433.160
[2018-06-05 00:46] Train Step 7575, Epoch 7.0, Batch Size = 256, Examples/Sec = 3860.01, Train LB = -434.576, Loss = 433.318
[2018-06-05 00:46] Train Step 7600, Epoch 7.0, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -434.657, Loss = 433.181
Performance on test set:
  Test Lower Bound = -434.906, Test Loss = 434.906
[2018-06-05 00:46] Train Step 7625, Epoch 7.1, Batch Size = 256, Examples/Sec = 3887.33, Train LB = -426.080, Loss = 432.738
[2018-06-05 00:46] Train Step 7650, Epoch 7.1, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -425.866, Loss = 433.252
[2018-06-05 00:46] Train Step 7675, Epoch 7.1, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -430.248, Loss = 432.941
[2018-06-05 00:46] Train Step 7700, Epoch 7.1, Batch Size = 256, Examples/Sec = 3864.20, Train LB = -437.913, Loss = 432.828
[2018-06-05 00:46] Train Step 7725, Epoch 7.2, Batch Size = 256, Examples/Sec = 3861.41, Train LB = -430.956, Loss = 433.062
[2018-06-05 00:46] Train Step 7750, Epoch 7.2, Batch Size = 256, Examples/Sec = 3854.95, Train LB = -423.075, Loss = 432.589
[2018-06-05 00:46] Train Step 7775, Epoch 7.2, Batch Size = 256, Examples/Sec = 3846.91, Train LB = -431.088, Loss = 432.819
[2018-06-05 00:46] Train Step 7800, Epoch 7.2, Batch Size = 256, Examples/Sec = 3862.17, Train LB = -433.762, Loss = 433.402
Performance on test set:
  Test Lower Bound = -435.340, Test Loss = 435.340
[2018-06-05 00:47] Train Step 7825, Epoch 7.2, Batch Size = 256, Examples/Sec = 3853.73, Train LB = -428.572, Loss = 433.490
[2018-06-05 00:47] Train Step 7850, Epoch 7.3, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -421.544, Loss = 432.702
[2018-06-05 00:47] Train Step 7875, Epoch 7.3, Batch Size = 256, Examples/Sec = 3842.11, Train LB = -437.754, Loss = 432.450
[2018-06-05 00:47] Train Step 7900, Epoch 7.3, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -439.354, Loss = 432.457
[2018-06-05 00:47] Train Step 7925, Epoch 7.3, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -431.332, Loss = 432.139
[2018-06-05 00:47] Train Step 7950, Epoch 7.4, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -435.480, Loss = 431.706
[2018-06-05 00:47] Train Step 7975, Epoch 7.4, Batch Size = 256, Examples/Sec = 3848.18, Train LB = -434.215, Loss = 432.164
[2018-06-05 00:47] Train Step 8000, Epoch 7.4, Batch Size = 256, Examples/Sec = 3868.41, Train LB = -437.181, Loss = 432.917
Performance on test set:
  Test Lower Bound = -434.992, Test Loss = 434.992
[2018-06-05 00:47] Train Step 8025, Epoch 7.4, Batch Size = 256, Examples/Sec = 3855.42, Train LB = -438.241, Loss = 432.619
[2018-06-05 00:47] Train Step 8050, Epoch 7.5, Batch Size = 256, Examples/Sec = 3876.55, Train LB = -434.771, Loss = 432.702
[2018-06-05 00:47] Train Step 8075, Epoch 7.5, Batch Size = 256, Examples/Sec = 3860.20, Train LB = -436.396, Loss = 432.428
[2018-06-05 00:47] Train Step 8100, Epoch 7.5, Batch Size = 256, Examples/Sec = 3889.57, Train LB = -425.196, Loss = 432.287
[2018-06-05 00:47] Train Step 8125, Epoch 7.5, Batch Size = 256, Examples/Sec = 3859.78, Train LB = -429.178, Loss = 431.724
[2018-06-05 00:47] Train Step 8150, Epoch 7.5, Batch Size = 256, Examples/Sec = 3802.90, Train LB = -436.716, Loss = 431.799
[2018-06-05 00:47] Train Step 8175, Epoch 7.6, Batch Size = 256, Examples/Sec = 3878.26, Train LB = -422.513, Loss = 431.423
[2018-06-05 00:47] Train Step 8200, Epoch 7.6, Batch Size = 256, Examples/Sec = 3865.33, Train LB = -444.366, Loss = 431.498
Performance on test set:
  Test Lower Bound = -434.297, Test Loss = 434.297
[2018-06-05 00:47] Train Step 8225, Epoch 7.6, Batch Size = 256, Examples/Sec = 3815.82, Train LB = -431.860, Loss = 431.684
[2018-06-05 00:47] Train Step 8250, Epoch 7.6, Batch Size = 256, Examples/Sec = 3799.46, Train LB = -428.718, Loss = 431.546
[2018-06-05 00:47] Train Step 8275, Epoch 7.7, Batch Size = 256, Examples/Sec = 3506.18, Train LB = -430.779, Loss = 432.106
[2018-06-05 00:47] Train Step 8300, Epoch 7.7, Batch Size = 256, Examples/Sec = 3588.30, Train LB = -419.747, Loss = 431.447
[2018-06-05 00:47] Train Step 8325, Epoch 7.7, Batch Size = 256, Examples/Sec = 3589.15, Train LB = -425.512, Loss = 431.624
[2018-06-05 00:47] Train Step 8350, Epoch 7.7, Batch Size = 256, Examples/Sec = 3527.62, Train LB = -430.010, Loss = 431.120
[2018-06-05 00:47] Train Step 8375, Epoch 7.8, Batch Size = 256, Examples/Sec = 3523.50, Train LB = -426.584, Loss = 430.994
[2018-06-05 00:47] Train Step 8400, Epoch 7.8, Batch Size = 256, Examples/Sec = 3539.43, Train LB = -428.621, Loss = 431.891
Performance on test set:
  Test Lower Bound = -433.491, Test Loss = 433.491
[2018-06-05 00:47] Train Step 8425, Epoch 7.8, Batch Size = 256, Examples/Sec = 3857.86, Train LB = -440.714, Loss = 431.584
[2018-06-05 00:47] Train Step 8450, Epoch 7.8, Batch Size = 256, Examples/Sec = 3842.99, Train LB = -423.990, Loss = 431.242
[2018-06-05 00:47] Train Step 8475, Epoch 7.8, Batch Size = 256, Examples/Sec = 3848.23, Train LB = -436.797, Loss = 430.990
[2018-06-05 00:47] Train Step 8500, Epoch 7.9, Batch Size = 256, Examples/Sec = 3868.48, Train LB = -432.977, Loss = 430.909
[2018-06-05 00:48] Train Step 8525, Epoch 7.9, Batch Size = 256, Examples/Sec = 3885.15, Train LB = -437.371, Loss = 431.014
[2018-06-05 00:48] Train Step 8550, Epoch 7.9, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -430.948, Loss = 431.027
[2018-06-05 00:48] Train Step 8575, Epoch 7.9, Batch Size = 256, Examples/Sec = 3819.08, Train LB = -435.292, Loss = 432.120
[2018-06-05 00:48] Train Step 8600, Epoch 8.0, Batch Size = 256, Examples/Sec = 3817.02, Train LB = -420.028, Loss = 431.811
Performance on test set:
  Test Lower Bound = -433.734, Test Loss = 433.734
[2018-06-05 00:48] Train Step 8625, Epoch 8.0, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -428.819, Loss = 431.551
[2018-06-05 00:48] Train Step 8650, Epoch 8.0, Batch Size = 256, Examples/Sec = 3856.11, Train LB = -430.681, Loss = 430.753
[2018-06-05 00:48] Train Step 8675, Epoch 8.0, Batch Size = 256, Examples/Sec = 3814.41, Train LB = -438.539, Loss = 431.106
[2018-06-05 00:48] Train Step 8700, Epoch 8.1, Batch Size = 256, Examples/Sec = 3880.13, Train LB = -433.410, Loss = 430.993
[2018-06-05 00:48] Train Step 8725, Epoch 8.1, Batch Size = 256, Examples/Sec = 3883.14, Train LB = -421.581, Loss = 430.753
[2018-06-05 00:48] Train Step 8750, Epoch 8.1, Batch Size = 256, Examples/Sec = 3859.42, Train LB = -428.737, Loss = 430.420
[2018-06-05 00:48] Train Step 8775, Epoch 8.1, Batch Size = 256, Examples/Sec = 3870.23, Train LB = -427.654, Loss = 430.725
[2018-06-05 00:48] Train Step 8800, Epoch 8.1, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -433.097, Loss = 431.492
Performance on test set:
  Test Lower Bound = -434.732, Test Loss = 434.732
[2018-06-05 00:48] Train Step 8825, Epoch 8.2, Batch Size = 256, Examples/Sec = 3844.77, Train LB = -421.543, Loss = 431.027
[2018-06-05 00:48] Train Step 8850, Epoch 8.2, Batch Size = 256, Examples/Sec = 3884.74, Train LB = -437.659, Loss = 431.171
[2018-06-05 00:48] Train Step 8875, Epoch 8.2, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -436.160, Loss = 431.383
[2018-06-05 00:48] Train Step 8900, Epoch 8.2, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -414.412, Loss = 431.151
[2018-06-05 00:48] Train Step 8925, Epoch 8.3, Batch Size = 256, Examples/Sec = 3792.02, Train LB = -447.210, Loss = 430.574
[2018-06-05 00:48] Train Step 8950, Epoch 8.3, Batch Size = 256, Examples/Sec = 3845.59, Train LB = -447.615, Loss = 430.337
[2018-06-05 00:48] Train Step 8975, Epoch 8.3, Batch Size = 256, Examples/Sec = 3830.05, Train LB = -430.392, Loss = 430.360
[2018-06-05 00:48] Train Step 9000, Epoch 8.3, Batch Size = 256, Examples/Sec = 3767.42, Train LB = -450.940, Loss = 431.000
Performance on test set:
  Test Lower Bound = -434.070, Test Loss = 434.070
[2018-06-05 00:48] Train Step 9025, Epoch 8.4, Batch Size = 256, Examples/Sec = 3882.79, Train LB = -424.344, Loss = 430.384
[2018-06-05 00:48] Train Step 9050, Epoch 8.4, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -437.155, Loss = 430.770
[2018-06-05 00:48] Train Step 9075, Epoch 8.4, Batch Size = 256, Examples/Sec = 3860.84, Train LB = -436.979, Loss = 430.880
[2018-06-05 00:48] Train Step 9100, Epoch 8.4, Batch Size = 256, Examples/Sec = 3869.87, Train LB = -414.025, Loss = 430.444
[2018-06-05 00:48] Train Step 9125, Epoch 8.4, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -424.213, Loss = 430.665
[2018-06-05 00:48] Train Step 9150, Epoch 8.5, Batch Size = 256, Examples/Sec = 3875.61, Train LB = -433.968, Loss = 430.144
[2018-06-05 00:48] Train Step 9175, Epoch 8.5, Batch Size = 256, Examples/Sec = 3879.49, Train LB = -422.887, Loss = 430.637
[2018-06-05 00:48] Train Step 9200, Epoch 8.5, Batch Size = 256, Examples/Sec = 3874.09, Train LB = -437.786, Loss = 430.637
Performance on test set:
  Test Lower Bound = -434.162, Test Loss = 434.162
[2018-06-05 00:49] Train Step 9225, Epoch 8.5, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -426.295, Loss = 430.794
[2018-06-05 00:49] Train Step 9250, Epoch 8.6, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -436.337, Loss = 430.309
[2018-06-05 00:49] Train Step 9275, Epoch 8.6, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -425.298, Loss = 430.188
[2018-06-05 00:49] Train Step 9300, Epoch 8.6, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -421.641, Loss = 429.885
[2018-06-05 00:49] Train Step 9325, Epoch 8.6, Batch Size = 256, Examples/Sec = 3864.49, Train LB = -431.667, Loss = 429.792
[2018-06-05 00:49] Train Step 9350, Epoch 8.7, Batch Size = 256, Examples/Sec = 3860.84, Train LB = -435.107, Loss = 429.846
[2018-06-05 00:49] Train Step 9375, Epoch 8.7, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -436.289, Loss = 430.071
[2018-06-05 00:49] Train Step 9400, Epoch 8.7, Batch Size = 256, Examples/Sec = 3864.22, Train LB = -439.663, Loss = 429.976
Performance on test set:
  Test Lower Bound = -434.515, Test Loss = 434.515
[2018-06-05 00:49] Train Step 9425, Epoch 8.7, Batch Size = 256, Examples/Sec = 3855.54, Train LB = -439.238, Loss = 429.867
[2018-06-05 00:49] Train Step 9450, Epoch 8.8, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -441.512, Loss = 430.018
[2018-06-05 00:49] Train Step 9475, Epoch 8.8, Batch Size = 256, Examples/Sec = 3807.76, Train LB = -439.721, Loss = 430.314
[2018-06-05 00:49] Train Step 9500, Epoch 8.8, Batch Size = 256, Examples/Sec = 3800.30, Train LB = -430.067, Loss = 429.578
[2018-06-05 00:49] Train Step 9525, Epoch 8.8, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -423.704, Loss = 429.320
[2018-06-05 00:49] Train Step 9550, Epoch 8.8, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -431.445, Loss = 429.324
[2018-06-05 00:49] Train Step 9575, Epoch 8.9, Batch Size = 256, Examples/Sec = 3856.42, Train LB = -430.396, Loss = 429.354
[2018-06-05 00:49] Train Step 9600, Epoch 8.9, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -439.546, Loss = 430.075
Performance on test set:
  Test Lower Bound = -432.927, Test Loss = 432.927
[2018-06-05 00:49] Train Step 9625, Epoch 8.9, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -432.478, Loss = 429.094
[2018-06-05 00:49] Train Step 9650, Epoch 8.9, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -437.916, Loss = 429.653
[2018-06-05 00:49] Train Step 9675, Epoch 9.0, Batch Size = 256, Examples/Sec = 3845.74, Train LB = -440.859, Loss = 429.922
[2018-06-05 00:49] Train Step 9700, Epoch 9.0, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -423.272, Loss = 429.606
[2018-06-05 00:49] Train Step 9725, Epoch 9.0, Batch Size = 256, Examples/Sec = 3865.44, Train LB = -428.295, Loss = 429.385
[2018-06-05 00:49] Train Step 9750, Epoch 9.0, Batch Size = 256, Examples/Sec = 3878.73, Train LB = -437.951, Loss = 430.109
[2018-06-05 00:49] Train Step 9775, Epoch 9.1, Batch Size = 256, Examples/Sec = 3878.84, Train LB = -432.550, Loss = 430.219
[2018-06-05 00:49] Train Step 9800, Epoch 9.1, Batch Size = 256, Examples/Sec = 3876.25, Train LB = -425.679, Loss = 430.255
Performance on test set:
  Test Lower Bound = -433.803, Test Loss = 433.803
[2018-06-05 00:49] Train Step 9825, Epoch 9.1, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -432.281, Loss = 429.788
[2018-06-05 00:49] Train Step 9850, Epoch 9.1, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -436.200, Loss = 429.715
[2018-06-05 00:49] Train Step 9875, Epoch 9.1, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -433.928, Loss = 429.491
[2018-06-05 00:49] Train Step 9900, Epoch 9.2, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -432.049, Loss = 429.677
[2018-06-05 00:49] Train Step 9925, Epoch 9.2, Batch Size = 256, Examples/Sec = 3863.85, Train LB = -423.354, Loss = 429.294
[2018-06-05 00:49] Train Step 9950, Epoch 9.2, Batch Size = 256, Examples/Sec = 3814.57, Train LB = -435.077, Loss = 429.099
[2018-06-05 00:50] Train Step 9975, Epoch 9.2, Batch Size = 256, Examples/Sec = 3875.37, Train LB = -442.740, Loss = 429.546
[2018-06-05 00:50] Train Step 10000, Epoch 9.3, Batch Size = 256, Examples/Sec = 3830.78, Train LB = -432.553, Loss = 429.835
Performance on test set:
  Test Lower Bound = -432.959, Test Loss = 432.959
[2018-06-05 00:50] Train Step 10025, Epoch 9.3, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -424.793, Loss = 429.556
[2018-06-05 00:50] Train Step 10050, Epoch 9.3, Batch Size = 256, Examples/Sec = 3820.56, Train LB = -427.316, Loss = 429.490
[2018-06-05 00:50] Train Step 10075, Epoch 9.3, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -438.111, Loss = 429.695
[2018-06-05 00:50] Train Step 10100, Epoch 9.4, Batch Size = 256, Examples/Sec = 3817.36, Train LB = -421.325, Loss = 429.125
[2018-06-05 00:50] Train Step 10125, Epoch 9.4, Batch Size = 256, Examples/Sec = 3848.87, Train LB = -422.787, Loss = 429.309
[2018-06-05 00:50] Train Step 10150, Epoch 9.4, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -414.617, Loss = 429.323
[2018-06-05 00:50] Train Step 10175, Epoch 9.4, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -432.101, Loss = 429.417
[2018-06-05 00:50] Train Step 10200, Epoch 9.4, Batch Size = 256, Examples/Sec = 3858.49, Train LB = -431.110, Loss = 429.170
Performance on test set:
  Test Lower Bound = -433.478, Test Loss = 433.478
[2018-06-05 00:50] Train Step 10225, Epoch 9.5, Batch Size = 256, Examples/Sec = 3852.47, Train LB = -424.735, Loss = 428.925
[2018-06-05 00:50] Train Step 10250, Epoch 9.5, Batch Size = 256, Examples/Sec = 3861.30, Train LB = -435.040, Loss = 429.198
[2018-06-05 00:50] Train Step 10275, Epoch 9.5, Batch Size = 256, Examples/Sec = 3879.31, Train LB = -435.266, Loss = 429.186
[2018-06-05 00:50] Train Step 10300, Epoch 9.5, Batch Size = 256, Examples/Sec = 3877.85, Train LB = -422.568, Loss = 429.405
[2018-06-05 00:50] Train Step 10325, Epoch 9.6, Batch Size = 256, Examples/Sec = 3816.34, Train LB = -429.095, Loss = 429.111
[2018-06-05 00:50] Train Step 10350, Epoch 9.6, Batch Size = 256, Examples/Sec = 3849.92, Train LB = -431.374, Loss = 428.491
[2018-06-05 00:50] Train Step 10375, Epoch 9.6, Batch Size = 256, Examples/Sec = 3859.66, Train LB = -430.468, Loss = 428.997
[2018-06-05 00:50] Train Step 10400, Epoch 9.6, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -431.827, Loss = 429.378
Performance on test set:
  Test Lower Bound = -432.620, Test Loss = 432.620
[2018-06-05 00:50] Train Step 10425, Epoch 9.7, Batch Size = 256, Examples/Sec = 3840.91, Train LB = -437.733, Loss = 428.940
[2018-06-05 00:50] Train Step 10450, Epoch 9.7, Batch Size = 256, Examples/Sec = 3880.54, Train LB = -419.362, Loss = 428.862
[2018-06-05 00:50] Train Step 10475, Epoch 9.7, Batch Size = 256, Examples/Sec = 3872.51, Train LB = -438.850, Loss = 428.765
[2018-06-05 00:50] Train Step 10500, Epoch 9.7, Batch Size = 256, Examples/Sec = 3880.32, Train LB = -429.876, Loss = 428.852
[2018-06-05 00:50] Train Step 10525, Epoch 9.7, Batch Size = 256, Examples/Sec = 3825.12, Train LB = -431.559, Loss = 428.640
[2018-06-05 00:50] Train Step 10550, Epoch 9.8, Batch Size = 256, Examples/Sec = 3876.49, Train LB = -438.432, Loss = 428.629
[2018-06-05 00:50] Train Step 10575, Epoch 9.8, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -416.873, Loss = 429.043
[2018-06-05 00:50] Train Step 10600, Epoch 9.8, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -438.910, Loss = 429.597
Performance on test set:
  Test Lower Bound = -434.580, Test Loss = 434.580
[2018-06-05 00:50] Train Step 10625, Epoch 9.8, Batch Size = 256, Examples/Sec = 3808.39, Train LB = -432.254, Loss = 429.135
[2018-06-05 00:50] Train Step 10650, Epoch 9.9, Batch Size = 256, Examples/Sec = 3828.72, Train LB = -434.473, Loss = 429.543
[2018-06-05 00:51] Train Step 10675, Epoch 9.9, Batch Size = 256, Examples/Sec = 3880.56, Train LB = -433.461, Loss = 429.926
[2018-06-05 00:51] Train Step 10700, Epoch 9.9, Batch Size = 256, Examples/Sec = 3859.96, Train LB = -443.164, Loss = 429.418
[2018-06-05 00:51] Train Step 10725, Epoch 9.9, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -441.428, Loss = 429.116
[2018-06-05 00:51] Train Step 10750, Epoch 10.0, Batch Size = 256, Examples/Sec = 3873.51, Train LB = -418.807, Loss = 428.944
[2018-06-05 00:51] Train Step 10775, Epoch 10.0, Batch Size = 256, Examples/Sec = 3871.92, Train LB = -433.144, Loss = 428.961
[2018-06-05 00:51] Train Step 10800, Epoch 10.0, Batch Size = 256, Examples/Sec = 3840.66, Train LB = -431.932, Loss = 429.465
Performance on test set:
  Test Lower Bound = -434.047, Test Loss = 434.047
[2018-06-05 00:51] Train Step 10825, Epoch 10.0, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -427.196, Loss = 428.890
[2018-06-05 00:51] Train Step 10850, Epoch 10.0, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -420.263, Loss = 428.523
[2018-06-05 00:51] Train Step 10875, Epoch 10.1, Batch Size = 256, Examples/Sec = 3837.90, Train LB = -418.532, Loss = 428.304
[2018-06-05 00:51] Train Step 10900, Epoch 10.1, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -435.774, Loss = 428.536
[2018-06-05 00:51] Train Step 10925, Epoch 10.1, Batch Size = 256, Examples/Sec = 3858.62, Train LB = -419.848, Loss = 428.415
[2018-06-05 00:51] Train Step 10950, Epoch 10.1, Batch Size = 256, Examples/Sec = 3877.08, Train LB = -422.865, Loss = 428.126
[2018-06-05 00:51] Train Step 10975, Epoch 10.2, Batch Size = 256, Examples/Sec = 3881.27, Train LB = -426.704, Loss = 428.121
[2018-06-05 00:51] Train Step 11000, Epoch 10.2, Batch Size = 256, Examples/Sec = 3855.49, Train LB = -436.793, Loss = 428.618
Performance on test set:
  Test Lower Bound = -433.152, Test Loss = 433.152
[2018-06-05 00:51] Train Step 11025, Epoch 10.2, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -423.975, Loss = 428.305
[2018-06-05 00:51] Train Step 11050, Epoch 10.2, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -426.376, Loss = 428.369
[2018-06-05 00:51] Train Step 11075, Epoch 10.3, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -425.406, Loss = 428.224
[2018-06-05 00:51] Train Step 11100, Epoch 10.3, Batch Size = 256, Examples/Sec = 3813.60, Train LB = -430.195, Loss = 428.313
[2018-06-05 00:51] Train Step 11125, Epoch 10.3, Batch Size = 256, Examples/Sec = 3836.53, Train LB = -425.079, Loss = 428.097
[2018-06-05 00:51] Train Step 11150, Epoch 10.3, Batch Size = 256, Examples/Sec = 3799.40, Train LB = -430.599, Loss = 428.255
[2018-06-05 00:51] Train Step 11175, Epoch 10.3, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -440.022, Loss = 428.104
[2018-06-05 00:51] Train Step 11200, Epoch 10.4, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -431.799, Loss = 428.852
Performance on test set:
  Test Lower Bound = -432.387, Test Loss = 432.387
[2018-06-05 00:51] Train Step 11225, Epoch 10.4, Batch Size = 256, Examples/Sec = 3870.00, Train LB = -418.266, Loss = 428.287
[2018-06-05 00:51] Train Step 11250, Epoch 10.4, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -441.773, Loss = 428.076
[2018-06-05 00:51] Train Step 11275, Epoch 10.4, Batch Size = 256, Examples/Sec = 3806.52, Train LB = -427.223, Loss = 428.040
[2018-06-05 00:51] Train Step 11300, Epoch 10.5, Batch Size = 256, Examples/Sec = 3852.58, Train LB = -427.786, Loss = 427.576
[2018-06-05 00:51] Train Step 11325, Epoch 10.5, Batch Size = 256, Examples/Sec = 3871.63, Train LB = -420.095, Loss = 427.491
[2018-06-05 00:51] Train Step 11350, Epoch 10.5, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -434.174, Loss = 427.930
[2018-06-05 00:51] Train Step 11375, Epoch 10.5, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -435.834, Loss = 427.259
[2018-06-05 00:52] Train Step 11400, Epoch 10.6, Batch Size = 256, Examples/Sec = 3735.65, Train LB = -423.307, Loss = 427.906
Performance on test set:
  Test Lower Bound = -432.776, Test Loss = 432.776
[2018-06-05 00:52] Train Step 11425, Epoch 10.6, Batch Size = 256, Examples/Sec = 3861.17, Train LB = -420.226, Loss = 427.475
[2018-06-05 00:52] Train Step 11450, Epoch 10.6, Batch Size = 256, Examples/Sec = 3872.73, Train LB = -425.565, Loss = 427.280
[2018-06-05 00:52] Train Step 11475, Epoch 10.6, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -423.323, Loss = 427.160
[2018-06-05 00:52] Train Step 11500, Epoch 10.6, Batch Size = 256, Examples/Sec = 3857.69, Train LB = -428.251, Loss = 426.780
[2018-06-05 00:52] Train Step 11525, Epoch 10.7, Batch Size = 256, Examples/Sec = 3872.58, Train LB = -423.067, Loss = 426.922
[2018-06-05 00:52] Train Step 11550, Epoch 10.7, Batch Size = 256, Examples/Sec = 3859.20, Train LB = -412.962, Loss = 427.126
[2018-06-05 00:52] Train Step 11575, Epoch 10.7, Batch Size = 256, Examples/Sec = 3816.57, Train LB = -428.930, Loss = 427.066
[2018-06-05 00:52] Train Step 11600, Epoch 10.7, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -430.800, Loss = 427.594
Performance on test set:
  Test Lower Bound = -431.838, Test Loss = 431.838
[2018-06-05 00:52] Train Step 11625, Epoch 10.8, Batch Size = 256, Examples/Sec = 3857.69, Train LB = -437.037, Loss = 426.911
[2018-06-05 00:52] Train Step 11650, Epoch 10.8, Batch Size = 256, Examples/Sec = 3858.73, Train LB = -438.990, Loss = 427.078
[2018-06-05 00:52] Train Step 11675, Epoch 10.8, Batch Size = 256, Examples/Sec = 3815.14, Train LB = -434.697, Loss = 427.037
[2018-06-05 00:52] Train Step 11700, Epoch 10.8, Batch Size = 256, Examples/Sec = 3856.71, Train LB = -441.314, Loss = 426.940
[2018-06-05 00:52] Train Step 11725, Epoch 10.9, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -428.669, Loss = 426.640
[2018-06-05 00:52] Train Step 11750, Epoch 10.9, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -427.553, Loss = 426.567
[2018-06-05 00:52] Train Step 11775, Epoch 10.9, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -433.752, Loss = 426.967
[2018-06-05 00:52] Train Step 11800, Epoch 10.9, Batch Size = 256, Examples/Sec = 3873.33, Train LB = -435.735, Loss = 427.745
Performance on test set:
  Test Lower Bound = -432.228, Test Loss = 432.228
[2018-06-05 00:52] Train Step 11825, Epoch 10.9, Batch Size = 256, Examples/Sec = 3838.32, Train LB = -425.435, Loss = 427.345
[2018-06-05 00:52] Train Step 11850, Epoch 11.0, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -423.977, Loss = 427.483
[2018-06-05 00:52] Train Step 11875, Epoch 11.0, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -423.664, Loss = 427.684
[2018-06-05 00:52] Train Step 11900, Epoch 11.0, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -433.587, Loss = 427.425
[2018-06-05 00:52] Train Step 11925, Epoch 11.0, Batch Size = 256, Examples/Sec = 3862.64, Train LB = -424.670, Loss = 427.833
[2018-06-05 00:52] Train Step 11950, Epoch 11.1, Batch Size = 256, Examples/Sec = 3824.73, Train LB = -427.828, Loss = 427.354
[2018-06-05 00:52] Train Step 11975, Epoch 11.1, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -435.561, Loss = 427.508
[2018-06-05 00:52] Train Step 12000, Epoch 11.1, Batch Size = 256, Examples/Sec = 3864.22, Train LB = -412.418, Loss = 427.638
Performance on test set:
  Test Lower Bound = -431.077, Test Loss = 431.077
[2018-06-05 00:52] Train Step 12025, Epoch 11.1, Batch Size = 256, Examples/Sec = 3895.25, Train LB = -413.068, Loss = 427.100
[2018-06-05 00:52] Train Step 12050, Epoch 11.2, Batch Size = 256, Examples/Sec = 3867.76, Train LB = -413.676, Loss = 426.768
[2018-06-05 00:52] Train Step 12075, Epoch 11.2, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -433.719, Loss = 426.597
[2018-06-05 00:53] Train Step 12100, Epoch 11.2, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -415.717, Loss = 426.755
[2018-06-05 00:53] Train Step 12125, Epoch 11.2, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -434.717, Loss = 426.388
[2018-06-05 00:53] Train Step 12150, Epoch 11.2, Batch Size = 256, Examples/Sec = 3801.88, Train LB = -424.294, Loss = 426.700
[2018-06-05 00:53] Train Step 12175, Epoch 11.3, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -423.618, Loss = 426.065
[2018-06-05 00:53] Train Step 12200, Epoch 11.3, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -426.067, Loss = 427.262
Performance on test set:
  Test Lower Bound = -432.217, Test Loss = 432.217
[2018-06-05 00:53] Train Step 12225, Epoch 11.3, Batch Size = 256, Examples/Sec = 3874.21, Train LB = -418.333, Loss = 426.672
[2018-06-05 00:53] Train Step 12250, Epoch 11.3, Batch Size = 256, Examples/Sec = 3875.26, Train LB = -430.171, Loss = 427.336
[2018-06-05 00:53] Train Step 12275, Epoch 11.4, Batch Size = 256, Examples/Sec = 3842.92, Train LB = -431.480, Loss = 426.632
[2018-06-05 00:53] Train Step 12300, Epoch 11.4, Batch Size = 256, Examples/Sec = 3870.22, Train LB = -428.565, Loss = 426.994
[2018-06-05 00:53] Train Step 12325, Epoch 11.4, Batch Size = 256, Examples/Sec = 3854.38, Train LB = -430.524, Loss = 425.989
[2018-06-05 00:53] Train Step 12350, Epoch 11.4, Batch Size = 256, Examples/Sec = 3844.60, Train LB = -423.136, Loss = 426.050
[2018-06-05 00:53] Train Step 12375, Epoch 11.5, Batch Size = 256, Examples/Sec = 3855.72, Train LB = -427.297, Loss = 425.973
[2018-06-05 00:53] Train Step 12400, Epoch 11.5, Batch Size = 256, Examples/Sec = 3805.40, Train LB = -424.063, Loss = 426.589
Performance on test set:
  Test Lower Bound = -431.309, Test Loss = 431.309
[2018-06-05 00:53] Train Step 12425, Epoch 11.5, Batch Size = 256, Examples/Sec = 3879.45, Train LB = -428.108, Loss = 426.063
[2018-06-05 00:53] Train Step 12450, Epoch 11.5, Batch Size = 256, Examples/Sec = 3847.24, Train LB = -425.217, Loss = 426.303
[2018-06-05 00:53] Train Step 12475, Epoch 11.6, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -432.121, Loss = 426.454
[2018-06-05 00:53] Train Step 12500, Epoch 11.6, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -416.976, Loss = 426.189
[2018-06-05 00:53] Train Step 12525, Epoch 11.6, Batch Size = 256, Examples/Sec = 3874.39, Train LB = -433.745, Loss = 426.144
[2018-06-05 00:53] Train Step 12550, Epoch 11.6, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -416.776, Loss = 426.414
[2018-06-05 00:53] Train Step 12575, Epoch 11.6, Batch Size = 256, Examples/Sec = 3879.25, Train LB = -422.176, Loss = 426.268
[2018-06-05 00:53] Train Step 12600, Epoch 11.7, Batch Size = 256, Examples/Sec = 3860.02, Train LB = -435.436, Loss = 426.640
Performance on test set:
  Test Lower Bound = -432.208, Test Loss = 432.208
[2018-06-05 00:53] Train Step 12625, Epoch 11.7, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -431.332, Loss = 426.512
[2018-06-05 00:53] Train Step 12650, Epoch 11.7, Batch Size = 256, Examples/Sec = 3855.71, Train LB = -427.896, Loss = 426.517
[2018-06-05 00:53] Train Step 12675, Epoch 11.7, Batch Size = 256, Examples/Sec = 3860.83, Train LB = -424.362, Loss = 426.127
[2018-06-05 00:53] Train Step 12700, Epoch 11.8, Batch Size = 256, Examples/Sec = 3842.06, Train LB = -424.628, Loss = 426.016
[2018-06-05 00:53] Train Step 12725, Epoch 11.8, Batch Size = 256, Examples/Sec = 3809.13, Train LB = -414.051, Loss = 425.315
[2018-06-05 00:53] Train Step 12750, Epoch 11.8, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -427.854, Loss = 425.320
[2018-06-05 00:53] Train Step 12775, Epoch 11.8, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -435.830, Loss = 425.489
[2018-06-05 00:53] Train Step 12800, Epoch 11.9, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -427.995, Loss = 425.830
Performance on test set:
  Test Lower Bound = -432.261, Test Loss = 432.261
[2018-06-05 00:54] Train Step 12825, Epoch 11.9, Batch Size = 256, Examples/Sec = 3813.21, Train LB = -420.013, Loss = 425.685
[2018-06-05 00:54] Train Step 12850, Epoch 11.9, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -428.403, Loss = 425.851
[2018-06-05 00:54] Train Step 12875, Epoch 11.9, Batch Size = 256, Examples/Sec = 3866.50, Train LB = -426.290, Loss = 426.164
[2018-06-05 00:54] Train Step 12900, Epoch 11.9, Batch Size = 256, Examples/Sec = 3873.28, Train LB = -429.865, Loss = 425.295
[2018-06-05 00:54] Train Step 12925, Epoch 12.0, Batch Size = 256, Examples/Sec = 3877.74, Train LB = -420.125, Loss = 425.245
[2018-06-05 00:54] Train Step 12950, Epoch 12.0, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -427.557, Loss = 425.269
[2018-06-05 00:54] Train Step 12975, Epoch 12.0, Batch Size = 256, Examples/Sec = 3884.61, Train LB = -432.453, Loss = 425.839
[2018-06-05 00:54] Train Step 13000, Epoch 12.0, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -422.399, Loss = 426.750
Performance on test set:
  Test Lower Bound = -431.798, Test Loss = 431.798
[2018-06-05 00:54] Train Step 13025, Epoch 12.1, Batch Size = 256, Examples/Sec = 3854.37, Train LB = -419.024, Loss = 426.239
[2018-06-05 00:54] Train Step 13050, Epoch 12.1, Batch Size = 256, Examples/Sec = 3879.84, Train LB = -426.152, Loss = 426.035
[2018-06-05 00:54] Train Step 13075, Epoch 12.1, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -422.741, Loss = 426.218
[2018-06-05 00:54] Train Step 13100, Epoch 12.1, Batch Size = 256, Examples/Sec = 3854.38, Train LB = -423.380, Loss = 425.945
[2018-06-05 00:54] Train Step 13125, Epoch 12.2, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -429.638, Loss = 425.948
[2018-06-05 00:54] Train Step 13150, Epoch 12.2, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -423.471, Loss = 425.772
[2018-06-05 00:54] Train Step 13175, Epoch 12.2, Batch Size = 256, Examples/Sec = 3834.40, Train LB = -426.429, Loss = 425.698
[2018-06-05 00:54] Train Step 13200, Epoch 12.2, Batch Size = 256, Examples/Sec = 3803.31, Train LB = -426.330, Loss = 426.168
Performance on test set:
  Test Lower Bound = -431.435, Test Loss = 431.435
[2018-06-05 00:54] Train Step 13225, Epoch 12.2, Batch Size = 256, Examples/Sec = 3795.68, Train LB = -438.151, Loss = 425.709
[2018-06-05 00:54] Train Step 13250, Epoch 12.3, Batch Size = 256, Examples/Sec = 3864.80, Train LB = -431.041, Loss = 425.901
[2018-06-05 00:54] Train Step 13275, Epoch 12.3, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -422.662, Loss = 425.293
[2018-06-05 00:54] Train Step 13300, Epoch 12.3, Batch Size = 256, Examples/Sec = 3786.65, Train LB = -422.350, Loss = 425.311
[2018-06-05 00:54] Train Step 13325, Epoch 12.3, Batch Size = 256, Examples/Sec = 3854.26, Train LB = -422.213, Loss = 425.549
[2018-06-05 00:54] Train Step 13350, Epoch 12.4, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -430.414, Loss = 424.894
[2018-06-05 00:54] Train Step 13375, Epoch 12.4, Batch Size = 256, Examples/Sec = 3880.44, Train LB = -420.684, Loss = 425.127
[2018-06-05 00:54] Train Step 13400, Epoch 12.4, Batch Size = 256, Examples/Sec = 3867.29, Train LB = -423.852, Loss = 425.691
Performance on test set:
  Test Lower Bound = -430.851, Test Loss = 430.851
[2018-06-05 00:54] Train Step 13425, Epoch 12.4, Batch Size = 256, Examples/Sec = 3838.71, Train LB = -429.636, Loss = 425.153
[2018-06-05 00:54] Train Step 13450, Epoch 12.5, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -425.914, Loss = 424.934
[2018-06-05 00:54] Train Step 13475, Epoch 12.5, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -437.790, Loss = 425.219
[2018-06-05 00:54] Train Step 13500, Epoch 12.5, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -430.702, Loss = 425.061
[2018-06-05 00:54] Train Step 13525, Epoch 12.5, Batch Size = 256, Examples/Sec = 3829.46, Train LB = -429.091, Loss = 425.016
[2018-06-05 00:55] Train Step 13550, Epoch 12.5, Batch Size = 256, Examples/Sec = 3861.52, Train LB = -424.082, Loss = 425.346
[2018-06-05 00:55] Train Step 13575, Epoch 12.6, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -425.591, Loss = 426.082
[2018-06-05 00:55] Train Step 13600, Epoch 12.6, Batch Size = 256, Examples/Sec = 3883.15, Train LB = -424.847, Loss = 425.739
Performance on test set:
  Test Lower Bound = -431.717, Test Loss = 431.717
[2018-06-05 00:55] Train Step 13625, Epoch 12.6, Batch Size = 256, Examples/Sec = 3853.40, Train LB = -414.810, Loss = 424.880
[2018-06-05 00:55] Train Step 13650, Epoch 12.6, Batch Size = 256, Examples/Sec = 3859.48, Train LB = -432.937, Loss = 424.793
[2018-06-05 00:55] Train Step 13675, Epoch 12.7, Batch Size = 256, Examples/Sec = 3876.14, Train LB = -433.857, Loss = 425.665
[2018-06-05 00:55] Train Step 13700, Epoch 12.7, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -420.352, Loss = 425.145
[2018-06-05 00:55] Train Step 13725, Epoch 12.7, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -428.179, Loss = 424.961
[2018-06-05 00:55] Train Step 13750, Epoch 12.7, Batch Size = 256, Examples/Sec = 3809.97, Train LB = -422.388, Loss = 424.551
[2018-06-05 00:55] Train Step 13775, Epoch 12.8, Batch Size = 256, Examples/Sec = 3813.27, Train LB = -423.394, Loss = 425.546
[2018-06-05 00:55] Train Step 13800, Epoch 12.8, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -431.322, Loss = 425.349
Performance on test set:
  Test Lower Bound = -430.722, Test Loss = 430.722
[2018-06-05 00:55] Train Step 13825, Epoch 12.8, Batch Size = 256, Examples/Sec = 3870.71, Train LB = -431.795, Loss = 425.261
[2018-06-05 00:55] Train Step 13850, Epoch 12.8, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -424.527, Loss = 424.793
[2018-06-05 00:55] Train Step 13875, Epoch 12.8, Batch Size = 256, Examples/Sec = 3806.80, Train LB = -420.997, Loss = 425.034
[2018-06-05 00:55] Train Step 13900, Epoch 12.9, Batch Size = 256, Examples/Sec = 3864.98, Train LB = -414.753, Loss = 424.897
[2018-06-05 00:55] Train Step 13925, Epoch 12.9, Batch Size = 256, Examples/Sec = 3873.85, Train LB = -418.738, Loss = 424.167
[2018-06-05 00:55] Train Step 13950, Epoch 12.9, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -422.663, Loss = 424.387
[2018-06-05 00:55] Train Step 13975, Epoch 12.9, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -414.422, Loss = 424.755
[2018-06-05 00:55] Train Step 14000, Epoch 13.0, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -436.926, Loss = 425.026
Performance on test set:
  Test Lower Bound = -430.061, Test Loss = 430.061
[2018-06-05 00:55] Train Step 14025, Epoch 13.0, Batch Size = 256, Examples/Sec = 3864.51, Train LB = -416.815, Loss = 424.808
[2018-06-05 00:55] Train Step 14050, Epoch 13.0, Batch Size = 256, Examples/Sec = 3883.90, Train LB = -432.381, Loss = 424.544
[2018-06-05 00:55] Train Step 14075, Epoch 13.0, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -423.295, Loss = 424.365
[2018-06-05 00:55] Train Step 14100, Epoch 13.1, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -428.880, Loss = 424.160
[2018-06-05 00:55] Train Step 14125, Epoch 13.1, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -434.677, Loss = 423.928
[2018-06-05 00:55] Train Step 14150, Epoch 13.1, Batch Size = 256, Examples/Sec = 3875.08, Train LB = -430.877, Loss = 424.170
[2018-06-05 00:55] Train Step 14175, Epoch 13.1, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -422.616, Loss = 424.611
[2018-06-05 00:55] Train Step 14200, Epoch 13.1, Batch Size = 256, Examples/Sec = 3841.13, Train LB = -428.525, Loss = 425.106
Performance on test set:
  Test Lower Bound = -431.306, Test Loss = 431.306
[2018-06-05 00:56] Train Step 14225, Epoch 13.2, Batch Size = 256, Examples/Sec = 3800.37, Train LB = -426.231, Loss = 425.242
[2018-06-05 00:56] Train Step 14250, Epoch 13.2, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -425.219, Loss = 424.526
[2018-06-05 00:56] Train Step 14275, Epoch 13.2, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -433.884, Loss = 424.176
[2018-06-05 00:56] Train Step 14300, Epoch 13.2, Batch Size = 256, Examples/Sec = 3830.85, Train LB = -416.248, Loss = 424.493
[2018-06-05 00:56] Train Step 14325, Epoch 13.3, Batch Size = 256, Examples/Sec = 3864.90, Train LB = -416.790, Loss = 424.353
[2018-06-05 00:56] Train Step 14350, Epoch 13.3, Batch Size = 256, Examples/Sec = 3746.09, Train LB = -420.316, Loss = 424.400
[2018-06-05 00:56] Train Step 14375, Epoch 13.3, Batch Size = 256, Examples/Sec = 3867.71, Train LB = -425.378, Loss = 424.260
[2018-06-05 00:56] Train Step 14400, Epoch 13.3, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -423.327, Loss = 425.313
Performance on test set:
  Test Lower Bound = -431.232, Test Loss = 431.232
[2018-06-05 00:56] Train Step 14425, Epoch 13.4, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -419.446, Loss = 424.687
[2018-06-05 00:56] Train Step 14450, Epoch 13.4, Batch Size = 256, Examples/Sec = 3823.30, Train LB = -425.091, Loss = 424.562
[2018-06-05 00:56] Train Step 14475, Epoch 13.4, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -413.807, Loss = 424.464
[2018-06-05 00:56] Train Step 14500, Epoch 13.4, Batch Size = 256, Examples/Sec = 3881.62, Train LB = -411.997, Loss = 424.405
[2018-06-05 00:56] Train Step 14525, Epoch 13.4, Batch Size = 256, Examples/Sec = 3870.40, Train LB = -440.522, Loss = 424.107
[2018-06-05 00:56] Train Step 14550, Epoch 13.5, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -417.945, Loss = 423.788
[2018-06-05 00:56] Train Step 14575, Epoch 13.5, Batch Size = 256, Examples/Sec = 3852.18, Train LB = -420.320, Loss = 424.250
[2018-06-05 00:56] Train Step 14600, Epoch 13.5, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -430.286, Loss = 424.716
Performance on test set:
  Test Lower Bound = -430.642, Test Loss = 430.642
[2018-06-05 00:56] Train Step 14625, Epoch 13.5, Batch Size = 256, Examples/Sec = 3810.20, Train LB = -426.270, Loss = 424.026
[2018-06-05 00:56] Train Step 14650, Epoch 13.6, Batch Size = 256, Examples/Sec = 3881.02, Train LB = -425.286, Loss = 423.943
[2018-06-05 00:56] Train Step 14675, Epoch 13.6, Batch Size = 256, Examples/Sec = 3871.22, Train LB = -411.636, Loss = 424.276
[2018-06-05 00:56] Train Step 14700, Epoch 13.6, Batch Size = 256, Examples/Sec = 3858.73, Train LB = -416.691, Loss = 424.228
[2018-06-05 00:56] Train Step 14725, Epoch 13.6, Batch Size = 256, Examples/Sec = 3874.03, Train LB = -428.947, Loss = 423.836
[2018-06-05 00:56] Train Step 14750, Epoch 13.7, Batch Size = 256, Examples/Sec = 3854.38, Train LB = -410.055, Loss = 423.850
[2018-06-05 00:56] Train Step 14775, Epoch 13.7, Batch Size = 256, Examples/Sec = 3878.14, Train LB = -423.368, Loss = 424.058
[2018-06-05 00:56] Train Step 14800, Epoch 13.7, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -420.736, Loss = 424.947
Performance on test set:
  Test Lower Bound = -430.301, Test Loss = 430.301
[2018-06-05 00:56] Train Step 14825, Epoch 13.7, Batch Size = 256, Examples/Sec = 3870.93, Train LB = -412.357, Loss = 423.968
[2018-06-05 00:56] Train Step 14850, Epoch 13.8, Batch Size = 256, Examples/Sec = 3875.15, Train LB = -420.069, Loss = 423.998
[2018-06-05 00:56] Train Step 14875, Epoch 13.8, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -405.504, Loss = 424.209
[2018-06-05 00:56] Train Step 14900, Epoch 13.8, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -423.535, Loss = 423.649
[2018-06-05 00:56] Train Step 14925, Epoch 13.8, Batch Size = 256, Examples/Sec = 3756.14, Train LB = -399.821, Loss = 423.463
[2018-06-05 00:56] Train Step 14950, Epoch 13.8, Batch Size = 256, Examples/Sec = 3882.32, Train LB = -434.443, Loss = 423.589
[2018-06-05 00:57] Train Step 14975, Epoch 13.9, Batch Size = 256, Examples/Sec = 3875.68, Train LB = -425.258, Loss = 423.957
[2018-06-05 00:57] Train Step 15000, Epoch 13.9, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -431.454, Loss = 424.786
Performance on test set:
  Test Lower Bound = -430.661, Test Loss = 430.661
[2018-06-05 00:57] Train Step 15025, Epoch 13.9, Batch Size = 256, Examples/Sec = 3765.31, Train LB = -431.018, Loss = 424.024
[2018-06-05 00:57] Train Step 15050, Epoch 13.9, Batch Size = 256, Examples/Sec = 3851.24, Train LB = -420.520, Loss = 423.678
[2018-06-05 00:57] Train Step 15075, Epoch 14.0, Batch Size = 256, Examples/Sec = 3871.81, Train LB = -425.387, Loss = 424.030
[2018-06-05 00:57] Train Step 15100, Epoch 14.0, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -424.453, Loss = 423.829
[2018-06-05 00:57] Train Step 15125, Epoch 14.0, Batch Size = 256, Examples/Sec = 3885.26, Train LB = -428.177, Loss = 423.600
[2018-06-05 00:57] Train Step 15150, Epoch 14.0, Batch Size = 256, Examples/Sec = 3878.13, Train LB = -413.816, Loss = 423.494
[2018-06-05 00:57] Train Step 15175, Epoch 14.1, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -428.532, Loss = 424.063
[2018-06-05 00:57] Train Step 15200, Epoch 14.1, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -436.229, Loss = 424.370
Performance on test set:
  Test Lower Bound = -431.608, Test Loss = 431.608
[2018-06-05 00:57] Train Step 15225, Epoch 14.1, Batch Size = 256, Examples/Sec = 3860.60, Train LB = -435.214, Loss = 423.742
[2018-06-05 00:57] Train Step 15250, Epoch 14.1, Batch Size = 256, Examples/Sec = 3803.75, Train LB = -402.028, Loss = 423.705
[2018-06-05 00:57] Train Step 15275, Epoch 14.1, Batch Size = 256, Examples/Sec = 3871.75, Train LB = -426.170, Loss = 423.778
[2018-06-05 00:57] Train Step 15300, Epoch 14.2, Batch Size = 256, Examples/Sec = 3870.27, Train LB = -419.971, Loss = 423.764
[2018-06-05 00:57] Train Step 15325, Epoch 14.2, Batch Size = 256, Examples/Sec = 3882.79, Train LB = -431.006, Loss = 423.183
[2018-06-05 00:57] Train Step 15350, Epoch 14.2, Batch Size = 256, Examples/Sec = 3864.26, Train LB = -445.366, Loss = 423.216
[2018-06-05 00:57] Train Step 15375, Epoch 14.2, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -424.123, Loss = 423.869
[2018-06-05 00:57] Train Step 15400, Epoch 14.3, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -437.524, Loss = 424.007
Performance on test set:
  Test Lower Bound = -431.535, Test Loss = 431.535
[2018-06-05 00:57] Train Step 15425, Epoch 14.3, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -424.520, Loss = 423.797
[2018-06-05 00:57] Train Step 15450, Epoch 14.3, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -424.173, Loss = 423.884
[2018-06-05 00:57] Train Step 15475, Epoch 14.3, Batch Size = 256, Examples/Sec = 3882.84, Train LB = -414.967, Loss = 423.982
[2018-06-05 00:57] Train Step 15500, Epoch 14.4, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -418.710, Loss = 423.486
[2018-06-05 00:57] Train Step 15525, Epoch 14.4, Batch Size = 256, Examples/Sec = 3816.23, Train LB = -420.160, Loss = 422.638
[2018-06-05 00:57] Train Step 15550, Epoch 14.4, Batch Size = 256, Examples/Sec = 3803.35, Train LB = -418.804, Loss = 422.654
[2018-06-05 00:57] Train Step 15575, Epoch 14.4, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -420.299, Loss = 423.602
[2018-06-05 00:57] Train Step 15600, Epoch 14.4, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -437.404, Loss = 423.930
Performance on test set:
  Test Lower Bound = -430.384, Test Loss = 430.384
[2018-06-05 00:57] Train Step 15625, Epoch 14.5, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -444.506, Loss = 423.629
[2018-06-05 00:57] Train Step 15650, Epoch 14.5, Batch Size = 256, Examples/Sec = 3860.26, Train LB = -415.901, Loss = 423.517
[2018-06-05 00:58] Train Step 15675, Epoch 14.5, Batch Size = 256, Examples/Sec = 3862.76, Train LB = -427.066, Loss = 423.429
[2018-06-05 00:58] Train Step 15700, Epoch 14.5, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -418.216, Loss = 423.165
[2018-06-05 00:58] Train Step 15725, Epoch 14.6, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -418.904, Loss = 422.440
[2018-06-05 00:58] Train Step 15750, Epoch 14.6, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -429.383, Loss = 422.478
[2018-06-05 00:58] Train Step 15775, Epoch 14.6, Batch Size = 256, Examples/Sec = 3843.27, Train LB = -419.275, Loss = 422.618
[2018-06-05 00:58] Train Step 15800, Epoch 14.6, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -423.539, Loss = 423.334
Performance on test set:
  Test Lower Bound = -431.962, Test Loss = 431.962
[2018-06-05 00:58] Train Step 15825, Epoch 14.7, Batch Size = 256, Examples/Sec = 3865.37, Train LB = -414.958, Loss = 423.039
[2018-06-05 00:58] Train Step 15850, Epoch 14.7, Batch Size = 256, Examples/Sec = 3872.45, Train LB = -418.690, Loss = 422.633
[2018-06-05 00:58] Train Step 15875, Epoch 14.7, Batch Size = 256, Examples/Sec = 3816.74, Train LB = -415.691, Loss = 422.526
[2018-06-05 00:58] Train Step 15900, Epoch 14.7, Batch Size = 256, Examples/Sec = 3870.22, Train LB = -424.824, Loss = 421.902
[2018-06-05 00:58] Train Step 15925, Epoch 14.7, Batch Size = 256, Examples/Sec = 3839.74, Train LB = -430.741, Loss = 422.112
[2018-06-05 00:58] Train Step 15950, Epoch 14.8, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -414.782, Loss = 422.205
[2018-06-05 00:58] Train Step 15975, Epoch 14.8, Batch Size = 256, Examples/Sec = 3837.97, Train LB = -419.735, Loss = 422.366
[2018-06-05 00:58] Train Step 16000, Epoch 14.8, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -424.993, Loss = 423.287
Performance on test set:
  Test Lower Bound = -432.059, Test Loss = 432.059
[2018-06-05 00:58] Train Step 16025, Epoch 14.8, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -416.012, Loss = 422.899
[2018-06-05 00:58] Train Step 16050, Epoch 14.9, Batch Size = 256, Examples/Sec = 3856.07, Train LB = -417.615, Loss = 422.838
[2018-06-05 00:58] Train Step 16075, Epoch 14.9, Batch Size = 256, Examples/Sec = 3808.45, Train LB = -413.852, Loss = 422.869
[2018-06-05 00:58] Train Step 16100, Epoch 14.9, Batch Size = 256, Examples/Sec = 3812.98, Train LB = -411.330, Loss = 421.884
[2018-06-05 00:58] Train Step 16125, Epoch 14.9, Batch Size = 256, Examples/Sec = 3848.69, Train LB = -421.517, Loss = 421.864
[2018-06-05 00:58] Train Step 16150, Epoch 15.0, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -425.636, Loss = 422.099
[2018-06-05 00:58] Train Step 16175, Epoch 15.0, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -430.248, Loss = 422.496
[2018-06-05 00:58] Train Step 16200, Epoch 15.0, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -430.458, Loss = 423.070
Performance on test set:
  Test Lower Bound = -431.330, Test Loss = 431.330
[2018-06-05 00:58] Train Step 16225, Epoch 15.0, Batch Size = 256, Examples/Sec = 3845.99, Train LB = -431.557, Loss = 422.076
[2018-06-05 00:58] Train Step 16250, Epoch 15.0, Batch Size = 256, Examples/Sec = 3878.66, Train LB = -420.478, Loss = 422.273
[2018-06-05 00:58] Train Step 16275, Epoch 15.1, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -421.675, Loss = 422.306
[2018-06-05 00:58] Train Step 16300, Epoch 15.1, Batch Size = 256, Examples/Sec = 3844.87, Train LB = -415.594, Loss = 422.125
[2018-06-05 00:58] Train Step 16325, Epoch 15.1, Batch Size = 256, Examples/Sec = 3799.30, Train LB = -428.993, Loss = 422.746
[2018-06-05 00:58] Train Step 16350, Epoch 15.1, Batch Size = 256, Examples/Sec = 3872.45, Train LB = -412.201, Loss = 422.557
[2018-06-05 00:58] Train Step 16375, Epoch 15.2, Batch Size = 256, Examples/Sec = 3865.15, Train LB = -425.125, Loss = 422.228
[2018-06-05 00:58] Train Step 16400, Epoch 15.2, Batch Size = 256, Examples/Sec = 3842.34, Train LB = -434.552, Loss = 423.480
Performance on test set:
  Test Lower Bound = -431.455, Test Loss = 431.455
[2018-06-05 00:59] Train Step 16425, Epoch 15.2, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -414.626, Loss = 423.012
[2018-06-05 00:59] Train Step 16450, Epoch 15.2, Batch Size = 256, Examples/Sec = 3868.95, Train LB = -422.750, Loss = 422.580
[2018-06-05 00:59] Train Step 16475, Epoch 15.3, Batch Size = 256, Examples/Sec = 3875.21, Train LB = -437.703, Loss = 422.105
[2018-06-05 00:59] Train Step 16500, Epoch 15.3, Batch Size = 256, Examples/Sec = 3875.85, Train LB = -425.096, Loss = 422.532
[2018-06-05 00:59] Train Step 16525, Epoch 15.3, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -421.112, Loss = 422.295
[2018-06-05 00:59] Train Step 16550, Epoch 15.3, Batch Size = 256, Examples/Sec = 3798.62, Train LB = -421.447, Loss = 422.753
[2018-06-05 00:59] Train Step 16575, Epoch 15.3, Batch Size = 256, Examples/Sec = 3854.27, Train LB = -444.190, Loss = 422.876
[2018-06-05 00:59] Train Step 16600, Epoch 15.4, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -432.017, Loss = 423.619
Performance on test set:
  Test Lower Bound = -430.321, Test Loss = 430.321
[2018-06-05 00:59] Train Step 16625, Epoch 15.4, Batch Size = 256, Examples/Sec = 3885.85, Train LB = -414.189, Loss = 423.342
[2018-06-05 00:59] Train Step 16650, Epoch 15.4, Batch Size = 256, Examples/Sec = 3764.99, Train LB = -429.527, Loss = 423.047
[2018-06-05 00:59] Train Step 16675, Epoch 15.4, Batch Size = 256, Examples/Sec = 3877.19, Train LB = -422.400, Loss = 422.987
[2018-06-05 00:59] Train Step 16700, Epoch 15.5, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -401.713, Loss = 422.614
[2018-06-05 00:59] Train Step 16725, Epoch 15.5, Batch Size = 256, Examples/Sec = 3868.02, Train LB = -414.070, Loss = 422.060
[2018-06-05 00:59] Train Step 16750, Epoch 15.5, Batch Size = 256, Examples/Sec = 3845.46, Train LB = -412.356, Loss = 421.942
[2018-06-05 00:59] Train Step 16775, Epoch 15.5, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -415.202, Loss = 422.264
[2018-06-05 00:59] Train Step 16800, Epoch 15.6, Batch Size = 256, Examples/Sec = 3866.50, Train LB = -421.181, Loss = 422.994
Performance on test set:
  Test Lower Bound = -430.773, Test Loss = 430.773
[2018-06-05 00:59] Train Step 16825, Epoch 15.6, Batch Size = 256, Examples/Sec = 3858.11, Train LB = -418.359, Loss = 422.519
[2018-06-05 00:59] Train Step 16850, Epoch 15.6, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -426.327, Loss = 422.261
[2018-06-05 00:59] Train Step 16875, Epoch 15.6, Batch Size = 256, Examples/Sec = 3817.87, Train LB = -413.190, Loss = 421.831
[2018-06-05 00:59] Train Step 16900, Epoch 15.6, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -416.396, Loss = 421.768
[2018-06-05 00:59] Train Step 16925, Epoch 15.7, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -420.545, Loss = 421.671
[2018-06-05 00:59] Train Step 16950, Epoch 15.7, Batch Size = 256, Examples/Sec = 3857.69, Train LB = -411.858, Loss = 422.195
[2018-06-05 00:59] Train Step 16975, Epoch 15.7, Batch Size = 256, Examples/Sec = 3868.66, Train LB = -417.884, Loss = 421.888
[2018-06-05 00:59] Train Step 17000, Epoch 15.7, Batch Size = 256, Examples/Sec = 3852.24, Train LB = -435.781, Loss = 422.756
Performance on test set:
  Test Lower Bound = -431.215, Test Loss = 431.215
[2018-06-05 00:59] Train Step 17025, Epoch 15.8, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -423.265, Loss = 422.961
[2018-06-05 00:59] Train Step 17050, Epoch 15.8, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -412.553, Loss = 422.814
[2018-06-05 00:59] Train Step 17075, Epoch 15.8, Batch Size = 256, Examples/Sec = 3860.48, Train LB = -415.815, Loss = 422.519
[2018-06-05 01:00] Train Step 17100, Epoch 15.8, Batch Size = 256, Examples/Sec = 3848.41, Train LB = -418.522, Loss = 421.824
[2018-06-05 01:00] Train Step 17125, Epoch 15.9, Batch Size = 256, Examples/Sec = 3819.99, Train LB = -413.678, Loss = 421.510
[2018-06-05 01:00] Train Step 17150, Epoch 15.9, Batch Size = 256, Examples/Sec = 3873.81, Train LB = -433.411, Loss = 421.661
[2018-06-05 01:00] Train Step 17175, Epoch 15.9, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -430.084, Loss = 421.524
[2018-06-05 01:00] Train Step 17200, Epoch 15.9, Batch Size = 256, Examples/Sec = 3858.45, Train LB = -427.567, Loss = 422.631
Performance on test set:
  Test Lower Bound = -430.229, Test Loss = 430.229
[2018-06-05 01:00] Train Step 17225, Epoch 15.9, Batch Size = 256, Examples/Sec = 3809.76, Train LB = -414.466, Loss = 422.379
[2018-06-05 01:00] Train Step 17250, Epoch 16.0, Batch Size = 256, Examples/Sec = 3850.15, Train LB = -407.553, Loss = 422.083
[2018-06-05 01:00] Train Step 17275, Epoch 16.0, Batch Size = 256, Examples/Sec = 3845.17, Train LB = -416.200, Loss = 421.940
[2018-06-05 01:00] Train Step 17300, Epoch 16.0, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -425.315, Loss = 421.630
[2018-06-05 01:00] Train Step 17325, Epoch 16.0, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -421.536, Loss = 421.268
[2018-06-05 01:00] Train Step 17350, Epoch 16.1, Batch Size = 256, Examples/Sec = 3855.18, Train LB = -414.600, Loss = 421.381
[2018-06-05 01:00] Train Step 17375, Epoch 16.1, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -422.624, Loss = 421.666
[2018-06-05 01:00] Train Step 17400, Epoch 16.1, Batch Size = 256, Examples/Sec = 3881.44, Train LB = -420.955, Loss = 422.409
Performance on test set:
  Test Lower Bound = -430.404, Test Loss = 430.404
[2018-06-05 01:00] Train Step 17425, Epoch 16.1, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -433.271, Loss = 422.601
[2018-06-05 01:00] Train Step 17450, Epoch 16.2, Batch Size = 256, Examples/Sec = 3853.97, Train LB = -435.411, Loss = 422.229
[2018-06-05 01:00] Train Step 17475, Epoch 16.2, Batch Size = 256, Examples/Sec = 3877.85, Train LB = -418.537, Loss = 421.686
[2018-06-05 01:00] Train Step 17500, Epoch 16.2, Batch Size = 256, Examples/Sec = 3874.73, Train LB = -425.484, Loss = 421.869
[2018-06-05 01:00] Train Step 17525, Epoch 16.2, Batch Size = 256, Examples/Sec = 3874.32, Train LB = -420.987, Loss = 421.124
[2018-06-05 01:00] Train Step 17550, Epoch 16.2, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -430.118, Loss = 421.494
[2018-06-05 01:00] Train Step 17575, Epoch 16.3, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -424.240, Loss = 421.281
[2018-06-05 01:00] Train Step 17600, Epoch 16.3, Batch Size = 256, Examples/Sec = 3787.82, Train LB = -434.407, Loss = 421.735
Performance on test set:
  Test Lower Bound = -431.103, Test Loss = 431.103
[2018-06-05 01:00] Train Step 17625, Epoch 16.3, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -416.268, Loss = 421.415
[2018-06-05 01:00] Train Step 17650, Epoch 16.3, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -421.489, Loss = 421.701
[2018-06-05 01:00] Train Step 17675, Epoch 16.4, Batch Size = 256, Examples/Sec = 3865.13, Train LB = -422.595, Loss = 421.108
[2018-06-05 01:00] Train Step 17700, Epoch 16.4, Batch Size = 256, Examples/Sec = 3812.53, Train LB = -424.002, Loss = 420.514
[2018-06-05 01:00] Train Step 17725, Epoch 16.4, Batch Size = 256, Examples/Sec = 3853.00, Train LB = -428.337, Loss = 420.465
[2018-06-05 01:00] Train Step 17750, Epoch 16.4, Batch Size = 256, Examples/Sec = 3865.26, Train LB = -437.656, Loss = 420.719
[2018-06-05 01:00] Train Step 17775, Epoch 16.5, Batch Size = 256, Examples/Sec = 3859.13, Train LB = -429.344, Loss = 421.134
[2018-06-05 01:00] Train Step 17800, Epoch 16.5, Batch Size = 256, Examples/Sec = 3883.02, Train LB = -413.839, Loss = 422.029
Performance on test set:
  Test Lower Bound = -430.481, Test Loss = 430.481
[2018-06-05 01:01] Train Step 17825, Epoch 16.5, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -417.838, Loss = 420.831
[2018-06-05 01:01] Train Step 17850, Epoch 16.5, Batch Size = 256, Examples/Sec = 3872.45, Train LB = -424.748, Loss = 421.447
[2018-06-05 01:01] Train Step 17875, Epoch 16.6, Batch Size = 256, Examples/Sec = 3849.61, Train LB = -424.222, Loss = 421.320
[2018-06-05 01:01] Train Step 17900, Epoch 16.6, Batch Size = 256, Examples/Sec = 3875.02, Train LB = -414.109, Loss = 420.462
[2018-06-05 01:01] Train Step 17925, Epoch 16.6, Batch Size = 256, Examples/Sec = 3885.62, Train LB = -414.741, Loss = 420.872
[2018-06-05 01:01] Train Step 17950, Epoch 16.6, Batch Size = 256, Examples/Sec = 3857.97, Train LB = -423.576, Loss = 420.726
[2018-06-05 01:01] Train Step 17975, Epoch 16.6, Batch Size = 256, Examples/Sec = 3876.67, Train LB = -422.880, Loss = 420.841
[2018-06-05 01:01] Train Step 18000, Epoch 16.7, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -431.567, Loss = 421.853
Performance on test set:
  Test Lower Bound = -432.131, Test Loss = 432.131
[2018-06-05 01:01] Train Step 18025, Epoch 16.7, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -424.706, Loss = 421.417
[2018-06-05 01:01] Train Step 18050, Epoch 16.7, Batch Size = 256, Examples/Sec = 3828.67, Train LB = -415.279, Loss = 420.955
[2018-06-05 01:01] Train Step 18075, Epoch 16.7, Batch Size = 256, Examples/Sec = 3849.85, Train LB = -418.544, Loss = 421.165
[2018-06-05 01:01] Train Step 18100, Epoch 16.8, Batch Size = 256, Examples/Sec = 3869.23, Train LB = -423.735, Loss = 420.947
[2018-06-05 01:01] Train Step 18125, Epoch 16.8, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -426.403, Loss = 420.990
[2018-06-05 01:01] Train Step 18150, Epoch 16.8, Batch Size = 256, Examples/Sec = 3838.01, Train LB = -414.619, Loss = 420.398
[2018-06-05 01:01] Train Step 18175, Epoch 16.8, Batch Size = 256, Examples/Sec = 3807.77, Train LB = -408.650, Loss = 420.871
[2018-06-05 01:01] Train Step 18200, Epoch 16.9, Batch Size = 256, Examples/Sec = 3882.73, Train LB = -429.408, Loss = 422.057
Performance on test set:
  Test Lower Bound = -430.822, Test Loss = 430.822
[2018-06-05 01:01] Train Step 18225, Epoch 16.9, Batch Size = 256, Examples/Sec = 3883.38, Train LB = -414.056, Loss = 421.594
[2018-06-05 01:01] Train Step 18250, Epoch 16.9, Batch Size = 256, Examples/Sec = 3872.73, Train LB = -418.453, Loss = 421.494
[2018-06-05 01:01] Train Step 18275, Epoch 16.9, Batch Size = 256, Examples/Sec = 3812.64, Train LB = -413.831, Loss = 420.965
[2018-06-05 01:01] Train Step 18300, Epoch 16.9, Batch Size = 256, Examples/Sec = 3870.57, Train LB = -424.249, Loss = 420.959
[2018-06-05 01:01] Train Step 18325, Epoch 17.0, Batch Size = 256, Examples/Sec = 3872.33, Train LB = -428.504, Loss = 420.445
[2018-06-05 01:01] Train Step 18350, Epoch 17.0, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -433.190, Loss = 420.494
[2018-06-05 01:01] Train Step 18375, Epoch 17.0, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -431.376, Loss = 420.667
[2018-06-05 01:01] Train Step 18400, Epoch 17.0, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -432.199, Loss = 421.310
Performance on test set:
  Test Lower Bound = -430.880, Test Loss = 430.880
[2018-06-05 01:01] Train Step 18425, Epoch 17.1, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -419.495, Loss = 420.795
[2018-06-05 01:01] Train Step 18450, Epoch 17.1, Batch Size = 256, Examples/Sec = 3876.55, Train LB = -419.400, Loss = 420.352
[2018-06-05 01:01] Train Step 18475, Epoch 17.1, Batch Size = 256, Examples/Sec = 3871.92, Train LB = -416.749, Loss = 419.759
[2018-06-05 01:01] Train Step 18500, Epoch 17.1, Batch Size = 256, Examples/Sec = 3880.85, Train LB = -420.012, Loss = 419.962
[2018-06-05 01:01] Train Step 18525, Epoch 17.2, Batch Size = 256, Examples/Sec = 3877.67, Train LB = -411.384, Loss = 420.219
[2018-06-05 01:02] Train Step 18550, Epoch 17.2, Batch Size = 256, Examples/Sec = 3867.89, Train LB = -420.432, Loss = 420.524
[2018-06-05 01:02] Train Step 18575, Epoch 17.2, Batch Size = 256, Examples/Sec = 3849.27, Train LB = -419.655, Loss = 420.643
[2018-06-05 01:02] Train Step 18600, Epoch 17.2, Batch Size = 256, Examples/Sec = 3873.85, Train LB = -422.024, Loss = 421.098
Performance on test set:
  Test Lower Bound = -431.855, Test Loss = 431.855
[2018-06-05 01:02] Train Step 18625, Epoch 17.2, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -406.339, Loss = 421.461
[2018-06-05 01:02] Train Step 18650, Epoch 17.3, Batch Size = 256, Examples/Sec = 3857.86, Train LB = -422.557, Loss = 420.531
[2018-06-05 01:02] Train Step 18675, Epoch 17.3, Batch Size = 256, Examples/Sec = 3834.23, Train LB = -422.394, Loss = 420.145
[2018-06-05 01:02] Train Step 18700, Epoch 17.3, Batch Size = 256, Examples/Sec = 3865.38, Train LB = -409.111, Loss = 420.129
[2018-06-05 01:02] Train Step 18725, Epoch 17.3, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -414.631, Loss = 420.114
[2018-06-05 01:02] Train Step 18750, Epoch 17.4, Batch Size = 256, Examples/Sec = 3845.34, Train LB = -425.493, Loss = 419.698
[2018-06-05 01:02] Train Step 18775, Epoch 17.4, Batch Size = 256, Examples/Sec = 3882.67, Train LB = -419.525, Loss = 420.274
[2018-06-05 01:02] Train Step 18800, Epoch 17.4, Batch Size = 256, Examples/Sec = 3842.12, Train LB = -436.931, Loss = 421.515
Performance on test set:
  Test Lower Bound = -430.584, Test Loss = 430.584
[2018-06-05 01:02] Train Step 18825, Epoch 17.4, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -422.701, Loss = 421.064
[2018-06-05 01:02] Train Step 18850, Epoch 17.5, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -422.495, Loss = 420.293
[2018-06-05 01:02] Train Step 18875, Epoch 17.5, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -431.418, Loss = 420.204
[2018-06-05 01:02] Train Step 18900, Epoch 17.5, Batch Size = 256, Examples/Sec = 3824.03, Train LB = -426.053, Loss = 420.536
[2018-06-05 01:02] Train Step 18925, Epoch 17.5, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -408.882, Loss = 419.751
[2018-06-05 01:02] Train Step 18950, Epoch 17.5, Batch Size = 256, Examples/Sec = 3841.54, Train LB = -411.472, Loss = 419.902
[2018-06-05 01:02] Train Step 18975, Epoch 17.6, Batch Size = 256, Examples/Sec = 3860.06, Train LB = -414.171, Loss = 420.132
[2018-06-05 01:02] Train Step 19000, Epoch 17.6, Batch Size = 256, Examples/Sec = 3852.13, Train LB = -433.682, Loss = 421.074
Performance on test set:
  Test Lower Bound = -431.084, Test Loss = 431.084
[2018-06-05 01:02] Train Step 19025, Epoch 17.6, Batch Size = 256, Examples/Sec = 3832.16, Train LB = -426.313, Loss = 420.438
[2018-06-05 01:02] Train Step 19050, Epoch 17.6, Batch Size = 256, Examples/Sec = 3868.46, Train LB = -414.395, Loss = 419.801
[2018-06-05 01:02] Train Step 19075, Epoch 17.7, Batch Size = 256, Examples/Sec = 3865.61, Train LB = -414.374, Loss = 419.714
[2018-06-05 01:02] Train Step 19100, Epoch 17.7, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -427.623, Loss = 420.112
[2018-06-05 01:02] Train Step 19125, Epoch 17.7, Batch Size = 256, Examples/Sec = 3849.32, Train LB = -421.328, Loss = 419.550
[2018-06-05 01:02] Train Step 19150, Epoch 17.7, Batch Size = 256, Examples/Sec = 3848.94, Train LB = -425.338, Loss = 419.543
[2018-06-05 01:02] Train Step 19175, Epoch 17.8, Batch Size = 256, Examples/Sec = 3859.73, Train LB = -424.758, Loss = 420.057
[2018-06-05 01:02] Train Step 19200, Epoch 17.8, Batch Size = 256, Examples/Sec = 3865.62, Train LB = -423.721, Loss = 421.396
Performance on test set:
  Test Lower Bound = -430.404, Test Loss = 430.404
[2018-06-05 01:02] Train Step 19225, Epoch 17.8, Batch Size = 256, Examples/Sec = 3887.62, Train LB = -418.712, Loss = 420.865
[2018-06-05 01:03] Train Step 19250, Epoch 17.8, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -431.638, Loss = 420.668
[2018-06-05 01:03] Train Step 19275, Epoch 17.8, Batch Size = 256, Examples/Sec = 3865.37, Train LB = -423.209, Loss = 420.220
[2018-06-05 01:03] Train Step 19300, Epoch 17.9, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -419.697, Loss = 419.978
[2018-06-05 01:03] Train Step 19325, Epoch 17.9, Batch Size = 256, Examples/Sec = 3811.51, Train LB = -428.581, Loss = 419.671
[2018-06-05 01:03] Train Step 19350, Epoch 17.9, Batch Size = 256, Examples/Sec = 3842.74, Train LB = -425.952, Loss = 419.645
[2018-06-05 01:03] Train Step 19375, Epoch 17.9, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -428.838, Loss = 420.119
[2018-06-05 01:03] Train Step 19400, Epoch 18.0, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -426.089, Loss = 421.128
Performance on test set:
  Test Lower Bound = -431.409, Test Loss = 431.409
[2018-06-05 01:03] Train Step 19425, Epoch 18.0, Batch Size = 256, Examples/Sec = 3852.24, Train LB = -421.188, Loss = 421.204
[2018-06-05 01:03] Train Step 19450, Epoch 18.0, Batch Size = 256, Examples/Sec = 3812.08, Train LB = -413.823, Loss = 420.506
[2018-06-05 01:03] Train Step 19475, Epoch 18.0, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -409.615, Loss = 420.100
[2018-06-05 01:03] Train Step 19500, Epoch 18.1, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -435.137, Loss = 419.606
[2018-06-05 01:03] Train Step 19525, Epoch 18.1, Batch Size = 256, Examples/Sec = 3831.64, Train LB = -409.407, Loss = 419.530
[2018-06-05 01:03] Train Step 19550, Epoch 18.1, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -411.707, Loss = 419.276
[2018-06-05 01:03] Train Step 19575, Epoch 18.1, Batch Size = 256, Examples/Sec = 3865.44, Train LB = -421.165, Loss = 419.345
[2018-06-05 01:03] Train Step 19600, Epoch 18.1, Batch Size = 256, Examples/Sec = 3867.49, Train LB = -421.036, Loss = 420.591
Performance on test set:
  Test Lower Bound = -429.752, Test Loss = 429.752
[2018-06-05 01:03] Train Step 19625, Epoch 18.2, Batch Size = 256, Examples/Sec = 3877.37, Train LB = -413.627, Loss = 420.244
[2018-06-05 01:03] Train Step 19650, Epoch 18.2, Batch Size = 256, Examples/Sec = 3857.04, Train LB = -425.488, Loss = 419.771
[2018-06-05 01:03] Train Step 19675, Epoch 18.2, Batch Size = 256, Examples/Sec = 3837.90, Train LB = -418.226, Loss = 418.867
[2018-06-05 01:03] Train Step 19700, Epoch 18.2, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -427.882, Loss = 418.601
[2018-06-05 01:03] Train Step 19725, Epoch 18.3, Batch Size = 256, Examples/Sec = 3875.39, Train LB = -413.640, Loss = 419.251
[2018-06-05 01:03] Train Step 19750, Epoch 18.3, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -420.561, Loss = 419.537
[2018-06-05 01:03] Train Step 19775, Epoch 18.3, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -419.624, Loss = 419.921
[2018-06-05 01:03] Train Step 19800, Epoch 18.3, Batch Size = 256, Examples/Sec = 3825.17, Train LB = -415.152, Loss = 420.998
Performance on test set:
  Test Lower Bound = -430.214, Test Loss = 430.214
[2018-06-05 01:03] Train Step 19825, Epoch 18.4, Batch Size = 256, Examples/Sec = 3813.94, Train LB = -407.109, Loss = 419.859
[2018-06-05 01:03] Train Step 19850, Epoch 18.4, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -414.703, Loss = 419.771
[2018-06-05 01:03] Train Step 19875, Epoch 18.4, Batch Size = 256, Examples/Sec = 3859.44, Train LB = -424.781, Loss = 419.833
[2018-06-05 01:03] Train Step 19900, Epoch 18.4, Batch Size = 256, Examples/Sec = 3801.89, Train LB = -426.279, Loss = 419.772
[2018-06-05 01:03] Train Step 19925, Epoch 18.4, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -417.770, Loss = 418.907
[2018-06-05 01:03] Train Step 19950, Epoch 18.5, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -419.176, Loss = 419.254
[2018-06-05 01:03] Train Step 19975, Epoch 18.5, Batch Size = 256, Examples/Sec = 3804.48, Train LB = -412.504, Loss = 419.707
[2018-06-05 01:04] Train Step 20000, Epoch 18.5, Batch Size = 256, Examples/Sec = 3877.02, Train LB = -429.324, Loss = 420.331
Performance on test set:
  Test Lower Bound = -430.456, Test Loss = 430.456
[2018-06-05 01:04] Train Step 20025, Epoch 18.5, Batch Size = 256, Examples/Sec = 3834.86, Train LB = -415.906, Loss = 419.569
[2018-06-05 01:04] Train Step 20050, Epoch 18.6, Batch Size = 256, Examples/Sec = 3880.26, Train LB = -409.063, Loss = 419.834
[2018-06-05 01:04] Train Step 20075, Epoch 18.6, Batch Size = 256, Examples/Sec = 3817.31, Train LB = -417.364, Loss = 418.951
[2018-06-05 01:04] Train Step 20100, Epoch 18.6, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -410.838, Loss = 418.506
[2018-06-05 01:04] Train Step 20125, Epoch 18.6, Batch Size = 256, Examples/Sec = 3844.58, Train LB = -416.838, Loss = 418.268
[2018-06-05 01:04] Train Step 20150, Epoch 18.7, Batch Size = 256, Examples/Sec = 3855.29, Train LB = -412.796, Loss = 418.621
[2018-06-05 01:04] Train Step 20175, Epoch 18.7, Batch Size = 256, Examples/Sec = 3869.01, Train LB = -421.617, Loss = 419.373
[2018-06-05 01:04] Train Step 20200, Epoch 18.7, Batch Size = 256, Examples/Sec = 3837.92, Train LB = -423.893, Loss = 419.950
Performance on test set:
  Test Lower Bound = -430.461, Test Loss = 430.461
[2018-06-05 01:04] Train Step 20225, Epoch 18.7, Batch Size = 256, Examples/Sec = 3876.03, Train LB = -414.414, Loss = 419.542
[2018-06-05 01:04] Train Step 20250, Epoch 18.8, Batch Size = 256, Examples/Sec = 3876.84, Train LB = -413.612, Loss = 419.159
[2018-06-05 01:04] Train Step 20275, Epoch 18.8, Batch Size = 256, Examples/Sec = 3853.50, Train LB = -406.855, Loss = 418.871
[2018-06-05 01:04] Train Step 20300, Epoch 18.8, Batch Size = 256, Examples/Sec = 3873.85, Train LB = -412.898, Loss = 418.423
[2018-06-05 01:04] Train Step 20325, Epoch 18.8, Batch Size = 256, Examples/Sec = 3860.84, Train LB = -423.359, Loss = 418.490
[2018-06-05 01:04] Train Step 20350, Epoch 18.8, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -421.455, Loss = 418.747
[2018-06-05 01:04] Train Step 20375, Epoch 18.9, Batch Size = 256, Examples/Sec = 3808.00, Train LB = -423.929, Loss = 419.011
[2018-06-05 01:04] Train Step 20400, Epoch 18.9, Batch Size = 256, Examples/Sec = 3863.21, Train LB = -418.370, Loss = 420.226
Performance on test set:
  Test Lower Bound = -431.485, Test Loss = 431.485
[2018-06-05 01:04] Train Step 20425, Epoch 18.9, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -422.683, Loss = 419.703
[2018-06-05 01:04] Train Step 20450, Epoch 18.9, Batch Size = 256, Examples/Sec = 3846.26, Train LB = -422.356, Loss = 420.110
[2018-06-05 01:04] Train Step 20475, Epoch 19.0, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -432.894, Loss = 419.423
[2018-06-05 01:04] Train Step 20500, Epoch 19.0, Batch Size = 256, Examples/Sec = 3849.28, Train LB = -414.744, Loss = 419.260
[2018-06-05 01:04] Train Step 20525, Epoch 19.0, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -425.690, Loss = 418.980
[2018-06-05 01:04] Train Step 20550, Epoch 19.0, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -425.058, Loss = 419.098
[2018-06-05 01:04] Train Step 20575, Epoch 19.1, Batch Size = 256, Examples/Sec = 3882.73, Train LB = -412.571, Loss = 419.292
[2018-06-05 01:04] Train Step 20600, Epoch 19.1, Batch Size = 256, Examples/Sec = 3875.09, Train LB = -419.546, Loss = 419.561
Performance on test set:
  Test Lower Bound = -431.532, Test Loss = 431.532
[2018-06-05 01:04] Train Step 20625, Epoch 19.1, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -407.956, Loss = 419.286
[2018-06-05 01:04] Train Step 20650, Epoch 19.1, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -422.785, Loss = 418.780
[2018-06-05 01:05] Train Step 20675, Epoch 19.1, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -412.079, Loss = 418.315
[2018-06-05 01:05] Train Step 20700, Epoch 19.2, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -410.993, Loss = 418.361
[2018-06-05 01:05] Train Step 20725, Epoch 19.2, Batch Size = 256, Examples/Sec = 3862.01, Train LB = -415.021, Loss = 418.791
[2018-06-05 01:05] Train Step 20750, Epoch 19.2, Batch Size = 256, Examples/Sec = 3858.22, Train LB = -398.482, Loss = 418.812
[2018-06-05 01:05] Train Step 20775, Epoch 19.2, Batch Size = 256, Examples/Sec = 3841.83, Train LB = -418.108, Loss = 419.060
[2018-06-05 01:05] Train Step 20800, Epoch 19.3, Batch Size = 256, Examples/Sec = 3874.09, Train LB = -433.712, Loss = 419.468
Performance on test set:
  Test Lower Bound = -430.908, Test Loss = 430.908
[2018-06-05 01:05] Train Step 20825, Epoch 19.3, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -427.146, Loss = 418.972
[2018-06-05 01:05] Train Step 20850, Epoch 19.3, Batch Size = 256, Examples/Sec = 3846.04, Train LB = -406.957, Loss = 418.960
[2018-06-05 01:05] Train Step 20875, Epoch 19.3, Batch Size = 256, Examples/Sec = 3865.43, Train LB = -413.730, Loss = 418.639
[2018-06-05 01:05] Train Step 20900, Epoch 19.4, Batch Size = 256, Examples/Sec = 3878.14, Train LB = -409.528, Loss = 417.793
[2018-06-05 01:05] Train Step 20925, Epoch 19.4, Batch Size = 256, Examples/Sec = 3870.92, Train LB = -418.555, Loss = 418.145
[2018-06-05 01:05] Train Step 20950, Epoch 19.4, Batch Size = 256, Examples/Sec = 3806.58, Train LB = -421.693, Loss = 418.132
[2018-06-05 01:05] Train Step 20975, Epoch 19.4, Batch Size = 256, Examples/Sec = 3871.80, Train LB = -410.905, Loss = 418.988
[2018-06-05 01:05] Train Step 21000, Epoch 19.4, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -421.249, Loss = 419.940
Performance on test set:
  Test Lower Bound = -430.778, Test Loss = 430.778
[2018-06-05 01:05] Train Step 21025, Epoch 19.5, Batch Size = 256, Examples/Sec = 3868.06, Train LB = -406.367, Loss = 419.744
[2018-06-05 01:05] Train Step 21050, Epoch 19.5, Batch Size = 256, Examples/Sec = 3805.50, Train LB = -423.347, Loss = 419.440
[2018-06-05 01:05] Train Step 21075, Epoch 19.5, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -428.854, Loss = 419.122
[2018-06-05 01:05] Train Step 21100, Epoch 19.5, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -420.488, Loss = 419.137
[2018-06-05 01:05] Train Step 21125, Epoch 19.6, Batch Size = 256, Examples/Sec = 3867.29, Train LB = -409.318, Loss = 419.370
[2018-06-05 01:05] Train Step 21150, Epoch 19.6, Batch Size = 256, Examples/Sec = 3812.25, Train LB = -407.305, Loss = 419.021
[2018-06-05 01:05] Train Step 21175, Epoch 19.6, Batch Size = 256, Examples/Sec = 3878.66, Train LB = -433.526, Loss = 419.175
[2018-06-05 01:05] Train Step 21200, Epoch 19.6, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -421.975, Loss = 419.611
Performance on test set:
  Test Lower Bound = -431.064, Test Loss = 431.065
[2018-06-05 01:05] Train Step 21225, Epoch 19.7, Batch Size = 256, Examples/Sec = 3877.02, Train LB = -419.480, Loss = 419.194
[2018-06-05 01:05] Train Step 21250, Epoch 19.7, Batch Size = 256, Examples/Sec = 3817.48, Train LB = -423.522, Loss = 418.535
[2018-06-05 01:05] Train Step 21275, Epoch 19.7, Batch Size = 256, Examples/Sec = 3854.13, Train LB = -421.864, Loss = 418.197
[2018-06-05 01:05] Train Step 21300, Epoch 19.7, Batch Size = 256, Examples/Sec = 3866.65, Train LB = -423.523, Loss = 417.453
[2018-06-05 01:05] Train Step 21325, Epoch 19.7, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -421.519, Loss = 417.765
[2018-06-05 01:05] Train Step 21350, Epoch 19.8, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -412.571, Loss = 417.759
[2018-06-05 01:05] Train Step 21375, Epoch 19.8, Batch Size = 256, Examples/Sec = 3879.97, Train LB = -420.911, Loss = 418.139
[2018-06-05 01:05] Train Step 21400, Epoch 19.8, Batch Size = 256, Examples/Sec = 3866.02, Train LB = -425.630, Loss = 419.102
Performance on test set:
  Test Lower Bound = -431.200, Test Loss = 431.200
[2018-06-05 01:06] Train Step 21425, Epoch 19.8, Batch Size = 256, Examples/Sec = 3838.95, Train LB = -421.541, Loss = 418.517
[2018-06-05 01:06] Train Step 21450, Epoch 19.9, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -428.543, Loss = 418.270
[2018-06-05 01:06] Train Step 21475, Epoch 19.9, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -411.108, Loss = 418.125
[2018-06-05 01:06] Train Step 21500, Epoch 19.9, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -401.075, Loss = 417.853
[2018-06-05 01:06] Train Step 21525, Epoch 19.9, Batch Size = 256, Examples/Sec = 3783.90, Train LB = -407.485, Loss = 417.901
[2018-06-05 01:06] Train Step 21550, Epoch 20.0, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -408.879, Loss = 417.619
[2018-06-05 01:06] Train Step 21575, Epoch 20.0, Batch Size = 256, Examples/Sec = 3876.49, Train LB = -428.950, Loss = 418.132
[2018-06-05 01:06] Train Step 21600, Epoch 20.0, Batch Size = 256, Examples/Sec = 3806.87, Train LB = -427.578, Loss = 419.399
Performance on test set:
  Test Lower Bound = -431.333, Test Loss = 431.333
[2018-06-05 01:06] Train Step 21625, Epoch 20.0, Batch Size = 256, Examples/Sec = 3799.81, Train LB = -424.984, Loss = 418.704
[2018-06-05 01:06] Train Step 21650, Epoch 20.0, Batch Size = 256, Examples/Sec = 3855.42, Train LB = -409.914, Loss = 417.904
[2018-06-05 01:06] Train Step 21675, Epoch 20.1, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -421.650, Loss = 418.203
[2018-06-05 01:06] Train Step 21700, Epoch 20.1, Batch Size = 256, Examples/Sec = 3807.54, Train LB = -437.623, Loss = 417.671
[2018-06-05 01:06] Train Step 21725, Epoch 20.1, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -417.447, Loss = 417.997
[2018-06-05 01:06] Train Step 21750, Epoch 20.1, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -410.117, Loss = 417.542
[2018-06-05 01:06] Train Step 21775, Epoch 20.2, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -425.960, Loss = 418.548
[2018-06-05 01:06] Train Step 21800, Epoch 20.2, Batch Size = 256, Examples/Sec = 3872.09, Train LB = -419.245, Loss = 419.766
Performance on test set:
  Test Lower Bound = -432.411, Test Loss = 432.411
[2018-06-05 01:06] Train Step 21825, Epoch 20.2, Batch Size = 256, Examples/Sec = 3851.93, Train LB = -408.849, Loss = 418.976
[2018-06-05 01:06] Train Step 21850, Epoch 20.2, Batch Size = 256, Examples/Sec = 3866.07, Train LB = -420.477, Loss = 418.575
[2018-06-05 01:06] Train Step 21875, Epoch 20.3, Batch Size = 256, Examples/Sec = 3802.85, Train LB = -409.225, Loss = 418.365
[2018-06-05 01:06] Train Step 21900, Epoch 20.3, Batch Size = 256, Examples/Sec = 3863.21, Train LB = -414.379, Loss = 418.220
[2018-06-05 01:06] Train Step 21925, Epoch 20.3, Batch Size = 256, Examples/Sec = 3862.16, Train LB = -412.299, Loss = 417.698
[2018-06-05 01:06] Train Step 21950, Epoch 20.3, Batch Size = 256, Examples/Sec = 3872.27, Train LB = -401.857, Loss = 417.778
[2018-06-05 01:06] Train Step 21975, Epoch 20.3, Batch Size = 256, Examples/Sec = 3847.49, Train LB = -417.295, Loss = 418.133
[2018-06-05 01:06] Train Step 22000, Epoch 20.4, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -429.215, Loss = 418.449
Performance on test set:
  Test Lower Bound = -431.066, Test Loss = 431.066
[2018-06-05 01:06] Train Step 22025, Epoch 20.4, Batch Size = 256, Examples/Sec = 3879.50, Train LB = -411.834, Loss = 418.338
[2018-06-05 01:06] Train Step 22050, Epoch 20.4, Batch Size = 256, Examples/Sec = 3846.50, Train LB = -418.789, Loss = 417.849
[2018-06-05 01:06] Train Step 22075, Epoch 20.4, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -414.440, Loss = 417.992
[2018-06-05 01:06] Train Step 22100, Epoch 20.5, Batch Size = 256, Examples/Sec = 3880.32, Train LB = -423.268, Loss = 417.759
[2018-06-05 01:07] Train Step 22125, Epoch 20.5, Batch Size = 256, Examples/Sec = 3865.15, Train LB = -412.493, Loss = 417.255
[2018-06-05 01:07] Train Step 22150, Epoch 20.5, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -416.806, Loss = 417.671
[2018-06-05 01:07] Train Step 22175, Epoch 20.5, Batch Size = 256, Examples/Sec = 3851.41, Train LB = -420.127, Loss = 417.990
[2018-06-05 01:07] Train Step 22200, Epoch 20.6, Batch Size = 256, Examples/Sec = 3827.07, Train LB = -423.563, Loss = 418.657
Performance on test set:
  Test Lower Bound = -431.763, Test Loss = 431.763
[2018-06-05 01:07] Train Step 22225, Epoch 20.6, Batch Size = 256, Examples/Sec = 3862.51, Train LB = -401.552, Loss = 418.354
[2018-06-05 01:07] Train Step 22250, Epoch 20.6, Batch Size = 256, Examples/Sec = 3877.02, Train LB = -408.223, Loss = 417.403
[2018-06-05 01:07] Train Step 22275, Epoch 20.6, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -408.449, Loss = 417.236
[2018-06-05 01:07] Train Step 22300, Epoch 20.6, Batch Size = 256, Examples/Sec = 3770.08, Train LB = -412.947, Loss = 416.991
[2018-06-05 01:07] Train Step 22325, Epoch 20.7, Batch Size = 256, Examples/Sec = 3861.41, Train LB = -406.006, Loss = 417.011
[2018-06-05 01:07] Train Step 22350, Epoch 20.7, Batch Size = 256, Examples/Sec = 3849.28, Train LB = -414.646, Loss = 417.625
[2018-06-05 01:07] Train Step 22375, Epoch 20.7, Batch Size = 256, Examples/Sec = 3864.16, Train LB = -414.693, Loss = 418.092
[2018-06-05 01:07] Train Step 22400, Epoch 20.7, Batch Size = 256, Examples/Sec = 3867.43, Train LB = -416.636, Loss = 418.749
Performance on test set:
  Test Lower Bound = -431.534, Test Loss = 431.534
[2018-06-05 01:07] Train Step 22425, Epoch 20.8, Batch Size = 256, Examples/Sec = 3879.14, Train LB = -422.660, Loss = 418.474
[2018-06-05 01:07] Train Step 22450, Epoch 20.8, Batch Size = 256, Examples/Sec = 3875.08, Train LB = -415.737, Loss = 417.619
[2018-06-05 01:07] Train Step 22475, Epoch 20.8, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -418.591, Loss = 417.464
[2018-06-05 01:07] Train Step 22500, Epoch 20.8, Batch Size = 256, Examples/Sec = 3875.50, Train LB = -426.343, Loss = 417.635
[2018-06-05 01:07] Train Step 22525, Epoch 20.9, Batch Size = 256, Examples/Sec = 3856.76, Train LB = -407.757, Loss = 417.128
[2018-06-05 01:07] Train Step 22550, Epoch 20.9, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -408.047, Loss = 417.109
[2018-06-05 01:07] Train Step 22575, Epoch 20.9, Batch Size = 256, Examples/Sec = 3868.82, Train LB = -425.639, Loss = 417.586
[2018-06-05 01:07] Train Step 22600, Epoch 20.9, Batch Size = 256, Examples/Sec = 3893.53, Train LB = -423.446, Loss = 418.412
Performance on test set:
  Test Lower Bound = -430.091, Test Loss = 430.091
[2018-06-05 01:07] Train Step 22625, Epoch 20.9, Batch Size = 256, Examples/Sec = 3821.81, Train LB = -408.794, Loss = 417.827
[2018-06-05 01:07] Train Step 22650, Epoch 21.0, Batch Size = 256, Examples/Sec = 3805.68, Train LB = -425.895, Loss = 417.486
[2018-06-05 01:07] Train Step 22675, Epoch 21.0, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -407.119, Loss = 417.203
[2018-06-05 01:07] Train Step 22700, Epoch 21.0, Batch Size = 256, Examples/Sec = 3859.42, Train LB = -419.785, Loss = 416.747
[2018-06-05 01:07] Train Step 22725, Epoch 21.0, Batch Size = 256, Examples/Sec = 3860.66, Train LB = -421.330, Loss = 416.881
[2018-06-05 01:07] Train Step 22750, Epoch 21.1, Batch Size = 256, Examples/Sec = 3847.78, Train LB = -422.247, Loss = 416.623
[2018-06-05 01:07] Train Step 22775, Epoch 21.1, Batch Size = 256, Examples/Sec = 3874.56, Train LB = -419.382, Loss = 417.028
[2018-06-05 01:07] Train Step 22800, Epoch 21.1, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -422.475, Loss = 418.537
Performance on test set:
  Test Lower Bound = -431.158, Test Loss = 431.158
[2018-06-05 01:08] Train Step 22825, Epoch 21.1, Batch Size = 256, Examples/Sec = 3853.16, Train LB = -424.013, Loss = 417.791
[2018-06-05 01:08] Train Step 22850, Epoch 21.2, Batch Size = 256, Examples/Sec = 3843.55, Train LB = -415.328, Loss = 417.431
[2018-06-05 01:08] Train Step 22875, Epoch 21.2, Batch Size = 256, Examples/Sec = 3847.76, Train LB = -412.932, Loss = 417.144
[2018-06-05 01:08] Train Step 22900, Epoch 21.2, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -410.927, Loss = 416.600
[2018-06-05 01:08] Train Step 22925, Epoch 21.2, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -416.001, Loss = 416.568
[2018-06-05 01:08] Train Step 22950, Epoch 21.2, Batch Size = 256, Examples/Sec = 3867.14, Train LB = -413.908, Loss = 416.165
[2018-06-05 01:08] Train Step 22975, Epoch 21.3, Batch Size = 256, Examples/Sec = 3860.30, Train LB = -419.357, Loss = 416.706
[2018-06-05 01:08] Train Step 23000, Epoch 21.3, Batch Size = 256, Examples/Sec = 3852.71, Train LB = -415.288, Loss = 418.276
Performance on test set:
  Test Lower Bound = -430.407, Test Loss = 430.407
[2018-06-05 01:08] Train Step 23025, Epoch 21.3, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -424.563, Loss = 417.150
[2018-06-05 01:08] Train Step 23050, Epoch 21.3, Batch Size = 256, Examples/Sec = 3849.90, Train LB = -408.395, Loss = 417.196
[2018-06-05 01:08] Train Step 23075, Epoch 21.4, Batch Size = 256, Examples/Sec = 3872.40, Train LB = -417.159, Loss = 416.828
[2018-06-05 01:08] Train Step 23100, Epoch 21.4, Batch Size = 256, Examples/Sec = 3859.38, Train LB = -411.679, Loss = 416.632
[2018-06-05 01:08] Train Step 23125, Epoch 21.4, Batch Size = 256, Examples/Sec = 3842.50, Train LB = -414.555, Loss = 416.466
[2018-06-05 01:08] Train Step 23150, Epoch 21.4, Batch Size = 256, Examples/Sec = 3796.31, Train LB = -418.517, Loss = 416.258
[2018-06-05 01:08] Train Step 23175, Epoch 21.5, Batch Size = 256, Examples/Sec = 3880.13, Train LB = -425.096, Loss = 416.919
[2018-06-05 01:08] Train Step 23200, Epoch 21.5, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -422.373, Loss = 418.188
Performance on test set:
  Test Lower Bound = -430.939, Test Loss = 430.939
[2018-06-05 01:08] Train Step 23225, Epoch 21.5, Batch Size = 256, Examples/Sec = 3795.08, Train LB = -418.159, Loss = 417.541
[2018-06-05 01:08] Train Step 23250, Epoch 21.5, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -417.862, Loss = 416.763
[2018-06-05 01:08] Train Step 23275, Epoch 21.6, Batch Size = 256, Examples/Sec = 3867.78, Train LB = -418.075, Loss = 416.524
[2018-06-05 01:08] Train Step 23300, Epoch 21.6, Batch Size = 256, Examples/Sec = 3879.78, Train LB = -415.516, Loss = 416.120
[2018-06-05 01:08] Train Step 23325, Epoch 21.6, Batch Size = 256, Examples/Sec = 3851.24, Train LB = -420.123, Loss = 416.004
[2018-06-05 01:08] Train Step 23350, Epoch 21.6, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -404.169, Loss = 416.197
[2018-06-05 01:08] Train Step 23375, Epoch 21.6, Batch Size = 256, Examples/Sec = 3854.56, Train LB = -411.212, Loss = 416.419
[2018-06-05 01:08] Train Step 23400, Epoch 21.7, Batch Size = 256, Examples/Sec = 3839.81, Train LB = -425.028, Loss = 417.551
Performance on test set:
  Test Lower Bound = -431.454, Test Loss = 431.454
[2018-06-05 01:08] Train Step 23425, Epoch 21.7, Batch Size = 256, Examples/Sec = 3875.37, Train LB = -420.144, Loss = 416.797
[2018-06-05 01:08] Train Step 23450, Epoch 21.7, Batch Size = 256, Examples/Sec = 3856.07, Train LB = -406.254, Loss = 416.487
[2018-06-05 01:08] Train Step 23475, Epoch 21.7, Batch Size = 256, Examples/Sec = 3818.67, Train LB = -422.555, Loss = 416.377
[2018-06-05 01:08] Train Step 23500, Epoch 21.8, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -417.667, Loss = 416.113
[2018-06-05 01:08] Train Step 23525, Epoch 21.8, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -413.226, Loss = 415.808
[2018-06-05 01:09] Train Step 23550, Epoch 21.8, Batch Size = 256, Examples/Sec = 3847.36, Train LB = -407.540, Loss = 416.035
[2018-06-05 01:09] Train Step 23575, Epoch 21.8, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -413.414, Loss = 416.178
[2018-06-05 01:09] Train Step 23600, Epoch 21.9, Batch Size = 256, Examples/Sec = 3793.15, Train LB = -433.557, Loss = 417.667
Performance on test set:
  Test Lower Bound = -432.233, Test Loss = 432.233
[2018-06-05 01:09] Train Step 23625, Epoch 21.9, Batch Size = 256, Examples/Sec = 3865.61, Train LB = -394.027, Loss = 417.293
[2018-06-05 01:09] Train Step 23650, Epoch 21.9, Batch Size = 256, Examples/Sec = 3861.81, Train LB = -406.546, Loss = 416.606
[2018-06-05 01:09] Train Step 23675, Epoch 21.9, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -411.073, Loss = 416.151
[2018-06-05 01:09] Train Step 23700, Epoch 21.9, Batch Size = 256, Examples/Sec = 3849.68, Train LB = -397.945, Loss = 416.175
[2018-06-05 01:09] Train Step 23725, Epoch 22.0, Batch Size = 256, Examples/Sec = 3871.92, Train LB = -417.896, Loss = 416.173
[2018-06-05 01:09] Train Step 23750, Epoch 22.0, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -417.127, Loss = 416.205
[2018-06-05 01:09] Train Step 23775, Epoch 22.0, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -419.577, Loss = 416.593
[2018-06-05 01:09] Train Step 23800, Epoch 22.0, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -425.315, Loss = 417.972
Performance on test set:
  Test Lower Bound = -431.667, Test Loss = 431.667
[2018-06-05 01:09] Train Step 23825, Epoch 22.1, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -407.125, Loss = 417.604
[2018-06-05 01:09] Train Step 23850, Epoch 22.1, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -416.044, Loss = 417.078
[2018-06-05 01:09] Train Step 23875, Epoch 22.1, Batch Size = 256, Examples/Sec = 3867.24, Train LB = -420.143, Loss = 416.809
[2018-06-05 01:09] Train Step 23900, Epoch 22.1, Batch Size = 256, Examples/Sec = 3867.78, Train LB = -420.472, Loss = 416.149
[2018-06-05 01:09] Train Step 23925, Epoch 22.2, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -416.668, Loss = 415.854
[2018-06-05 01:09] Train Step 23950, Epoch 22.2, Batch Size = 256, Examples/Sec = 3864.98, Train LB = -413.220, Loss = 415.712
[2018-06-05 01:09] Train Step 23975, Epoch 22.2, Batch Size = 256, Examples/Sec = 3865.61, Train LB = -415.075, Loss = 416.173
[2018-06-05 01:09] Train Step 24000, Epoch 22.2, Batch Size = 256, Examples/Sec = 3818.96, Train LB = -423.392, Loss = 417.015
Performance on test set:
  Test Lower Bound = -431.493, Test Loss = 431.493
[2018-06-05 01:09] Train Step 24025, Epoch 22.2, Batch Size = 256, Examples/Sec = 3795.91, Train LB = -402.405, Loss = 416.255
[2018-06-05 01:09] Train Step 24050, Epoch 22.3, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -413.827, Loss = 415.738
[2018-06-05 01:09] Train Step 24075, Epoch 22.3, Batch Size = 256, Examples/Sec = 3885.09, Train LB = -418.745, Loss = 415.447
[2018-06-05 01:09] Train Step 24100, Epoch 22.3, Batch Size = 256, Examples/Sec = 3819.07, Train LB = -418.270, Loss = 416.322
[2018-06-05 01:09] Train Step 24125, Epoch 22.3, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -405.816, Loss = 416.035
[2018-06-05 01:09] Train Step 24150, Epoch 22.4, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -425.864, Loss = 415.905
[2018-06-05 01:09] Train Step 24175, Epoch 22.4, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -432.370, Loss = 415.937
[2018-06-05 01:09] Train Step 24200, Epoch 22.4, Batch Size = 256, Examples/Sec = 3850.50, Train LB = -410.958, Loss = 416.961
Performance on test set:
  Test Lower Bound = -432.706, Test Loss = 432.706
[2018-06-05 01:09] Train Step 24225, Epoch 22.4, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -421.182, Loss = 416.298
[2018-06-05 01:10] Train Step 24250, Epoch 22.5, Batch Size = 256, Examples/Sec = 3866.85, Train LB = -410.512, Loss = 415.769
[2018-06-05 01:10] Train Step 24275, Epoch 22.5, Batch Size = 256, Examples/Sec = 3805.96, Train LB = -427.067, Loss = 415.343
[2018-06-05 01:10] Train Step 24300, Epoch 22.5, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -409.260, Loss = 415.709
[2018-06-05 01:10] Train Step 24325, Epoch 22.5, Batch Size = 256, Examples/Sec = 3870.18, Train LB = -410.622, Loss = 416.023
[2018-06-05 01:10] Train Step 24350, Epoch 22.5, Batch Size = 256, Examples/Sec = 3876.49, Train LB = -417.378, Loss = 415.853
[2018-06-05 01:10] Train Step 24375, Epoch 22.6, Batch Size = 256, Examples/Sec = 3849.74, Train LB = -411.314, Loss = 415.698
[2018-06-05 01:10] Train Step 24400, Epoch 22.6, Batch Size = 256, Examples/Sec = 3852.58, Train LB = -428.114, Loss = 417.136
Performance on test set:
  Test Lower Bound = -432.447, Test Loss = 432.447
[2018-06-05 01:10] Train Step 24425, Epoch 22.6, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -417.374, Loss = 416.487
[2018-06-05 01:10] Train Step 24450, Epoch 22.6, Batch Size = 256, Examples/Sec = 3886.75, Train LB = -417.183, Loss = 416.648
[2018-06-05 01:10] Train Step 24475, Epoch 22.7, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -414.468, Loss = 416.331
[2018-06-05 01:10] Train Step 24500, Epoch 22.7, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -415.588, Loss = 415.847
[2018-06-05 01:10] Train Step 24525, Epoch 22.7, Batch Size = 256, Examples/Sec = 3892.88, Train LB = -406.526, Loss = 415.574
[2018-06-05 01:10] Train Step 24550, Epoch 22.7, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -410.679, Loss = 415.350
[2018-06-05 01:10] Train Step 24575, Epoch 22.8, Batch Size = 256, Examples/Sec = 3819.30, Train LB = -427.339, Loss = 415.192
[2018-06-05 01:10] Train Step 24600, Epoch 22.8, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -430.055, Loss = 416.815
Performance on test set:
  Test Lower Bound = -432.617, Test Loss = 432.617
[2018-06-05 01:10] Train Step 24625, Epoch 22.8, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -410.975, Loss = 416.908
[2018-06-05 01:10] Train Step 24650, Epoch 22.8, Batch Size = 256, Examples/Sec = 3876.62, Train LB = -413.549, Loss = 416.293
[2018-06-05 01:10] Train Step 24675, Epoch 22.8, Batch Size = 256, Examples/Sec = 3864.74, Train LB = -408.656, Loss = 416.069
[2018-06-05 01:10] Train Step 24700, Epoch 22.9, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -407.191, Loss = 415.500
[2018-06-05 01:10] Train Step 24725, Epoch 22.9, Batch Size = 256, Examples/Sec = 3884.02, Train LB = -405.765, Loss = 415.441
[2018-06-05 01:10] Train Step 24750, Epoch 22.9, Batch Size = 256, Examples/Sec = 3872.28, Train LB = -416.405, Loss = 414.847
[2018-06-05 01:10] Train Step 24775, Epoch 22.9, Batch Size = 256, Examples/Sec = 3822.44, Train LB = -418.495, Loss = 415.237
[2018-06-05 01:10] Train Step 24800, Epoch 23.0, Batch Size = 256, Examples/Sec = 3879.97, Train LB = -427.685, Loss = 416.784
Performance on test set:
  Test Lower Bound = -431.384, Test Loss = 431.384
[2018-06-05 01:10] Train Step 24825, Epoch 23.0, Batch Size = 256, Examples/Sec = 3885.68, Train LB = -409.297, Loss = 416.325
[2018-06-05 01:10] Train Step 24850, Epoch 23.0, Batch Size = 256, Examples/Sec = 3866.37, Train LB = -408.915, Loss = 415.758
[2018-06-05 01:10] Train Step 24875, Epoch 23.0, Batch Size = 256, Examples/Sec = 3800.76, Train LB = -419.185, Loss = 415.850
[2018-06-05 01:10] Train Step 24900, Epoch 23.1, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -421.766, Loss = 415.342
[2018-06-05 01:10] Train Step 24925, Epoch 23.1, Batch Size = 256, Examples/Sec = 3797.37, Train LB = -408.794, Loss = 414.580
[2018-06-05 01:10] Train Step 24950, Epoch 23.1, Batch Size = 256, Examples/Sec = 3868.17, Train LB = -404.260, Loss = 414.704
[2018-06-05 01:10] Train Step 24975, Epoch 23.1, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -430.247, Loss = 415.172
[2018-06-05 01:11] Train Step 25000, Epoch 23.1, Batch Size = 256, Examples/Sec = 3847.02, Train LB = -418.113, Loss = 416.307
Performance on test set:
  Test Lower Bound = -430.777, Test Loss = 430.777
[2018-06-05 01:11] Train Step 25025, Epoch 23.2, Batch Size = 256, Examples/Sec = 3826.09, Train LB = -416.554, Loss = 415.540
[2018-06-05 01:11] Train Step 25050, Epoch 23.2, Batch Size = 256, Examples/Sec = 3861.99, Train LB = -408.422, Loss = 415.257
[2018-06-05 01:11] Train Step 25075, Epoch 23.2, Batch Size = 256, Examples/Sec = 3883.02, Train LB = -422.521, Loss = 415.207
[2018-06-05 01:11] Train Step 25100, Epoch 23.2, Batch Size = 256, Examples/Sec = 3882.84, Train LB = -418.446, Loss = 414.673
[2018-06-05 01:11] Train Step 25125, Epoch 23.3, Batch Size = 256, Examples/Sec = 3873.74, Train LB = -405.159, Loss = 414.764
[2018-06-05 01:11] Train Step 25150, Epoch 23.3, Batch Size = 256, Examples/Sec = 3858.85, Train LB = -424.868, Loss = 414.884
[2018-06-05 01:11] Train Step 25175, Epoch 23.3, Batch Size = 256, Examples/Sec = 3888.27, Train LB = -423.584, Loss = 415.346
[2018-06-05 01:11] Train Step 25200, Epoch 23.3, Batch Size = 256, Examples/Sec = 3875.61, Train LB = -434.045, Loss = 416.544
Performance on test set:
  Test Lower Bound = -431.110, Test Loss = 431.110
[2018-06-05 01:11] Train Step 25225, Epoch 23.4, Batch Size = 256, Examples/Sec = 3873.79, Train LB = -405.338, Loss = 416.088
[2018-06-05 01:11] Train Step 25250, Epoch 23.4, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -412.227, Loss = 415.635
[2018-06-05 01:11] Train Step 25275, Epoch 23.4, Batch Size = 256, Examples/Sec = 3868.07, Train LB = -418.375, Loss = 415.711
[2018-06-05 01:11] Train Step 25300, Epoch 23.4, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -424.577, Loss = 414.868
[2018-06-05 01:11] Train Step 25325, Epoch 23.4, Batch Size = 256, Examples/Sec = 3850.79, Train LB = -420.687, Loss = 414.851
[2018-06-05 01:11] Train Step 25350, Epoch 23.5, Batch Size = 256, Examples/Sec = 3841.76, Train LB = -410.284, Loss = 415.128
[2018-06-05 01:11] Train Step 25375, Epoch 23.5, Batch Size = 256, Examples/Sec = 3868.00, Train LB = -405.907, Loss = 415.167
[2018-06-05 01:11] Train Step 25400, Epoch 23.5, Batch Size = 256, Examples/Sec = 3798.22, Train LB = -413.579, Loss = 415.948
Performance on test set:
  Test Lower Bound = -431.359, Test Loss = 431.359
[2018-06-05 01:11] Train Step 25425, Epoch 23.5, Batch Size = 256, Examples/Sec = 3841.02, Train LB = -416.371, Loss = 415.819
[2018-06-05 01:11] Train Step 25450, Epoch 23.6, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -409.660, Loss = 415.367
[2018-06-05 01:11] Train Step 25475, Epoch 23.6, Batch Size = 256, Examples/Sec = 3872.75, Train LB = -408.198, Loss = 414.874
[2018-06-05 01:11] Train Step 25500, Epoch 23.6, Batch Size = 256, Examples/Sec = 3808.05, Train LB = -406.720, Loss = 414.701
[2018-06-05 01:11] Train Step 25525, Epoch 23.6, Batch Size = 256, Examples/Sec = 3861.17, Train LB = -420.987, Loss = 413.751
[2018-06-05 01:11] Train Step 25550, Epoch 23.7, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -406.802, Loss = 414.137
[2018-06-05 01:11] Train Step 25575, Epoch 23.7, Batch Size = 256, Examples/Sec = 3803.52, Train LB = -404.000, Loss = 414.639
[2018-06-05 01:11] Train Step 25600, Epoch 23.7, Batch Size = 256, Examples/Sec = 3841.29, Train LB = -423.177, Loss = 416.344
Performance on test set:
  Test Lower Bound = -430.398, Test Loss = 430.398
[2018-06-05 01:11] Train Step 25625, Epoch 23.7, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -417.858, Loss = 415.523
[2018-06-05 01:11] Train Step 25650, Epoch 23.8, Batch Size = 256, Examples/Sec = 3813.22, Train LB = -416.979, Loss = 415.063
[2018-06-05 01:12] Train Step 25675, Epoch 23.8, Batch Size = 256, Examples/Sec = 3861.30, Train LB = -421.612, Loss = 415.433
[2018-06-05 01:12] Train Step 25700, Epoch 23.8, Batch Size = 256, Examples/Sec = 3870.64, Train LB = -421.675, Loss = 415.395
[2018-06-05 01:12] Train Step 25725, Epoch 23.8, Batch Size = 256, Examples/Sec = 3842.39, Train LB = -398.659, Loss = 414.377
[2018-06-05 01:12] Train Step 25750, Epoch 23.8, Batch Size = 256, Examples/Sec = 3841.94, Train LB = -418.942, Loss = 414.376
[2018-06-05 01:12] Train Step 25775, Epoch 23.9, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -419.409, Loss = 415.128
[2018-06-05 01:12] Train Step 25800, Epoch 23.9, Batch Size = 256, Examples/Sec = 3866.32, Train LB = -413.230, Loss = 416.832
Performance on test set:
  Test Lower Bound = -431.170, Test Loss = 431.170
[2018-06-05 01:12] Train Step 25825, Epoch 23.9, Batch Size = 256, Examples/Sec = 3867.07, Train LB = -420.892, Loss = 415.901
[2018-06-05 01:12] Train Step 25850, Epoch 23.9, Batch Size = 256, Examples/Sec = 3846.10, Train LB = -406.055, Loss = 415.258
[2018-06-05 01:12] Train Step 25875, Epoch 24.0, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -407.785, Loss = 415.533
[2018-06-05 01:12] Train Step 25900, Epoch 24.0, Batch Size = 256, Examples/Sec = 3844.20, Train LB = -434.710, Loss = 414.980
[2018-06-05 01:12] Train Step 25925, Epoch 24.0, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -423.970, Loss = 415.169
[2018-06-05 01:12] Train Step 25950, Epoch 24.0, Batch Size = 256, Examples/Sec = 3821.29, Train LB = -417.643, Loss = 415.096
[2018-06-05 01:12] Train Step 25975, Epoch 24.1, Batch Size = 256, Examples/Sec = 3828.15, Train LB = -420.403, Loss = 415.052
[2018-06-05 01:12] Train Step 26000, Epoch 24.1, Batch Size = 256, Examples/Sec = 3874.44, Train LB = -424.216, Loss = 415.831
Performance on test set:
  Test Lower Bound = -431.914, Test Loss = 431.914
[2018-06-05 01:12] Train Step 26025, Epoch 24.1, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -411.401, Loss = 415.540
[2018-06-05 01:12] Train Step 26050, Epoch 24.1, Batch Size = 256, Examples/Sec = 3848.58, Train LB = -404.109, Loss = 414.912
[2018-06-05 01:12] Train Step 26075, Epoch 24.1, Batch Size = 256, Examples/Sec = 3808.00, Train LB = -408.630, Loss = 414.495
[2018-06-05 01:12] Train Step 26100, Epoch 24.2, Batch Size = 256, Examples/Sec = 3870.40, Train LB = -407.697, Loss = 414.542
[2018-06-05 01:12] Train Step 26125, Epoch 24.2, Batch Size = 256, Examples/Sec = 3825.01, Train LB = -413.125, Loss = 414.198
[2018-06-05 01:12] Train Step 26150, Epoch 24.2, Batch Size = 256, Examples/Sec = 3842.74, Train LB = -414.814, Loss = 414.697
[2018-06-05 01:12] Train Step 26175, Epoch 24.2, Batch Size = 256, Examples/Sec = 3813.10, Train LB = -416.297, Loss = 414.986
[2018-06-05 01:12] Train Step 26200, Epoch 24.3, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -411.163, Loss = 415.891
Performance on test set:
  Test Lower Bound = -431.776, Test Loss = 431.776
[2018-06-05 01:12] Train Step 26225, Epoch 24.3, Batch Size = 256, Examples/Sec = 3870.29, Train LB = -417.230, Loss = 415.347
[2018-06-05 01:12] Train Step 26250, Epoch 24.3, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -409.911, Loss = 414.798
[2018-06-05 01:12] Train Step 26275, Epoch 24.3, Batch Size = 256, Examples/Sec = 3873.15, Train LB = -413.758, Loss = 413.875
[2018-06-05 01:12] Train Step 26300, Epoch 24.4, Batch Size = 256, Examples/Sec = 3863.63, Train LB = -410.766, Loss = 413.539
[2018-06-05 01:12] Train Step 26325, Epoch 24.4, Batch Size = 256, Examples/Sec = 3883.19, Train LB = -424.418, Loss = 413.937
[2018-06-05 01:12] Train Step 26350, Epoch 24.4, Batch Size = 256, Examples/Sec = 3872.03, Train LB = -420.301, Loss = 414.195
[2018-06-05 01:12] Train Step 26375, Epoch 24.4, Batch Size = 256, Examples/Sec = 3851.02, Train LB = -434.034, Loss = 414.608
[2018-06-05 01:12] Train Step 26400, Epoch 24.4, Batch Size = 256, Examples/Sec = 3851.24, Train LB = -420.685, Loss = 416.253
Performance on test set:
  Test Lower Bound = -431.738, Test Loss = 431.738
[2018-06-05 01:13] Train Step 26425, Epoch 24.5, Batch Size = 256, Examples/Sec = 3878.02, Train LB = -399.776, Loss = 415.734
[2018-06-05 01:13] Train Step 26450, Epoch 24.5, Batch Size = 256, Examples/Sec = 3794.61, Train LB = -420.062, Loss = 414.711
[2018-06-05 01:13] Train Step 26475, Epoch 24.5, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -415.803, Loss = 414.752
[2018-06-05 01:13] Train Step 26500, Epoch 24.5, Batch Size = 256, Examples/Sec = 3858.33, Train LB = -415.798, Loss = 414.436
[2018-06-05 01:13] Train Step 26525, Epoch 24.6, Batch Size = 256, Examples/Sec = 3857.57, Train LB = -424.018, Loss = 414.242
[2018-06-05 01:13] Train Step 26550, Epoch 24.6, Batch Size = 256, Examples/Sec = 3866.25, Train LB = -410.622, Loss = 414.910
[2018-06-05 01:13] Train Step 26575, Epoch 24.6, Batch Size = 256, Examples/Sec = 3876.56, Train LB = -409.132, Loss = 414.825
[2018-06-05 01:13] Train Step 26600, Epoch 24.6, Batch Size = 256, Examples/Sec = 3892.34, Train LB = -413.455, Loss = 415.669
Performance on test set:
  Test Lower Bound = -431.900, Test Loss = 431.900
[2018-06-05 01:13] Train Step 26625, Epoch 24.7, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -411.514, Loss = 414.932
[2018-06-05 01:13] Train Step 26650, Epoch 24.7, Batch Size = 256, Examples/Sec = 3888.93, Train LB = -406.256, Loss = 414.602
[2018-06-05 01:13] Train Step 26675, Epoch 24.7, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -421.907, Loss = 413.944
[2018-06-05 01:13] Train Step 26700, Epoch 24.7, Batch Size = 256, Examples/Sec = 3859.48, Train LB = -417.612, Loss = 413.456
[2018-06-05 01:13] Train Step 26725, Epoch 24.7, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -406.693, Loss = 413.344
[2018-06-05 01:13] Train Step 26750, Epoch 24.8, Batch Size = 256, Examples/Sec = 3804.37, Train LB = -411.475, Loss = 413.484
[2018-06-05 01:13] Train Step 26775, Epoch 24.8, Batch Size = 256, Examples/Sec = 3849.86, Train LB = -408.073, Loss = 413.763
[2018-06-05 01:13] Train Step 26800, Epoch 24.8, Batch Size = 256, Examples/Sec = 3878.73, Train LB = -440.625, Loss = 414.731
Performance on test set:
  Test Lower Bound = -433.390, Test Loss = 433.390
[2018-06-05 01:13] Train Step 26825, Epoch 24.8, Batch Size = 256, Examples/Sec = 3810.93, Train LB = -406.845, Loss = 414.832
[2018-06-05 01:13] Train Step 26850, Epoch 24.9, Batch Size = 256, Examples/Sec = 3858.85, Train LB = -417.253, Loss = 414.091
[2018-06-05 01:13] Train Step 26875, Epoch 24.9, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -402.912, Loss = 413.423
[2018-06-05 01:13] Train Step 26900, Epoch 24.9, Batch Size = 256, Examples/Sec = 3867.76, Train LB = -422.845, Loss = 412.868
[2018-06-05 01:13] Train Step 26925, Epoch 24.9, Batch Size = 256, Examples/Sec = 3872.40, Train LB = -408.927, Loss = 413.210
[2018-06-05 01:13] Train Step 26950, Epoch 25.0, Batch Size = 256, Examples/Sec = 3874.44, Train LB = -419.629, Loss = 413.331
[2018-06-05 01:13] Train Step 26975, Epoch 25.0, Batch Size = 256, Examples/Sec = 3794.27, Train LB = -421.630, Loss = 413.663
[2018-06-05 01:13] Train Step 27000, Epoch 25.0, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -418.809, Loss = 415.428
Performance on test set:
  Test Lower Bound = -431.508, Test Loss = 431.508
[2018-06-05 01:13] Train Step 27025, Epoch 25.0, Batch Size = 256, Examples/Sec = 3882.73, Train LB = -417.476, Loss = 414.890
[2018-06-05 01:13] Train Step 27050, Epoch 25.0, Batch Size = 256, Examples/Sec = 3881.20, Train LB = -411.088, Loss = 414.138
[2018-06-05 01:13] Train Step 27075, Epoch 25.1, Batch Size = 256, Examples/Sec = 3805.27, Train LB = -407.097, Loss = 414.059
[2018-06-05 01:13] Train Step 27100, Epoch 25.1, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -414.063, Loss = 413.624
[2018-06-05 01:14] Train Step 27125, Epoch 25.1, Batch Size = 256, Examples/Sec = 3859.48, Train LB = -410.642, Loss = 413.470
[2018-06-05 01:14] Train Step 27150, Epoch 25.1, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -410.673, Loss = 413.968
[2018-06-05 01:14] Train Step 27175, Epoch 25.2, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -413.867, Loss = 414.209
[2018-06-05 01:14] Train Step 27200, Epoch 25.2, Batch Size = 256, Examples/Sec = 3795.68, Train LB = -420.871, Loss = 415.532
Performance on test set:
  Test Lower Bound = -432.521, Test Loss = 432.521
[2018-06-05 01:14] Train Step 27225, Epoch 25.2, Batch Size = 256, Examples/Sec = 3876.56, Train LB = -414.351, Loss = 414.394
[2018-06-05 01:14] Train Step 27250, Epoch 25.2, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -405.605, Loss = 414.092
[2018-06-05 01:14] Train Step 27275, Epoch 25.3, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -430.177, Loss = 413.431
[2018-06-05 01:14] Train Step 27300, Epoch 25.3, Batch Size = 256, Examples/Sec = 3709.13, Train LB = -409.004, Loss = 413.411
[2018-06-05 01:14] Train Step 27325, Epoch 25.3, Batch Size = 256, Examples/Sec = 3865.61, Train LB = -428.923, Loss = 412.880
[2018-06-05 01:14] Train Step 27350, Epoch 25.3, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -406.358, Loss = 413.289
[2018-06-05 01:14] Train Step 27375, Epoch 25.3, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -418.547, Loss = 413.562
[2018-06-05 01:14] Train Step 27400, Epoch 25.4, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -425.126, Loss = 415.509
Performance on test set:
  Test Lower Bound = -432.548, Test Loss = 432.548
[2018-06-05 01:14] Train Step 27425, Epoch 25.4, Batch Size = 256, Examples/Sec = 3882.14, Train LB = -410.408, Loss = 414.600
[2018-06-05 01:14] Train Step 27450, Epoch 25.4, Batch Size = 256, Examples/Sec = 3849.45, Train LB = -410.879, Loss = 414.128
[2018-06-05 01:14] Train Step 27475, Epoch 25.4, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -413.217, Loss = 414.197
[2018-06-05 01:14] Train Step 27500, Epoch 25.5, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -405.658, Loss = 413.419
[2018-06-05 01:14] Train Step 27525, Epoch 25.5, Batch Size = 256, Examples/Sec = 3812.25, Train LB = -423.196, Loss = 412.989
[2018-06-05 01:14] Train Step 27550, Epoch 25.5, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -416.563, Loss = 413.084
[2018-06-05 01:14] Train Step 27575, Epoch 25.5, Batch Size = 256, Examples/Sec = 3875.74, Train LB = -422.476, Loss = 413.728
[2018-06-05 01:14] Train Step 27600, Epoch 25.6, Batch Size = 256, Examples/Sec = 3839.07, Train LB = -427.403, Loss = 415.262
Performance on test set:
  Test Lower Bound = -432.254, Test Loss = 432.254
[2018-06-05 01:14] Train Step 27625, Epoch 25.6, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -428.074, Loss = 414.841
[2018-06-05 01:14] Train Step 27650, Epoch 25.6, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -397.444, Loss = 414.840
[2018-06-05 01:14] Train Step 27675, Epoch 25.6, Batch Size = 256, Examples/Sec = 3833.31, Train LB = -405.980, Loss = 413.921
[2018-06-05 01:14] Train Step 27700, Epoch 25.6, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -416.592, Loss = 413.701
[2018-06-05 01:14] Train Step 27725, Epoch 25.7, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -419.310, Loss = 412.859
[2018-06-05 01:14] Train Step 27750, Epoch 25.7, Batch Size = 256, Examples/Sec = 3868.46, Train LB = -412.306, Loss = 412.862
[2018-06-05 01:14] Train Step 27775, Epoch 25.7, Batch Size = 256, Examples/Sec = 3803.35, Train LB = -418.751, Loss = 413.369
[2018-06-05 01:14] Train Step 27800, Epoch 25.7, Batch Size = 256, Examples/Sec = 3848.70, Train LB = -436.269, Loss = 414.453
Performance on test set:
  Test Lower Bound = -431.903, Test Loss = 431.903
[2018-06-05 01:15] Train Step 27825, Epoch 25.8, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -426.416, Loss = 413.492
[2018-06-05 01:15] Train Step 27850, Epoch 25.8, Batch Size = 256, Examples/Sec = 3813.84, Train LB = -416.357, Loss = 413.343
[2018-06-05 01:15] Train Step 27875, Epoch 25.8, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -403.271, Loss = 413.107
[2018-06-05 01:15] Train Step 27900, Epoch 25.8, Batch Size = 256, Examples/Sec = 3855.54, Train LB = -417.272, Loss = 413.056
[2018-06-05 01:15] Train Step 27925, Epoch 25.9, Batch Size = 256, Examples/Sec = 3872.10, Train LB = -416.257, Loss = 413.033
[2018-06-05 01:15] Train Step 27950, Epoch 25.9, Batch Size = 256, Examples/Sec = 3868.94, Train LB = -411.896, Loss = 413.023
[2018-06-05 01:15] Train Step 27975, Epoch 25.9, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -425.162, Loss = 413.476
[2018-06-05 01:15] Train Step 28000, Epoch 25.9, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -418.540, Loss = 414.419
Performance on test set:
  Test Lower Bound = -432.905, Test Loss = 432.905
[2018-06-05 01:15] Train Step 28025, Epoch 25.9, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -388.714, Loss = 414.011
[2018-06-05 01:15] Train Step 28050, Epoch 26.0, Batch Size = 256, Examples/Sec = 3872.05, Train LB = -413.579, Loss = 413.099
[2018-06-05 01:15] Train Step 28075, Epoch 26.0, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -396.803, Loss = 412.987
[2018-06-05 01:15] Train Step 28100, Epoch 26.0, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -415.124, Loss = 412.981
[2018-06-05 01:15] Train Step 28125, Epoch 26.0, Batch Size = 256, Examples/Sec = 3862.35, Train LB = -414.582, Loss = 412.973
[2018-06-05 01:15] Train Step 28150, Epoch 26.1, Batch Size = 256, Examples/Sec = 3849.90, Train LB = -400.408, Loss = 413.153
[2018-06-05 01:15] Train Step 28175, Epoch 26.1, Batch Size = 256, Examples/Sec = 3882.90, Train LB = -421.266, Loss = 413.499
[2018-06-05 01:15] Train Step 28200, Epoch 26.1, Batch Size = 256, Examples/Sec = 3817.37, Train LB = -425.255, Loss = 414.201
Performance on test set:
  Test Lower Bound = -431.796, Test Loss = 431.796
[2018-06-05 01:15] Train Step 28225, Epoch 26.1, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -410.470, Loss = 414.008
[2018-06-05 01:15] Train Step 28250, Epoch 26.2, Batch Size = 256, Examples/Sec = 3858.27, Train LB = -416.126, Loss = 413.653
[2018-06-05 01:15] Train Step 28275, Epoch 26.2, Batch Size = 256, Examples/Sec = 3821.69, Train LB = -399.088, Loss = 412.968
[2018-06-05 01:15] Train Step 28300, Epoch 26.2, Batch Size = 256, Examples/Sec = 3863.80, Train LB = -413.519, Loss = 412.455
[2018-06-05 01:15] Train Step 28325, Epoch 26.2, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -403.084, Loss = 412.496
[2018-06-05 01:15] Train Step 28350, Epoch 26.2, Batch Size = 256, Examples/Sec = 3846.22, Train LB = -425.575, Loss = 412.509
[2018-06-05 01:15] Train Step 28375, Epoch 26.3, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -414.367, Loss = 413.005
[2018-06-05 01:15] Train Step 28400, Epoch 26.3, Batch Size = 256, Examples/Sec = 3873.21, Train LB = -430.678, Loss = 414.467
Performance on test set:
  Test Lower Bound = -432.861, Test Loss = 432.861
[2018-06-05 01:15] Train Step 28425, Epoch 26.3, Batch Size = 256, Examples/Sec = 3880.15, Train LB = -411.093, Loss = 413.980
[2018-06-05 01:15] Train Step 28450, Epoch 26.3, Batch Size = 256, Examples/Sec = 3870.64, Train LB = -411.293, Loss = 413.101
[2018-06-05 01:15] Train Step 28475, Epoch 26.4, Batch Size = 256, Examples/Sec = 3809.93, Train LB = -401.818, Loss = 412.839
[2018-06-05 01:15] Train Step 28500, Epoch 26.4, Batch Size = 256, Examples/Sec = 3855.18, Train LB = -411.559, Loss = 412.423
[2018-06-05 01:15] Train Step 28525, Epoch 26.4, Batch Size = 256, Examples/Sec = 3864.44, Train LB = -410.160, Loss = 412.058
[2018-06-05 01:16] Train Step 28550, Epoch 26.4, Batch Size = 256, Examples/Sec = 3884.32, Train LB = -417.588, Loss = 412.510
[2018-06-05 01:16] Train Step 28575, Epoch 26.5, Batch Size = 256, Examples/Sec = 3879.91, Train LB = -409.677, Loss = 413.261
[2018-06-05 01:16] Train Step 28600, Epoch 26.5, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -419.339, Loss = 414.078
Performance on test set:
  Test Lower Bound = -433.431, Test Loss = 433.431
[2018-06-05 01:16] Train Step 28625, Epoch 26.5, Batch Size = 256, Examples/Sec = 3797.32, Train LB = -423.767, Loss = 413.380
[2018-06-05 01:16] Train Step 28650, Epoch 26.5, Batch Size = 256, Examples/Sec = 3870.99, Train LB = -408.681, Loss = 413.258
[2018-06-05 01:16] Train Step 28675, Epoch 26.6, Batch Size = 256, Examples/Sec = 3876.97, Train LB = -408.593, Loss = 413.556
[2018-06-05 01:16] Train Step 28700, Epoch 26.6, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -392.581, Loss = 412.706
[2018-06-05 01:16] Train Step 28725, Epoch 26.6, Batch Size = 256, Examples/Sec = 3849.16, Train LB = -414.165, Loss = 412.248
[2018-06-05 01:16] Train Step 28750, Epoch 26.6, Batch Size = 256, Examples/Sec = 3872.05, Train LB = -417.416, Loss = 412.488
[2018-06-05 01:16] Train Step 28775, Epoch 26.6, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -418.632, Loss = 412.464
[2018-06-05 01:16] Train Step 28800, Epoch 26.7, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -426.599, Loss = 413.652
Performance on test set:
  Test Lower Bound = -432.448, Test Loss = 432.448
[2018-06-05 01:16] Train Step 28825, Epoch 26.7, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -405.358, Loss = 412.939
[2018-06-05 01:16] Train Step 28850, Epoch 26.7, Batch Size = 256, Examples/Sec = 3846.62, Train LB = -415.646, Loss = 412.317
[2018-06-05 01:16] Train Step 28875, Epoch 26.7, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -412.603, Loss = 412.181
[2018-06-05 01:16] Train Step 28900, Epoch 26.8, Batch Size = 256, Examples/Sec = 3867.14, Train LB = -404.068, Loss = 411.553
[2018-06-05 01:16] Train Step 28925, Epoch 26.8, Batch Size = 256, Examples/Sec = 3820.33, Train LB = -415.894, Loss = 411.068
[2018-06-05 01:16] Train Step 28950, Epoch 26.8, Batch Size = 256, Examples/Sec = 3856.11, Train LB = -415.565, Loss = 411.946
[2018-06-05 01:16] Train Step 28975, Epoch 26.8, Batch Size = 256, Examples/Sec = 3849.10, Train LB = -422.069, Loss = 412.297
[2018-06-05 01:16] Train Step 29000, Epoch 26.9, Batch Size = 256, Examples/Sec = 3818.67, Train LB = -405.482, Loss = 413.837
Performance on test set:
  Test Lower Bound = -434.111, Test Loss = 434.111
[2018-06-05 01:16] Train Step 29025, Epoch 26.9, Batch Size = 256, Examples/Sec = 3757.47, Train LB = -409.502, Loss = 412.990
[2018-06-05 01:16] Train Step 29050, Epoch 26.9, Batch Size = 256, Examples/Sec = 3883.32, Train LB = -426.405, Loss = 412.595
[2018-06-05 01:16] Train Step 29075, Epoch 26.9, Batch Size = 256, Examples/Sec = 3823.35, Train LB = -399.224, Loss = 411.962
[2018-06-05 01:16] Train Step 29100, Epoch 26.9, Batch Size = 256, Examples/Sec = 3849.21, Train LB = -420.776, Loss = 412.113
[2018-06-05 01:16] Train Step 29125, Epoch 27.0, Batch Size = 256, Examples/Sec = 3868.02, Train LB = -407.743, Loss = 411.927
[2018-06-05 01:16] Train Step 29150, Epoch 27.0, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -420.228, Loss = 411.974
[2018-06-05 01:16] Train Step 29175, Epoch 27.0, Batch Size = 256, Examples/Sec = 3833.60, Train LB = -420.572, Loss = 412.622
[2018-06-05 01:16] Train Step 29200, Epoch 27.0, Batch Size = 256, Examples/Sec = 3871.46, Train LB = -414.711, Loss = 413.634
Performance on test set:
  Test Lower Bound = -432.133, Test Loss = 432.133
[2018-06-05 01:16] Train Step 29225, Epoch 27.1, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -399.184, Loss = 413.319
[2018-06-05 01:17] Train Step 29250, Epoch 27.1, Batch Size = 256, Examples/Sec = 3899.52, Train LB = -409.595, Loss = 413.315
[2018-06-05 01:17] Train Step 29275, Epoch 27.1, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -410.211, Loss = 412.563
[2018-06-05 01:17] Train Step 29300, Epoch 27.1, Batch Size = 256, Examples/Sec = 3805.77, Train LB = -408.090, Loss = 412.409
[2018-06-05 01:17] Train Step 29325, Epoch 27.2, Batch Size = 256, Examples/Sec = 3845.74, Train LB = -403.981, Loss = 411.435
[2018-06-05 01:17] Train Step 29350, Epoch 27.2, Batch Size = 256, Examples/Sec = 3876.49, Train LB = -431.752, Loss = 411.353
[2018-06-05 01:17] Train Step 29375, Epoch 27.2, Batch Size = 256, Examples/Sec = 3860.89, Train LB = -418.741, Loss = 413.140
[2018-06-05 01:17] Train Step 29400, Epoch 27.2, Batch Size = 256, Examples/Sec = 3798.27, Train LB = -418.141, Loss = 414.506
Performance on test set:
  Test Lower Bound = -432.474, Test Loss = 432.474
[2018-06-05 01:17] Train Step 29425, Epoch 27.2, Batch Size = 256, Examples/Sec = 3870.57, Train LB = -409.067, Loss = 413.552
[2018-06-05 01:17] Train Step 29450, Epoch 27.3, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -412.339, Loss = 413.555
[2018-06-05 01:17] Train Step 29475, Epoch 27.3, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -418.631, Loss = 413.209
[2018-06-05 01:17] Train Step 29500, Epoch 27.3, Batch Size = 256, Examples/Sec = 3804.88, Train LB = -406.126, Loss = 412.323
[2018-06-05 01:17] Train Step 29525, Epoch 27.3, Batch Size = 256, Examples/Sec = 3864.26, Train LB = -400.969, Loss = 412.173
[2018-06-05 01:17] Train Step 29550, Epoch 27.4, Batch Size = 256, Examples/Sec = 3831.88, Train LB = -420.845, Loss = 412.176
[2018-06-05 01:17] Train Step 29575, Epoch 27.4, Batch Size = 256, Examples/Sec = 3832.51, Train LB = -428.801, Loss = 411.889
[2018-06-05 01:17] Train Step 29600, Epoch 27.4, Batch Size = 256, Examples/Sec = 3873.33, Train LB = -416.489, Loss = 413.744
Performance on test set:
  Test Lower Bound = -432.805, Test Loss = 432.805
[2018-06-05 01:17] Train Step 29625, Epoch 27.4, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -415.013, Loss = 413.214
[2018-06-05 01:17] Train Step 29650, Epoch 27.5, Batch Size = 256, Examples/Sec = 3879.25, Train LB = -416.086, Loss = 412.872
[2018-06-05 01:17] Train Step 29675, Epoch 27.5, Batch Size = 256, Examples/Sec = 3876.91, Train LB = -413.745, Loss = 412.096
[2018-06-05 01:17] Train Step 29700, Epoch 27.5, Batch Size = 256, Examples/Sec = 3863.80, Train LB = -407.627, Loss = 412.501
[2018-06-05 01:17] Train Step 29725, Epoch 27.5, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -420.939, Loss = 411.832
[2018-06-05 01:17] Train Step 29750, Epoch 27.5, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -409.690, Loss = 411.738
[2018-06-05 01:17] Train Step 29775, Epoch 27.6, Batch Size = 256, Examples/Sec = 3843.10, Train LB = -421.566, Loss = 412.047
[2018-06-05 01:17] Train Step 29800, Epoch 27.6, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -420.980, Loss = 413.738
Performance on test set:
  Test Lower Bound = -432.238, Test Loss = 432.238
[2018-06-05 01:17] Train Step 29825, Epoch 27.6, Batch Size = 256, Examples/Sec = 3844.36, Train LB = -418.235, Loss = 412.981
[2018-06-05 01:17] Train Step 29850, Epoch 27.6, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -415.848, Loss = 412.444
[2018-06-05 01:17] Train Step 29875, Epoch 27.7, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -410.029, Loss = 412.146
[2018-06-05 01:17] Train Step 29900, Epoch 27.7, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -408.820, Loss = 411.292
[2018-06-05 01:17] Train Step 29925, Epoch 27.7, Batch Size = 256, Examples/Sec = 3886.20, Train LB = -413.920, Loss = 410.512
[2018-06-05 01:17] Train Step 29950, Epoch 27.7, Batch Size = 256, Examples/Sec = 3866.66, Train LB = -408.992, Loss = 411.183
[2018-06-05 01:17] Train Step 29975, Epoch 27.8, Batch Size = 256, Examples/Sec = 3807.95, Train LB = -423.076, Loss = 411.952
[2018-06-05 01:18] Train Step 30000, Epoch 27.8, Batch Size = 256, Examples/Sec = 3881.62, Train LB = -423.664, Loss = 413.243
Performance on test set:
  Test Lower Bound = -432.632, Test Loss = 432.632
[2018-06-05 01:18] Train Step 30025, Epoch 27.8, Batch Size = 256, Examples/Sec = 3859.27, Train LB = -419.652, Loss = 412.467
[2018-06-05 01:18] Train Step 30050, Epoch 27.8, Batch Size = 256, Examples/Sec = 3885.50, Train LB = -396.739, Loss = 412.123
[2018-06-05 01:18] Train Step 30075, Epoch 27.8, Batch Size = 256, Examples/Sec = 3816.84, Train LB = -418.565, Loss = 411.062
[2018-06-05 01:18] Train Step 30100, Epoch 27.9, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -410.028, Loss = 411.416
[2018-06-05 01:18] Train Step 30125, Epoch 27.9, Batch Size = 256, Examples/Sec = 3878.31, Train LB = -409.225, Loss = 411.309
[2018-06-05 01:18] Train Step 30150, Epoch 27.9, Batch Size = 256, Examples/Sec = 3847.20, Train LB = -410.860, Loss = 411.417
[2018-06-05 01:18] Train Step 30175, Epoch 27.9, Batch Size = 256, Examples/Sec = 3815.02, Train LB = -416.028, Loss = 411.652
[2018-06-05 01:18] Train Step 30200, Epoch 28.0, Batch Size = 256, Examples/Sec = 3858.55, Train LB = -420.440, Loss = 412.717
Performance on test set:
  Test Lower Bound = -432.696, Test Loss = 432.696
[2018-06-05 01:18] Train Step 30225, Epoch 28.0, Batch Size = 256, Examples/Sec = 3878.37, Train LB = -407.620, Loss = 412.080
[2018-06-05 01:18] Train Step 30250, Epoch 28.0, Batch Size = 256, Examples/Sec = 3798.56, Train LB = -421.039, Loss = 411.665
[2018-06-05 01:18] Train Step 30275, Epoch 28.0, Batch Size = 256, Examples/Sec = 3874.86, Train LB = -406.650, Loss = 411.159
[2018-06-05 01:18] Train Step 30300, Epoch 28.1, Batch Size = 256, Examples/Sec = 3862.46, Train LB = -405.313, Loss = 410.707
[2018-06-05 01:18] Train Step 30325, Epoch 28.1, Batch Size = 256, Examples/Sec = 3849.10, Train LB = -409.096, Loss = 410.763
[2018-06-05 01:18] Train Step 30350, Epoch 28.1, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -402.357, Loss = 411.021
[2018-06-05 01:18] Train Step 30375, Epoch 28.1, Batch Size = 256, Examples/Sec = 3869.58, Train LB = -420.339, Loss = 412.104
[2018-06-05 01:18] Train Step 30400, Epoch 28.1, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -429.467, Loss = 413.969
Performance on test set:
  Test Lower Bound = -433.438, Test Loss = 433.438
[2018-06-05 01:18] Train Step 30425, Epoch 28.2, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -402.928, Loss = 413.549
[2018-06-05 01:18] Train Step 30450, Epoch 28.2, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -418.676, Loss = 412.837
[2018-06-05 01:18] Train Step 30475, Epoch 28.2, Batch Size = 256, Examples/Sec = 3867.07, Train LB = -404.918, Loss = 412.492
[2018-06-05 01:18] Train Step 30500, Epoch 28.2, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -421.589, Loss = 411.249
[2018-06-05 01:18] Train Step 30525, Epoch 28.3, Batch Size = 256, Examples/Sec = 3822.90, Train LB = -411.517, Loss = 410.808
[2018-06-05 01:18] Train Step 30550, Epoch 28.3, Batch Size = 256, Examples/Sec = 3808.39, Train LB = -410.788, Loss = 410.999
[2018-06-05 01:18] Train Step 30575, Epoch 28.3, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -416.988, Loss = 411.667
[2018-06-05 01:18] Train Step 30600, Epoch 28.3, Batch Size = 256, Examples/Sec = 3860.26, Train LB = -409.306, Loss = 413.198
Performance on test set:
  Test Lower Bound = -433.843, Test Loss = 433.843
[2018-06-05 01:18] Train Step 30625, Epoch 28.4, Batch Size = 256, Examples/Sec = 3864.84, Train LB = -397.319, Loss = 412.876
[2018-06-05 01:18] Train Step 30650, Epoch 28.4, Batch Size = 256, Examples/Sec = 3799.58, Train LB = -405.685, Loss = 412.089
[2018-06-05 01:19] Train Step 30675, Epoch 28.4, Batch Size = 256, Examples/Sec = 3874.27, Train LB = -394.049, Loss = 412.006
[2018-06-05 01:19] Train Step 30700, Epoch 28.4, Batch Size = 256, Examples/Sec = 3848.76, Train LB = -401.721, Loss = 411.303
[2018-06-05 01:19] Train Step 30725, Epoch 28.4, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -416.654, Loss = 410.788
[2018-06-05 01:19] Train Step 30750, Epoch 28.5, Batch Size = 256, Examples/Sec = 3862.64, Train LB = -413.334, Loss = 410.786
[2018-06-05 01:19] Train Step 30775, Epoch 28.5, Batch Size = 256, Examples/Sec = 3866.65, Train LB = -416.630, Loss = 411.036
[2018-06-05 01:19] Train Step 30800, Epoch 28.5, Batch Size = 256, Examples/Sec = 3859.13, Train LB = -421.725, Loss = 412.480
Performance on test set:
  Test Lower Bound = -433.607, Test Loss = 433.607
[2018-06-05 01:19] Train Step 30825, Epoch 28.5, Batch Size = 256, Examples/Sec = 3817.25, Train LB = -422.466, Loss = 411.970
[2018-06-05 01:19] Train Step 30850, Epoch 28.6, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -419.518, Loss = 411.528
[2018-06-05 01:19] Train Step 30875, Epoch 28.6, Batch Size = 256, Examples/Sec = 3839.80, Train LB = -412.040, Loss = 411.131
[2018-06-05 01:19] Train Step 30900, Epoch 28.6, Batch Size = 256, Examples/Sec = 3846.22, Train LB = -421.649, Loss = 411.017
[2018-06-05 01:19] Train Step 30925, Epoch 28.6, Batch Size = 256, Examples/Sec = 3872.33, Train LB = -418.371, Loss = 410.826
[2018-06-05 01:19] Train Step 30950, Epoch 28.7, Batch Size = 256, Examples/Sec = 3874.74, Train LB = -406.612, Loss = 410.706
[2018-06-05 01:19] Train Step 30975, Epoch 28.7, Batch Size = 256, Examples/Sec = 3890.23, Train LB = -421.118, Loss = 411.744
[2018-06-05 01:19] Train Step 31000, Epoch 28.7, Batch Size = 256, Examples/Sec = 3877.79, Train LB = -424.172, Loss = 413.305
Performance on test set:
  Test Lower Bound = -432.443, Test Loss = 432.443
[2018-06-05 01:19] Train Step 31025, Epoch 28.7, Batch Size = 256, Examples/Sec = 3865.97, Train LB = -408.420, Loss = 413.311
[2018-06-05 01:19] Train Step 31050, Epoch 28.8, Batch Size = 256, Examples/Sec = 3878.68, Train LB = -427.369, Loss = 412.107
[2018-06-05 01:19] Train Step 31075, Epoch 28.8, Batch Size = 256, Examples/Sec = 3847.71, Train LB = -414.766, Loss = 411.561
[2018-06-05 01:19] Train Step 31100, Epoch 28.8, Batch Size = 256, Examples/Sec = 3855.88, Train LB = -418.570, Loss = 411.598
[2018-06-05 01:19] Train Step 31125, Epoch 28.8, Batch Size = 256, Examples/Sec = 3846.44, Train LB = -399.141, Loss = 411.384
[2018-06-05 01:19] Train Step 31150, Epoch 28.8, Batch Size = 256, Examples/Sec = 3867.19, Train LB = -391.861, Loss = 411.088
[2018-06-05 01:19] Train Step 31175, Epoch 28.9, Batch Size = 256, Examples/Sec = 3862.81, Train LB = -421.631, Loss = 411.216
[2018-06-05 01:19] Train Step 31200, Epoch 28.9, Batch Size = 256, Examples/Sec = 3873.21, Train LB = -432.666, Loss = 412.812
Performance on test set:
  Test Lower Bound = -434.056, Test Loss = 434.056
[2018-06-05 01:19] Train Step 31225, Epoch 28.9, Batch Size = 256, Examples/Sec = 3811.68, Train LB = -406.208, Loss = 412.123
[2018-06-05 01:19] Train Step 31250, Epoch 28.9, Batch Size = 256, Examples/Sec = 3882.14, Train LB = -405.936, Loss = 412.615
[2018-06-05 01:19] Train Step 31275, Epoch 29.0, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -398.920, Loss = 412.138
[2018-06-05 01:19] Train Step 31300, Epoch 29.0, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -417.595, Loss = 411.514
[2018-06-05 01:19] Train Step 31325, Epoch 29.0, Batch Size = 256, Examples/Sec = 3885.03, Train LB = -402.042, Loss = 410.568
[2018-06-05 01:19] Train Step 31350, Epoch 29.0, Batch Size = 256, Examples/Sec = 3868.70, Train LB = -414.389, Loss = 410.988
[2018-06-05 01:19] Train Step 31375, Epoch 29.1, Batch Size = 256, Examples/Sec = 3876.55, Train LB = -424.212, Loss = 411.429
[2018-06-05 01:19] Train Step 31400, Epoch 29.1, Batch Size = 256, Examples/Sec = 3860.20, Train LB = -430.358, Loss = 412.784
Performance on test set:
  Test Lower Bound = -432.757, Test Loss = 432.757
[2018-06-05 01:20] Train Step 31425, Epoch 29.1, Batch Size = 256, Examples/Sec = 3889.69, Train LB = -403.826, Loss = 411.883
[2018-06-05 01:20] Train Step 31450, Epoch 29.1, Batch Size = 256, Examples/Sec = 3860.83, Train LB = -418.190, Loss = 411.194
[2018-06-05 01:20] Train Step 31475, Epoch 29.1, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -422.821, Loss = 411.356
[2018-06-05 01:20] Train Step 31500, Epoch 29.2, Batch Size = 256, Examples/Sec = 3852.17, Train LB = -409.977, Loss = 411.088
[2018-06-05 01:20] Train Step 31525, Epoch 29.2, Batch Size = 256, Examples/Sec = 3861.77, Train LB = -420.505, Loss = 409.738
[2018-06-05 01:20] Train Step 31550, Epoch 29.2, Batch Size = 256, Examples/Sec = 3853.69, Train LB = -414.588, Loss = 410.436
[2018-06-05 01:20] Train Step 31575, Epoch 29.2, Batch Size = 256, Examples/Sec = 3869.93, Train LB = -416.181, Loss = 411.023
[2018-06-05 01:20] Train Step 31600, Epoch 29.3, Batch Size = 256, Examples/Sec = 3785.07, Train LB = -432.913, Loss = 412.621
Performance on test set:
  Test Lower Bound = -434.218, Test Loss = 434.218
[2018-06-05 01:20] Train Step 31625, Epoch 29.3, Batch Size = 256, Examples/Sec = 3872.28, Train LB = -408.724, Loss = 412.249
[2018-06-05 01:20] Train Step 31650, Epoch 29.3, Batch Size = 256, Examples/Sec = 3870.00, Train LB = -411.607, Loss = 411.464
[2018-06-05 01:20] Train Step 31675, Epoch 29.3, Batch Size = 256, Examples/Sec = 3866.96, Train LB = -403.366, Loss = 411.066
[2018-06-05 01:20] Train Step 31700, Epoch 29.4, Batch Size = 256, Examples/Sec = 3805.38, Train LB = -423.773, Loss = 410.162
[2018-06-05 01:20] Train Step 31725, Epoch 29.4, Batch Size = 256, Examples/Sec = 3794.84, Train LB = -398.131, Loss = 410.084
[2018-06-05 01:20] Train Step 31750, Epoch 29.4, Batch Size = 256, Examples/Sec = 3859.66, Train LB = -405.260, Loss = 410.034
[2018-06-05 01:20] Train Step 31775, Epoch 29.4, Batch Size = 256, Examples/Sec = 3865.15, Train LB = -421.008, Loss = 410.825
[2018-06-05 01:20] Train Step 31800, Epoch 29.4, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -413.671, Loss = 412.993
Performance on test set:
  Test Lower Bound = -433.352, Test Loss = 433.352
[2018-06-05 01:20] Train Step 31825, Epoch 29.5, Batch Size = 256, Examples/Sec = 3844.18, Train LB = -403.845, Loss = 412.251
[2018-06-05 01:20] Train Step 31850, Epoch 29.5, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -409.377, Loss = 411.706
[2018-06-05 01:20] Train Step 31875, Epoch 29.5, Batch Size = 256, Examples/Sec = 3816.68, Train LB = -417.636, Loss = 411.199
[2018-06-05 01:20] Train Step 31900, Epoch 29.5, Batch Size = 256, Examples/Sec = 3858.80, Train LB = -414.354, Loss = 410.303
[2018-06-05 01:20] Train Step 31925, Epoch 29.6, Batch Size = 256, Examples/Sec = 3878.38, Train LB = -404.045, Loss = 410.416
[2018-06-05 01:20] Train Step 31950, Epoch 29.6, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -428.380, Loss = 410.034
[2018-06-05 01:20] Train Step 31975, Epoch 29.6, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -414.216, Loss = 410.823
[2018-06-05 01:20] Train Step 32000, Epoch 29.6, Batch Size = 256, Examples/Sec = 3869.23, Train LB = -427.625, Loss = 411.911
Performance on test set:
  Test Lower Bound = -433.780, Test Loss = 433.780
[2018-06-05 01:20] Train Step 32025, Epoch 29.7, Batch Size = 256, Examples/Sec = 3856.94, Train LB = -410.159, Loss = 411.022
[2018-06-05 01:20] Train Step 32050, Epoch 29.7, Batch Size = 256, Examples/Sec = 3875.85, Train LB = -395.838, Loss = 410.879
[2018-06-05 01:20] Train Step 32075, Epoch 29.7, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -418.176, Loss = 409.860
[2018-06-05 01:20] Train Step 32100, Epoch 29.7, Batch Size = 256, Examples/Sec = 3861.87, Train LB = -391.702, Loss = 410.032
[2018-06-05 01:21] Train Step 32125, Epoch 29.7, Batch Size = 256, Examples/Sec = 3868.17, Train LB = -409.865, Loss = 410.556
[2018-06-05 01:21] Train Step 32150, Epoch 29.8, Batch Size = 256, Examples/Sec = 3831.02, Train LB = -413.372, Loss = 410.101
[2018-06-05 01:21] Train Step 32175, Epoch 29.8, Batch Size = 256, Examples/Sec = 3818.56, Train LB = -398.639, Loss = 410.413
[2018-06-05 01:21] Train Step 32200, Epoch 29.8, Batch Size = 256, Examples/Sec = 3824.96, Train LB = -422.775, Loss = 411.925
Performance on test set:
  Test Lower Bound = -433.584, Test Loss = 433.584
[2018-06-05 01:21] Train Step 32225, Epoch 29.8, Batch Size = 256, Examples/Sec = 3831.48, Train LB = -407.138, Loss = 411.626
[2018-06-05 01:21] Train Step 32250, Epoch 29.9, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -401.719, Loss = 410.915
[2018-06-05 01:21] Train Step 32275, Epoch 29.9, Batch Size = 256, Examples/Sec = 3884.61, Train LB = -405.324, Loss = 410.768
[2018-06-05 01:21] Train Step 32300, Epoch 29.9, Batch Size = 256, Examples/Sec = 3884.02, Train LB = -402.829, Loss = 409.741
[2018-06-05 01:21] Train Step 32325, Epoch 29.9, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -418.039, Loss = 409.360
[2018-06-05 01:21] Train Step 32350, Epoch 30.0, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -405.421, Loss = 410.111
[2018-06-05 01:21] Train Step 32375, Epoch 30.0, Batch Size = 256, Examples/Sec = 3883.14, Train LB = -416.763, Loss = 410.170
[2018-06-05 01:21] Train Step 32400, Epoch 30.0, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -416.357, Loss = 411.984
Performance on test set:
  Test Lower Bound = -433.529, Test Loss = 433.529
[2018-06-05 01:21] Train Step 32425, Epoch 30.0, Batch Size = 256, Examples/Sec = 3849.79, Train LB = -412.641, Loss = 410.905
[2018-06-05 01:21] Train Step 32450, Epoch 30.0, Batch Size = 256, Examples/Sec = 3804.60, Train LB = -400.298, Loss = 410.338
[2018-06-05 01:21] Train Step 32475, Epoch 30.1, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -405.043, Loss = 409.495
[2018-06-05 01:21] Train Step 32500, Epoch 30.1, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -404.352, Loss = 409.257
[2018-06-05 01:21] Train Step 32525, Epoch 30.1, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -420.013, Loss = 409.066
[2018-06-05 01:21] Train Step 32550, Epoch 30.1, Batch Size = 256, Examples/Sec = 3878.61, Train LB = -407.648, Loss = 409.789
[2018-06-05 01:21] Train Step 32575, Epoch 30.2, Batch Size = 256, Examples/Sec = 3791.25, Train LB = -420.282, Loss = 410.770
[2018-06-05 01:21] Train Step 32600, Epoch 30.2, Batch Size = 256, Examples/Sec = 3868.94, Train LB = -403.084, Loss = 412.444
Performance on test set:
  Test Lower Bound = -433.595, Test Loss = 433.595
[2018-06-05 01:21] Train Step 32625, Epoch 30.2, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -394.241, Loss = 411.515
[2018-06-05 01:21] Train Step 32650, Epoch 30.2, Batch Size = 256, Examples/Sec = 3865.73, Train LB = -398.882, Loss = 410.734
[2018-06-05 01:21] Train Step 32675, Epoch 30.3, Batch Size = 256, Examples/Sec = 3800.43, Train LB = -413.694, Loss = 409.967
[2018-06-05 01:21] Train Step 32700, Epoch 30.3, Batch Size = 256, Examples/Sec = 3868.36, Train LB = -413.052, Loss = 410.179
[2018-06-05 01:21] Train Step 32725, Epoch 30.3, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -422.097, Loss = 409.380
[2018-06-05 01:21] Train Step 32750, Epoch 30.3, Batch Size = 256, Examples/Sec = 3833.55, Train LB = -408.934, Loss = 409.782
[2018-06-05 01:21] Train Step 32775, Epoch 30.3, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -422.313, Loss = 410.368
[2018-06-05 01:21] Train Step 32800, Epoch 30.4, Batch Size = 256, Examples/Sec = 3865.09, Train LB = -415.615, Loss = 411.487
Performance on test set:
  Test Lower Bound = -434.092, Test Loss = 434.092
[2018-06-05 01:22] Train Step 32825, Epoch 30.4, Batch Size = 256, Examples/Sec = 3865.95, Train LB = -419.291, Loss = 410.720
[2018-06-05 01:22] Train Step 32850, Epoch 30.4, Batch Size = 256, Examples/Sec = 3866.07, Train LB = -414.583, Loss = 409.943
[2018-06-05 01:22] Train Step 32875, Epoch 30.4, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -398.352, Loss = 409.917
[2018-06-05 01:22] Train Step 32900, Epoch 30.5, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -386.215, Loss = 409.632
[2018-06-05 01:22] Train Step 32925, Epoch 30.5, Batch Size = 256, Examples/Sec = 3866.36, Train LB = -409.412, Loss = 409.564
[2018-06-05 01:22] Train Step 32950, Epoch 30.5, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -408.086, Loss = 409.442
[2018-06-05 01:22] Train Step 32975, Epoch 30.5, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -411.321, Loss = 409.449
[2018-06-05 01:22] Train Step 33000, Epoch 30.6, Batch Size = 256, Examples/Sec = 3883.56, Train LB = -420.713, Loss = 411.212
Performance on test set:
  Test Lower Bound = -434.380, Test Loss = 434.380
[2018-06-05 01:22] Train Step 33025, Epoch 30.6, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -388.620, Loss = 410.774
[2018-06-05 01:22] Train Step 33050, Epoch 30.6, Batch Size = 256, Examples/Sec = 3864.16, Train LB = -410.076, Loss = 409.598
[2018-06-05 01:22] Train Step 33075, Epoch 30.6, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -420.038, Loss = 409.952
[2018-06-05 01:22] Train Step 33100, Epoch 30.6, Batch Size = 256, Examples/Sec = 3854.38, Train LB = -421.873, Loss = 409.238
[2018-06-05 01:22] Train Step 33125, Epoch 30.7, Batch Size = 256, Examples/Sec = 3877.19, Train LB = -424.167, Loss = 409.038
[2018-06-05 01:22] Train Step 33150, Epoch 30.7, Batch Size = 256, Examples/Sec = 3811.68, Train LB = -411.019, Loss = 409.769
[2018-06-05 01:22] Train Step 33175, Epoch 30.7, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -423.131, Loss = 410.494
[2018-06-05 01:22] Train Step 33200, Epoch 30.7, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -416.718, Loss = 411.737
Performance on test set:
  Test Lower Bound = -433.824, Test Loss = 433.824
[2018-06-05 01:22] Train Step 33225, Epoch 30.8, Batch Size = 256, Examples/Sec = 3801.60, Train LB = -393.228, Loss = 411.453
[2018-06-05 01:22] Train Step 33250, Epoch 30.8, Batch Size = 256, Examples/Sec = 3812.81, Train LB = -414.293, Loss = 410.020
[2018-06-05 01:22] Train Step 33275, Epoch 30.8, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -408.023, Loss = 410.241
[2018-06-05 01:22] Train Step 33300, Epoch 30.8, Batch Size = 256, Examples/Sec = 3883.14, Train LB = -401.381, Loss = 409.348
[2018-06-05 01:22] Train Step 33325, Epoch 30.9, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -411.428, Loss = 409.286
[2018-06-05 01:22] Train Step 33350, Epoch 30.9, Batch Size = 256, Examples/Sec = 3878.09, Train LB = -410.852, Loss = 409.407
[2018-06-05 01:22] Train Step 33375, Epoch 30.9, Batch Size = 256, Examples/Sec = 3872.09, Train LB = -415.928, Loss = 409.870
[2018-06-05 01:22] Train Step 33400, Epoch 30.9, Batch Size = 256, Examples/Sec = 3861.30, Train LB = -426.710, Loss = 411.213
Performance on test set:
  Test Lower Bound = -434.518, Test Loss = 434.518
[2018-06-05 01:22] Train Step 33425, Epoch 30.9, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -418.118, Loss = 410.659
[2018-06-05 01:22] Train Step 33450, Epoch 31.0, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -410.644, Loss = 410.226
[2018-06-05 01:22] Train Step 33475, Epoch 31.0, Batch Size = 256, Examples/Sec = 3864.69, Train LB = -397.192, Loss = 409.969
[2018-06-05 01:22] Train Step 33500, Epoch 31.0, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -417.112, Loss = 409.113
[2018-06-05 01:22] Train Step 33525, Epoch 31.0, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -396.543, Loss = 408.304
[2018-06-05 01:22] Train Step 33550, Epoch 31.1, Batch Size = 256, Examples/Sec = 3863.98, Train LB = -399.792, Loss = 408.187
[2018-06-05 01:23] Train Step 33575, Epoch 31.1, Batch Size = 256, Examples/Sec = 3801.54, Train LB = -407.741, Loss = 409.224
[2018-06-05 01:23] Train Step 33600, Epoch 31.1, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -434.288, Loss = 410.830
Performance on test set:
  Test Lower Bound = -434.405, Test Loss = 434.405
[2018-06-05 01:23] Train Step 33625, Epoch 31.1, Batch Size = 256, Examples/Sec = 3795.98, Train LB = -413.204, Loss = 410.753
[2018-06-05 01:23] Train Step 33650, Epoch 31.2, Batch Size = 256, Examples/Sec = 3850.48, Train LB = -402.898, Loss = 410.323
[2018-06-05 01:23] Train Step 33675, Epoch 31.2, Batch Size = 256, Examples/Sec = 3842.34, Train LB = -405.256, Loss = 409.809
[2018-06-05 01:23] Train Step 33700, Epoch 31.2, Batch Size = 256, Examples/Sec = 3874.69, Train LB = -399.139, Loss = 409.444
[2018-06-05 01:23] Train Step 33725, Epoch 31.2, Batch Size = 256, Examples/Sec = 3802.74, Train LB = -397.991, Loss = 408.662
[2018-06-05 01:23] Train Step 33750, Epoch 31.2, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -403.568, Loss = 408.761
[2018-06-05 01:23] Train Step 33775, Epoch 31.3, Batch Size = 256, Examples/Sec = 3863.87, Train LB = -414.020, Loss = 409.685
[2018-06-05 01:23] Train Step 33800, Epoch 31.3, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -416.830, Loss = 410.748
Performance on test set:
  Test Lower Bound = -433.834, Test Loss = 433.834
[2018-06-05 01:23] Train Step 33825, Epoch 31.3, Batch Size = 256, Examples/Sec = 3874.80, Train LB = -405.891, Loss = 409.861
[2018-06-05 01:23] Train Step 33850, Epoch 31.3, Batch Size = 256, Examples/Sec = 3869.87, Train LB = -400.454, Loss = 409.763
[2018-06-05 01:23] Train Step 33875, Epoch 31.4, Batch Size = 256, Examples/Sec = 3859.15, Train LB = -410.997, Loss = 409.194
[2018-06-05 01:23] Train Step 33900, Epoch 31.4, Batch Size = 256, Examples/Sec = 3863.87, Train LB = -398.937, Loss = 408.973
[2018-06-05 01:23] Train Step 33925, Epoch 31.4, Batch Size = 256, Examples/Sec = 3866.96, Train LB = -406.422, Loss = 408.881
[2018-06-05 01:23] Train Step 33950, Epoch 31.4, Batch Size = 256, Examples/Sec = 3865.43, Train LB = -411.473, Loss = 408.822
[2018-06-05 01:23] Train Step 33975, Epoch 31.5, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -414.006, Loss = 409.162
[2018-06-05 01:23] Train Step 34000, Epoch 31.5, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -422.283, Loss = 410.552
Performance on test set:
  Test Lower Bound = -433.654, Test Loss = 433.654
[2018-06-05 01:23] Train Step 34025, Epoch 31.5, Batch Size = 256, Examples/Sec = 3881.03, Train LB = -416.572, Loss = 410.333
[2018-06-05 01:23] Train Step 34050, Epoch 31.5, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -404.065, Loss = 409.610
[2018-06-05 01:23] Train Step 34075, Epoch 31.6, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -409.447, Loss = 409.636
[2018-06-05 01:23] Train Step 34100, Epoch 31.6, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -406.907, Loss = 408.890
[2018-06-05 01:23] Train Step 34125, Epoch 31.6, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -410.688, Loss = 408.227
[2018-06-05 01:23] Train Step 34150, Epoch 31.6, Batch Size = 256, Examples/Sec = 3870.93, Train LB = -415.071, Loss = 408.084
[2018-06-05 01:23] Train Step 34175, Epoch 31.6, Batch Size = 256, Examples/Sec = 3886.03, Train LB = -416.189, Loss = 408.987
[2018-06-05 01:23] Train Step 34200, Epoch 31.7, Batch Size = 256, Examples/Sec = 3787.14, Train LB = -418.318, Loss = 410.610
Performance on test set:
  Test Lower Bound = -435.534, Test Loss = 435.534
[2018-06-05 01:23] Train Step 34225, Epoch 31.7, Batch Size = 256, Examples/Sec = 3858.55, Train LB = -403.776, Loss = 410.167
[2018-06-05 01:24] Train Step 34250, Epoch 31.7, Batch Size = 256, Examples/Sec = 3885.15, Train LB = -409.441, Loss = 409.132
[2018-06-05 01:24] Train Step 34275, Epoch 31.7, Batch Size = 256, Examples/Sec = 3859.13, Train LB = -408.738, Loss = 409.178
[2018-06-05 01:24] Train Step 34300, Epoch 31.8, Batch Size = 256, Examples/Sec = 3817.76, Train LB = -405.744, Loss = 409.099
[2018-06-05 01:24] Train Step 34325, Epoch 31.8, Batch Size = 256, Examples/Sec = 3850.54, Train LB = -409.523, Loss = 408.635
[2018-06-05 01:24] Train Step 34350, Epoch 31.8, Batch Size = 256, Examples/Sec = 3882.25, Train LB = -404.599, Loss = 408.441
[2018-06-05 01:24] Train Step 34375, Epoch 31.8, Batch Size = 256, Examples/Sec = 3874.80, Train LB = -419.715, Loss = 408.741
[2018-06-05 01:24] Train Step 34400, Epoch 31.9, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -418.570, Loss = 410.133
Performance on test set:
  Test Lower Bound = -434.231, Test Loss = 434.231
[2018-06-05 01:24] Train Step 34425, Epoch 31.9, Batch Size = 256, Examples/Sec = 3857.57, Train LB = -409.759, Loss = 409.517
[2018-06-05 01:24] Train Step 34450, Epoch 31.9, Batch Size = 256, Examples/Sec = 3870.53, Train LB = -405.775, Loss = 409.517
[2018-06-05 01:24] Train Step 34475, Epoch 31.9, Batch Size = 256, Examples/Sec = 3861.41, Train LB = -400.502, Loss = 408.757
[2018-06-05 01:24] Train Step 34500, Epoch 31.9, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -400.030, Loss = 408.022
[2018-06-05 01:24] Train Step 34525, Epoch 32.0, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -399.258, Loss = 408.192
[2018-06-05 01:24] Train Step 34550, Epoch 32.0, Batch Size = 256, Examples/Sec = 3864.26, Train LB = -418.291, Loss = 407.895
[2018-06-05 01:24] Train Step 34575, Epoch 32.0, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -419.026, Loss = 408.761
[2018-06-05 01:24] Train Step 34600, Epoch 32.0, Batch Size = 256, Examples/Sec = 3856.35, Train LB = -435.031, Loss = 410.449
Performance on test set:
  Test Lower Bound = -434.661, Test Loss = 434.661
[2018-06-05 01:24] Train Step 34625, Epoch 32.1, Batch Size = 256, Examples/Sec = 3874.39, Train LB = -415.611, Loss = 410.217
[2018-06-05 01:24] Train Step 34650, Epoch 32.1, Batch Size = 256, Examples/Sec = 3874.73, Train LB = -417.927, Loss = 409.121
[2018-06-05 01:24] Train Step 34675, Epoch 32.1, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -412.258, Loss = 408.690
[2018-06-05 01:24] Train Step 34700, Epoch 32.1, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -411.022, Loss = 408.510
[2018-06-05 01:24] Train Step 34725, Epoch 32.2, Batch Size = 256, Examples/Sec = 3843.44, Train LB = -404.813, Loss = 408.260
[2018-06-05 01:24] Train Step 34750, Epoch 32.2, Batch Size = 256, Examples/Sec = 3838.60, Train LB = -409.701, Loss = 408.167
[2018-06-05 01:24] Train Step 34775, Epoch 32.2, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -407.791, Loss = 409.243
[2018-06-05 01:24] Train Step 34800, Epoch 32.2, Batch Size = 256, Examples/Sec = 3844.82, Train LB = -423.778, Loss = 410.781
Performance on test set:
  Test Lower Bound = -435.413, Test Loss = 435.413
[2018-06-05 01:24] Train Step 34825, Epoch 32.2, Batch Size = 256, Examples/Sec = 3858.85, Train LB = -405.741, Loss = 409.797
[2018-06-05 01:24] Train Step 34850, Epoch 32.3, Batch Size = 256, Examples/Sec = 3860.01, Train LB = -407.003, Loss = 409.308
[2018-06-05 01:24] Train Step 34875, Epoch 32.3, Batch Size = 256, Examples/Sec = 3814.18, Train LB = -398.595, Loss = 409.203
[2018-06-05 01:24] Train Step 34900, Epoch 32.3, Batch Size = 256, Examples/Sec = 3883.02, Train LB = -412.108, Loss = 409.086
[2018-06-05 01:24] Train Step 34925, Epoch 32.3, Batch Size = 256, Examples/Sec = 3880.85, Train LB = -419.307, Loss = 408.709
[2018-06-05 01:24] Train Step 34950, Epoch 32.4, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -401.875, Loss = 408.314
[2018-06-05 01:24] Train Step 34975, Epoch 32.4, Batch Size = 256, Examples/Sec = 3866.90, Train LB = -398.406, Loss = 409.214
[2018-06-05 01:25] Train Step 35000, Epoch 32.4, Batch Size = 256, Examples/Sec = 3854.31, Train LB = -421.028, Loss = 410.838
Performance on test set:
  Test Lower Bound = -434.170, Test Loss = 434.170
[2018-06-05 01:25] Train Step 35025, Epoch 32.4, Batch Size = 256, Examples/Sec = 3857.33, Train LB = -407.216, Loss = 409.779
[2018-06-05 01:25] Train Step 35050, Epoch 32.5, Batch Size = 256, Examples/Sec = 3797.88, Train LB = -405.773, Loss = 408.994
[2018-06-05 01:25] Train Step 35075, Epoch 32.5, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -420.405, Loss = 409.033
[2018-06-05 01:25] Train Step 35100, Epoch 32.5, Batch Size = 256, Examples/Sec = 3806.91, Train LB = -388.718, Loss = 408.449
[2018-06-05 01:25] Train Step 35125, Epoch 32.5, Batch Size = 256, Examples/Sec = 3866.85, Train LB = -395.439, Loss = 408.076
[2018-06-05 01:25] Train Step 35150, Epoch 32.5, Batch Size = 256, Examples/Sec = 3849.74, Train LB = -395.775, Loss = 408.385
[2018-06-05 01:25] Train Step 35175, Epoch 32.6, Batch Size = 256, Examples/Sec = 3859.09, Train LB = -434.550, Loss = 409.195
[2018-06-05 01:25] Train Step 35200, Epoch 32.6, Batch Size = 256, Examples/Sec = 3840.37, Train LB = -412.362, Loss = 410.738
Performance on test set:
  Test Lower Bound = -434.133, Test Loss = 434.133
[2018-06-05 01:25] Train Step 35225, Epoch 32.6, Batch Size = 256, Examples/Sec = 3869.17, Train LB = -389.900, Loss = 409.931
[2018-06-05 01:25] Train Step 35250, Epoch 32.6, Batch Size = 256, Examples/Sec = 3874.03, Train LB = -410.420, Loss = 409.513
[2018-06-05 01:25] Train Step 35275, Epoch 32.7, Batch Size = 256, Examples/Sec = 3851.53, Train LB = -396.244, Loss = 409.028
[2018-06-05 01:25] Train Step 35300, Epoch 32.7, Batch Size = 256, Examples/Sec = 3862.94, Train LB = -417.761, Loss = 408.166
[2018-06-05 01:25] Train Step 35325, Epoch 32.7, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -397.446, Loss = 407.733
[2018-06-05 01:25] Train Step 35350, Epoch 32.7, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -397.478, Loss = 407.634
[2018-06-05 01:25] Train Step 35375, Epoch 32.8, Batch Size = 256, Examples/Sec = 3868.82, Train LB = -413.971, Loss = 408.644
[2018-06-05 01:25] Train Step 35400, Epoch 32.8, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -408.569, Loss = 410.061
Performance on test set:
  Test Lower Bound = -434.671, Test Loss = 434.671
[2018-06-05 01:25] Train Step 35425, Epoch 32.8, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -397.243, Loss = 409.311
[2018-06-05 01:25] Train Step 35450, Epoch 32.8, Batch Size = 256, Examples/Sec = 3872.93, Train LB = -403.359, Loss = 409.093
[2018-06-05 01:25] Train Step 35475, Epoch 32.8, Batch Size = 256, Examples/Sec = 3848.23, Train LB = -411.917, Loss = 408.868
[2018-06-05 01:25] Train Step 35500, Epoch 32.9, Batch Size = 256, Examples/Sec = 3843.44, Train LB = -393.696, Loss = 407.731
[2018-06-05 01:25] Train Step 35525, Epoch 32.9, Batch Size = 256, Examples/Sec = 3816.68, Train LB = -411.408, Loss = 406.947
[2018-06-05 01:25] Train Step 35550, Epoch 32.9, Batch Size = 256, Examples/Sec = 3810.32, Train LB = -410.248, Loss = 407.016
[2018-06-05 01:25] Train Step 35575, Epoch 32.9, Batch Size = 256, Examples/Sec = 3865.09, Train LB = -414.443, Loss = 407.731
[2018-06-05 01:25] Train Step 35600, Epoch 33.0, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -435.068, Loss = 409.904
Performance on test set:
  Test Lower Bound = -435.506, Test Loss = 435.506
[2018-06-05 01:25] Train Step 35625, Epoch 33.0, Batch Size = 256, Examples/Sec = 3779.10, Train LB = -397.006, Loss = 409.550
[2018-06-05 01:25] Train Step 35650, Epoch 33.0, Batch Size = 256, Examples/Sec = 3817.19, Train LB = -399.858, Loss = 408.679
[2018-06-05 01:25] Train Step 35675, Epoch 33.0, Batch Size = 256, Examples/Sec = 3882.20, Train LB = -392.525, Loss = 408.315
[2018-06-05 01:26] Train Step 35700, Epoch 33.1, Batch Size = 256, Examples/Sec = 3849.85, Train LB = -401.541, Loss = 407.685
[2018-06-05 01:26] Train Step 35725, Epoch 33.1, Batch Size = 256, Examples/Sec = 3825.53, Train LB = -413.755, Loss = 407.372
[2018-06-05 01:26] Train Step 35750, Epoch 33.1, Batch Size = 256, Examples/Sec = 3873.09, Train LB = -424.708, Loss = 407.791
[2018-06-05 01:26] Train Step 35775, Epoch 33.1, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -409.936, Loss = 408.832
[2018-06-05 01:26] Train Step 35800, Epoch 33.1, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -418.870, Loss = 410.329
Performance on test set:
  Test Lower Bound = -435.923, Test Loss = 435.923
[2018-06-05 01:26] Train Step 35825, Epoch 33.2, Batch Size = 256, Examples/Sec = 3852.24, Train LB = -407.455, Loss = 409.592
[2018-06-05 01:26] Train Step 35850, Epoch 33.2, Batch Size = 256, Examples/Sec = 3843.38, Train LB = -407.497, Loss = 409.146
[2018-06-05 01:26] Train Step 35875, Epoch 33.2, Batch Size = 256, Examples/Sec = 3870.64, Train LB = -399.716, Loss = 408.740
[2018-06-05 01:26] Train Step 35900, Epoch 33.2, Batch Size = 256, Examples/Sec = 3876.38, Train LB = -395.031, Loss = 407.435
[2018-06-05 01:26] Train Step 35925, Epoch 33.3, Batch Size = 256, Examples/Sec = 3862.46, Train LB = -408.968, Loss = 407.275
[2018-06-05 01:26] Train Step 35950, Epoch 33.3, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -411.940, Loss = 407.191
[2018-06-05 01:26] Train Step 35975, Epoch 33.3, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -416.544, Loss = 407.715
[2018-06-05 01:26] Train Step 36000, Epoch 33.3, Batch Size = 256, Examples/Sec = 3866.02, Train LB = -425.286, Loss = 409.802
Performance on test set:
  Test Lower Bound = -435.260, Test Loss = 435.260
[2018-06-05 01:26] Train Step 36025, Epoch 33.4, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -400.509, Loss = 409.180
[2018-06-05 01:26] Train Step 36050, Epoch 33.4, Batch Size = 256, Examples/Sec = 3844.47, Train LB = -417.357, Loss = 408.104
[2018-06-05 01:26] Train Step 36075, Epoch 33.4, Batch Size = 256, Examples/Sec = 3848.05, Train LB = -412.612, Loss = 407.558
[2018-06-05 01:26] Train Step 36100, Epoch 33.4, Batch Size = 256, Examples/Sec = 3863.63, Train LB = -404.134, Loss = 407.301
[2018-06-05 01:26] Train Step 36125, Epoch 33.4, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -404.059, Loss = 407.154
[2018-06-05 01:26] Train Step 36150, Epoch 33.5, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -404.042, Loss = 407.492
[2018-06-05 01:26] Train Step 36175, Epoch 33.5, Batch Size = 256, Examples/Sec = 3816.00, Train LB = -410.593, Loss = 407.807
[2018-06-05 01:26] Train Step 36200, Epoch 33.5, Batch Size = 256, Examples/Sec = 3869.59, Train LB = -422.518, Loss = 409.484
Performance on test set:
  Test Lower Bound = -435.802, Test Loss = 435.802
[2018-06-05 01:26] Train Step 36225, Epoch 33.5, Batch Size = 256, Examples/Sec = 3870.29, Train LB = -399.682, Loss = 408.805
[2018-06-05 01:26] Train Step 36250, Epoch 33.6, Batch Size = 256, Examples/Sec = 3847.24, Train LB = -417.414, Loss = 407.940
[2018-06-05 01:26] Train Step 36275, Epoch 33.6, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -388.407, Loss = 407.822
[2018-06-05 01:26] Train Step 36300, Epoch 33.6, Batch Size = 256, Examples/Sec = 3840.61, Train LB = -407.501, Loss = 407.046
[2018-06-05 01:26] Train Step 36325, Epoch 33.6, Batch Size = 256, Examples/Sec = 3847.78, Train LB = -411.658, Loss = 407.082
[2018-06-05 01:26] Train Step 36350, Epoch 33.7, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -418.675, Loss = 407.423
[2018-06-05 01:26] Train Step 36375, Epoch 33.7, Batch Size = 256, Examples/Sec = 3865.04, Train LB = -422.375, Loss = 407.606
[2018-06-05 01:26] Train Step 36400, Epoch 33.7, Batch Size = 256, Examples/Sec = 3840.97, Train LB = -423.094, Loss = 409.611
Performance on test set:
  Test Lower Bound = -434.951, Test Loss = 434.951
[2018-06-05 01:27] Train Step 36425, Epoch 33.7, Batch Size = 256, Examples/Sec = 3855.24, Train LB = -413.179, Loss = 408.789
[2018-06-05 01:27] Train Step 36450, Epoch 33.8, Batch Size = 256, Examples/Sec = 3857.39, Train LB = -402.809, Loss = 408.675
[2018-06-05 01:27] Train Step 36475, Epoch 33.8, Batch Size = 256, Examples/Sec = 3892.36, Train LB = -411.640, Loss = 408.305
[2018-06-05 01:27] Train Step 36500, Epoch 33.8, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -407.832, Loss = 407.628
[2018-06-05 01:27] Train Step 36525, Epoch 33.8, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -408.019, Loss = 407.227
[2018-06-05 01:27] Train Step 36550, Epoch 33.8, Batch Size = 256, Examples/Sec = 3846.22, Train LB = -412.707, Loss = 407.394
[2018-06-05 01:27] Train Step 36575, Epoch 33.9, Batch Size = 256, Examples/Sec = 3826.67, Train LB = -423.258, Loss = 407.703
[2018-06-05 01:27] Train Step 36600, Epoch 33.9, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -417.423, Loss = 410.164
Performance on test set:
  Test Lower Bound = -435.221, Test Loss = 435.221
[2018-06-05 01:27] Train Step 36625, Epoch 33.9, Batch Size = 256, Examples/Sec = 3868.46, Train LB = -408.119, Loss = 409.412
[2018-06-05 01:27] Train Step 36650, Epoch 33.9, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -411.097, Loss = 408.836
[2018-06-05 01:27] Train Step 36675, Epoch 34.0, Batch Size = 256, Examples/Sec = 3856.07, Train LB = -403.227, Loss = 407.782
[2018-06-05 01:27] Train Step 36700, Epoch 34.0, Batch Size = 256, Examples/Sec = 3854.27, Train LB = -414.692, Loss = 406.986
[2018-06-05 01:27] Train Step 36725, Epoch 34.0, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -398.753, Loss = 406.683
[2018-06-05 01:27] Train Step 36750, Epoch 34.0, Batch Size = 256, Examples/Sec = 3804.21, Train LB = -409.804, Loss = 406.847
[2018-06-05 01:27] Train Step 36775, Epoch 34.1, Batch Size = 256, Examples/Sec = 3863.56, Train LB = -433.249, Loss = 407.500
[2018-06-05 01:27] Train Step 36800, Epoch 34.1, Batch Size = 256, Examples/Sec = 3877.37, Train LB = -433.517, Loss = 409.801
Performance on test set:
  Test Lower Bound = -435.911, Test Loss = 435.911
[2018-06-05 01:27] Train Step 36825, Epoch 34.1, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -410.475, Loss = 409.439
[2018-06-05 01:27] Train Step 36850, Epoch 34.1, Batch Size = 256, Examples/Sec = 3808.91, Train LB = -406.689, Loss = 408.499
[2018-06-05 01:27] Train Step 36875, Epoch 34.1, Batch Size = 256, Examples/Sec = 3861.41, Train LB = -399.696, Loss = 407.611
[2018-06-05 01:27] Train Step 36900, Epoch 34.2, Batch Size = 256, Examples/Sec = 3841.02, Train LB = -402.881, Loss = 407.051
[2018-06-05 01:27] Train Step 36925, Epoch 34.2, Batch Size = 256, Examples/Sec = 3854.37, Train LB = -420.666, Loss = 406.892
[2018-06-05 01:27] Train Step 36950, Epoch 34.2, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -409.608, Loss = 406.948
[2018-06-05 01:27] Train Step 36975, Epoch 34.2, Batch Size = 256, Examples/Sec = 3852.91, Train LB = -407.883, Loss = 408.176
[2018-06-05 01:27] Train Step 37000, Epoch 34.3, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -419.444, Loss = 409.233
Performance on test set:
  Test Lower Bound = -434.899, Test Loss = 434.899
[2018-06-05 01:27] Train Step 37025, Epoch 34.3, Batch Size = 256, Examples/Sec = 3861.41, Train LB = -398.805, Loss = 408.477
[2018-06-05 01:27] Train Step 37050, Epoch 34.3, Batch Size = 256, Examples/Sec = 3871.06, Train LB = -396.661, Loss = 408.254
[2018-06-05 01:27] Train Step 37075, Epoch 34.3, Batch Size = 256, Examples/Sec = 3875.21, Train LB = -393.064, Loss = 407.150
[2018-06-05 01:27] Train Step 37100, Epoch 34.4, Batch Size = 256, Examples/Sec = 3846.97, Train LB = -406.246, Loss = 406.431
[2018-06-05 01:28] Train Step 37125, Epoch 34.4, Batch Size = 256, Examples/Sec = 3813.44, Train LB = -417.709, Loss = 405.977
[2018-06-05 01:28] Train Step 37150, Epoch 34.4, Batch Size = 256, Examples/Sec = 3842.23, Train LB = -401.739, Loss = 406.225
[2018-06-05 01:28] Train Step 37175, Epoch 34.4, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -405.478, Loss = 407.439
[2018-06-05 01:28] Train Step 37200, Epoch 34.4, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -415.651, Loss = 409.051
Performance on test set:
  Test Lower Bound = -436.185, Test Loss = 436.185
[2018-06-05 01:28] Train Step 37225, Epoch 34.5, Batch Size = 256, Examples/Sec = 3855.43, Train LB = -413.609, Loss = 408.658
[2018-06-05 01:28] Train Step 37250, Epoch 34.5, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -413.460, Loss = 408.038
[2018-06-05 01:28] Train Step 37275, Epoch 34.5, Batch Size = 256, Examples/Sec = 3882.27, Train LB = -401.231, Loss = 406.689
[2018-06-05 01:28] Train Step 37300, Epoch 34.5, Batch Size = 256, Examples/Sec = 3852.82, Train LB = -404.678, Loss = 406.313
[2018-06-05 01:28] Train Step 37325, Epoch 34.6, Batch Size = 256, Examples/Sec = 3786.47, Train LB = -406.066, Loss = 405.683
[2018-06-05 01:28] Train Step 37350, Epoch 34.6, Batch Size = 256, Examples/Sec = 3868.99, Train LB = -409.825, Loss = 406.511
[2018-06-05 01:28] Train Step 37375, Epoch 34.6, Batch Size = 256, Examples/Sec = 3868.95, Train LB = -406.954, Loss = 407.023
[2018-06-05 01:28] Train Step 37400, Epoch 34.6, Batch Size = 256, Examples/Sec = 3869.35, Train LB = -428.848, Loss = 408.636
Performance on test set:
  Test Lower Bound = -435.673, Test Loss = 435.673
[2018-06-05 01:28] Train Step 37425, Epoch 34.7, Batch Size = 256, Examples/Sec = 3793.16, Train LB = -409.400, Loss = 407.818
[2018-06-05 01:28] Train Step 37450, Epoch 34.7, Batch Size = 256, Examples/Sec = 3814.52, Train LB = -409.120, Loss = 407.460
[2018-06-05 01:28] Train Step 37475, Epoch 34.7, Batch Size = 256, Examples/Sec = 3852.22, Train LB = -416.345, Loss = 407.330
[2018-06-05 01:28] Train Step 37500, Epoch 34.7, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -402.596, Loss = 406.436
[2018-06-05 01:28] Train Step 37525, Epoch 34.7, Batch Size = 256, Examples/Sec = 3865.19, Train LB = -415.777, Loss = 406.035
[2018-06-05 01:28] Train Step 37550, Epoch 34.8, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -407.822, Loss = 406.536
[2018-06-05 01:28] Train Step 37575, Epoch 34.8, Batch Size = 256, Examples/Sec = 3832.79, Train LB = -411.781, Loss = 408.026
[2018-06-05 01:28] Train Step 37600, Epoch 34.8, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -415.883, Loss = 409.444
Performance on test set:
  Test Lower Bound = -436.242, Test Loss = 436.242
[2018-06-05 01:28] Train Step 37625, Epoch 34.8, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -401.159, Loss = 409.127
[2018-06-05 01:28] Train Step 37650, Epoch 34.9, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -396.180, Loss = 407.958
[2018-06-05 01:28] Train Step 37675, Epoch 34.9, Batch Size = 256, Examples/Sec = 3800.36, Train LB = -399.433, Loss = 407.283
[2018-06-05 01:28] Train Step 37700, Epoch 34.9, Batch Size = 256, Examples/Sec = 3853.09, Train LB = -409.953, Loss = 406.955
[2018-06-05 01:28] Train Step 37725, Epoch 34.9, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -396.359, Loss = 406.178
[2018-06-05 01:28] Train Step 37750, Epoch 35.0, Batch Size = 256, Examples/Sec = 3852.47, Train LB = -407.447, Loss = 406.004
[2018-06-05 01:28] Train Step 37775, Epoch 35.0, Batch Size = 256, Examples/Sec = 3858.79, Train LB = -417.832, Loss = 406.848
[2018-06-05 01:28] Train Step 37800, Epoch 35.0, Batch Size = 256, Examples/Sec = 3814.52, Train LB = -435.671, Loss = 408.958
Performance on test set:
  Test Lower Bound = -436.105, Test Loss = 436.105
[2018-06-05 01:29] Train Step 37825, Epoch 35.0, Batch Size = 256, Examples/Sec = 3842.70, Train LB = -403.295, Loss = 408.551
[2018-06-05 01:29] Train Step 37850, Epoch 35.0, Batch Size = 256, Examples/Sec = 3873.81, Train LB = -410.995, Loss = 407.208
[2018-06-05 01:29] Train Step 37875, Epoch 35.1, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -414.668, Loss = 406.875
[2018-06-05 01:29] Train Step 37900, Epoch 35.1, Batch Size = 256, Examples/Sec = 3817.87, Train LB = -409.582, Loss = 406.259
[2018-06-05 01:29] Train Step 37925, Epoch 35.1, Batch Size = 256, Examples/Sec = 3861.48, Train LB = -409.894, Loss = 405.884
[2018-06-05 01:29] Train Step 37950, Epoch 35.1, Batch Size = 256, Examples/Sec = 3844.14, Train LB = -395.808, Loss = 406.242
[2018-06-05 01:29] Train Step 37975, Epoch 35.2, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -401.926, Loss = 406.568
[2018-06-05 01:29] Train Step 38000, Epoch 35.2, Batch Size = 256, Examples/Sec = 3863.62, Train LB = -425.108, Loss = 408.514
Performance on test set:
  Test Lower Bound = -435.685, Test Loss = 435.685
[2018-06-05 01:29] Train Step 38025, Epoch 35.2, Batch Size = 256, Examples/Sec = 3844.65, Train LB = -406.372, Loss = 407.596
[2018-06-05 01:29] Train Step 38050, Epoch 35.2, Batch Size = 256, Examples/Sec = 3870.27, Train LB = -404.203, Loss = 406.927
[2018-06-05 01:29] Train Step 38075, Epoch 35.3, Batch Size = 256, Examples/Sec = 3873.86, Train LB = -404.577, Loss = 407.252
[2018-06-05 01:29] Train Step 38100, Epoch 35.3, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -412.436, Loss = 406.579
[2018-06-05 01:29] Train Step 38125, Epoch 35.3, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -407.937, Loss = 406.202
[2018-06-05 01:29] Train Step 38150, Epoch 35.3, Batch Size = 256, Examples/Sec = 3876.32, Train LB = -418.098, Loss = 406.592
[2018-06-05 01:29] Train Step 38175, Epoch 35.3, Batch Size = 256, Examples/Sec = 3852.51, Train LB = -419.248, Loss = 407.168
[2018-06-05 01:29] Train Step 38200, Epoch 35.4, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -401.287, Loss = 408.967
Performance on test set:
  Test Lower Bound = -437.101, Test Loss = 437.101
[2018-06-05 01:29] Train Step 38225, Epoch 35.4, Batch Size = 256, Examples/Sec = 3856.42, Train LB = -413.901, Loss = 408.289
[2018-06-05 01:29] Train Step 38250, Epoch 35.4, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -415.831, Loss = 407.480
[2018-06-05 01:29] Train Step 38275, Epoch 35.4, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -403.211, Loss = 406.559
[2018-06-05 01:29] Train Step 38300, Epoch 35.5, Batch Size = 256, Examples/Sec = 3796.69, Train LB = -397.464, Loss = 406.457
[2018-06-05 01:29] Train Step 38325, Epoch 35.5, Batch Size = 256, Examples/Sec = 3848.11, Train LB = -411.317, Loss = 405.936
[2018-06-05 01:29] Train Step 38350, Epoch 35.5, Batch Size = 256, Examples/Sec = 3857.39, Train LB = -403.577, Loss = 406.449
[2018-06-05 01:29] Train Step 38375, Epoch 35.5, Batch Size = 256, Examples/Sec = 3832.45, Train LB = -413.625, Loss = 407.135
[2018-06-05 01:29] Train Step 38400, Epoch 35.6, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -417.148, Loss = 409.003
Performance on test set:
  Test Lower Bound = -436.222, Test Loss = 436.222
[2018-06-05 01:29] Train Step 38425, Epoch 35.6, Batch Size = 256, Examples/Sec = 3832.16, Train LB = -403.718, Loss = 408.473
[2018-06-05 01:29] Train Step 38450, Epoch 35.6, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -404.395, Loss = 407.830
[2018-06-05 01:29] Train Step 38475, Epoch 35.6, Batch Size = 256, Examples/Sec = 3803.31, Train LB = -401.275, Loss = 407.228
[2018-06-05 01:29] Train Step 38500, Epoch 35.6, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -412.209, Loss = 406.550
[2018-06-05 01:29] Train Step 38525, Epoch 35.7, Batch Size = 256, Examples/Sec = 3863.56, Train LB = -400.034, Loss = 405.757
[2018-06-05 01:29] Train Step 38550, Epoch 35.7, Batch Size = 256, Examples/Sec = 3877.14, Train LB = -399.504, Loss = 406.022
[2018-06-05 01:30] Train Step 38575, Epoch 35.7, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -406.897, Loss = 406.532
[2018-06-05 01:30] Train Step 38600, Epoch 35.7, Batch Size = 256, Examples/Sec = 3815.48, Train LB = -433.577, Loss = 408.166
Performance on test set:
  Test Lower Bound = -436.122, Test Loss = 436.122
[2018-06-05 01:30] Train Step 38625, Epoch 35.8, Batch Size = 256, Examples/Sec = 3822.49, Train LB = -419.897, Loss = 407.914
[2018-06-05 01:30] Train Step 38650, Epoch 35.8, Batch Size = 256, Examples/Sec = 3835.96, Train LB = -406.900, Loss = 407.348
[2018-06-05 01:30] Train Step 38675, Epoch 35.8, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -400.280, Loss = 406.966
[2018-06-05 01:30] Train Step 38700, Epoch 35.8, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -411.785, Loss = 406.132
[2018-06-05 01:30] Train Step 38725, Epoch 35.9, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -404.066, Loss = 405.134
[2018-06-05 01:30] Train Step 38750, Epoch 35.9, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -393.084, Loss = 405.300
[2018-06-05 01:30] Train Step 38775, Epoch 35.9, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -405.326, Loss = 406.082
[2018-06-05 01:30] Train Step 38800, Epoch 35.9, Batch Size = 256, Examples/Sec = 3863.62, Train LB = -417.559, Loss = 408.646
Performance on test set:
  Test Lower Bound = -436.000, Test Loss = 436.000
[2018-06-05 01:30] Train Step 38825, Epoch 35.9, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -394.582, Loss = 407.963
[2018-06-05 01:30] Train Step 38850, Epoch 36.0, Batch Size = 256, Examples/Sec = 3866.59, Train LB = -401.214, Loss = 406.602
[2018-06-05 01:30] Train Step 38875, Epoch 36.0, Batch Size = 256, Examples/Sec = 3817.94, Train LB = -416.663, Loss = 406.314
[2018-06-05 01:30] Train Step 38900, Epoch 36.0, Batch Size = 256, Examples/Sec = 3856.76, Train LB = -405.795, Loss = 406.386
[2018-06-05 01:30] Train Step 38925, Epoch 36.0, Batch Size = 256, Examples/Sec = 3850.73, Train LB = -411.123, Loss = 405.424
[2018-06-05 01:30] Train Step 38950, Epoch 36.1, Batch Size = 256, Examples/Sec = 3846.15, Train LB = -413.213, Loss = 405.399
[2018-06-05 01:30] Train Step 38975, Epoch 36.1, Batch Size = 256, Examples/Sec = 3851.48, Train LB = -410.413, Loss = 406.458
[2018-06-05 01:30] Train Step 39000, Epoch 36.1, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -413.947, Loss = 408.867
Performance on test set:
  Test Lower Bound = -436.346, Test Loss = 436.346
[2018-06-05 01:30] Train Step 39025, Epoch 36.1, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -399.443, Loss = 407.805
[2018-06-05 01:30] Train Step 39050, Epoch 36.2, Batch Size = 256, Examples/Sec = 3877.84, Train LB = -400.711, Loss = 407.570
[2018-06-05 01:30] Train Step 39075, Epoch 36.2, Batch Size = 256, Examples/Sec = 3796.69, Train LB = -397.350, Loss = 406.897
[2018-06-05 01:30] Train Step 39100, Epoch 36.2, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -405.308, Loss = 406.071
[2018-06-05 01:30] Train Step 39125, Epoch 36.2, Batch Size = 256, Examples/Sec = 3862.81, Train LB = -407.679, Loss = 404.865
[2018-06-05 01:30] Train Step 39150, Epoch 36.2, Batch Size = 256, Examples/Sec = 3846.04, Train LB = -403.840, Loss = 405.396
[2018-06-05 01:30] Train Step 39175, Epoch 36.3, Batch Size = 256, Examples/Sec = 3845.12, Train LB = -406.608, Loss = 406.575
[2018-06-05 01:30] Train Step 39200, Epoch 36.3, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -408.264, Loss = 408.054
Performance on test set:
  Test Lower Bound = -436.239, Test Loss = 436.239
[2018-06-05 01:30] Train Step 39225, Epoch 36.3, Batch Size = 256, Examples/Sec = 3879.49, Train LB = -403.302, Loss = 406.859
[2018-06-05 01:30] Train Step 39250, Epoch 36.3, Batch Size = 256, Examples/Sec = 3848.69, Train LB = -403.368, Loss = 406.551
[2018-06-05 01:31] Train Step 39275, Epoch 36.4, Batch Size = 256, Examples/Sec = 3872.80, Train LB = -402.484, Loss = 406.378
[2018-06-05 01:31] Train Step 39300, Epoch 36.4, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -398.279, Loss = 405.660
[2018-06-05 01:31] Train Step 39325, Epoch 36.4, Batch Size = 256, Examples/Sec = 3866.96, Train LB = -407.123, Loss = 405.131
[2018-06-05 01:31] Train Step 39350, Epoch 36.4, Batch Size = 256, Examples/Sec = 3844.54, Train LB = -413.258, Loss = 404.950
[2018-06-05 01:31] Train Step 39375, Epoch 36.5, Batch Size = 256, Examples/Sec = 3888.57, Train LB = -422.706, Loss = 405.862
[2018-06-05 01:31] Train Step 39400, Epoch 36.5, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -424.036, Loss = 408.410
Performance on test set:
  Test Lower Bound = -436.901, Test Loss = 436.901
[2018-06-05 01:31] Train Step 39425, Epoch 36.5, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -408.100, Loss = 407.758
[2018-06-05 01:31] Train Step 39450, Epoch 36.5, Batch Size = 256, Examples/Sec = 3825.17, Train LB = -404.594, Loss = 406.862
[2018-06-05 01:31] Train Step 39475, Epoch 36.6, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -402.786, Loss = 406.074
[2018-06-05 01:31] Train Step 39500, Epoch 36.6, Batch Size = 256, Examples/Sec = 3874.38, Train LB = -391.495, Loss = 405.267
[2018-06-05 01:31] Train Step 39525, Epoch 36.6, Batch Size = 256, Examples/Sec = 3874.56, Train LB = -381.206, Loss = 405.210
[2018-06-05 01:31] Train Step 39550, Epoch 36.6, Batch Size = 256, Examples/Sec = 3854.96, Train LB = -388.932, Loss = 405.044
[2018-06-05 01:31] Train Step 39575, Epoch 36.6, Batch Size = 256, Examples/Sec = 3878.68, Train LB = -401.274, Loss = 406.033
[2018-06-05 01:31] Train Step 39600, Epoch 36.7, Batch Size = 256, Examples/Sec = 3811.91, Train LB = -407.628, Loss = 408.382
Performance on test set:
  Test Lower Bound = -436.385, Test Loss = 436.385
[2018-06-05 01:31] Train Step 39625, Epoch 36.7, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -407.654, Loss = 408.068
[2018-06-05 01:31] Train Step 39650, Epoch 36.7, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -395.336, Loss = 406.697
[2018-06-05 01:31] Train Step 39675, Epoch 36.7, Batch Size = 256, Examples/Sec = 3863.33, Train LB = -404.255, Loss = 406.423
[2018-06-05 01:31] Train Step 39700, Epoch 36.8, Batch Size = 256, Examples/Sec = 3863.80, Train LB = -403.876, Loss = 405.230
[2018-06-05 01:31] Train Step 39725, Epoch 36.8, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -433.191, Loss = 405.100
[2018-06-05 01:31] Train Step 39750, Epoch 36.8, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -409.124, Loss = 406.018
[2018-06-05 01:31] Train Step 39775, Epoch 36.8, Batch Size = 256, Examples/Sec = 3849.85, Train LB = -417.721, Loss = 406.823
[2018-06-05 01:31] Train Step 39800, Epoch 36.9, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -410.968, Loss = 408.446
Performance on test set:
  Test Lower Bound = -436.869, Test Loss = 436.869
[2018-06-05 01:31] Train Step 39825, Epoch 36.9, Batch Size = 256, Examples/Sec = 3869.28, Train LB = -392.943, Loss = 407.002
[2018-06-05 01:31] Train Step 39850, Epoch 36.9, Batch Size = 256, Examples/Sec = 3875.61, Train LB = -410.579, Loss = 406.573
[2018-06-05 01:31] Train Step 39875, Epoch 36.9, Batch Size = 256, Examples/Sec = 3875.97, Train LB = -403.397, Loss = 405.816
[2018-06-05 01:31] Train Step 39900, Epoch 36.9, Batch Size = 256, Examples/Sec = 3867.24, Train LB = -412.493, Loss = 404.723
[2018-06-05 01:31] Train Step 39925, Epoch 37.0, Batch Size = 256, Examples/Sec = 3809.18, Train LB = -405.794, Loss = 404.891
[2018-06-05 01:31] Train Step 39950, Epoch 37.0, Batch Size = 256, Examples/Sec = 3882.79, Train LB = -414.214, Loss = 404.572
[2018-06-05 01:31] Train Step 39975, Epoch 37.0, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -419.492, Loss = 406.452
[2018-06-05 01:32] Train Step 40000, Epoch 37.0, Batch Size = 256, Examples/Sec = 3873.57, Train LB = -424.974, Loss = 408.074
Performance on test set:
  Test Lower Bound = -436.308, Test Loss = 436.308
[2018-06-05 01:32] Train Step 40025, Epoch 37.1, Batch Size = 256, Examples/Sec = 3814.18, Train LB = -413.183, Loss = 407.095
[2018-06-05 01:32] Train Step 40050, Epoch 37.1, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -397.385, Loss = 406.313
[2018-06-05 01:32] Train Step 40075, Epoch 37.1, Batch Size = 256, Examples/Sec = 3882.01, Train LB = -397.139, Loss = 406.074
[2018-06-05 01:32] Train Step 40100, Epoch 37.1, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -398.579, Loss = 405.208
[2018-06-05 01:32] Train Step 40125, Epoch 37.2, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -402.621, Loss = 404.666
[2018-06-05 01:32] Train Step 40150, Epoch 37.2, Batch Size = 256, Examples/Sec = 3844.13, Train LB = -415.954, Loss = 405.713
[2018-06-05 01:32] Train Step 40175, Epoch 37.2, Batch Size = 256, Examples/Sec = 3847.08, Train LB = -412.647, Loss = 406.168
[2018-06-05 01:32] Train Step 40200, Epoch 37.2, Batch Size = 256, Examples/Sec = 3875.50, Train LB = -402.172, Loss = 407.551
Performance on test set:
  Test Lower Bound = -437.206, Test Loss = 437.206
[2018-06-05 01:32] Train Step 40225, Epoch 37.2, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -391.854, Loss = 406.783
[2018-06-05 01:32] Train Step 40250, Epoch 37.3, Batch Size = 256, Examples/Sec = 3855.18, Train LB = -410.838, Loss = 406.614
[2018-06-05 01:32] Train Step 40275, Epoch 37.3, Batch Size = 256, Examples/Sec = 3876.03, Train LB = -406.193, Loss = 406.298
[2018-06-05 01:32] Train Step 40300, Epoch 37.3, Batch Size = 256, Examples/Sec = 3861.76, Train LB = -413.435, Loss = 404.847
[2018-06-05 01:32] Train Step 40325, Epoch 37.3, Batch Size = 256, Examples/Sec = 3874.49, Train LB = -405.923, Loss = 404.750
[2018-06-05 01:32] Train Step 40350, Epoch 37.4, Batch Size = 256, Examples/Sec = 3877.02, Train LB = -422.739, Loss = 404.706
[2018-06-05 01:32] Train Step 40375, Epoch 37.4, Batch Size = 256, Examples/Sec = 3871.45, Train LB = -412.881, Loss = 405.489
[2018-06-05 01:32] Train Step 40400, Epoch 37.4, Batch Size = 256, Examples/Sec = 3829.40, Train LB = -417.608, Loss = 406.933
Performance on test set:
  Test Lower Bound = -437.964, Test Loss = 437.964
[2018-06-05 01:32] Train Step 40425, Epoch 37.4, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -391.701, Loss = 407.276
[2018-06-05 01:32] Train Step 40450, Epoch 37.5, Batch Size = 256, Examples/Sec = 3855.43, Train LB = -411.941, Loss = 406.078
[2018-06-05 01:32] Train Step 40475, Epoch 37.5, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -387.023, Loss = 406.274
[2018-06-05 01:32] Train Step 40500, Epoch 37.5, Batch Size = 256, Examples/Sec = 3799.17, Train LB = -404.196, Loss = 404.687
[2018-06-05 01:32] Train Step 40525, Epoch 37.5, Batch Size = 256, Examples/Sec = 3874.34, Train LB = -414.651, Loss = 404.543
[2018-06-05 01:32] Train Step 40550, Epoch 37.5, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -394.959, Loss = 404.820
[2018-06-05 01:32] Train Step 40575, Epoch 37.6, Batch Size = 256, Examples/Sec = 3880.72, Train LB = -403.044, Loss = 405.630
[2018-06-05 01:32] Train Step 40600, Epoch 37.6, Batch Size = 256, Examples/Sec = 3885.39, Train LB = -419.804, Loss = 407.397
Performance on test set:
  Test Lower Bound = -436.330, Test Loss = 436.330
[2018-06-05 01:32] Train Step 40625, Epoch 37.6, Batch Size = 256, Examples/Sec = 3856.94, Train LB = -402.418, Loss = 406.978
[2018-06-05 01:32] Train Step 40650, Epoch 37.6, Batch Size = 256, Examples/Sec = 3873.21, Train LB = -403.719, Loss = 405.745
[2018-06-05 01:32] Train Step 40675, Epoch 37.7, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -405.608, Loss = 404.755
[2018-06-05 01:33] Train Step 40700, Epoch 37.7, Batch Size = 256, Examples/Sec = 3882.49, Train LB = -401.727, Loss = 404.715
[2018-06-05 01:33] Train Step 40725, Epoch 37.7, Batch Size = 256, Examples/Sec = 3839.47, Train LB = -395.736, Loss = 403.978
[2018-06-05 01:33] Train Step 40750, Epoch 37.7, Batch Size = 256, Examples/Sec = 3880.96, Train LB = -399.633, Loss = 403.877
[2018-06-05 01:33] Train Step 40775, Epoch 37.8, Batch Size = 256, Examples/Sec = 3791.65, Train LB = -423.344, Loss = 404.821
[2018-06-05 01:33] Train Step 40800, Epoch 37.8, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -424.909, Loss = 407.017
Performance on test set:
  Test Lower Bound = -437.195, Test Loss = 437.195
[2018-06-05 01:33] Train Step 40825, Epoch 37.8, Batch Size = 256, Examples/Sec = 3852.47, Train LB = -399.403, Loss = 407.136
[2018-06-05 01:33] Train Step 40850, Epoch 37.8, Batch Size = 256, Examples/Sec = 3848.36, Train LB = -407.005, Loss = 405.943
[2018-06-05 01:33] Train Step 40875, Epoch 37.8, Batch Size = 256, Examples/Sec = 3843.49, Train LB = -399.575, Loss = 405.439
[2018-06-05 01:33] Train Step 40900, Epoch 37.9, Batch Size = 256, Examples/Sec = 3853.68, Train LB = -408.196, Loss = 404.448
[2018-06-05 01:33] Train Step 40925, Epoch 37.9, Batch Size = 256, Examples/Sec = 3847.38, Train LB = -403.606, Loss = 404.187
[2018-06-05 01:33] Train Step 40950, Epoch 37.9, Batch Size = 256, Examples/Sec = 3864.55, Train LB = -408.185, Loss = 403.695
[2018-06-05 01:33] Train Step 40975, Epoch 37.9, Batch Size = 256, Examples/Sec = 3804.48, Train LB = -406.062, Loss = 404.600
[2018-06-05 01:33] Train Step 41000, Epoch 38.0, Batch Size = 256, Examples/Sec = 3845.74, Train LB = -402.989, Loss = 407.172
Performance on test set:
  Test Lower Bound = -436.698, Test Loss = 436.698
[2018-06-05 01:33] Train Step 41025, Epoch 38.0, Batch Size = 256, Examples/Sec = 3801.38, Train LB = -407.130, Loss = 406.318
[2018-06-05 01:33] Train Step 41050, Epoch 38.0, Batch Size = 256, Examples/Sec = 3875.97, Train LB = -404.971, Loss = 406.091
[2018-06-05 01:33] Train Step 41075, Epoch 38.0, Batch Size = 256, Examples/Sec = 3814.81, Train LB = -403.343, Loss = 404.965
[2018-06-05 01:33] Train Step 41100, Epoch 38.1, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -393.585, Loss = 404.309
[2018-06-05 01:33] Train Step 41125, Epoch 38.1, Batch Size = 256, Examples/Sec = 3877.37, Train LB = -409.622, Loss = 403.786
[2018-06-05 01:33] Train Step 41150, Epoch 38.1, Batch Size = 256, Examples/Sec = 3877.08, Train LB = -405.264, Loss = 403.983
[2018-06-05 01:33] Train Step 41175, Epoch 38.1, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -400.705, Loss = 404.954
[2018-06-05 01:33] Train Step 41200, Epoch 38.1, Batch Size = 256, Examples/Sec = 3851.53, Train LB = -413.103, Loss = 406.661
Performance on test set:
  Test Lower Bound = -437.575, Test Loss = 437.575
[2018-06-05 01:33] Train Step 41225, Epoch 38.2, Batch Size = 256, Examples/Sec = 3872.97, Train LB = -405.770, Loss = 405.534
[2018-06-05 01:33] Train Step 41250, Epoch 38.2, Batch Size = 256, Examples/Sec = 3854.95, Train LB = -399.025, Loss = 405.839
[2018-06-05 01:33] Train Step 41275, Epoch 38.2, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -402.242, Loss = 405.565
[2018-06-05 01:33] Train Step 41300, Epoch 38.2, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -392.578, Loss = 404.719
[2018-06-05 01:33] Train Step 41325, Epoch 38.3, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -416.254, Loss = 404.187
[2018-06-05 01:33] Train Step 41350, Epoch 38.3, Batch Size = 256, Examples/Sec = 3877.02, Train LB = -413.147, Loss = 404.227
[2018-06-05 01:33] Train Step 41375, Epoch 38.3, Batch Size = 256, Examples/Sec = 3846.10, Train LB = -420.022, Loss = 405.484
[2018-06-05 01:33] Train Step 41400, Epoch 38.3, Batch Size = 256, Examples/Sec = 3890.45, Train LB = -425.098, Loss = 407.192
Performance on test set:
  Test Lower Bound = -437.719, Test Loss = 437.719
[2018-06-05 01:34] Train Step 41425, Epoch 38.4, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -418.057, Loss = 406.144
[2018-06-05 01:34] Train Step 41450, Epoch 38.4, Batch Size = 256, Examples/Sec = 3876.38, Train LB = -398.528, Loss = 405.707
[2018-06-05 01:34] Train Step 41475, Epoch 38.4, Batch Size = 256, Examples/Sec = 3854.03, Train LB = -409.137, Loss = 405.529
[2018-06-05 01:34] Train Step 41500, Epoch 38.4, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -392.612, Loss = 404.347
[2018-06-05 01:34] Train Step 41525, Epoch 38.4, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -414.084, Loss = 403.405
[2018-06-05 01:34] Train Step 41550, Epoch 38.5, Batch Size = 256, Examples/Sec = 3815.77, Train LB = -402.360, Loss = 404.026
[2018-06-05 01:34] Train Step 41575, Epoch 38.5, Batch Size = 256, Examples/Sec = 3860.66, Train LB = -404.888, Loss = 404.752
[2018-06-05 01:34] Train Step 41600, Epoch 38.5, Batch Size = 256, Examples/Sec = 3890.40, Train LB = -414.099, Loss = 406.508
Performance on test set:
  Test Lower Bound = -436.913, Test Loss = 436.913
[2018-06-05 01:34] Train Step 41625, Epoch 38.5, Batch Size = 256, Examples/Sec = 3858.80, Train LB = -401.607, Loss = 405.310
[2018-06-05 01:34] Train Step 41650, Epoch 38.6, Batch Size = 256, Examples/Sec = 3878.68, Train LB = -413.897, Loss = 405.278
[2018-06-05 01:34] Train Step 41675, Epoch 38.6, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -387.059, Loss = 405.085
[2018-06-05 01:34] Train Step 41700, Epoch 38.6, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -423.544, Loss = 403.836
[2018-06-05 01:34] Train Step 41725, Epoch 38.6, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -394.111, Loss = 403.819
[2018-06-05 01:34] Train Step 41750, Epoch 38.7, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -414.260, Loss = 403.680
[2018-06-05 01:34] Train Step 41775, Epoch 38.7, Batch Size = 256, Examples/Sec = 3870.75, Train LB = -394.805, Loss = 404.304
[2018-06-05 01:34] Train Step 41800, Epoch 38.7, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -420.317, Loss = 406.690
Performance on test set:
  Test Lower Bound = -438.832, Test Loss = 438.832
[2018-06-05 01:34] Train Step 41825, Epoch 38.7, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -390.518, Loss = 406.186
[2018-06-05 01:34] Train Step 41850, Epoch 38.8, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -404.368, Loss = 404.527
[2018-06-05 01:34] Train Step 41875, Epoch 38.8, Batch Size = 256, Examples/Sec = 3805.40, Train LB = -402.168, Loss = 404.104
[2018-06-05 01:34] Train Step 41900, Epoch 38.8, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -420.144, Loss = 403.680
[2018-06-05 01:34] Train Step 41925, Epoch 38.8, Batch Size = 256, Examples/Sec = 3851.53, Train LB = -401.708, Loss = 403.288
[2018-06-05 01:34] Train Step 41950, Epoch 38.8, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -408.833, Loss = 403.340
[2018-06-05 01:34] Train Step 41975, Epoch 38.9, Batch Size = 256, Examples/Sec = 3858.49, Train LB = -420.029, Loss = 404.423
[2018-06-05 01:34] Train Step 42000, Epoch 38.9, Batch Size = 256, Examples/Sec = 3866.36, Train LB = -434.334, Loss = 406.979
Performance on test set:
  Test Lower Bound = -436.939, Test Loss = 436.939
[2018-06-05 01:34] Train Step 42025, Epoch 38.9, Batch Size = 256, Examples/Sec = 3813.21, Train LB = -404.736, Loss = 406.324
[2018-06-05 01:34] Train Step 42050, Epoch 38.9, Batch Size = 256, Examples/Sec = 3861.23, Train LB = -396.257, Loss = 405.593
[2018-06-05 01:34] Train Step 42075, Epoch 39.0, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -403.572, Loss = 404.771
[2018-06-05 01:34] Train Step 42100, Epoch 39.0, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -403.874, Loss = 404.374
[2018-06-05 01:34] Train Step 42125, Epoch 39.0, Batch Size = 256, Examples/Sec = 3852.22, Train LB = -374.104, Loss = 404.308
[2018-06-05 01:35] Train Step 42150, Epoch 39.0, Batch Size = 256, Examples/Sec = 3874.03, Train LB = -390.545, Loss = 404.331
[2018-06-05 01:35] Train Step 42175, Epoch 39.1, Batch Size = 256, Examples/Sec = 3871.68, Train LB = -414.072, Loss = 404.651
[2018-06-05 01:35] Train Step 42200, Epoch 39.1, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -411.003, Loss = 406.686
Performance on test set:
  Test Lower Bound = -438.272, Test Loss = 438.272
[2018-06-05 01:35] Train Step 42225, Epoch 39.1, Batch Size = 256, Examples/Sec = 3869.24, Train LB = -402.856, Loss = 405.346
[2018-06-05 01:35] Train Step 42250, Epoch 39.1, Batch Size = 256, Examples/Sec = 3867.24, Train LB = -390.385, Loss = 404.856
[2018-06-05 01:35] Train Step 42275, Epoch 39.1, Batch Size = 256, Examples/Sec = 3846.32, Train LB = -409.122, Loss = 404.067
[2018-06-05 01:35] Train Step 42300, Epoch 39.2, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -408.344, Loss = 403.729
[2018-06-05 01:35] Train Step 42325, Epoch 39.2, Batch Size = 256, Examples/Sec = 3886.61, Train LB = -403.968, Loss = 403.297
[2018-06-05 01:35] Train Step 42350, Epoch 39.2, Batch Size = 256, Examples/Sec = 3876.73, Train LB = -406.050, Loss = 403.030
[2018-06-05 01:35] Train Step 42375, Epoch 39.2, Batch Size = 256, Examples/Sec = 3879.43, Train LB = -416.979, Loss = 404.103
[2018-06-05 01:35] Train Step 42400, Epoch 39.3, Batch Size = 256, Examples/Sec = 3816.22, Train LB = -430.161, Loss = 405.602
Performance on test set:
  Test Lower Bound = -437.878, Test Loss = 437.878
[2018-06-05 01:35] Train Step 42425, Epoch 39.3, Batch Size = 256, Examples/Sec = 3859.08, Train LB = -399.591, Loss = 405.604
[2018-06-05 01:35] Train Step 42450, Epoch 39.3, Batch Size = 256, Examples/Sec = 3841.42, Train LB = -405.393, Loss = 404.987
[2018-06-05 01:35] Train Step 42475, Epoch 39.3, Batch Size = 256, Examples/Sec = 3869.58, Train LB = -404.533, Loss = 403.763
[2018-06-05 01:35] Train Step 42500, Epoch 39.4, Batch Size = 256, Examples/Sec = 3830.16, Train LB = -419.641, Loss = 403.438
[2018-06-05 01:35] Train Step 42525, Epoch 39.4, Batch Size = 256, Examples/Sec = 3851.48, Train LB = -397.671, Loss = 403.087
[2018-06-05 01:35] Train Step 42550, Epoch 39.4, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -394.041, Loss = 403.347
[2018-06-05 01:35] Train Step 42575, Epoch 39.4, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -414.128, Loss = 403.797
[2018-06-05 01:35] Train Step 42600, Epoch 39.4, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -429.466, Loss = 405.960
Performance on test set:
  Test Lower Bound = -438.225, Test Loss = 438.225
[2018-06-05 01:35] Train Step 42625, Epoch 39.5, Batch Size = 256, Examples/Sec = 3801.60, Train LB = -398.704, Loss = 405.444
[2018-06-05 01:35] Train Step 42650, Epoch 39.5, Batch Size = 256, Examples/Sec = 3876.86, Train LB = -411.176, Loss = 404.779
[2018-06-05 01:35] Train Step 42675, Epoch 39.5, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -397.631, Loss = 404.580
[2018-06-05 01:35] Train Step 42700, Epoch 39.5, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -412.589, Loss = 403.525
[2018-06-05 01:35] Train Step 42725, Epoch 39.6, Batch Size = 256, Examples/Sec = 3829.13, Train LB = -411.805, Loss = 403.808
[2018-06-05 01:35] Train Step 42750, Epoch 39.6, Batch Size = 256, Examples/Sec = 3859.04, Train LB = -415.287, Loss = 403.278
[2018-06-05 01:35] Train Step 42775, Epoch 39.6, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -400.777, Loss = 403.771
[2018-06-05 01:35] Train Step 42800, Epoch 39.6, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -436.468, Loss = 405.848
Performance on test set:
  Test Lower Bound = -438.029, Test Loss = 438.029
[2018-06-05 01:36] Train Step 42825, Epoch 39.7, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -397.065, Loss = 405.279
[2018-06-05 01:36] Train Step 42850, Epoch 39.7, Batch Size = 256, Examples/Sec = 3880.61, Train LB = -395.655, Loss = 404.604
[2018-06-05 01:36] Train Step 42875, Epoch 39.7, Batch Size = 256, Examples/Sec = 3846.33, Train LB = -415.341, Loss = 403.737
[2018-06-05 01:36] Train Step 42900, Epoch 39.7, Batch Size = 256, Examples/Sec = 3883.14, Train LB = -400.914, Loss = 403.969
[2018-06-05 01:36] Train Step 42925, Epoch 39.7, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -401.591, Loss = 403.618
[2018-06-05 01:36] Train Step 42950, Epoch 39.8, Batch Size = 256, Examples/Sec = 3814.63, Train LB = -417.720, Loss = 403.404
[2018-06-05 01:36] Train Step 42975, Epoch 39.8, Batch Size = 256, Examples/Sec = 3875.26, Train LB = -426.121, Loss = 404.505
[2018-06-05 01:36] Train Step 43000, Epoch 39.8, Batch Size = 256, Examples/Sec = 3866.26, Train LB = -412.163, Loss = 406.501
Performance on test set:
  Test Lower Bound = -438.115, Test Loss = 438.115
[2018-06-05 01:36] Train Step 43025, Epoch 39.8, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -405.270, Loss = 405.677
[2018-06-05 01:36] Train Step 43050, Epoch 39.9, Batch Size = 256, Examples/Sec = 3831.02, Train LB = -399.746, Loss = 405.233
[2018-06-05 01:36] Train Step 43075, Epoch 39.9, Batch Size = 256, Examples/Sec = 3830.21, Train LB = -394.404, Loss = 403.787
[2018-06-05 01:36] Train Step 43100, Epoch 39.9, Batch Size = 256, Examples/Sec = 3844.60, Train LB = -408.012, Loss = 403.394
[2018-06-05 01:36] Train Step 43125, Epoch 39.9, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -391.233, Loss = 403.169
[2018-06-05 01:36] Train Step 43150, Epoch 40.0, Batch Size = 256, Examples/Sec = 3847.14, Train LB = -416.816, Loss = 402.389
[2018-06-05 01:36] Train Step 43175, Epoch 40.0, Batch Size = 256, Examples/Sec = 3815.77, Train LB = -405.760, Loss = 404.131
[2018-06-05 01:36] Train Step 43200, Epoch 40.0, Batch Size = 256, Examples/Sec = 3875.09, Train LB = -411.402, Loss = 406.047
Performance on test set:
  Test Lower Bound = -438.069, Test Loss = 438.069
[2018-06-05 01:36] Train Step 43225, Epoch 40.0, Batch Size = 256, Examples/Sec = 3875.79, Train LB = -409.301, Loss = 405.129
[2018-06-05 01:36] Train Step 43250, Epoch 40.0, Batch Size = 256, Examples/Sec = 3872.27, Train LB = -403.812, Loss = 404.299
[2018-06-05 01:36] Train Step 43275, Epoch 40.1, Batch Size = 256, Examples/Sec = 3839.00, Train LB = -409.312, Loss = 403.595
[2018-06-05 01:36] Train Step 43300, Epoch 40.1, Batch Size = 256, Examples/Sec = 3873.85, Train LB = -392.693, Loss = 403.018
[2018-06-05 01:36] Train Step 43325, Epoch 40.1, Batch Size = 256, Examples/Sec = 3835.96, Train LB = -400.218, Loss = 402.446
[2018-06-05 01:36] Train Step 43350, Epoch 40.1, Batch Size = 256, Examples/Sec = 3835.78, Train LB = -388.258, Loss = 402.996
[2018-06-05 01:36] Train Step 43375, Epoch 40.2, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -405.839, Loss = 403.723
[2018-06-05 01:36] Train Step 43400, Epoch 40.2, Batch Size = 256, Examples/Sec = 3871.63, Train LB = -420.756, Loss = 405.706
Performance on test set:
  Test Lower Bound = -438.906, Test Loss = 438.906
[2018-06-05 01:36] Train Step 43425, Epoch 40.2, Batch Size = 256, Examples/Sec = 3872.10, Train LB = -404.621, Loss = 405.217
[2018-06-05 01:36] Train Step 43450, Epoch 40.2, Batch Size = 256, Examples/Sec = 3843.73, Train LB = -405.356, Loss = 404.575
[2018-06-05 01:36] Train Step 43475, Epoch 40.3, Batch Size = 256, Examples/Sec = 3879.08, Train LB = -392.538, Loss = 403.965
[2018-06-05 01:36] Train Step 43500, Epoch 40.3, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -401.737, Loss = 403.479
[2018-06-05 01:36] Train Step 43525, Epoch 40.3, Batch Size = 256, Examples/Sec = 3844.71, Train LB = -406.784, Loss = 402.972
[2018-06-05 01:36] Train Step 43550, Epoch 40.3, Batch Size = 256, Examples/Sec = 3855.76, Train LB = -403.119, Loss = 402.949
[2018-06-05 01:37] Train Step 43575, Epoch 40.3, Batch Size = 256, Examples/Sec = 3835.15, Train LB = -418.075, Loss = 404.213
[2018-06-05 01:37] Train Step 43600, Epoch 40.4, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -410.553, Loss = 406.104
Performance on test set:
  Test Lower Bound = -438.187, Test Loss = 438.187
[2018-06-05 01:37] Train Step 43625, Epoch 40.4, Batch Size = 256, Examples/Sec = 3868.71, Train LB = -407.907, Loss = 404.788
[2018-06-05 01:37] Train Step 43650, Epoch 40.4, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -401.507, Loss = 404.203
[2018-06-05 01:37] Train Step 43675, Epoch 40.4, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -399.234, Loss = 403.713
[2018-06-05 01:37] Train Step 43700, Epoch 40.5, Batch Size = 256, Examples/Sec = 3872.05, Train LB = -391.137, Loss = 403.588
[2018-06-05 01:37] Train Step 43725, Epoch 40.5, Batch Size = 256, Examples/Sec = 3845.88, Train LB = -413.088, Loss = 402.755
[2018-06-05 01:37] Train Step 43750, Epoch 40.5, Batch Size = 256, Examples/Sec = 3783.95, Train LB = -408.299, Loss = 403.157
[2018-06-05 01:37] Train Step 43775, Epoch 40.5, Batch Size = 256, Examples/Sec = 3857.87, Train LB = -399.361, Loss = 404.183
[2018-06-05 01:37] Train Step 43800, Epoch 40.6, Batch Size = 256, Examples/Sec = 3837.38, Train LB = -420.640, Loss = 406.493
Performance on test set:
  Test Lower Bound = -437.954, Test Loss = 437.954
[2018-06-05 01:37] Train Step 43825, Epoch 40.6, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -399.269, Loss = 405.663
[2018-06-05 01:37] Train Step 43850, Epoch 40.6, Batch Size = 256, Examples/Sec = 3804.94, Train LB = -395.266, Loss = 404.394
[2018-06-05 01:37] Train Step 43875, Epoch 40.6, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -404.341, Loss = 403.958
[2018-06-05 01:37] Train Step 43900, Epoch 40.6, Batch Size = 256, Examples/Sec = 3857.58, Train LB = -408.102, Loss = 403.691
[2018-06-05 01:37] Train Step 43925, Epoch 40.7, Batch Size = 256, Examples/Sec = 3881.66, Train LB = -412.945, Loss = 402.905
[2018-06-05 01:37] Train Step 43950, Epoch 40.7, Batch Size = 256, Examples/Sec = 3849.45, Train LB = -403.241, Loss = 402.794
[2018-06-05 01:37] Train Step 43975, Epoch 40.7, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -411.270, Loss = 403.398
[2018-06-05 01:37] Train Step 44000, Epoch 40.7, Batch Size = 256, Examples/Sec = 3858.84, Train LB = -420.471, Loss = 405.898
Performance on test set:
  Test Lower Bound = -439.144, Test Loss = 439.144
[2018-06-05 01:37] Train Step 44025, Epoch 40.8, Batch Size = 256, Examples/Sec = 3865.13, Train LB = -401.871, Loss = 404.833
[2018-06-05 01:37] Train Step 44050, Epoch 40.8, Batch Size = 256, Examples/Sec = 3861.77, Train LB = -384.361, Loss = 404.461
[2018-06-05 01:37] Train Step 44075, Epoch 40.8, Batch Size = 256, Examples/Sec = 3876.27, Train LB = -404.327, Loss = 404.070
[2018-06-05 01:37] Train Step 44100, Epoch 40.8, Batch Size = 256, Examples/Sec = 3838.03, Train LB = -391.872, Loss = 403.060
[2018-06-05 01:37] Train Step 44125, Epoch 40.9, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -407.479, Loss = 402.533
[2018-06-05 01:37] Train Step 44150, Epoch 40.9, Batch Size = 256, Examples/Sec = 3851.02, Train LB = -398.640, Loss = 402.440
[2018-06-05 01:37] Train Step 44175, Epoch 40.9, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -416.993, Loss = 403.188
[2018-06-05 01:37] Train Step 44200, Epoch 40.9, Batch Size = 256, Examples/Sec = 3796.81, Train LB = -424.524, Loss = 405.471
Performance on test set:
  Test Lower Bound = -437.690, Test Loss = 437.690
[2018-06-05 01:37] Train Step 44225, Epoch 40.9, Batch Size = 256, Examples/Sec = 3879.97, Train LB = -408.685, Loss = 404.767
[2018-06-05 01:37] Train Step 44250, Epoch 41.0, Batch Size = 256, Examples/Sec = 3863.28, Train LB = -401.325, Loss = 403.982
[2018-06-05 01:38] Train Step 44275, Epoch 41.0, Batch Size = 256, Examples/Sec = 3856.65, Train LB = -410.562, Loss = 403.006
[2018-06-05 01:38] Train Step 44300, Epoch 41.0, Batch Size = 256, Examples/Sec = 3858.73, Train LB = -399.464, Loss = 402.611
[2018-06-05 01:38] Train Step 44325, Epoch 41.0, Batch Size = 256, Examples/Sec = 3832.51, Train LB = -396.736, Loss = 402.099
[2018-06-05 01:38] Train Step 44350, Epoch 41.1, Batch Size = 256, Examples/Sec = 3878.86, Train LB = -413.578, Loss = 402.109
[2018-06-05 01:38] Train Step 44375, Epoch 41.1, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -413.611, Loss = 402.575
[2018-06-05 01:38] Train Step 44400, Epoch 41.1, Batch Size = 256, Examples/Sec = 3829.08, Train LB = -426.298, Loss = 404.933
Performance on test set:
  Test Lower Bound = -439.295, Test Loss = 439.295
[2018-06-05 01:38] Train Step 44425, Epoch 41.1, Batch Size = 256, Examples/Sec = 3809.35, Train LB = -402.920, Loss = 404.729
[2018-06-05 01:38] Train Step 44450, Epoch 41.2, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -407.072, Loss = 403.858
[2018-06-05 01:38] Train Step 44475, Epoch 41.2, Batch Size = 256, Examples/Sec = 3867.71, Train LB = -396.610, Loss = 402.513
[2018-06-05 01:38] Train Step 44500, Epoch 41.2, Batch Size = 256, Examples/Sec = 3869.34, Train LB = -409.438, Loss = 402.483
[2018-06-05 01:38] Train Step 44525, Epoch 41.2, Batch Size = 256, Examples/Sec = 3813.95, Train LB = -410.995, Loss = 402.179
[2018-06-05 01:38] Train Step 44550, Epoch 41.2, Batch Size = 256, Examples/Sec = 3881.27, Train LB = -396.150, Loss = 402.164
[2018-06-05 01:38] Train Step 44575, Epoch 41.3, Batch Size = 256, Examples/Sec = 3885.26, Train LB = -411.526, Loss = 403.060
[2018-06-05 01:38] Train Step 44600, Epoch 41.3, Batch Size = 256, Examples/Sec = 3863.56, Train LB = -426.468, Loss = 405.094
Performance on test set:
  Test Lower Bound = -439.707, Test Loss = 439.707
[2018-06-05 01:38] Train Step 44625, Epoch 41.3, Batch Size = 256, Examples/Sec = 3871.06, Train LB = -413.088, Loss = 404.374
[2018-06-05 01:38] Train Step 44650, Epoch 41.3, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -416.661, Loss = 404.109
[2018-06-05 01:38] Train Step 44675, Epoch 41.4, Batch Size = 256, Examples/Sec = 3875.67, Train LB = -400.042, Loss = 403.285
[2018-06-05 01:38] Train Step 44700, Epoch 41.4, Batch Size = 256, Examples/Sec = 3825.86, Train LB = -424.306, Loss = 402.593
[2018-06-05 01:38] Train Step 44725, Epoch 41.4, Batch Size = 256, Examples/Sec = 3852.58, Train LB = -408.708, Loss = 402.345
[2018-06-05 01:38] Train Step 44750, Epoch 41.4, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -400.061, Loss = 402.555
[2018-06-05 01:38] Train Step 44775, Epoch 41.5, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -395.772, Loss = 403.003
[2018-06-05 01:38] Train Step 44800, Epoch 41.5, Batch Size = 256, Examples/Sec = 3854.44, Train LB = -414.336, Loss = 404.902
Performance on test set:
  Test Lower Bound = -439.323, Test Loss = 439.323
[2018-06-05 01:38] Train Step 44825, Epoch 41.5, Batch Size = 256, Examples/Sec = 3844.54, Train LB = -402.317, Loss = 404.005
[2018-06-05 01:38] Train Step 44850, Epoch 41.5, Batch Size = 256, Examples/Sec = 3859.67, Train LB = -417.756, Loss = 403.645
[2018-06-05 01:38] Train Step 44875, Epoch 41.6, Batch Size = 256, Examples/Sec = 3872.58, Train LB = -401.060, Loss = 403.157
[2018-06-05 01:38] Train Step 44900, Epoch 41.6, Batch Size = 256, Examples/Sec = 3805.27, Train LB = -389.152, Loss = 402.556
[2018-06-05 01:38] Train Step 44925, Epoch 41.6, Batch Size = 256, Examples/Sec = 3879.78, Train LB = -400.935, Loss = 401.717
[2018-06-05 01:38] Train Step 44950, Epoch 41.6, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -397.298, Loss = 401.484
[2018-06-05 01:38] Train Step 44975, Epoch 41.6, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -416.013, Loss = 402.485
[2018-06-05 01:38] Train Step 45000, Epoch 41.7, Batch Size = 256, Examples/Sec = 3876.67, Train LB = -431.012, Loss = 404.633
Performance on test set:
  Test Lower Bound = -438.607, Test Loss = 438.607
[2018-06-05 01:39] Train Step 45025, Epoch 41.7, Batch Size = 256, Examples/Sec = 3882.25, Train LB = -395.885, Loss = 403.666
[2018-06-05 01:39] Train Step 45050, Epoch 41.7, Batch Size = 256, Examples/Sec = 3849.45, Train LB = -399.425, Loss = 402.956
[2018-06-05 01:39] Train Step 45075, Epoch 41.7, Batch Size = 256, Examples/Sec = 3806.07, Train LB = -409.268, Loss = 402.767
[2018-06-05 01:39] Train Step 45100, Epoch 41.8, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -403.501, Loss = 402.262
[2018-06-05 01:39] Train Step 45125, Epoch 41.8, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -409.535, Loss = 401.681
[2018-06-05 01:39] Train Step 45150, Epoch 41.8, Batch Size = 256, Examples/Sec = 3856.46, Train LB = -404.982, Loss = 401.636
[2018-06-05 01:39] Train Step 45175, Epoch 41.8, Batch Size = 256, Examples/Sec = 3847.78, Train LB = -390.003, Loss = 402.761
[2018-06-05 01:39] Train Step 45200, Epoch 41.9, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -411.588, Loss = 404.819
Performance on test set:
  Test Lower Bound = -438.013, Test Loss = 438.013
[2018-06-05 01:39] Train Step 45225, Epoch 41.9, Batch Size = 256, Examples/Sec = 3854.15, Train LB = -395.354, Loss = 403.696
[2018-06-05 01:39] Train Step 45250, Epoch 41.9, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -395.226, Loss = 403.361
[2018-06-05 01:39] Train Step 45275, Epoch 41.9, Batch Size = 256, Examples/Sec = 3891.30, Train LB = -402.122, Loss = 402.893
[2018-06-05 01:39] Train Step 45300, Epoch 41.9, Batch Size = 256, Examples/Sec = 3828.16, Train LB = -404.009, Loss = 402.035
[2018-06-05 01:39] Train Step 45325, Epoch 42.0, Batch Size = 256, Examples/Sec = 3859.20, Train LB = -407.728, Loss = 401.893
[2018-06-05 01:39] Train Step 45350, Epoch 42.0, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -412.538, Loss = 402.551
[2018-06-05 01:39] Train Step 45375, Epoch 42.0, Batch Size = 256, Examples/Sec = 3811.68, Train LB = -396.971, Loss = 403.272
[2018-06-05 01:39] Train Step 45400, Epoch 42.0, Batch Size = 256, Examples/Sec = 3890.57, Train LB = -417.351, Loss = 405.450
Performance on test set:
  Test Lower Bound = -438.335, Test Loss = 438.335
[2018-06-05 01:39] Train Step 45425, Epoch 42.1, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -393.404, Loss = 405.032
[2018-06-05 01:39] Train Step 45450, Epoch 42.1, Batch Size = 256, Examples/Sec = 3853.09, Train LB = -396.567, Loss = 403.993
[2018-06-05 01:39] Train Step 45475, Epoch 42.1, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -403.769, Loss = 402.874
[2018-06-05 01:39] Train Step 45500, Epoch 42.1, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -400.508, Loss = 401.999
[2018-06-05 01:39] Train Step 45525, Epoch 42.2, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -398.856, Loss = 401.863
[2018-06-05 01:39] Train Step 45550, Epoch 42.2, Batch Size = 256, Examples/Sec = 3875.21, Train LB = -410.222, Loss = 401.842
[2018-06-05 01:39] Train Step 45575, Epoch 42.2, Batch Size = 256, Examples/Sec = 3865.66, Train LB = -411.019, Loss = 403.410
[2018-06-05 01:39] Train Step 45600, Epoch 42.2, Batch Size = 256, Examples/Sec = 3782.67, Train LB = -410.085, Loss = 405.111
Performance on test set:
  Test Lower Bound = -439.560, Test Loss = 439.560
[2018-06-05 01:39] Train Step 45625, Epoch 42.2, Batch Size = 256, Examples/Sec = 3875.79, Train LB = -393.093, Loss = 403.832
[2018-06-05 01:39] Train Step 45650, Epoch 42.3, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -394.558, Loss = 402.751
[2018-06-05 01:39] Train Step 45675, Epoch 42.3, Batch Size = 256, Examples/Sec = 3883.73, Train LB = -396.509, Loss = 402.895
[2018-06-05 01:39] Train Step 45700, Epoch 42.3, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -398.946, Loss = 402.013
[2018-06-05 01:40] Train Step 45725, Epoch 42.3, Batch Size = 256, Examples/Sec = 3853.98, Train LB = -413.118, Loss = 400.889
[2018-06-05 01:40] Train Step 45750, Epoch 42.4, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -398.500, Loss = 401.031
[2018-06-05 01:40] Train Step 45775, Epoch 42.4, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -412.167, Loss = 402.014
[2018-06-05 01:40] Train Step 45800, Epoch 42.4, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -425.148, Loss = 404.994
Performance on test set:
  Test Lower Bound = -439.440, Test Loss = 439.440
[2018-06-05 01:40] Train Step 45825, Epoch 42.4, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -388.822, Loss = 404.187
[2018-06-05 01:40] Train Step 45850, Epoch 42.5, Batch Size = 256, Examples/Sec = 3881.61, Train LB = -394.839, Loss = 403.527
[2018-06-05 01:40] Train Step 45875, Epoch 42.5, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -400.209, Loss = 402.138
[2018-06-05 01:40] Train Step 45900, Epoch 42.5, Batch Size = 256, Examples/Sec = 3868.11, Train LB = -401.478, Loss = 401.346
[2018-06-05 01:40] Train Step 45925, Epoch 42.5, Batch Size = 256, Examples/Sec = 3816.11, Train LB = -411.595, Loss = 401.095
[2018-06-05 01:40] Train Step 45950, Epoch 42.5, Batch Size = 256, Examples/Sec = 3815.89, Train LB = -406.599, Loss = 401.290
[2018-06-05 01:40] Train Step 45975, Epoch 42.6, Batch Size = 256, Examples/Sec = 3838.82, Train LB = -404.789, Loss = 402.214
[2018-06-05 01:40] Train Step 46000, Epoch 42.6, Batch Size = 256, Examples/Sec = 3834.34, Train LB = -419.655, Loss = 404.996
Performance on test set:
  Test Lower Bound = -439.586, Test Loss = 439.586
[2018-06-05 01:40] Train Step 46025, Epoch 42.6, Batch Size = 256, Examples/Sec = 3871.87, Train LB = -415.186, Loss = 404.248
[2018-06-05 01:40] Train Step 46050, Epoch 42.6, Batch Size = 256, Examples/Sec = 3808.05, Train LB = -396.871, Loss = 403.256
[2018-06-05 01:40] Train Step 46075, Epoch 42.7, Batch Size = 256, Examples/Sec = 3877.74, Train LB = -403.714, Loss = 402.212
[2018-06-05 01:40] Train Step 46100, Epoch 42.7, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -402.291, Loss = 401.348
[2018-06-05 01:40] Train Step 46125, Epoch 42.7, Batch Size = 256, Examples/Sec = 3852.22, Train LB = -402.304, Loss = 401.053
[2018-06-05 01:40] Train Step 46150, Epoch 42.7, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -412.108, Loss = 401.404
[2018-06-05 01:40] Train Step 46175, Epoch 42.8, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -410.407, Loss = 402.455
[2018-06-05 01:40] Train Step 46200, Epoch 42.8, Batch Size = 256, Examples/Sec = 3864.44, Train LB = -430.645, Loss = 404.615
Performance on test set:
  Test Lower Bound = -438.445, Test Loss = 438.445
[2018-06-05 01:40] Train Step 46225, Epoch 42.8, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -400.197, Loss = 404.613
[2018-06-05 01:40] Train Step 46250, Epoch 42.8, Batch Size = 256, Examples/Sec = 3890.52, Train LB = -399.838, Loss = 403.720
[2018-06-05 01:40] Train Step 46275, Epoch 42.8, Batch Size = 256, Examples/Sec = 3857.04, Train LB = -400.751, Loss = 402.708
[2018-06-05 01:40] Train Step 46300, Epoch 42.9, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -401.252, Loss = 402.191
[2018-06-05 01:40] Train Step 46325, Epoch 42.9, Batch Size = 256, Examples/Sec = 3864.15, Train LB = -395.492, Loss = 401.462
[2018-06-05 01:40] Train Step 46350, Epoch 42.9, Batch Size = 256, Examples/Sec = 3852.80, Train LB = -407.112, Loss = 401.566
[2018-06-05 01:40] Train Step 46375, Epoch 42.9, Batch Size = 256, Examples/Sec = 3835.61, Train LB = -391.598, Loss = 402.504
[2018-06-05 01:40] Train Step 46400, Epoch 43.0, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -415.236, Loss = 404.964
Performance on test set:
  Test Lower Bound = -438.738, Test Loss = 438.738
[2018-06-05 01:41] Train Step 46425, Epoch 43.0, Batch Size = 256, Examples/Sec = 3867.89, Train LB = -404.579, Loss = 404.270
[2018-06-05 01:41] Train Step 46450, Epoch 43.0, Batch Size = 256, Examples/Sec = 3856.76, Train LB = -400.887, Loss = 403.569
[2018-06-05 01:41] Train Step 46475, Epoch 43.0, Batch Size = 256, Examples/Sec = 3861.77, Train LB = -402.961, Loss = 402.165
[2018-06-05 01:41] Train Step 46500, Epoch 43.1, Batch Size = 256, Examples/Sec = 3857.34, Train LB = -412.625, Loss = 401.971
[2018-06-05 01:41] Train Step 46525, Epoch 43.1, Batch Size = 256, Examples/Sec = 3805.06, Train LB = -423.873, Loss = 401.576
[2018-06-05 01:41] Train Step 46550, Epoch 43.1, Batch Size = 256, Examples/Sec = 3845.52, Train LB = -392.944, Loss = 401.929
[2018-06-05 01:41] Train Step 46575, Epoch 43.1, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -401.012, Loss = 402.424
[2018-06-05 01:41] Train Step 46600, Epoch 43.1, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -429.283, Loss = 404.576
Performance on test set:
  Test Lower Bound = -439.586, Test Loss = 439.586
[2018-06-05 01:41] Train Step 46625, Epoch 43.2, Batch Size = 256, Examples/Sec = 3788.21, Train LB = -400.677, Loss = 403.759
[2018-06-05 01:41] Train Step 46650, Epoch 43.2, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -398.493, Loss = 403.035
[2018-06-05 01:41] Train Step 46675, Epoch 43.2, Batch Size = 256, Examples/Sec = 3867.88, Train LB = -395.512, Loss = 401.885
[2018-06-05 01:41] Train Step 46700, Epoch 43.2, Batch Size = 256, Examples/Sec = 3846.57, Train LB = -418.014, Loss = 401.191
[2018-06-05 01:41] Train Step 46725, Epoch 43.3, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -383.529, Loss = 400.940
[2018-06-05 01:41] Train Step 46750, Epoch 43.3, Batch Size = 256, Examples/Sec = 3864.15, Train LB = -401.951, Loss = 400.797
[2018-06-05 01:41] Train Step 46775, Epoch 43.3, Batch Size = 256, Examples/Sec = 3870.80, Train LB = -401.033, Loss = 401.514
[2018-06-05 01:41] Train Step 46800, Epoch 43.3, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -414.747, Loss = 404.565
Performance on test set:
  Test Lower Bound = -439.197, Test Loss = 439.197
[2018-06-05 01:41] Train Step 46825, Epoch 43.4, Batch Size = 256, Examples/Sec = 3872.03, Train LB = -396.701, Loss = 403.778
[2018-06-05 01:41] Train Step 46850, Epoch 43.4, Batch Size = 256, Examples/Sec = 3856.60, Train LB = -419.341, Loss = 402.707
[2018-06-05 01:41] Train Step 46875, Epoch 43.4, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -389.484, Loss = 401.805
[2018-06-05 01:41] Train Step 46900, Epoch 43.4, Batch Size = 256, Examples/Sec = 3851.93, Train LB = -393.859, Loss = 400.899
[2018-06-05 01:41] Train Step 46925, Epoch 43.4, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -393.229, Loss = 400.824
[2018-06-05 01:41] Train Step 46950, Epoch 43.5, Batch Size = 256, Examples/Sec = 3846.95, Train LB = -407.774, Loss = 400.891
[2018-06-05 01:41] Train Step 46975, Epoch 43.5, Batch Size = 256, Examples/Sec = 3871.06, Train LB = -397.889, Loss = 402.179
[2018-06-05 01:41] Train Step 47000, Epoch 43.5, Batch Size = 256, Examples/Sec = 3865.68, Train LB = -434.606, Loss = 404.630
Performance on test set:
  Test Lower Bound = -439.704, Test Loss = 439.704
[2018-06-05 01:41] Train Step 47025, Epoch 43.5, Batch Size = 256, Examples/Sec = 3878.68, Train LB = -388.405, Loss = 403.704
[2018-06-05 01:41] Train Step 47050, Epoch 43.6, Batch Size = 256, Examples/Sec = 3864.51, Train LB = -397.504, Loss = 403.039
[2018-06-05 01:41] Train Step 47075, Epoch 43.6, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -399.523, Loss = 402.588
[2018-06-05 01:41] Train Step 47100, Epoch 43.6, Batch Size = 256, Examples/Sec = 3857.57, Train LB = -401.792, Loss = 402.405
[2018-06-05 01:41] Train Step 47125, Epoch 43.6, Batch Size = 256, Examples/Sec = 3811.62, Train LB = -401.558, Loss = 401.478
[2018-06-05 01:42] Train Step 47150, Epoch 43.7, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -398.633, Loss = 401.073
[2018-06-05 01:42] Train Step 47175, Epoch 43.7, Batch Size = 256, Examples/Sec = 3862.39, Train LB = -406.693, Loss = 402.119
[2018-06-05 01:42] Train Step 47200, Epoch 43.7, Batch Size = 256, Examples/Sec = 3858.80, Train LB = -419.176, Loss = 403.794
Performance on test set:
  Test Lower Bound = -439.378, Test Loss = 439.378
[2018-06-05 01:42] Train Step 47225, Epoch 43.7, Batch Size = 256, Examples/Sec = 3821.35, Train LB = -391.420, Loss = 403.566
[2018-06-05 01:42] Train Step 47250, Epoch 43.8, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -406.381, Loss = 402.168
[2018-06-05 01:42] Train Step 47275, Epoch 43.8, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -408.889, Loss = 402.352
[2018-06-05 01:42] Train Step 47300, Epoch 43.8, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -401.485, Loss = 401.221
[2018-06-05 01:42] Train Step 47325, Epoch 43.8, Batch Size = 256, Examples/Sec = 3850.77, Train LB = -395.108, Loss = 400.657
[2018-06-05 01:42] Train Step 47350, Epoch 43.8, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -407.215, Loss = 400.753
[2018-06-05 01:42] Train Step 47375, Epoch 43.9, Batch Size = 256, Examples/Sec = 3829.92, Train LB = -413.305, Loss = 401.648
[2018-06-05 01:42] Train Step 47400, Epoch 43.9, Batch Size = 256, Examples/Sec = 3871.92, Train LB = -408.986, Loss = 404.324
Performance on test set:
  Test Lower Bound = -440.096, Test Loss = 440.096
[2018-06-05 01:42] Train Step 47425, Epoch 43.9, Batch Size = 256, Examples/Sec = 3878.26, Train LB = -403.487, Loss = 403.425
[2018-06-05 01:42] Train Step 47450, Epoch 43.9, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -388.713, Loss = 402.709
[2018-06-05 01:42] Train Step 47475, Epoch 44.0, Batch Size = 256, Examples/Sec = 3869.30, Train LB = -391.817, Loss = 401.035
[2018-06-05 01:42] Train Step 47500, Epoch 44.0, Batch Size = 256, Examples/Sec = 3856.94, Train LB = -390.983, Loss = 400.259
[2018-06-05 01:42] Train Step 47525, Epoch 44.0, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -392.066, Loss = 400.357
[2018-06-05 01:42] Train Step 47550, Epoch 44.0, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -396.063, Loss = 400.436
[2018-06-05 01:42] Train Step 47575, Epoch 44.1, Batch Size = 256, Examples/Sec = 3869.65, Train LB = -408.284, Loss = 401.715
[2018-06-05 01:42] Train Step 47600, Epoch 44.1, Batch Size = 256, Examples/Sec = 3804.65, Train LB = -418.477, Loss = 404.309
Performance on test set:
  Test Lower Bound = -440.737, Test Loss = 440.737
[2018-06-05 01:42] Train Step 47625, Epoch 44.1, Batch Size = 256, Examples/Sec = 3879.84, Train LB = -399.210, Loss = 404.024
[2018-06-05 01:42] Train Step 47650, Epoch 44.1, Batch Size = 256, Examples/Sec = 3836.30, Train LB = -412.987, Loss = 403.046
[2018-06-05 01:42] Train Step 47675, Epoch 44.1, Batch Size = 256, Examples/Sec = 3805.73, Train LB = -393.726, Loss = 401.736
[2018-06-05 01:42] Train Step 47700, Epoch 44.2, Batch Size = 256, Examples/Sec = 3833.14, Train LB = -391.065, Loss = 401.107
[2018-06-05 01:42] Train Step 47725, Epoch 44.2, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -401.649, Loss = 400.434
[2018-06-05 01:42] Train Step 47750, Epoch 44.2, Batch Size = 256, Examples/Sec = 3855.18, Train LB = -407.561, Loss = 400.071
[2018-06-05 01:42] Train Step 47775, Epoch 44.2, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -409.588, Loss = 401.445
[2018-06-05 01:42] Train Step 47800, Epoch 44.3, Batch Size = 256, Examples/Sec = 3848.29, Train LB = -430.556, Loss = 404.023
Performance on test set:
  Test Lower Bound = -439.494, Test Loss = 439.494
[2018-06-05 01:42] Train Step 47825, Epoch 44.3, Batch Size = 256, Examples/Sec = 3848.16, Train LB = -406.035, Loss = 403.077
[2018-06-05 01:43] Train Step 47850, Epoch 44.3, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -387.947, Loss = 402.470
[2018-06-05 01:43] Train Step 47875, Epoch 44.3, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -392.025, Loss = 401.340
[2018-06-05 01:43] Train Step 47900, Epoch 44.4, Batch Size = 256, Examples/Sec = 3844.54, Train LB = -399.544, Loss = 400.423
[2018-06-05 01:43] Train Step 47925, Epoch 44.4, Batch Size = 256, Examples/Sec = 3841.31, Train LB = -393.478, Loss = 400.187
[2018-06-05 01:43] Train Step 47950, Epoch 44.4, Batch Size = 256, Examples/Sec = 3831.08, Train LB = -403.116, Loss = 400.361
[2018-06-05 01:43] Train Step 47975, Epoch 44.4, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -398.483, Loss = 401.333
[2018-06-05 01:43] Train Step 48000, Epoch 44.4, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -425.241, Loss = 403.546
Performance on test set:
  Test Lower Bound = -440.586, Test Loss = 440.586
[2018-06-05 01:43] Train Step 48025, Epoch 44.5, Batch Size = 256, Examples/Sec = 3845.06, Train LB = -409.044, Loss = 402.623
[2018-06-05 01:43] Train Step 48050, Epoch 44.5, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -402.815, Loss = 402.374
[2018-06-05 01:43] Train Step 48075, Epoch 44.5, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -402.448, Loss = 401.369
[2018-06-05 01:43] Train Step 48100, Epoch 44.5, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -389.446, Loss = 400.578
[2018-06-05 01:43] Train Step 48125, Epoch 44.6, Batch Size = 256, Examples/Sec = 3880.74, Train LB = -399.284, Loss = 399.941
[2018-06-05 01:43] Train Step 48150, Epoch 44.6, Batch Size = 256, Examples/Sec = 3869.70, Train LB = -412.312, Loss = 400.622
[2018-06-05 01:43] Train Step 48175, Epoch 44.6, Batch Size = 256, Examples/Sec = 3801.33, Train LB = -407.737, Loss = 401.663
[2018-06-05 01:43] Train Step 48200, Epoch 44.6, Batch Size = 256, Examples/Sec = 3814.13, Train LB = -430.187, Loss = 403.531
Performance on test set:
  Test Lower Bound = -440.778, Test Loss = 440.778
[2018-06-05 01:43] Train Step 48225, Epoch 44.7, Batch Size = 256, Examples/Sec = 3822.83, Train LB = -398.263, Loss = 403.144
[2018-06-05 01:43] Train Step 48250, Epoch 44.7, Batch Size = 256, Examples/Sec = 3875.44, Train LB = -421.284, Loss = 401.948
[2018-06-05 01:43] Train Step 48275, Epoch 44.7, Batch Size = 256, Examples/Sec = 3813.49, Train LB = -391.692, Loss = 400.942
[2018-06-05 01:43] Train Step 48300, Epoch 44.7, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -408.393, Loss = 400.258
[2018-06-05 01:43] Train Step 48325, Epoch 44.7, Batch Size = 256, Examples/Sec = 3888.97, Train LB = -395.764, Loss = 399.784
[2018-06-05 01:43] Train Step 48350, Epoch 44.8, Batch Size = 256, Examples/Sec = 3874.21, Train LB = -382.460, Loss = 399.623
[2018-06-05 01:43] Train Step 48375, Epoch 44.8, Batch Size = 256, Examples/Sec = 3870.64, Train LB = -413.432, Loss = 401.405
[2018-06-05 01:43] Train Step 48400, Epoch 44.8, Batch Size = 256, Examples/Sec = 3841.31, Train LB = -427.806, Loss = 403.471
Performance on test set:
  Test Lower Bound = -441.258, Test Loss = 441.258
[2018-06-05 01:43] Train Step 48425, Epoch 44.8, Batch Size = 256, Examples/Sec = 3876.14, Train LB = -391.778, Loss = 403.003
[2018-06-05 01:43] Train Step 48450, Epoch 44.9, Batch Size = 256, Examples/Sec = 3856.65, Train LB = -401.645, Loss = 401.977
[2018-06-05 01:43] Train Step 48475, Epoch 44.9, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -394.747, Loss = 401.358
[2018-06-05 01:43] Train Step 48500, Epoch 44.9, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -400.021, Loss = 401.068
[2018-06-05 01:43] Train Step 48525, Epoch 44.9, Batch Size = 256, Examples/Sec = 3808.57, Train LB = -396.040, Loss = 399.921
[2018-06-05 01:43] Train Step 48550, Epoch 45.0, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -406.758, Loss = 400.337
[2018-06-05 01:44] Train Step 48575, Epoch 45.0, Batch Size = 256, Examples/Sec = 3850.79, Train LB = -407.741, Loss = 400.951
[2018-06-05 01:44] Train Step 48600, Epoch 45.0, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -409.873, Loss = 403.731
Performance on test set:
  Test Lower Bound = -440.849, Test Loss = 440.849
[2018-06-05 01:44] Train Step 48625, Epoch 45.0, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -399.837, Loss = 403.193
[2018-06-05 01:44] Train Step 48650, Epoch 45.0, Batch Size = 256, Examples/Sec = 3870.47, Train LB = -403.926, Loss = 402.352
[2018-06-05 01:44] Train Step 48675, Epoch 45.1, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -404.549, Loss = 401.224
[2018-06-05 01:44] Train Step 48700, Epoch 45.1, Batch Size = 256, Examples/Sec = 3866.01, Train LB = -382.679, Loss = 400.323
[2018-06-05 01:44] Train Step 48725, Epoch 45.1, Batch Size = 256, Examples/Sec = 3865.37, Train LB = -402.918, Loss = 399.424
[2018-06-05 01:44] Train Step 48750, Epoch 45.1, Batch Size = 256, Examples/Sec = 3843.67, Train LB = -401.047, Loss = 400.724
[2018-06-05 01:44] Train Step 48775, Epoch 45.2, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -405.856, Loss = 402.011
[2018-06-05 01:44] Train Step 48800, Epoch 45.2, Batch Size = 256, Examples/Sec = 3875.15, Train LB = -387.682, Loss = 404.118
Performance on test set:
  Test Lower Bound = -442.342, Test Loss = 442.342
[2018-06-05 01:44] Train Step 48825, Epoch 45.2, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -407.609, Loss = 402.872
[2018-06-05 01:44] Train Step 48850, Epoch 45.2, Batch Size = 256, Examples/Sec = 3882.79, Train LB = -396.319, Loss = 402.647
[2018-06-05 01:44] Train Step 48875, Epoch 45.3, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -407.200, Loss = 401.913
[2018-06-05 01:44] Train Step 48900, Epoch 45.3, Batch Size = 256, Examples/Sec = 3873.51, Train LB = -388.677, Loss = 401.087
[2018-06-05 01:44] Train Step 48925, Epoch 45.3, Batch Size = 256, Examples/Sec = 3816.34, Train LB = -401.089, Loss = 400.420
[2018-06-05 01:44] Train Step 48950, Epoch 45.3, Batch Size = 256, Examples/Sec = 3887.51, Train LB = -395.722, Loss = 400.263
[2018-06-05 01:44] Train Step 48975, Epoch 45.3, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -407.244, Loss = 401.622
[2018-06-05 01:44] Train Step 49000, Epoch 45.4, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -424.044, Loss = 403.905
Performance on test set:
  Test Lower Bound = -441.520, Test Loss = 441.520
[2018-06-05 01:44] Train Step 49025, Epoch 45.4, Batch Size = 256, Examples/Sec = 3816.50, Train LB = -405.368, Loss = 403.619
[2018-06-05 01:44] Train Step 49050, Epoch 45.4, Batch Size = 256, Examples/Sec = 3857.09, Train LB = -397.341, Loss = 401.963
[2018-06-05 01:44] Train Step 49075, Epoch 45.4, Batch Size = 256, Examples/Sec = 3878.31, Train LB = -410.966, Loss = 401.831
[2018-06-05 01:44] Train Step 49100, Epoch 45.5, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -398.197, Loss = 401.026
[2018-06-05 01:44] Train Step 49125, Epoch 45.5, Batch Size = 256, Examples/Sec = 3879.32, Train LB = -399.376, Loss = 400.666
[2018-06-05 01:44] Train Step 49150, Epoch 45.5, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -384.539, Loss = 400.808
[2018-06-05 01:44] Train Step 49175, Epoch 45.5, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -394.456, Loss = 400.641
[2018-06-05 01:44] Train Step 49200, Epoch 45.6, Batch Size = 256, Examples/Sec = 3858.38, Train LB = -427.612, Loss = 403.103
Performance on test set:
  Test Lower Bound = -442.085, Test Loss = 442.085
[2018-06-05 01:44] Train Step 49225, Epoch 45.6, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -388.175, Loss = 402.547
[2018-06-05 01:44] Train Step 49250, Epoch 45.6, Batch Size = 256, Examples/Sec = 3844.42, Train LB = -395.346, Loss = 400.607
[2018-06-05 01:45] Train Step 49275, Epoch 45.6, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -411.936, Loss = 400.570
[2018-06-05 01:45] Train Step 49300, Epoch 45.6, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -402.250, Loss = 399.751
[2018-06-05 01:45] Train Step 49325, Epoch 45.7, Batch Size = 256, Examples/Sec = 3841.24, Train LB = -394.111, Loss = 399.588
[2018-06-05 01:45] Train Step 49350, Epoch 45.7, Batch Size = 256, Examples/Sec = 3854.13, Train LB = -403.107, Loss = 399.605
[2018-06-05 01:45] Train Step 49375, Epoch 45.7, Batch Size = 256, Examples/Sec = 3869.34, Train LB = -395.409, Loss = 400.525
[2018-06-05 01:45] Train Step 49400, Epoch 45.7, Batch Size = 256, Examples/Sec = 3812.48, Train LB = -409.630, Loss = 402.994
Performance on test set:
  Test Lower Bound = -440.692, Test Loss = 440.692
[2018-06-05 01:45] Train Step 49425, Epoch 45.8, Batch Size = 256, Examples/Sec = 3881.55, Train LB = -385.198, Loss = 401.942
[2018-06-05 01:45] Train Step 49450, Epoch 45.8, Batch Size = 256, Examples/Sec = 3878.07, Train LB = -405.394, Loss = 400.914
[2018-06-05 01:45] Train Step 49475, Epoch 45.8, Batch Size = 256, Examples/Sec = 3878.20, Train LB = -395.754, Loss = 400.058
[2018-06-05 01:45] Train Step 49500, Epoch 45.8, Batch Size = 256, Examples/Sec = 3809.53, Train LB = -380.993, Loss = 399.800
[2018-06-05 01:45] Train Step 49525, Epoch 45.9, Batch Size = 256, Examples/Sec = 3880.67, Train LB = -403.742, Loss = 398.958
[2018-06-05 01:45] Train Step 49550, Epoch 45.9, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -417.311, Loss = 399.851
[2018-06-05 01:45] Train Step 49575, Epoch 45.9, Batch Size = 256, Examples/Sec = 3881.44, Train LB = -407.363, Loss = 400.896
[2018-06-05 01:45] Train Step 49600, Epoch 45.9, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -421.587, Loss = 403.516
Performance on test set:
  Test Lower Bound = -441.347, Test Loss = 441.347
[2018-06-05 01:45] Train Step 49625, Epoch 45.9, Batch Size = 256, Examples/Sec = 3844.60, Train LB = -398.481, Loss = 402.619
[2018-06-05 01:45] Train Step 49650, Epoch 46.0, Batch Size = 256, Examples/Sec = 3867.82, Train LB = -407.841, Loss = 401.892
[2018-06-05 01:45] Train Step 49675, Epoch 46.0, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -398.921, Loss = 400.995
[2018-06-05 01:45] Train Step 49700, Epoch 46.0, Batch Size = 256, Examples/Sec = 3814.52, Train LB = -402.148, Loss = 399.587
[2018-06-05 01:45] Train Step 49725, Epoch 46.0, Batch Size = 256, Examples/Sec = 3876.03, Train LB = -374.852, Loss = 399.121
[2018-06-05 01:45] Train Step 49750, Epoch 46.1, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -394.085, Loss = 399.714
[2018-06-05 01:45] Train Step 49775, Epoch 46.1, Batch Size = 256, Examples/Sec = 3875.39, Train LB = -402.710, Loss = 400.677
[2018-06-05 01:45] Train Step 49800, Epoch 46.1, Batch Size = 256, Examples/Sec = 3854.44, Train LB = -414.499, Loss = 403.497
Performance on test set:
  Test Lower Bound = -440.787, Test Loss = 440.787
[2018-06-05 01:45] Train Step 49825, Epoch 46.1, Batch Size = 256, Examples/Sec = 3880.26, Train LB = -395.661, Loss = 402.725
[2018-06-05 01:45] Train Step 49850, Epoch 46.2, Batch Size = 256, Examples/Sec = 3852.57, Train LB = -402.002, Loss = 401.714
[2018-06-05 01:45] Train Step 49875, Epoch 46.2, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -409.074, Loss = 400.733
[2018-06-05 01:45] Train Step 49900, Epoch 46.2, Batch Size = 256, Examples/Sec = 3855.76, Train LB = -386.592, Loss = 399.234
[2018-06-05 01:45] Train Step 49925, Epoch 46.2, Batch Size = 256, Examples/Sec = 1705.45, Train LB = -402.748, Loss = 398.496
[2018-06-05 01:45] Train Step 49950, Epoch 46.2, Batch Size = 256, Examples/Sec = 3863.03, Train LB = -420.882, Loss = 399.285
[2018-06-05 01:45] Train Step 49975, Epoch 46.3, Batch Size = 256, Examples/Sec = 3874.16, Train LB = -401.521, Loss = 400.346
[2018-06-05 01:45] Train Step 50000, Epoch 46.3, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -425.890, Loss = 403.156
Performance on test set:
  Test Lower Bound = -441.262, Test Loss = 441.262
[2018-06-05 01:46] Train Step 50025, Epoch 46.3, Batch Size = 256, Examples/Sec = 3865.04, Train LB = -391.645, Loss = 401.784
[2018-06-05 01:46] Train Step 50050, Epoch 46.3, Batch Size = 256, Examples/Sec = 3871.87, Train LB = -387.371, Loss = 401.288
[2018-06-05 01:46] Train Step 50075, Epoch 46.4, Batch Size = 256, Examples/Sec = 3842.52, Train LB = -404.704, Loss = 400.853
[2018-06-05 01:46] Train Step 50100, Epoch 46.4, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -394.454, Loss = 399.870
[2018-06-05 01:46] Train Step 50125, Epoch 46.4, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -399.176, Loss = 399.234
[2018-06-05 01:46] Train Step 50150, Epoch 46.4, Batch Size = 256, Examples/Sec = 3808.45, Train LB = -404.502, Loss = 399.139
[2018-06-05 01:46] Train Step 50175, Epoch 46.5, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -406.072, Loss = 399.948
[2018-06-05 01:46] Train Step 50200, Epoch 46.5, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -428.567, Loss = 402.025
Performance on test set:
  Test Lower Bound = -442.233, Test Loss = 442.233
[2018-06-05 01:46] Train Step 50225, Epoch 46.5, Batch Size = 256, Examples/Sec = 3861.17, Train LB = -402.283, Loss = 401.334
[2018-06-05 01:46] Train Step 50250, Epoch 46.5, Batch Size = 256, Examples/Sec = 3799.85, Train LB = -411.090, Loss = 400.535
[2018-06-05 01:46] Train Step 50275, Epoch 46.6, Batch Size = 256, Examples/Sec = 3847.54, Train LB = -415.568, Loss = 399.825
[2018-06-05 01:46] Train Step 50300, Epoch 46.6, Batch Size = 256, Examples/Sec = 3883.73, Train LB = -388.020, Loss = 399.331
[2018-06-05 01:46] Train Step 50325, Epoch 46.6, Batch Size = 256, Examples/Sec = 3843.37, Train LB = -400.214, Loss = 399.089
[2018-06-05 01:46] Train Step 50350, Epoch 46.6, Batch Size = 256, Examples/Sec = 3864.16, Train LB = -392.560, Loss = 398.869
[2018-06-05 01:46] Train Step 50375, Epoch 46.6, Batch Size = 256, Examples/Sec = 3860.48, Train LB = -405.704, Loss = 400.316
[2018-06-05 01:46] Train Step 50400, Epoch 46.7, Batch Size = 256, Examples/Sec = 3848.41, Train LB = -415.650, Loss = 402.570
Performance on test set:
  Test Lower Bound = -440.522, Test Loss = 440.522
[2018-06-05 01:46] Train Step 50425, Epoch 46.7, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -397.360, Loss = 401.957
[2018-06-05 01:46] Train Step 50450, Epoch 46.7, Batch Size = 256, Examples/Sec = 3862.80, Train LB = -399.001, Loss = 401.170
[2018-06-05 01:46] Train Step 50475, Epoch 46.7, Batch Size = 256, Examples/Sec = 3853.62, Train LB = -395.952, Loss = 399.979
[2018-06-05 01:46] Train Step 50500, Epoch 46.8, Batch Size = 256, Examples/Sec = 3862.59, Train LB = -393.363, Loss = 399.797
[2018-06-05 01:46] Train Step 50525, Epoch 46.8, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -395.595, Loss = 398.388
[2018-06-05 01:46] Train Step 50550, Epoch 46.8, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -393.480, Loss = 399.133
[2018-06-05 01:46] Train Step 50575, Epoch 46.8, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -388.075, Loss = 400.119
[2018-06-05 01:46] Train Step 50600, Epoch 46.9, Batch Size = 256, Examples/Sec = 3867.89, Train LB = -411.110, Loss = 401.995
Performance on test set:
  Test Lower Bound = -441.918, Test Loss = 441.918
[2018-06-05 01:46] Train Step 50625, Epoch 46.9, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -381.996, Loss = 401.748
[2018-06-05 01:46] Train Step 50650, Epoch 46.9, Batch Size = 256, Examples/Sec = 3853.98, Train LB = -410.943, Loss = 400.642
[2018-06-05 01:46] Train Step 50675, Epoch 46.9, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -412.981, Loss = 399.655
[2018-06-05 01:46] Train Step 50700, Epoch 46.9, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -390.346, Loss = 398.738
[2018-06-05 01:47] Train Step 50725, Epoch 47.0, Batch Size = 256, Examples/Sec = 3822.27, Train LB = -401.388, Loss = 398.531
[2018-06-05 01:47] Train Step 50750, Epoch 47.0, Batch Size = 256, Examples/Sec = 3846.50, Train LB = -392.521, Loss = 399.322
[2018-06-05 01:47] Train Step 50775, Epoch 47.0, Batch Size = 256, Examples/Sec = 3875.79, Train LB = -411.806, Loss = 400.379
[2018-06-05 01:47] Train Step 50800, Epoch 47.0, Batch Size = 256, Examples/Sec = 3882.90, Train LB = -410.709, Loss = 402.819
Performance on test set:
  Test Lower Bound = -440.995, Test Loss = 440.995
[2018-06-05 01:47] Train Step 50825, Epoch 47.1, Batch Size = 256, Examples/Sec = 3851.24, Train LB = -398.720, Loss = 402.096
[2018-06-05 01:47] Train Step 50850, Epoch 47.1, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -383.538, Loss = 400.863
[2018-06-05 01:47] Train Step 50875, Epoch 47.1, Batch Size = 256, Examples/Sec = 3871.74, Train LB = -403.264, Loss = 399.842
[2018-06-05 01:47] Train Step 50900, Epoch 47.1, Batch Size = 256, Examples/Sec = 3878.84, Train LB = -395.076, Loss = 399.089
[2018-06-05 01:47] Train Step 50925, Epoch 47.2, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -389.313, Loss = 398.140
[2018-06-05 01:47] Train Step 50950, Epoch 47.2, Batch Size = 256, Examples/Sec = 3882.79, Train LB = -411.148, Loss = 398.530
[2018-06-05 01:47] Train Step 50975, Epoch 47.2, Batch Size = 256, Examples/Sec = 3877.91, Train LB = -397.691, Loss = 399.871
[2018-06-05 01:47] Train Step 51000, Epoch 47.2, Batch Size = 256, Examples/Sec = 3873.39, Train LB = -403.064, Loss = 402.132
Performance on test set:
  Test Lower Bound = -441.498, Test Loss = 441.498
[2018-06-05 01:47] Train Step 51025, Epoch 47.2, Batch Size = 256, Examples/Sec = 3854.02, Train LB = -388.643, Loss = 401.351
[2018-06-05 01:47] Train Step 51050, Epoch 47.3, Batch Size = 256, Examples/Sec = 3806.30, Train LB = -395.000, Loss = 400.144
[2018-06-05 01:47] Train Step 51075, Epoch 47.3, Batch Size = 256, Examples/Sec = 3886.22, Train LB = -400.358, Loss = 400.065
[2018-06-05 01:47] Train Step 51100, Epoch 47.3, Batch Size = 256, Examples/Sec = 3859.48, Train LB = -402.088, Loss = 398.961
[2018-06-05 01:47] Train Step 51125, Epoch 47.3, Batch Size = 256, Examples/Sec = 3878.26, Train LB = -407.745, Loss = 399.303
[2018-06-05 01:47] Train Step 51150, Epoch 47.4, Batch Size = 256, Examples/Sec = 3870.75, Train LB = -401.679, Loss = 399.025
[2018-06-05 01:47] Train Step 51175, Epoch 47.4, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -408.141, Loss = 399.467
[2018-06-05 01:47] Train Step 51200, Epoch 47.4, Batch Size = 256, Examples/Sec = 3830.62, Train LB = -427.121, Loss = 402.421
Performance on test set:
  Test Lower Bound = -442.734, Test Loss = 442.734
[2018-06-05 01:47] Train Step 51225, Epoch 47.4, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -395.700, Loss = 401.914
[2018-06-05 01:47] Train Step 51250, Epoch 47.5, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -394.580, Loss = 401.292
[2018-06-05 01:47] Train Step 51275, Epoch 47.5, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -410.766, Loss = 399.886
[2018-06-05 01:47] Train Step 51300, Epoch 47.5, Batch Size = 256, Examples/Sec = 3818.85, Train LB = -404.568, Loss = 399.049
[2018-06-05 01:47] Train Step 51325, Epoch 47.5, Batch Size = 256, Examples/Sec = 3876.97, Train LB = -388.739, Loss = 398.398
[2018-06-05 01:47] Train Step 51350, Epoch 47.5, Batch Size = 256, Examples/Sec = 3881.61, Train LB = -380.506, Loss = 398.098
[2018-06-05 01:47] Train Step 51375, Epoch 47.6, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -412.497, Loss = 399.026
[2018-06-05 01:47] Train Step 51400, Epoch 47.6, Batch Size = 256, Examples/Sec = 3885.15, Train LB = -427.635, Loss = 401.831
Performance on test set:
  Test Lower Bound = -441.435, Test Loss = 441.435
[2018-06-05 01:48] Train Step 51425, Epoch 47.6, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -390.377, Loss = 401.070
[2018-06-05 01:48] Train Step 51450, Epoch 47.6, Batch Size = 256, Examples/Sec = 3868.89, Train LB = -395.285, Loss = 400.540
[2018-06-05 01:48] Train Step 51475, Epoch 47.7, Batch Size = 256, Examples/Sec = 3850.83, Train LB = -416.359, Loss = 399.891
[2018-06-05 01:48] Train Step 51500, Epoch 47.7, Batch Size = 256, Examples/Sec = 3877.26, Train LB = -402.254, Loss = 398.741
[2018-06-05 01:48] Train Step 51525, Epoch 47.7, Batch Size = 256, Examples/Sec = 3875.97, Train LB = -403.630, Loss = 398.027
[2018-06-05 01:48] Train Step 51550, Epoch 47.7, Batch Size = 256, Examples/Sec = 3858.73, Train LB = -392.613, Loss = 398.363
[2018-06-05 01:48] Train Step 51575, Epoch 47.8, Batch Size = 256, Examples/Sec = 3846.91, Train LB = -412.300, Loss = 399.272
[2018-06-05 01:48] Train Step 51600, Epoch 47.8, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -410.633, Loss = 402.702
Performance on test set:
  Test Lower Bound = -442.020, Test Loss = 442.020
[2018-06-05 01:48] Train Step 51625, Epoch 47.8, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -391.721, Loss = 401.935
[2018-06-05 01:48] Train Step 51650, Epoch 47.8, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -397.020, Loss = 400.831
[2018-06-05 01:48] Train Step 51675, Epoch 47.8, Batch Size = 256, Examples/Sec = 3866.37, Train LB = -389.242, Loss = 400.384
[2018-06-05 01:48] Train Step 51700, Epoch 47.9, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -385.001, Loss = 399.088
[2018-06-05 01:48] Train Step 51725, Epoch 47.9, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -386.734, Loss = 398.136
[2018-06-05 01:48] Train Step 51750, Epoch 47.9, Batch Size = 256, Examples/Sec = 3850.43, Train LB = -411.872, Loss = 398.605
[2018-06-05 01:48] Train Step 51775, Epoch 47.9, Batch Size = 256, Examples/Sec = 3803.40, Train LB = -412.712, Loss = 399.404
[2018-06-05 01:48] Train Step 51800, Epoch 48.0, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -416.376, Loss = 401.746
Performance on test set:
  Test Lower Bound = -442.182, Test Loss = 442.182
[2018-06-05 01:48] Train Step 51825, Epoch 48.0, Batch Size = 256, Examples/Sec = 3852.13, Train LB = -387.533, Loss = 400.573
[2018-06-05 01:48] Train Step 51850, Epoch 48.0, Batch Size = 256, Examples/Sec = 3869.24, Train LB = -398.044, Loss = 399.849
[2018-06-05 01:48] Train Step 51875, Epoch 48.0, Batch Size = 256, Examples/Sec = 3812.99, Train LB = -380.982, Loss = 398.995
[2018-06-05 01:48] Train Step 51900, Epoch 48.1, Batch Size = 256, Examples/Sec = 3867.71, Train LB = -411.863, Loss = 399.050
[2018-06-05 01:48] Train Step 51925, Epoch 48.1, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -398.576, Loss = 398.723
[2018-06-05 01:48] Train Step 51950, Epoch 48.1, Batch Size = 256, Examples/Sec = 3851.37, Train LB = -387.025, Loss = 398.830
[2018-06-05 01:48] Train Step 51975, Epoch 48.1, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -421.269, Loss = 399.325
[2018-06-05 01:48] Train Step 52000, Epoch 48.1, Batch Size = 256, Examples/Sec = 3880.32, Train LB = -436.727, Loss = 402.031
Performance on test set:
  Test Lower Bound = -441.671, Test Loss = 441.671
[2018-06-05 01:48] Train Step 52025, Epoch 48.2, Batch Size = 256, Examples/Sec = 3849.90, Train LB = -394.699, Loss = 401.387
[2018-06-05 01:48] Train Step 52050, Epoch 48.2, Batch Size = 256, Examples/Sec = 3871.45, Train LB = -387.213, Loss = 400.061
[2018-06-05 01:48] Train Step 52075, Epoch 48.2, Batch Size = 256, Examples/Sec = 3869.63, Train LB = -400.373, Loss = 399.098
[2018-06-05 01:48] Train Step 52100, Epoch 48.2, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -381.146, Loss = 398.459
[2018-06-05 01:48] Train Step 52125, Epoch 48.3, Batch Size = 256, Examples/Sec = 3821.12, Train LB = -381.715, Loss = 397.910
[2018-06-05 01:49] Train Step 52150, Epoch 48.3, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -406.822, Loss = 398.319
[2018-06-05 01:49] Train Step 52175, Epoch 48.3, Batch Size = 256, Examples/Sec = 3854.42, Train LB = -414.827, Loss = 399.184
[2018-06-05 01:49] Train Step 52200, Epoch 48.3, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -410.165, Loss = 402.385
Performance on test set:
  Test Lower Bound = -441.741, Test Loss = 441.741
[2018-06-05 01:49] Train Step 52225, Epoch 48.4, Batch Size = 256, Examples/Sec = 3804.03, Train LB = -375.919, Loss = 401.600
[2018-06-05 01:49] Train Step 52250, Epoch 48.4, Batch Size = 256, Examples/Sec = 3854.91, Train LB = -400.496, Loss = 400.243
[2018-06-05 01:49] Train Step 52275, Epoch 48.4, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -397.847, Loss = 399.982
[2018-06-05 01:49] Train Step 52300, Epoch 48.4, Batch Size = 256, Examples/Sec = 3879.91, Train LB = -398.677, Loss = 399.535
[2018-06-05 01:49] Train Step 52325, Epoch 48.4, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -395.197, Loss = 398.592
[2018-06-05 01:49] Train Step 52350, Epoch 48.5, Batch Size = 256, Examples/Sec = 3801.15, Train LB = -410.810, Loss = 398.539
[2018-06-05 01:49] Train Step 52375, Epoch 48.5, Batch Size = 256, Examples/Sec = 3841.60, Train LB = -400.822, Loss = 400.003
[2018-06-05 01:49] Train Step 52400, Epoch 48.5, Batch Size = 256, Examples/Sec = 3863.91, Train LB = -408.597, Loss = 402.299
Performance on test set:
  Test Lower Bound = -442.580, Test Loss = 442.580
[2018-06-05 01:49] Train Step 52425, Epoch 48.5, Batch Size = 256, Examples/Sec = 3867.89, Train LB = -398.182, Loss = 401.178
[2018-06-05 01:49] Train Step 52450, Epoch 48.6, Batch Size = 256, Examples/Sec = 3829.01, Train LB = -396.430, Loss = 400.118
[2018-06-05 01:49] Train Step 52475, Epoch 48.6, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -387.038, Loss = 399.499
[2018-06-05 01:49] Train Step 52500, Epoch 48.6, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -399.939, Loss = 398.900
[2018-06-05 01:49] Train Step 52525, Epoch 48.6, Batch Size = 256, Examples/Sec = 3884.98, Train LB = -390.365, Loss = 397.865
[2018-06-05 01:49] Train Step 52550, Epoch 48.7, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -392.926, Loss = 398.275
[2018-06-05 01:49] Train Step 52575, Epoch 48.7, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -417.494, Loss = 398.451
[2018-06-05 01:49] Train Step 52600, Epoch 48.7, Batch Size = 256, Examples/Sec = 3880.02, Train LB = -418.894, Loss = 401.570
Performance on test set:
  Test Lower Bound = -441.686, Test Loss = 441.686
[2018-06-05 01:49] Train Step 52625, Epoch 48.7, Batch Size = 256, Examples/Sec = 3876.21, Train LB = -385.924, Loss = 401.056
[2018-06-05 01:49] Train Step 52650, Epoch 48.8, Batch Size = 256, Examples/Sec = 3888.86, Train LB = -396.042, Loss = 400.377
[2018-06-05 01:49] Train Step 52675, Epoch 48.8, Batch Size = 256, Examples/Sec = 3862.41, Train LB = -381.475, Loss = 399.406
[2018-06-05 01:49] Train Step 52700, Epoch 48.8, Batch Size = 256, Examples/Sec = 3813.55, Train LB = -403.257, Loss = 398.044
[2018-06-05 01:49] Train Step 52725, Epoch 48.8, Batch Size = 256, Examples/Sec = 3874.97, Train LB = -391.365, Loss = 398.207
[2018-06-05 01:49] Train Step 52750, Epoch 48.8, Batch Size = 256, Examples/Sec = 3851.20, Train LB = -392.844, Loss = 398.163
[2018-06-05 01:49] Train Step 52775, Epoch 48.9, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -407.714, Loss = 398.304
[2018-06-05 01:49] Train Step 52800, Epoch 48.9, Batch Size = 256, Examples/Sec = 3858.45, Train LB = -399.366, Loss = 401.191
Performance on test set:
  Test Lower Bound = -443.741, Test Loss = 443.741
[2018-06-05 01:49] Train Step 52825, Epoch 48.9, Batch Size = 256, Examples/Sec = 3850.79, Train LB = -405.025, Loss = 399.891
[2018-06-05 01:50] Train Step 52850, Epoch 48.9, Batch Size = 256, Examples/Sec = 3867.18, Train LB = -379.453, Loss = 399.604
[2018-06-05 01:50] Train Step 52875, Epoch 49.0, Batch Size = 256, Examples/Sec = 3883.85, Train LB = -386.014, Loss = 398.856
[2018-06-05 01:50] Train Step 52900, Epoch 49.0, Batch Size = 256, Examples/Sec = 3872.75, Train LB = -399.958, Loss = 398.072
[2018-06-05 01:50] Train Step 52925, Epoch 49.0, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -386.090, Loss = 397.728
[2018-06-05 01:50] Train Step 52950, Epoch 49.0, Batch Size = 256, Examples/Sec = 3803.87, Train LB = -392.186, Loss = 397.775
[2018-06-05 01:50] Train Step 52975, Epoch 49.1, Batch Size = 256, Examples/Sec = 3858.27, Train LB = -410.504, Loss = 398.219
[2018-06-05 01:50] Train Step 53000, Epoch 49.1, Batch Size = 256, Examples/Sec = 3866.25, Train LB = -418.070, Loss = 401.535
Performance on test set:
  Test Lower Bound = -442.640, Test Loss = 442.640
[2018-06-05 01:50] Train Step 53025, Epoch 49.1, Batch Size = 256, Examples/Sec = 3820.33, Train LB = -393.569, Loss = 400.369
[2018-06-05 01:50] Train Step 53050, Epoch 49.1, Batch Size = 256, Examples/Sec = 3802.62, Train LB = -390.516, Loss = 400.111
[2018-06-05 01:50] Train Step 53075, Epoch 49.1, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -391.219, Loss = 399.349
[2018-06-05 01:50] Train Step 53100, Epoch 49.2, Batch Size = 256, Examples/Sec = 3863.91, Train LB = -385.747, Loss = 398.162
[2018-06-05 01:50] Train Step 53125, Epoch 49.2, Batch Size = 256, Examples/Sec = 3844.58, Train LB = -414.059, Loss = 397.745
[2018-06-05 01:50] Train Step 53150, Epoch 49.2, Batch Size = 256, Examples/Sec = 3877.32, Train LB = -391.217, Loss = 398.144
[2018-06-05 01:50] Train Step 53175, Epoch 49.2, Batch Size = 256, Examples/Sec = 3834.00, Train LB = -423.228, Loss = 398.745
[2018-06-05 01:50] Train Step 53200, Epoch 49.3, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -414.186, Loss = 401.811
Performance on test set:
  Test Lower Bound = -444.248, Test Loss = 444.248
[2018-06-05 01:50] Train Step 53225, Epoch 49.3, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -390.118, Loss = 401.082
[2018-06-05 01:50] Train Step 53250, Epoch 49.3, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -409.943, Loss = 399.568
[2018-06-05 01:50] Train Step 53275, Epoch 49.3, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -398.176, Loss = 398.790
[2018-06-05 01:50] Train Step 53300, Epoch 49.4, Batch Size = 256, Examples/Sec = 3871.81, Train LB = -392.529, Loss = 397.888
[2018-06-05 01:50] Train Step 53325, Epoch 49.4, Batch Size = 256, Examples/Sec = 3794.78, Train LB = -399.852, Loss = 397.530
[2018-06-05 01:50] Train Step 53350, Epoch 49.4, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -406.201, Loss = 397.234
[2018-06-05 01:50] Train Step 53375, Epoch 49.4, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -399.193, Loss = 398.776
[2018-06-05 01:50] Train Step 53400, Epoch 49.4, Batch Size = 256, Examples/Sec = 3881.38, Train LB = -417.531, Loss = 401.060
Performance on test set:
  Test Lower Bound = -442.850, Test Loss = 442.850
[2018-06-05 01:50] Train Step 53425, Epoch 49.5, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -405.673, Loss = 400.558
[2018-06-05 01:50] Train Step 53450, Epoch 49.5, Batch Size = 256, Examples/Sec = 3831.14, Train LB = -408.577, Loss = 400.020
[2018-06-05 01:50] Train Step 53475, Epoch 49.5, Batch Size = 256, Examples/Sec = 3876.91, Train LB = -382.362, Loss = 398.679
[2018-06-05 01:50] Train Step 53500, Epoch 49.5, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -395.245, Loss = 397.337
[2018-06-05 01:50] Train Step 53525, Epoch 49.6, Batch Size = 256, Examples/Sec = 3861.42, Train LB = -386.512, Loss = 396.996
[2018-06-05 01:50] Train Step 53550, Epoch 49.6, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -403.269, Loss = 397.079
[2018-06-05 01:51] Train Step 53575, Epoch 49.6, Batch Size = 256, Examples/Sec = 3865.13, Train LB = -422.029, Loss = 398.427
[2018-06-05 01:51] Train Step 53600, Epoch 49.6, Batch Size = 256, Examples/Sec = 3818.96, Train LB = -408.436, Loss = 401.427
Performance on test set:
  Test Lower Bound = -443.055, Test Loss = 443.055
[2018-06-05 01:51] Train Step 53625, Epoch 49.7, Batch Size = 256, Examples/Sec = 3833.42, Train LB = -388.250, Loss = 400.217
[2018-06-05 01:51] Train Step 53650, Epoch 49.7, Batch Size = 256, Examples/Sec = 3878.55, Train LB = -407.777, Loss = 399.462
[2018-06-05 01:51] Train Step 53675, Epoch 49.7, Batch Size = 256, Examples/Sec = 3850.15, Train LB = -386.295, Loss = 399.019
[2018-06-05 01:51] Train Step 53700, Epoch 49.7, Batch Size = 256, Examples/Sec = 3823.30, Train LB = -388.630, Loss = 398.111
[2018-06-05 01:51] Train Step 53725, Epoch 49.7, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -407.730, Loss = 397.715
[2018-06-05 01:51] Train Step 53750, Epoch 49.8, Batch Size = 256, Examples/Sec = 3883.45, Train LB = -403.362, Loss = 397.102
[2018-06-05 01:51] Train Step 53775, Epoch 49.8, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -415.386, Loss = 398.322
[2018-06-05 01:51] Train Step 53800, Epoch 49.8, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -425.285, Loss = 400.476
Performance on test set:
  Test Lower Bound = -444.065, Test Loss = 444.065
[2018-06-05 01:51] Train Step 53825, Epoch 49.8, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -402.411, Loss = 399.571
[2018-06-05 01:51] Train Step 53850, Epoch 49.9, Batch Size = 256, Examples/Sec = 3871.10, Train LB = -402.746, Loss = 398.716
[2018-06-05 01:51] Train Step 53875, Epoch 49.9, Batch Size = 256, Examples/Sec = 3885.62, Train LB = -401.322, Loss = 397.686
[2018-06-05 01:51] Train Step 53900, Epoch 49.9, Batch Size = 256, Examples/Sec = 3877.32, Train LB = -389.209, Loss = 397.892
[2018-06-05 01:51] Train Step 53925, Epoch 49.9, Batch Size = 256, Examples/Sec = 3858.74, Train LB = -402.671, Loss = 397.652
[2018-06-05 01:51] Train Step 53950, Epoch 50.0, Batch Size = 256, Examples/Sec = 3859.08, Train LB = -408.051, Loss = 397.677
[2018-06-05 01:51] Train Step 53975, Epoch 50.0, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -395.125, Loss = 398.583
[2018-06-05 01:51] Train Step 54000, Epoch 50.0, Batch Size = 256, Examples/Sec = 3873.46, Train LB = -422.833, Loss = 401.407
Performance on test set:
  Test Lower Bound = -443.448, Test Loss = 443.448
[2018-06-05 01:51] Train Step 54025, Epoch 50.0, Batch Size = 256, Examples/Sec = 3873.39, Train LB = -392.804, Loss = 400.686
[2018-06-05 01:51] Train Step 54050, Epoch 50.0, Batch Size = 256, Examples/Sec = 3874.39, Train LB = -396.124, Loss = 399.808
[2018-06-05 01:51] Train Step 54075, Epoch 50.1, Batch Size = 256, Examples/Sec = 3877.91, Train LB = -392.559, Loss = 398.771
[2018-06-05 01:51] Train Step 54100, Epoch 50.1, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -401.593, Loss = 397.834
[2018-06-05 01:51] Train Step 54125, Epoch 50.1, Batch Size = 256, Examples/Sec = 3848.40, Train LB = -395.417, Loss = 397.766
[2018-06-05 01:51] Train Step 54150, Epoch 50.1, Batch Size = 256, Examples/Sec = 3858.80, Train LB = -400.780, Loss = 397.156
[2018-06-05 01:51] Train Step 54175, Epoch 50.2, Batch Size = 256, Examples/Sec = 3803.24, Train LB = -416.513, Loss = 398.121
[2018-06-05 01:51] Train Step 54200, Epoch 50.2, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -411.200, Loss = 400.529
Performance on test set:
  Test Lower Bound = -443.635, Test Loss = 443.635
[2018-06-05 01:51] Train Step 54225, Epoch 50.2, Batch Size = 256, Examples/Sec = 3894.31, Train LB = -399.022, Loss = 400.036
[2018-06-05 01:51] Train Step 54250, Epoch 50.2, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -390.231, Loss = 398.810
[2018-06-05 01:52] Train Step 54275, Epoch 50.3, Batch Size = 256, Examples/Sec = 3793.71, Train LB = -404.846, Loss = 398.334
[2018-06-05 01:52] Train Step 54300, Epoch 50.3, Batch Size = 256, Examples/Sec = 3885.09, Train LB = -397.852, Loss = 397.818
[2018-06-05 01:52] Train Step 54325, Epoch 50.3, Batch Size = 256, Examples/Sec = 3864.90, Train LB = -383.016, Loss = 397.467
[2018-06-05 01:52] Train Step 54350, Epoch 50.3, Batch Size = 256, Examples/Sec = 3873.39, Train LB = -404.666, Loss = 397.473
[2018-06-05 01:52] Train Step 54375, Epoch 50.3, Batch Size = 256, Examples/Sec = 3856.11, Train LB = -396.076, Loss = 398.567
[2018-06-05 01:52] Train Step 54400, Epoch 50.4, Batch Size = 256, Examples/Sec = 3862.46, Train LB = -423.071, Loss = 400.975
Performance on test set:
  Test Lower Bound = -442.098, Test Loss = 442.098
[2018-06-05 01:52] Train Step 54425, Epoch 50.4, Batch Size = 256, Examples/Sec = 3851.66, Train LB = -411.238, Loss = 400.074
[2018-06-05 01:52] Train Step 54450, Epoch 50.4, Batch Size = 256, Examples/Sec = 3848.23, Train LB = -387.644, Loss = 398.790
[2018-06-05 01:52] Train Step 54475, Epoch 50.4, Batch Size = 256, Examples/Sec = 3857.39, Train LB = -409.561, Loss = 398.044
[2018-06-05 01:52] Train Step 54500, Epoch 50.5, Batch Size = 256, Examples/Sec = 3805.17, Train LB = -399.247, Loss = 397.753
[2018-06-05 01:52] Train Step 54525, Epoch 50.5, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -404.841, Loss = 397.508
[2018-06-05 01:52] Train Step 54550, Epoch 50.5, Batch Size = 256, Examples/Sec = 3843.61, Train LB = -409.727, Loss = 397.394
[2018-06-05 01:52] Train Step 54575, Epoch 50.5, Batch Size = 256, Examples/Sec = 3847.76, Train LB = -402.420, Loss = 398.320
[2018-06-05 01:52] Train Step 54600, Epoch 50.6, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -421.715, Loss = 400.923
Performance on test set:
  Test Lower Bound = -442.685, Test Loss = 442.685
[2018-06-05 01:52] Train Step 54625, Epoch 50.6, Batch Size = 256, Examples/Sec = 3856.11, Train LB = -388.894, Loss = 400.396
[2018-06-05 01:52] Train Step 54650, Epoch 50.6, Batch Size = 256, Examples/Sec = 3876.60, Train LB = -397.137, Loss = 398.733
[2018-06-05 01:52] Train Step 54675, Epoch 50.6, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -387.550, Loss = 397.388
[2018-06-05 01:52] Train Step 54700, Epoch 50.6, Batch Size = 256, Examples/Sec = 3884.68, Train LB = -387.884, Loss = 397.038
[2018-06-05 01:52] Train Step 54725, Epoch 50.7, Batch Size = 256, Examples/Sec = 3872.58, Train LB = -389.815, Loss = 396.545
[2018-06-05 01:52] Train Step 54750, Epoch 50.7, Batch Size = 256, Examples/Sec = 3781.89, Train LB = -409.129, Loss = 397.846
[2018-06-05 01:52] Train Step 54775, Epoch 50.7, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -413.979, Loss = 398.375
[2018-06-05 01:52] Train Step 54800, Epoch 50.7, Batch Size = 256, Examples/Sec = 3834.12, Train LB = -414.849, Loss = 401.225
Performance on test set:
  Test Lower Bound = -443.110, Test Loss = 443.110
[2018-06-05 01:52] Train Step 54825, Epoch 50.8, Batch Size = 256, Examples/Sec = 3874.79, Train LB = -387.474, Loss = 399.858
[2018-06-05 01:52] Train Step 54850, Epoch 50.8, Batch Size = 256, Examples/Sec = 3812.08, Train LB = -394.634, Loss = 398.797
[2018-06-05 01:52] Train Step 54875, Epoch 50.8, Batch Size = 256, Examples/Sec = 3836.35, Train LB = -393.131, Loss = 398.066
[2018-06-05 01:52] Train Step 54900, Epoch 50.8, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -399.923, Loss = 397.235
[2018-06-05 01:52] Train Step 54925, Epoch 50.9, Batch Size = 256, Examples/Sec = 3864.44, Train LB = -398.008, Loss = 396.585
[2018-06-05 01:52] Train Step 54950, Epoch 50.9, Batch Size = 256, Examples/Sec = 3878.77, Train LB = -411.201, Loss = 396.544
[2018-06-05 01:52] Train Step 54975, Epoch 50.9, Batch Size = 256, Examples/Sec = 3841.20, Train LB = -405.200, Loss = 398.253
[2018-06-05 01:52] Train Step 55000, Epoch 50.9, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -414.319, Loss = 401.075
Performance on test set:
  Test Lower Bound = -445.008, Test Loss = 445.008
[2018-06-05 01:53] Train Step 55025, Epoch 50.9, Batch Size = 256, Examples/Sec = 3870.00, Train LB = -387.357, Loss = 400.104
[2018-06-05 01:53] Train Step 55050, Epoch 51.0, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -401.537, Loss = 397.987
[2018-06-05 01:53] Train Step 55075, Epoch 51.0, Batch Size = 256, Examples/Sec = 3856.12, Train LB = -385.523, Loss = 397.787
[2018-06-05 01:53] Train Step 55100, Epoch 51.0, Batch Size = 256, Examples/Sec = 3853.38, Train LB = -395.738, Loss = 397.062
[2018-06-05 01:53] Train Step 55125, Epoch 51.0, Batch Size = 256, Examples/Sec = 3817.42, Train LB = -384.374, Loss = 396.776
[2018-06-05 01:53] Train Step 55150, Epoch 51.1, Batch Size = 256, Examples/Sec = 3874.03, Train LB = -382.717, Loss = 396.975
[2018-06-05 01:53] Train Step 55175, Epoch 51.1, Batch Size = 256, Examples/Sec = 3848.76, Train LB = -423.880, Loss = 398.181
[2018-06-05 01:53] Train Step 55200, Epoch 51.1, Batch Size = 256, Examples/Sec = 3878.79, Train LB = -401.895, Loss = 401.025
Performance on test set:
  Test Lower Bound = -443.996, Test Loss = 443.996
[2018-06-05 01:53] Train Step 55225, Epoch 51.1, Batch Size = 256, Examples/Sec = 3841.94, Train LB = -396.595, Loss = 399.859
[2018-06-05 01:53] Train Step 55250, Epoch 51.2, Batch Size = 256, Examples/Sec = 3868.13, Train LB = -393.758, Loss = 398.829
[2018-06-05 01:53] Train Step 55275, Epoch 51.2, Batch Size = 256, Examples/Sec = 3877.26, Train LB = -390.336, Loss = 397.407
[2018-06-05 01:53] Train Step 55300, Epoch 51.2, Batch Size = 256, Examples/Sec = 3871.87, Train LB = -405.555, Loss = 397.020
[2018-06-05 01:53] Train Step 55325, Epoch 51.2, Batch Size = 256, Examples/Sec = 3808.68, Train LB = -385.970, Loss = 396.409
[2018-06-05 01:53] Train Step 55350, Epoch 51.2, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -402.784, Loss = 396.789
[2018-06-05 01:53] Train Step 55375, Epoch 51.3, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -392.896, Loss = 397.295
[2018-06-05 01:53] Train Step 55400, Epoch 51.3, Batch Size = 256, Examples/Sec = 3867.19, Train LB = -421.527, Loss = 400.595
Performance on test set:
  Test Lower Bound = -443.400, Test Loss = 443.400
[2018-06-05 01:53] Train Step 55425, Epoch 51.3, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -389.081, Loss = 399.719
[2018-06-05 01:53] Train Step 55450, Epoch 51.3, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -387.750, Loss = 398.170
[2018-06-05 01:53] Train Step 55475, Epoch 51.4, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -401.218, Loss = 397.011
[2018-06-05 01:53] Train Step 55500, Epoch 51.4, Batch Size = 256, Examples/Sec = 3861.87, Train LB = -390.779, Loss = 396.730
[2018-06-05 01:53] Train Step 55525, Epoch 51.4, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -392.569, Loss = 397.003
[2018-06-05 01:53] Train Step 55550, Epoch 51.4, Batch Size = 256, Examples/Sec = 3881.79, Train LB = -409.535, Loss = 396.856
[2018-06-05 01:53] Train Step 55575, Epoch 51.5, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -417.104, Loss = 397.888
[2018-06-05 01:53] Train Step 55600, Epoch 51.5, Batch Size = 256, Examples/Sec = 3871.74, Train LB = -407.264, Loss = 401.425
Performance on test set:
  Test Lower Bound = -443.880, Test Loss = 443.880
[2018-06-05 01:53] Train Step 55625, Epoch 51.5, Batch Size = 256, Examples/Sec = 3851.84, Train LB = -404.536, Loss = 400.475
[2018-06-05 01:53] Train Step 55650, Epoch 51.5, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -395.919, Loss = 399.266
[2018-06-05 01:53] Train Step 55675, Epoch 51.6, Batch Size = 256, Examples/Sec = 3870.80, Train LB = -383.651, Loss = 398.254
[2018-06-05 01:54] Train Step 55700, Epoch 51.6, Batch Size = 256, Examples/Sec = 3815.48, Train LB = -398.626, Loss = 397.598
[2018-06-05 01:54] Train Step 55725, Epoch 51.6, Batch Size = 256, Examples/Sec = 3850.15, Train LB = -411.323, Loss = 396.177
[2018-06-05 01:54] Train Step 55750, Epoch 51.6, Batch Size = 256, Examples/Sec = 3836.29, Train LB = -386.260, Loss = 395.667
[2018-06-05 01:54] Train Step 55775, Epoch 51.6, Batch Size = 256, Examples/Sec = 3876.16, Train LB = -398.327, Loss = 397.501
[2018-06-05 01:54] Train Step 55800, Epoch 51.7, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -436.381, Loss = 400.531
Performance on test set:
  Test Lower Bound = -443.592, Test Loss = 443.592
[2018-06-05 01:54] Train Step 55825, Epoch 51.7, Batch Size = 256, Examples/Sec = 3847.60, Train LB = -397.728, Loss = 399.786
[2018-06-05 01:54] Train Step 55850, Epoch 51.7, Batch Size = 256, Examples/Sec = 3799.90, Train LB = -384.149, Loss = 398.941
[2018-06-05 01:54] Train Step 55875, Epoch 51.7, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -391.751, Loss = 397.526
[2018-06-05 01:54] Train Step 55900, Epoch 51.8, Batch Size = 256, Examples/Sec = 3870.82, Train LB = -402.448, Loss = 396.865
[2018-06-05 01:54] Train Step 55925, Epoch 51.8, Batch Size = 256, Examples/Sec = 3802.79, Train LB = -396.189, Loss = 396.337
[2018-06-05 01:54] Train Step 55950, Epoch 51.8, Batch Size = 256, Examples/Sec = 3850.72, Train LB = -393.342, Loss = 396.350
[2018-06-05 01:54] Train Step 55975, Epoch 51.8, Batch Size = 256, Examples/Sec = 3857.87, Train LB = -411.825, Loss = 397.211
[2018-06-05 01:54] Train Step 56000, Epoch 51.9, Batch Size = 256, Examples/Sec = 3858.44, Train LB = -418.129, Loss = 399.415
Performance on test set:
  Test Lower Bound = -443.809, Test Loss = 443.809
[2018-06-05 01:54] Train Step 56025, Epoch 51.9, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -372.883, Loss = 399.042
[2018-06-05 01:54] Train Step 56050, Epoch 51.9, Batch Size = 256, Examples/Sec = 3840.44, Train LB = -407.387, Loss = 397.771
[2018-06-05 01:54] Train Step 56075, Epoch 51.9, Batch Size = 256, Examples/Sec = 3875.39, Train LB = -382.650, Loss = 397.745
[2018-06-05 01:54] Train Step 56100, Epoch 51.9, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -406.546, Loss = 396.718
[2018-06-05 01:54] Train Step 56125, Epoch 52.0, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -401.225, Loss = 395.894
[2018-06-05 01:54] Train Step 56150, Epoch 52.0, Batch Size = 256, Examples/Sec = 3824.21, Train LB = -403.802, Loss = 396.532
[2018-06-05 01:54] Train Step 56175, Epoch 52.0, Batch Size = 256, Examples/Sec = 3879.97, Train LB = -406.011, Loss = 397.971
[2018-06-05 01:54] Train Step 56200, Epoch 52.0, Batch Size = 256, Examples/Sec = 3877.79, Train LB = -417.710, Loss = 400.592
Performance on test set:
  Test Lower Bound = -443.694, Test Loss = 443.694
[2018-06-05 01:54] Train Step 56225, Epoch 52.1, Batch Size = 256, Examples/Sec = 3845.01, Train LB = -402.643, Loss = 399.773
[2018-06-05 01:54] Train Step 56250, Epoch 52.1, Batch Size = 256, Examples/Sec = 3877.32, Train LB = -393.319, Loss = 398.574
[2018-06-05 01:54] Train Step 56275, Epoch 52.1, Batch Size = 256, Examples/Sec = 3855.13, Train LB = -379.270, Loss = 397.897
[2018-06-05 01:54] Train Step 56300, Epoch 52.1, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -394.192, Loss = 396.536
[2018-06-05 01:54] Train Step 56325, Epoch 52.2, Batch Size = 256, Examples/Sec = 3803.63, Train LB = -375.314, Loss = 396.551
[2018-06-05 01:54] Train Step 56350, Epoch 52.2, Batch Size = 256, Examples/Sec = 3864.22, Train LB = -394.479, Loss = 397.203
[2018-06-05 01:54] Train Step 56375, Epoch 52.2, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -401.366, Loss = 397.774
[2018-06-05 01:54] Train Step 56400, Epoch 52.2, Batch Size = 256, Examples/Sec = 3834.18, Train LB = -406.350, Loss = 399.979
Performance on test set:
  Test Lower Bound = -445.701, Test Loss = 445.701
[2018-06-05 01:55] Train Step 56425, Epoch 52.2, Batch Size = 256, Examples/Sec = 3813.15, Train LB = -387.099, Loss = 398.836
[2018-06-05 01:55] Train Step 56450, Epoch 52.3, Batch Size = 256, Examples/Sec = 3880.61, Train LB = -401.960, Loss = 397.471
[2018-06-05 01:55] Train Step 56475, Epoch 52.3, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -389.027, Loss = 396.913
[2018-06-05 01:55] Train Step 56500, Epoch 52.3, Batch Size = 256, Examples/Sec = 3845.74, Train LB = -392.898, Loss = 396.488
[2018-06-05 01:55] Train Step 56525, Epoch 52.3, Batch Size = 256, Examples/Sec = 3841.02, Train LB = -392.836, Loss = 395.968
[2018-06-05 01:55] Train Step 56550, Epoch 52.4, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -388.206, Loss = 395.910
[2018-06-05 01:55] Train Step 56575, Epoch 52.4, Batch Size = 256, Examples/Sec = 3873.57, Train LB = -418.234, Loss = 396.710
[2018-06-05 01:55] Train Step 56600, Epoch 52.4, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -410.617, Loss = 399.198
Performance on test set:
  Test Lower Bound = -445.045, Test Loss = 445.045
[2018-06-05 01:55] Train Step 56625, Epoch 52.4, Batch Size = 256, Examples/Sec = 3881.61, Train LB = -387.251, Loss = 398.248
[2018-06-05 01:55] Train Step 56650, Epoch 52.5, Batch Size = 256, Examples/Sec = 3874.32, Train LB = -388.092, Loss = 397.855
[2018-06-05 01:55] Train Step 56675, Epoch 52.5, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -397.369, Loss = 396.634
[2018-06-05 01:55] Train Step 56700, Epoch 52.5, Batch Size = 256, Examples/Sec = 3847.48, Train LB = -393.428, Loss = 395.940
[2018-06-05 01:55] Train Step 56725, Epoch 52.5, Batch Size = 256, Examples/Sec = 3875.08, Train LB = -415.854, Loss = 395.708
[2018-06-05 01:55] Train Step 56750, Epoch 52.5, Batch Size = 256, Examples/Sec = 3856.65, Train LB = -402.082, Loss = 395.673
[2018-06-05 01:55] Train Step 56775, Epoch 52.6, Batch Size = 256, Examples/Sec = 3808.84, Train LB = -399.763, Loss = 396.717
[2018-06-05 01:55] Train Step 56800, Epoch 52.6, Batch Size = 256, Examples/Sec = 3880.02, Train LB = -412.862, Loss = 399.694
Performance on test set:
  Test Lower Bound = -444.172, Test Loss = 444.172
[2018-06-05 01:55] Train Step 56825, Epoch 52.6, Batch Size = 256, Examples/Sec = 3867.07, Train LB = -388.165, Loss = 398.833
[2018-06-05 01:55] Train Step 56850, Epoch 52.6, Batch Size = 256, Examples/Sec = 3853.74, Train LB = -401.353, Loss = 397.731
[2018-06-05 01:55] Train Step 56875, Epoch 52.7, Batch Size = 256, Examples/Sec = 3859.38, Train LB = -385.092, Loss = 396.867
[2018-06-05 01:55] Train Step 56900, Epoch 52.7, Batch Size = 256, Examples/Sec = 3865.68, Train LB = -401.748, Loss = 395.687
[2018-06-05 01:55] Train Step 56925, Epoch 52.7, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -388.538, Loss = 395.617
[2018-06-05 01:55] Train Step 56950, Epoch 52.7, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -389.399, Loss = 395.971
[2018-06-05 01:55] Train Step 56975, Epoch 52.8, Batch Size = 256, Examples/Sec = 3827.75, Train LB = -405.276, Loss = 397.102
[2018-06-05 01:55] Train Step 57000, Epoch 52.8, Batch Size = 256, Examples/Sec = 3848.98, Train LB = -415.632, Loss = 400.074
Performance on test set:
  Test Lower Bound = -444.111, Test Loss = 444.111
[2018-06-05 01:55] Train Step 57025, Epoch 52.8, Batch Size = 256, Examples/Sec = 3854.38, Train LB = -378.932, Loss = 398.900
[2018-06-05 01:55] Train Step 57050, Epoch 52.8, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -396.904, Loss = 398.197
[2018-06-05 01:55] Train Step 57075, Epoch 52.8, Batch Size = 256, Examples/Sec = 3844.54, Train LB = -406.076, Loss = 397.296
[2018-06-05 01:55] Train Step 57100, Epoch 52.9, Batch Size = 256, Examples/Sec = 3794.10, Train LB = -381.211, Loss = 396.531
[2018-06-05 01:55] Train Step 57125, Epoch 52.9, Batch Size = 256, Examples/Sec = 3850.37, Train LB = -393.269, Loss = 395.727
[2018-06-05 01:56] Train Step 57150, Epoch 52.9, Batch Size = 256, Examples/Sec = 3883.97, Train LB = -402.339, Loss = 395.969
[2018-06-05 01:56] Train Step 57175, Epoch 52.9, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -392.222, Loss = 397.786
[2018-06-05 01:56] Train Step 57200, Epoch 53.0, Batch Size = 256, Examples/Sec = 3850.73, Train LB = -439.259, Loss = 400.172
Performance on test set:
  Test Lower Bound = -444.532, Test Loss = 444.532
[2018-06-05 01:56] Train Step 57225, Epoch 53.0, Batch Size = 256, Examples/Sec = 3862.46, Train LB = -402.838, Loss = 399.717
[2018-06-05 01:56] Train Step 57250, Epoch 53.0, Batch Size = 256, Examples/Sec = 3859.38, Train LB = -388.620, Loss = 398.409
[2018-06-05 01:56] Train Step 57275, Epoch 53.0, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -401.168, Loss = 396.908
[2018-06-05 01:56] Train Step 57300, Epoch 53.1, Batch Size = 256, Examples/Sec = 3845.23, Train LB = -399.881, Loss = 396.277
[2018-06-05 01:56] Train Step 57325, Epoch 53.1, Batch Size = 256, Examples/Sec = 3874.10, Train LB = -418.845, Loss = 395.832
[2018-06-05 01:56] Train Step 57350, Epoch 53.1, Batch Size = 256, Examples/Sec = 3880.32, Train LB = -394.070, Loss = 396.395
[2018-06-05 01:56] Train Step 57375, Epoch 53.1, Batch Size = 256, Examples/Sec = 3876.80, Train LB = -395.115, Loss = 397.529
[2018-06-05 01:56] Train Step 57400, Epoch 53.1, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -415.126, Loss = 399.710
Performance on test set:
  Test Lower Bound = -445.240, Test Loss = 445.240
[2018-06-05 01:56] Train Step 57425, Epoch 53.2, Batch Size = 256, Examples/Sec = 3871.99, Train LB = -389.759, Loss = 398.772
[2018-06-05 01:56] Train Step 57450, Epoch 53.2, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -371.905, Loss = 397.511
[2018-06-05 01:56] Train Step 57475, Epoch 53.2, Batch Size = 256, Examples/Sec = 3857.33, Train LB = -411.649, Loss = 396.910
[2018-06-05 01:56] Train Step 57500, Epoch 53.2, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -404.048, Loss = 396.142
[2018-06-05 01:56] Train Step 57525, Epoch 53.3, Batch Size = 256, Examples/Sec = 3854.84, Train LB = -394.511, Loss = 395.328
[2018-06-05 01:56] Train Step 57550, Epoch 53.3, Batch Size = 256, Examples/Sec = 3809.76, Train LB = -388.774, Loss = 395.771
[2018-06-05 01:56] Train Step 57575, Epoch 53.3, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -407.779, Loss = 396.784
[2018-06-05 01:56] Train Step 57600, Epoch 53.3, Batch Size = 256, Examples/Sec = 3856.89, Train LB = -414.882, Loss = 400.210
Performance on test set:
  Test Lower Bound = -444.326, Test Loss = 444.326
[2018-06-05 01:56] Train Step 57625, Epoch 53.4, Batch Size = 256, Examples/Sec = 3854.89, Train LB = -394.264, Loss = 399.026
[2018-06-05 01:56] Train Step 57650, Epoch 53.4, Batch Size = 256, Examples/Sec = 3789.28, Train LB = -394.375, Loss = 398.053
[2018-06-05 01:56] Train Step 57675, Epoch 53.4, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -400.985, Loss = 396.868
[2018-06-05 01:56] Train Step 57700, Epoch 53.4, Batch Size = 256, Examples/Sec = 3865.09, Train LB = -389.634, Loss = 396.044
[2018-06-05 01:56] Train Step 57725, Epoch 53.4, Batch Size = 256, Examples/Sec = 3822.26, Train LB = -394.401, Loss = 395.262
[2018-06-05 01:56] Train Step 57750, Epoch 53.5, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -402.885, Loss = 394.816
[2018-06-05 01:56] Train Step 57775, Epoch 53.5, Batch Size = 256, Examples/Sec = 3884.26, Train LB = -405.859, Loss = 396.555
[2018-06-05 01:56] Train Step 57800, Epoch 53.5, Batch Size = 256, Examples/Sec = 3873.63, Train LB = -422.321, Loss = 399.623
Performance on test set:
  Test Lower Bound = -446.180, Test Loss = 446.180
[2018-06-05 01:56] Train Step 57825, Epoch 53.5, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -401.952, Loss = 398.889
[2018-06-05 01:57] Train Step 57850, Epoch 53.6, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -394.803, Loss = 397.816
[2018-06-05 01:57] Train Step 57875, Epoch 53.6, Batch Size = 256, Examples/Sec = 3882.62, Train LB = -385.311, Loss = 396.687
[2018-06-05 01:57] Train Step 57900, Epoch 53.6, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -389.151, Loss = 395.937
[2018-06-05 01:57] Train Step 57925, Epoch 53.6, Batch Size = 256, Examples/Sec = 3864.74, Train LB = -381.127, Loss = 395.343
[2018-06-05 01:57] Train Step 57950, Epoch 53.7, Batch Size = 256, Examples/Sec = 3878.14, Train LB = -399.972, Loss = 395.480
[2018-06-05 01:57] Train Step 57975, Epoch 53.7, Batch Size = 256, Examples/Sec = 3859.13, Train LB = -401.801, Loss = 397.484
[2018-06-05 01:57] Train Step 58000, Epoch 53.7, Batch Size = 256, Examples/Sec = 3863.33, Train LB = -430.547, Loss = 399.733
Performance on test set:
  Test Lower Bound = -444.512, Test Loss = 444.512
[2018-06-05 01:57] Train Step 58025, Epoch 53.7, Batch Size = 256, Examples/Sec = 3887.92, Train LB = -397.708, Loss = 398.937
[2018-06-05 01:57] Train Step 58050, Epoch 53.8, Batch Size = 256, Examples/Sec = 3809.12, Train LB = -399.120, Loss = 398.047
[2018-06-05 01:57] Train Step 58075, Epoch 53.8, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -386.492, Loss = 396.780
[2018-06-05 01:57] Train Step 58100, Epoch 53.8, Batch Size = 256, Examples/Sec = 3831.70, Train LB = -398.506, Loss = 396.018
[2018-06-05 01:57] Train Step 58125, Epoch 53.8, Batch Size = 256, Examples/Sec = 3834.00, Train LB = -399.558, Loss = 395.707
[2018-06-05 01:57] Train Step 58150, Epoch 53.8, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -388.306, Loss = 395.119
[2018-06-05 01:57] Train Step 58175, Epoch 53.9, Batch Size = 256, Examples/Sec = 3874.04, Train LB = -413.024, Loss = 396.057
[2018-06-05 01:57] Train Step 58200, Epoch 53.9, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -428.438, Loss = 399.169
Performance on test set:
  Test Lower Bound = -444.911, Test Loss = 444.911
[2018-06-05 01:57] Train Step 58225, Epoch 53.9, Batch Size = 256, Examples/Sec = 3809.01, Train LB = -397.509, Loss = 398.386
[2018-06-05 01:57] Train Step 58250, Epoch 53.9, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -396.816, Loss = 397.611
[2018-06-05 01:57] Train Step 58275, Epoch 54.0, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -397.778, Loss = 396.539
[2018-06-05 01:57] Train Step 58300, Epoch 54.0, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -371.280, Loss = 395.523
[2018-06-05 01:57] Train Step 58325, Epoch 54.0, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -391.523, Loss = 395.109
[2018-06-05 01:57] Train Step 58350, Epoch 54.0, Batch Size = 256, Examples/Sec = 3883.80, Train LB = -398.842, Loss = 395.291
[2018-06-05 01:57] Train Step 58375, Epoch 54.1, Batch Size = 256, Examples/Sec = 3876.55, Train LB = -403.188, Loss = 397.162
[2018-06-05 01:57] Train Step 58400, Epoch 54.1, Batch Size = 256, Examples/Sec = 3856.17, Train LB = -415.340, Loss = 400.138
Performance on test set:
  Test Lower Bound = -444.707, Test Loss = 444.707
[2018-06-05 01:57] Train Step 58425, Epoch 54.1, Batch Size = 256, Examples/Sec = 3847.08, Train LB = -396.682, Loss = 399.302
[2018-06-05 01:57] Train Step 58450, Epoch 54.1, Batch Size = 256, Examples/Sec = 3863.21, Train LB = -399.223, Loss = 398.325
[2018-06-05 01:57] Train Step 58475, Epoch 54.1, Batch Size = 256, Examples/Sec = 3847.13, Train LB = -380.800, Loss = 396.870
[2018-06-05 01:57] Train Step 58500, Epoch 54.2, Batch Size = 256, Examples/Sec = 3865.91, Train LB = -392.902, Loss = 395.628
[2018-06-05 01:57] Train Step 58525, Epoch 54.2, Batch Size = 256, Examples/Sec = 3842.28, Train LB = -388.586, Loss = 394.888
[2018-06-05 01:57] Train Step 58550, Epoch 54.2, Batch Size = 256, Examples/Sec = 3876.49, Train LB = -386.443, Loss = 394.798
[2018-06-05 01:58] Train Step 58575, Epoch 54.2, Batch Size = 256, Examples/Sec = 3805.56, Train LB = -413.977, Loss = 395.941
[2018-06-05 01:58] Train Step 58600, Epoch 54.3, Batch Size = 256, Examples/Sec = 3798.45, Train LB = -410.886, Loss = 398.630
Performance on test set:
  Test Lower Bound = -444.843, Test Loss = 444.843
[2018-06-05 01:58] Train Step 58625, Epoch 54.3, Batch Size = 256, Examples/Sec = 3870.29, Train LB = -389.677, Loss = 397.691
[2018-06-05 01:58] Train Step 58650, Epoch 54.3, Batch Size = 256, Examples/Sec = 3851.06, Train LB = -399.862, Loss = 396.606
[2018-06-05 01:58] Train Step 58675, Epoch 54.3, Batch Size = 256, Examples/Sec = 3884.91, Train LB = -399.934, Loss = 395.467
[2018-06-05 01:58] Train Step 58700, Epoch 54.4, Batch Size = 256, Examples/Sec = 3813.03, Train LB = -394.005, Loss = 395.033
[2018-06-05 01:58] Train Step 58725, Epoch 54.4, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -408.500, Loss = 395.190
[2018-06-05 01:58] Train Step 58750, Epoch 54.4, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -406.910, Loss = 395.582
[2018-06-05 01:58] Train Step 58775, Epoch 54.4, Batch Size = 256, Examples/Sec = 3857.51, Train LB = -397.626, Loss = 396.869
[2018-06-05 01:58] Train Step 58800, Epoch 54.4, Batch Size = 256, Examples/Sec = 3832.62, Train LB = -418.652, Loss = 398.857
Performance on test set:
  Test Lower Bound = -446.258, Test Loss = 446.258
[2018-06-05 01:58] Train Step 58825, Epoch 54.5, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -374.785, Loss = 398.362
[2018-06-05 01:58] Train Step 58850, Epoch 54.5, Batch Size = 256, Examples/Sec = 3861.53, Train LB = -402.851, Loss = 396.708
[2018-06-05 01:58] Train Step 58875, Epoch 54.5, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -402.485, Loss = 396.349
[2018-06-05 01:58] Train Step 58900, Epoch 54.5, Batch Size = 256, Examples/Sec = 3863.23, Train LB = -395.076, Loss = 395.683
[2018-06-05 01:58] Train Step 58925, Epoch 54.6, Batch Size = 256, Examples/Sec = 3860.01, Train LB = -389.280, Loss = 395.039
[2018-06-05 01:58] Train Step 58950, Epoch 54.6, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -375.163, Loss = 395.326
[2018-06-05 01:58] Train Step 58975, Epoch 54.6, Batch Size = 256, Examples/Sec = 3851.99, Train LB = -401.851, Loss = 396.057
[2018-06-05 01:58] Train Step 59000, Epoch 54.6, Batch Size = 256, Examples/Sec = 3871.45, Train LB = -412.266, Loss = 399.228
Performance on test set:
  Test Lower Bound = -445.701, Test Loss = 445.701
[2018-06-05 01:58] Train Step 59025, Epoch 54.7, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -395.514, Loss = 397.903
[2018-06-05 01:58] Train Step 59050, Epoch 54.7, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -387.148, Loss = 397.100
[2018-06-05 01:58] Train Step 59075, Epoch 54.7, Batch Size = 256, Examples/Sec = 3867.14, Train LB = -390.276, Loss = 395.894
[2018-06-05 01:58] Train Step 59100, Epoch 54.7, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -385.988, Loss = 395.266
[2018-06-05 01:58] Train Step 59125, Epoch 54.7, Batch Size = 256, Examples/Sec = 3831.07, Train LB = -387.642, Loss = 395.042
[2018-06-05 01:58] Train Step 59150, Epoch 54.8, Batch Size = 256, Examples/Sec = 3845.93, Train LB = -400.224, Loss = 395.235
[2018-06-05 01:58] Train Step 59175, Epoch 54.8, Batch Size = 256, Examples/Sec = 3797.99, Train LB = -415.792, Loss = 396.128
[2018-06-05 01:58] Train Step 59200, Epoch 54.8, Batch Size = 256, Examples/Sec = 3849.86, Train LB = -420.104, Loss = 399.092
Performance on test set:
  Test Lower Bound = -445.886, Test Loss = 445.886
[2018-06-05 01:58] Train Step 59225, Epoch 54.8, Batch Size = 256, Examples/Sec = 3811.50, Train LB = -384.566, Loss = 398.736
[2018-06-05 01:58] Train Step 59250, Epoch 54.9, Batch Size = 256, Examples/Sec = 3850.15, Train LB = -391.162, Loss = 397.350
[2018-06-05 01:59] Train Step 59275, Epoch 54.9, Batch Size = 256, Examples/Sec = 3806.81, Train LB = -401.610, Loss = 395.937
[2018-06-05 01:59] Train Step 59300, Epoch 54.9, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -395.355, Loss = 395.156
[2018-06-05 01:59] Train Step 59325, Epoch 54.9, Batch Size = 256, Examples/Sec = 3869.65, Train LB = -380.978, Loss = 394.756
[2018-06-05 01:59] Train Step 59350, Epoch 55.0, Batch Size = 256, Examples/Sec = 3821.06, Train LB = -392.234, Loss = 395.430
[2018-06-05 01:59] Train Step 59375, Epoch 55.0, Batch Size = 256, Examples/Sec = 3881.02, Train LB = -406.771, Loss = 395.982
[2018-06-05 01:59] Train Step 59400, Epoch 55.0, Batch Size = 256, Examples/Sec = 3843.96, Train LB = -402.228, Loss = 398.649
Performance on test set:
  Test Lower Bound = -446.029, Test Loss = 446.029
[2018-06-05 01:59] Train Step 59425, Epoch 55.0, Batch Size = 256, Examples/Sec = 3862.74, Train LB = -413.348, Loss = 397.154
[2018-06-05 01:59] Train Step 59450, Epoch 55.0, Batch Size = 256, Examples/Sec = 3848.81, Train LB = -382.127, Loss = 396.446
[2018-06-05 01:59] Train Step 59475, Epoch 55.1, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -395.026, Loss = 395.783
[2018-06-05 01:59] Train Step 59500, Epoch 55.1, Batch Size = 256, Examples/Sec = 3869.88, Train LB = -387.446, Loss = 394.739
[2018-06-05 01:59] Train Step 59525, Epoch 55.1, Batch Size = 256, Examples/Sec = 3850.61, Train LB = -393.778, Loss = 394.404
[2018-06-05 01:59] Train Step 59550, Epoch 55.1, Batch Size = 256, Examples/Sec = 3871.87, Train LB = -399.719, Loss = 394.470
[2018-06-05 01:59] Train Step 59575, Epoch 55.2, Batch Size = 256, Examples/Sec = 3789.33, Train LB = -399.867, Loss = 395.986
[2018-06-05 01:59] Train Step 59600, Epoch 55.2, Batch Size = 256, Examples/Sec = 3874.49, Train LB = -413.877, Loss = 398.692
Performance on test set:
  Test Lower Bound = -445.752, Test Loss = 445.752
[2018-06-05 01:59] Train Step 59625, Epoch 55.2, Batch Size = 256, Examples/Sec = 3855.18, Train LB = -393.408, Loss = 396.930
[2018-06-05 01:59] Train Step 59650, Epoch 55.2, Batch Size = 256, Examples/Sec = 3856.06, Train LB = -387.787, Loss = 396.348
[2018-06-05 01:59] Train Step 59675, Epoch 55.3, Batch Size = 256, Examples/Sec = 3840.73, Train LB = -394.123, Loss = 395.803
[2018-06-05 01:59] Train Step 59700, Epoch 55.3, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -386.114, Loss = 395.319
[2018-06-05 01:59] Train Step 59725, Epoch 55.3, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -400.417, Loss = 395.075
[2018-06-05 01:59] Train Step 59750, Epoch 55.3, Batch Size = 256, Examples/Sec = 3824.49, Train LB = -379.433, Loss = 395.489
[2018-06-05 01:59] Train Step 59775, Epoch 55.3, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -403.921, Loss = 396.128
[2018-06-05 01:59] Train Step 59800, Epoch 55.4, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -410.107, Loss = 398.985
Performance on test set:
  Test Lower Bound = -445.859, Test Loss = 445.859
[2018-06-05 01:59] Train Step 59825, Epoch 55.4, Batch Size = 256, Examples/Sec = 3857.63, Train LB = -388.141, Loss = 397.912
[2018-06-05 01:59] Train Step 59850, Epoch 55.4, Batch Size = 256, Examples/Sec = 3827.81, Train LB = -399.824, Loss = 396.364
[2018-06-05 01:59] Train Step 59875, Epoch 55.4, Batch Size = 256, Examples/Sec = 3870.40, Train LB = -397.427, Loss = 395.546
[2018-06-05 01:59] Train Step 59900, Epoch 55.5, Batch Size = 256, Examples/Sec = 3855.36, Train LB = -397.504, Loss = 394.816
[2018-06-05 01:59] Train Step 59925, Epoch 55.5, Batch Size = 256, Examples/Sec = 3865.33, Train LB = -400.379, Loss = 394.575
[2018-06-05 01:59] Train Step 59950, Epoch 55.5, Batch Size = 256, Examples/Sec = 3845.06, Train LB = -406.613, Loss = 394.748
[2018-06-05 01:59] Train Step 59975, Epoch 55.5, Batch Size = 256, Examples/Sec = 3827.52, Train LB = -390.148, Loss = 396.319
[2018-06-05 01:59] Train Step 60000, Epoch 55.6, Batch Size = 256, Examples/Sec = 3883.45, Train LB = -404.693, Loss = 399.392
Performance on test set:
  Test Lower Bound = -445.460, Test Loss = 445.460
[2018-06-05 02:00] Train Step 60025, Epoch 55.6, Batch Size = 256, Examples/Sec = 3842.64, Train LB = -389.550, Loss = 398.825
[2018-06-05 02:00] Train Step 60050, Epoch 55.6, Batch Size = 256, Examples/Sec = 3864.98, Train LB = -379.750, Loss = 397.190
[2018-06-05 02:00] Train Step 60075, Epoch 55.6, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -383.620, Loss = 395.971
[2018-06-05 02:00] Train Step 60100, Epoch 55.6, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -400.247, Loss = 395.120
[2018-06-05 02:00] Train Step 60125, Epoch 55.7, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -396.398, Loss = 394.436
[2018-06-05 02:00] Train Step 60150, Epoch 55.7, Batch Size = 256, Examples/Sec = 3866.55, Train LB = -397.669, Loss = 394.505
[2018-06-05 02:00] Train Step 60175, Epoch 55.7, Batch Size = 256, Examples/Sec = 3840.84, Train LB = -404.449, Loss = 395.745
[2018-06-05 02:00] Train Step 60200, Epoch 55.7, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -413.355, Loss = 398.676
Performance on test set:
  Test Lower Bound = -445.673, Test Loss = 445.673
[2018-06-05 02:00] Train Step 60225, Epoch 55.8, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -392.134, Loss = 397.504
[2018-06-05 02:00] Train Step 60250, Epoch 55.8, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -390.489, Loss = 396.614
[2018-06-05 02:00] Train Step 60275, Epoch 55.8, Batch Size = 256, Examples/Sec = 3888.28, Train LB = -392.232, Loss = 395.801
[2018-06-05 02:00] Train Step 60300, Epoch 55.8, Batch Size = 256, Examples/Sec = 3849.56, Train LB = -399.691, Loss = 394.534
[2018-06-05 02:00] Train Step 60325, Epoch 55.9, Batch Size = 256, Examples/Sec = 3782.57, Train LB = -396.861, Loss = 394.559
[2018-06-05 02:00] Train Step 60350, Epoch 55.9, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -391.257, Loss = 394.665
[2018-06-05 02:00] Train Step 60375, Epoch 55.9, Batch Size = 256, Examples/Sec = 3848.45, Train LB = -397.501, Loss = 396.031
[2018-06-05 02:00] Train Step 60400, Epoch 55.9, Batch Size = 256, Examples/Sec = 3844.65, Train LB = -411.210, Loss = 398.633
Performance on test set:
  Test Lower Bound = -445.884, Test Loss = 445.884
[2018-06-05 02:00] Train Step 60425, Epoch 55.9, Batch Size = 256, Examples/Sec = 3827.02, Train LB = -394.803, Loss = 397.916
[2018-06-05 02:00] Train Step 60450, Epoch 56.0, Batch Size = 256, Examples/Sec = 3857.04, Train LB = -395.496, Loss = 396.819
[2018-06-05 02:00] Train Step 60475, Epoch 56.0, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -382.776, Loss = 395.766
[2018-06-05 02:00] Train Step 60500, Epoch 56.0, Batch Size = 256, Examples/Sec = 3867.18, Train LB = -399.406, Loss = 395.011
[2018-06-05 02:00] Train Step 60525, Epoch 56.0, Batch Size = 256, Examples/Sec = 3812.54, Train LB = -403.840, Loss = 394.613
[2018-06-05 02:00] Train Step 60550, Epoch 56.1, Batch Size = 256, Examples/Sec = 3875.37, Train LB = -403.413, Loss = 394.880
[2018-06-05 02:00] Train Step 60575, Epoch 56.1, Batch Size = 256, Examples/Sec = 3881.79, Train LB = -406.841, Loss = 395.869
[2018-06-05 02:00] Train Step 60600, Epoch 56.1, Batch Size = 256, Examples/Sec = 3811.11, Train LB = -416.501, Loss = 398.748
Performance on test set:
  Test Lower Bound = -446.610, Test Loss = 446.610
[2018-06-05 02:00] Train Step 60625, Epoch 56.1, Batch Size = 256, Examples/Sec = 3825.17, Train LB = -389.168, Loss = 397.839
[2018-06-05 02:00] Train Step 60650, Epoch 56.2, Batch Size = 256, Examples/Sec = 3874.74, Train LB = -390.786, Loss = 396.972
[2018-06-05 02:00] Train Step 60675, Epoch 56.2, Batch Size = 256, Examples/Sec = 3845.57, Train LB = -380.673, Loss = 396.221
[2018-06-05 02:00] Train Step 60700, Epoch 56.2, Batch Size = 256, Examples/Sec = 3849.45, Train LB = -394.215, Loss = 395.055
[2018-06-05 02:01] Train Step 60725, Epoch 56.2, Batch Size = 256, Examples/Sec = 3843.04, Train LB = -386.092, Loss = 394.414
[2018-06-05 02:01] Train Step 60750, Epoch 56.2, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -393.133, Loss = 394.420
[2018-06-05 02:01] Train Step 60775, Epoch 56.3, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -402.531, Loss = 395.459
[2018-06-05 02:01] Train Step 60800, Epoch 56.3, Batch Size = 256, Examples/Sec = 3816.23, Train LB = -417.601, Loss = 398.125
Performance on test set:
  Test Lower Bound = -446.554, Test Loss = 446.554
[2018-06-05 02:01] Train Step 60825, Epoch 56.3, Batch Size = 256, Examples/Sec = 3878.61, Train LB = -399.273, Loss = 397.351
[2018-06-05 02:01] Train Step 60850, Epoch 56.3, Batch Size = 256, Examples/Sec = 3862.76, Train LB = -384.328, Loss = 396.357
[2018-06-05 02:01] Train Step 60875, Epoch 56.4, Batch Size = 256, Examples/Sec = 3847.25, Train LB = -379.563, Loss = 395.294
[2018-06-05 02:01] Train Step 60900, Epoch 56.4, Batch Size = 256, Examples/Sec = 3810.88, Train LB = -379.490, Loss = 394.302
[2018-06-05 02:01] Train Step 60925, Epoch 56.4, Batch Size = 256, Examples/Sec = 3869.28, Train LB = -391.098, Loss = 393.622
[2018-06-05 02:01] Train Step 60950, Epoch 56.4, Batch Size = 256, Examples/Sec = 3844.71, Train LB = -390.173, Loss = 393.247
[2018-06-05 02:01] Train Step 60975, Epoch 56.5, Batch Size = 256, Examples/Sec = 3852.51, Train LB = -385.487, Loss = 394.324
[2018-06-05 02:01] Train Step 61000, Epoch 56.5, Batch Size = 256, Examples/Sec = 3870.16, Train LB = -424.218, Loss = 397.555
Performance on test set:
  Test Lower Bound = -446.094, Test Loss = 446.094
[2018-06-05 02:01] Train Step 61025, Epoch 56.5, Batch Size = 256, Examples/Sec = 3868.42, Train LB = -405.637, Loss = 396.855
[2018-06-05 02:01] Train Step 61050, Epoch 56.5, Batch Size = 256, Examples/Sec = 3887.03, Train LB = -380.066, Loss = 395.644
[2018-06-05 02:01] Train Step 61075, Epoch 56.6, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -379.914, Loss = 394.537
[2018-06-05 02:01] Train Step 61100, Epoch 56.6, Batch Size = 256, Examples/Sec = 3857.57, Train LB = -384.981, Loss = 393.948
[2018-06-05 02:01] Train Step 61125, Epoch 56.6, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -390.413, Loss = 393.284
[2018-06-05 02:01] Train Step 61150, Epoch 56.6, Batch Size = 256, Examples/Sec = 3854.03, Train LB = -391.185, Loss = 394.237
[2018-06-05 02:01] Train Step 61175, Epoch 56.6, Batch Size = 256, Examples/Sec = 3877.37, Train LB = -398.421, Loss = 395.564
[2018-06-05 02:01] Train Step 61200, Epoch 56.7, Batch Size = 256, Examples/Sec = 3843.37, Train LB = -424.631, Loss = 398.845
Performance on test set:
  Test Lower Bound = -446.238, Test Loss = 446.238
[2018-06-05 02:01] Train Step 61225, Epoch 56.7, Batch Size = 256, Examples/Sec = 3866.01, Train LB = -391.564, Loss = 398.145
[2018-06-05 02:01] Train Step 61250, Epoch 56.7, Batch Size = 256, Examples/Sec = 3872.03, Train LB = -382.008, Loss = 397.024
[2018-06-05 02:01] Train Step 61275, Epoch 56.7, Batch Size = 256, Examples/Sec = 3844.49, Train LB = -389.687, Loss = 395.745
[2018-06-05 02:01] Train Step 61300, Epoch 56.8, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -389.694, Loss = 394.791
[2018-06-05 02:01] Train Step 61325, Epoch 56.8, Batch Size = 256, Examples/Sec = 3855.49, Train LB = -400.307, Loss = 393.921
[2018-06-05 02:01] Train Step 61350, Epoch 56.8, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -377.301, Loss = 393.440
[2018-06-05 02:01] Train Step 61375, Epoch 56.8, Batch Size = 256, Examples/Sec = 3741.43, Train LB = -406.164, Loss = 394.976
[2018-06-05 02:01] Train Step 61400, Epoch 56.9, Batch Size = 256, Examples/Sec = 3872.23, Train LB = -414.984, Loss = 398.479
Performance on test set:
  Test Lower Bound = -447.698, Test Loss = 447.698
[2018-06-05 02:02] Train Step 61425, Epoch 56.9, Batch Size = 256, Examples/Sec = 3859.44, Train LB = -386.949, Loss = 397.502
[2018-06-05 02:02] Train Step 61450, Epoch 56.9, Batch Size = 256, Examples/Sec = 3837.00, Train LB = -390.552, Loss = 396.546
[2018-06-05 02:02] Train Step 61475, Epoch 56.9, Batch Size = 256, Examples/Sec = 3818.96, Train LB = -369.375, Loss = 395.044
[2018-06-05 02:02] Train Step 61500, Epoch 56.9, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -385.081, Loss = 393.778
[2018-06-05 02:02] Train Step 61525, Epoch 57.0, Batch Size = 256, Examples/Sec = 3871.81, Train LB = -393.049, Loss = 393.533
[2018-06-05 02:02] Train Step 61550, Epoch 57.0, Batch Size = 256, Examples/Sec = 3840.91, Train LB = -395.446, Loss = 393.966
[2018-06-05 02:02] Train Step 61575, Epoch 57.0, Batch Size = 256, Examples/Sec = 3878.09, Train LB = -395.377, Loss = 395.027
[2018-06-05 02:02] Train Step 61600, Epoch 57.0, Batch Size = 256, Examples/Sec = 3845.64, Train LB = -418.164, Loss = 397.431
Performance on test set:
  Test Lower Bound = -446.688, Test Loss = 446.688
[2018-06-05 02:02] Train Step 61625, Epoch 57.1, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -401.412, Loss = 396.592
[2018-06-05 02:02] Train Step 61650, Epoch 57.1, Batch Size = 256, Examples/Sec = 3866.01, Train LB = -393.562, Loss = 395.172
[2018-06-05 02:02] Train Step 61675, Epoch 57.1, Batch Size = 256, Examples/Sec = 3882.73, Train LB = -388.648, Loss = 395.239
[2018-06-05 02:02] Train Step 61700, Epoch 57.1, Batch Size = 256, Examples/Sec = 3809.19, Train LB = -404.854, Loss = 394.225
[2018-06-05 02:02] Train Step 61725, Epoch 57.2, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -389.049, Loss = 393.604
[2018-06-05 02:02] Train Step 61750, Epoch 57.2, Batch Size = 256, Examples/Sec = 3878.73, Train LB = -398.412, Loss = 393.770
[2018-06-05 02:02] Train Step 61775, Epoch 57.2, Batch Size = 256, Examples/Sec = 3808.45, Train LB = -404.294, Loss = 394.945
[2018-06-05 02:02] Train Step 61800, Epoch 57.2, Batch Size = 256, Examples/Sec = 3861.77, Train LB = -411.650, Loss = 397.462
Performance on test set:
  Test Lower Bound = -448.100, Test Loss = 448.100
[2018-06-05 02:02] Train Step 61825, Epoch 57.2, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -387.293, Loss = 397.106
[2018-06-05 02:02] Train Step 61850, Epoch 57.3, Batch Size = 256, Examples/Sec = 3875.74, Train LB = -397.527, Loss = 395.551
[2018-06-05 02:02] Train Step 61875, Epoch 57.3, Batch Size = 256, Examples/Sec = 3848.94, Train LB = -402.464, Loss = 395.047
[2018-06-05 02:02] Train Step 61900, Epoch 57.3, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -393.015, Loss = 393.794
[2018-06-05 02:02] Train Step 61925, Epoch 57.3, Batch Size = 256, Examples/Sec = 3797.32, Train LB = -390.719, Loss = 392.881
[2018-06-05 02:02] Train Step 61950, Epoch 57.4, Batch Size = 256, Examples/Sec = 3820.15, Train LB = -386.691, Loss = 393.384
[2018-06-05 02:02] Train Step 61975, Epoch 57.4, Batch Size = 256, Examples/Sec = 3851.93, Train LB = -399.001, Loss = 394.479
[2018-06-05 02:02] Train Step 62000, Epoch 57.4, Batch Size = 256, Examples/Sec = 3796.42, Train LB = -426.928, Loss = 397.554
Performance on test set:
  Test Lower Bound = -445.973, Test Loss = 445.973
[2018-06-05 02:02] Train Step 62025, Epoch 57.4, Batch Size = 256, Examples/Sec = 3875.67, Train LB = -387.318, Loss = 396.610
[2018-06-05 02:02] Train Step 62050, Epoch 57.5, Batch Size = 256, Examples/Sec = 3840.55, Train LB = -386.972, Loss = 396.062
[2018-06-05 02:02] Train Step 62075, Epoch 57.5, Batch Size = 256, Examples/Sec = 3877.14, Train LB = -388.405, Loss = 394.839
[2018-06-05 02:02] Train Step 62100, Epoch 57.5, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -397.361, Loss = 393.270
[2018-06-05 02:02] Train Step 62125, Epoch 57.5, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -396.220, Loss = 393.335
[2018-06-05 02:03] Train Step 62150, Epoch 57.5, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -413.147, Loss = 393.518
[2018-06-05 02:03] Train Step 62175, Epoch 57.6, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -407.752, Loss = 395.008
[2018-06-05 02:03] Train Step 62200, Epoch 57.6, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -416.192, Loss = 397.774
Performance on test set:
  Test Lower Bound = -447.054, Test Loss = 447.054
[2018-06-05 02:03] Train Step 62225, Epoch 57.6, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -403.912, Loss = 396.991
[2018-06-05 02:03] Train Step 62250, Epoch 57.6, Batch Size = 256, Examples/Sec = 3875.44, Train LB = -393.101, Loss = 395.871
[2018-06-05 02:03] Train Step 62275, Epoch 57.7, Batch Size = 256, Examples/Sec = 3853.44, Train LB = -397.419, Loss = 394.503
[2018-06-05 02:03] Train Step 62300, Epoch 57.7, Batch Size = 256, Examples/Sec = 3875.74, Train LB = -397.376, Loss = 393.764
[2018-06-05 02:03] Train Step 62325, Epoch 57.7, Batch Size = 256, Examples/Sec = 3889.99, Train LB = -396.856, Loss = 392.664
[2018-06-05 02:03] Train Step 62350, Epoch 57.7, Batch Size = 256, Examples/Sec = 3844.07, Train LB = -392.213, Loss = 393.509
[2018-06-05 02:03] Train Step 62375, Epoch 57.8, Batch Size = 256, Examples/Sec = 3841.65, Train LB = -410.296, Loss = 395.716
[2018-06-05 02:03] Train Step 62400, Epoch 57.8, Batch Size = 256, Examples/Sec = 3872.40, Train LB = -405.812, Loss = 398.442
Performance on test set:
  Test Lower Bound = -446.472, Test Loss = 446.472
[2018-06-05 02:03] Train Step 62425, Epoch 57.8, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -382.707, Loss = 397.025
[2018-06-05 02:03] Train Step 62450, Epoch 57.8, Batch Size = 256, Examples/Sec = 3878.26, Train LB = -400.926, Loss = 395.520
[2018-06-05 02:03] Train Step 62475, Epoch 57.8, Batch Size = 256, Examples/Sec = 3864.98, Train LB = -392.397, Loss = 394.176
[2018-06-05 02:03] Train Step 62500, Epoch 57.9, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -384.470, Loss = 393.583
[2018-06-05 02:03] Train Step 62525, Epoch 57.9, Batch Size = 256, Examples/Sec = 3777.36, Train LB = -380.399, Loss = 393.213
[2018-06-05 02:03] Train Step 62550, Epoch 57.9, Batch Size = 256, Examples/Sec = 3797.27, Train LB = -408.462, Loss = 393.778
[2018-06-05 02:03] Train Step 62575, Epoch 57.9, Batch Size = 256, Examples/Sec = 3847.02, Train LB = -394.391, Loss = 395.250
[2018-06-05 02:03] Train Step 62600, Epoch 58.0, Batch Size = 256, Examples/Sec = 3846.79, Train LB = -424.652, Loss = 397.935
Performance on test set:
  Test Lower Bound = -446.782, Test Loss = 446.782
[2018-06-05 02:03] Train Step 62625, Epoch 58.0, Batch Size = 256, Examples/Sec = 3809.64, Train LB = -384.368, Loss = 397.667
[2018-06-05 02:03] Train Step 62650, Epoch 58.0, Batch Size = 256, Examples/Sec = 3851.37, Train LB = -397.522, Loss = 395.756
[2018-06-05 02:03] Train Step 62675, Epoch 58.0, Batch Size = 256, Examples/Sec = 3874.56, Train LB = -389.095, Loss = 394.615
[2018-06-05 02:03] Train Step 62700, Epoch 58.1, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -390.419, Loss = 393.670
[2018-06-05 02:03] Train Step 62725, Epoch 58.1, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -392.062, Loss = 393.562
[2018-06-05 02:03] Train Step 62750, Epoch 58.1, Batch Size = 256, Examples/Sec = 3859.73, Train LB = -398.813, Loss = 393.124
[2018-06-05 02:03] Train Step 62775, Epoch 58.1, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -396.896, Loss = 394.180
[2018-06-05 02:03] Train Step 62800, Epoch 58.1, Batch Size = 256, Examples/Sec = 3873.68, Train LB = -407.962, Loss = 397.455
Performance on test set:
  Test Lower Bound = -448.467, Test Loss = 448.467
[2018-06-05 02:03] Train Step 62825, Epoch 58.2, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -382.703, Loss = 396.345
[2018-06-05 02:04] Train Step 62850, Epoch 58.2, Batch Size = 256, Examples/Sec = 3873.57, Train LB = -387.463, Loss = 394.865
[2018-06-05 02:04] Train Step 62875, Epoch 58.2, Batch Size = 256, Examples/Sec = 3815.25, Train LB = -390.657, Loss = 393.851
[2018-06-05 02:04] Train Step 62900, Epoch 58.2, Batch Size = 256, Examples/Sec = 3880.56, Train LB = -394.489, Loss = 393.026
[2018-06-05 02:04] Train Step 62925, Epoch 58.3, Batch Size = 256, Examples/Sec = 3876.32, Train LB = -404.121, Loss = 392.730
[2018-06-05 02:04] Train Step 62950, Epoch 58.3, Batch Size = 256, Examples/Sec = 3854.91, Train LB = -391.317, Loss = 393.656
[2018-06-05 02:04] Train Step 62975, Epoch 58.3, Batch Size = 256, Examples/Sec = 3855.14, Train LB = -412.930, Loss = 395.111
[2018-06-05 02:04] Train Step 63000, Epoch 58.3, Batch Size = 256, Examples/Sec = 3883.50, Train LB = -431.657, Loss = 397.735
Performance on test set:
  Test Lower Bound = -446.345, Test Loss = 446.345
[2018-06-05 02:04] Train Step 63025, Epoch 58.4, Batch Size = 256, Examples/Sec = 3849.74, Train LB = -381.020, Loss = 396.910
[2018-06-05 02:04] Train Step 63050, Epoch 58.4, Batch Size = 256, Examples/Sec = 3854.03, Train LB = -385.079, Loss = 395.353
[2018-06-05 02:04] Train Step 63075, Epoch 58.4, Batch Size = 256, Examples/Sec = 3868.89, Train LB = -388.318, Loss = 394.350
[2018-06-05 02:04] Train Step 63100, Epoch 58.4, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -386.676, Loss = 393.731
[2018-06-05 02:04] Train Step 63125, Epoch 58.4, Batch Size = 256, Examples/Sec = 3813.15, Train LB = -409.069, Loss = 393.489
[2018-06-05 02:04] Train Step 63150, Epoch 58.5, Batch Size = 256, Examples/Sec = 3875.44, Train LB = -393.273, Loss = 394.326
[2018-06-05 02:04] Train Step 63175, Epoch 58.5, Batch Size = 256, Examples/Sec = 3832.97, Train LB = -393.377, Loss = 394.928
[2018-06-05 02:04] Train Step 63200, Epoch 58.5, Batch Size = 256, Examples/Sec = 3849.28, Train LB = -424.261, Loss = 397.721
Performance on test set:
  Test Lower Bound = -447.151, Test Loss = 447.151
[2018-06-05 02:04] Train Step 63225, Epoch 58.5, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -386.180, Loss = 397.045
[2018-06-05 02:04] Train Step 63250, Epoch 58.6, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -393.325, Loss = 395.964
[2018-06-05 02:04] Train Step 63275, Epoch 58.6, Batch Size = 256, Examples/Sec = 3853.79, Train LB = -398.032, Loss = 394.684
[2018-06-05 02:04] Train Step 63300, Epoch 58.6, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -398.047, Loss = 393.844
[2018-06-05 02:04] Train Step 63325, Epoch 58.6, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -404.768, Loss = 393.295
[2018-06-05 02:04] Train Step 63350, Epoch 58.7, Batch Size = 256, Examples/Sec = 3846.50, Train LB = -380.949, Loss = 393.278
[2018-06-05 02:04] Train Step 63375, Epoch 58.7, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -395.876, Loss = 394.067
[2018-06-05 02:04] Train Step 63400, Epoch 58.7, Batch Size = 256, Examples/Sec = 3872.27, Train LB = -425.872, Loss = 397.206
Performance on test set:
  Test Lower Bound = -447.320, Test Loss = 447.319
[2018-06-05 02:04] Train Step 63425, Epoch 58.7, Batch Size = 256, Examples/Sec = 3841.89, Train LB = -391.014, Loss = 396.252
[2018-06-05 02:04] Train Step 63450, Epoch 58.8, Batch Size = 256, Examples/Sec = 3884.91, Train LB = -393.039, Loss = 395.050
[2018-06-05 02:04] Train Step 63475, Epoch 58.8, Batch Size = 256, Examples/Sec = 3873.39, Train LB = -397.737, Loss = 394.764
[2018-06-05 02:04] Train Step 63500, Epoch 58.8, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -381.285, Loss = 393.037
[2018-06-05 02:04] Train Step 63525, Epoch 58.8, Batch Size = 256, Examples/Sec = 3788.60, Train LB = -376.452, Loss = 393.056
[2018-06-05 02:04] Train Step 63550, Epoch 58.8, Batch Size = 256, Examples/Sec = 3847.72, Train LB = -404.991, Loss = 393.810
[2018-06-05 02:04] Train Step 63575, Epoch 58.9, Batch Size = 256, Examples/Sec = 3862.98, Train LB = -408.788, Loss = 394.643
[2018-06-05 02:05] Train Step 63600, Epoch 58.9, Batch Size = 256, Examples/Sec = 3850.44, Train LB = -427.386, Loss = 397.384
Performance on test set:
  Test Lower Bound = -446.820, Test Loss = 446.820
[2018-06-05 02:05] Train Step 63625, Epoch 58.9, Batch Size = 256, Examples/Sec = 3806.64, Train LB = -385.775, Loss = 396.598
[2018-06-05 02:05] Train Step 63650, Epoch 58.9, Batch Size = 256, Examples/Sec = 3849.79, Train LB = -387.943, Loss = 394.928
[2018-06-05 02:05] Train Step 63675, Epoch 59.0, Batch Size = 256, Examples/Sec = 3865.91, Train LB = -373.112, Loss = 394.207
[2018-06-05 02:05] Train Step 63700, Epoch 59.0, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -392.043, Loss = 393.012
[2018-06-05 02:05] Train Step 63725, Epoch 59.0, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -394.403, Loss = 392.586
[2018-06-05 02:05] Train Step 63750, Epoch 59.0, Batch Size = 256, Examples/Sec = 3862.98, Train LB = -390.243, Loss = 391.921
[2018-06-05 02:05] Train Step 63775, Epoch 59.1, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -408.476, Loss = 393.116
[2018-06-05 02:05] Train Step 63800, Epoch 59.1, Batch Size = 256, Examples/Sec = 3797.20, Train LB = -407.197, Loss = 396.164
Performance on test set:
  Test Lower Bound = -448.817, Test Loss = 448.817
[2018-06-05 02:05] Train Step 63825, Epoch 59.1, Batch Size = 256, Examples/Sec = 3848.40, Train LB = -387.340, Loss = 395.761
[2018-06-05 02:05] Train Step 63850, Epoch 59.1, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -385.712, Loss = 393.939
[2018-06-05 02:05] Train Step 63875, Epoch 59.1, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -387.621, Loss = 393.167
[2018-06-05 02:05] Train Step 63900, Epoch 59.2, Batch Size = 256, Examples/Sec = 3851.37, Train LB = -379.827, Loss = 392.837
[2018-06-05 02:05] Train Step 63925, Epoch 59.2, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -388.986, Loss = 392.740
[2018-06-05 02:05] Train Step 63950, Epoch 59.2, Batch Size = 256, Examples/Sec = 3871.70, Train LB = -393.987, Loss = 392.684
[2018-06-05 02:05] Train Step 63975, Epoch 59.2, Batch Size = 256, Examples/Sec = 3876.09, Train LB = -404.102, Loss = 393.974
[2018-06-05 02:05] Train Step 64000, Epoch 59.3, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -419.627, Loss = 397.118
Performance on test set:
  Test Lower Bound = -449.001, Test Loss = 449.001
[2018-06-05 02:05] Train Step 64025, Epoch 59.3, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -392.981, Loss = 396.787
[2018-06-05 02:05] Train Step 64050, Epoch 59.3, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -393.830, Loss = 395.463
[2018-06-05 02:05] Train Step 64075, Epoch 59.3, Batch Size = 256, Examples/Sec = 3843.27, Train LB = -385.534, Loss = 394.133
[2018-06-05 02:05] Train Step 64100, Epoch 59.4, Batch Size = 256, Examples/Sec = 3810.32, Train LB = -391.247, Loss = 393.411
[2018-06-05 02:05] Train Step 64125, Epoch 59.4, Batch Size = 256, Examples/Sec = 3876.21, Train LB = -387.576, Loss = 392.087
[2018-06-05 02:05] Train Step 64150, Epoch 59.4, Batch Size = 256, Examples/Sec = 3848.58, Train LB = -395.042, Loss = 392.425
[2018-06-05 02:05] Train Step 64175, Epoch 59.4, Batch Size = 256, Examples/Sec = 3868.13, Train LB = -398.603, Loss = 393.638
[2018-06-05 02:05] Train Step 64200, Epoch 59.4, Batch Size = 256, Examples/Sec = 3862.80, Train LB = -429.852, Loss = 396.844
Performance on test set:
  Test Lower Bound = -446.236, Test Loss = 446.236
[2018-06-05 02:05] Train Step 64225, Epoch 59.5, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -381.146, Loss = 396.075
[2018-06-05 02:05] Train Step 64250, Epoch 59.5, Batch Size = 256, Examples/Sec = 3849.27, Train LB = -402.368, Loss = 395.154
[2018-06-05 02:06] Train Step 64275, Epoch 59.5, Batch Size = 256, Examples/Sec = 3841.36, Train LB = -395.311, Loss = 394.048
[2018-06-05 02:06] Train Step 64300, Epoch 59.5, Batch Size = 256, Examples/Sec = 3848.34, Train LB = -393.265, Loss = 393.968
[2018-06-05 02:06] Train Step 64325, Epoch 59.6, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -388.268, Loss = 393.285
[2018-06-05 02:06] Train Step 64350, Epoch 59.6, Batch Size = 256, Examples/Sec = 3814.34, Train LB = -409.605, Loss = 393.614
[2018-06-05 02:06] Train Step 64375, Epoch 59.6, Batch Size = 256, Examples/Sec = 3873.16, Train LB = -390.895, Loss = 394.487
[2018-06-05 02:06] Train Step 64400, Epoch 59.6, Batch Size = 256, Examples/Sec = 3879.85, Train LB = -411.656, Loss = 396.656
Performance on test set:
  Test Lower Bound = -447.578, Test Loss = 447.578
[2018-06-05 02:06] Train Step 64425, Epoch 59.7, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -388.418, Loss = 395.624
[2018-06-05 02:06] Train Step 64450, Epoch 59.7, Batch Size = 256, Examples/Sec = 3813.50, Train LB = -380.676, Loss = 394.803
[2018-06-05 02:06] Train Step 64475, Epoch 59.7, Batch Size = 256, Examples/Sec = 3857.86, Train LB = -390.770, Loss = 393.870
[2018-06-05 02:06] Train Step 64500, Epoch 59.7, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -397.069, Loss = 393.123
[2018-06-05 02:06] Train Step 64525, Epoch 59.7, Batch Size = 256, Examples/Sec = 3797.48, Train LB = -398.936, Loss = 391.954
[2018-06-05 02:06] Train Step 64550, Epoch 59.8, Batch Size = 256, Examples/Sec = 3829.69, Train LB = -399.662, Loss = 392.101
[2018-06-05 02:06] Train Step 64575, Epoch 59.8, Batch Size = 256, Examples/Sec = 3820.51, Train LB = -394.886, Loss = 393.521
[2018-06-05 02:06] Train Step 64600, Epoch 59.8, Batch Size = 256, Examples/Sec = 3874.38, Train LB = -429.209, Loss = 396.826
Performance on test set:
  Test Lower Bound = -447.676, Test Loss = 447.676
[2018-06-05 02:06] Train Step 64625, Epoch 59.8, Batch Size = 256, Examples/Sec = 3853.38, Train LB = -387.297, Loss = 395.562
[2018-06-05 02:06] Train Step 64650, Epoch 59.9, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -394.945, Loss = 394.956
[2018-06-05 02:06] Train Step 64675, Epoch 59.9, Batch Size = 256, Examples/Sec = 3799.35, Train LB = -388.621, Loss = 393.926
[2018-06-05 02:06] Train Step 64700, Epoch 59.9, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -398.686, Loss = 392.765
[2018-06-05 02:06] Train Step 64725, Epoch 59.9, Batch Size = 256, Examples/Sec = 3886.33, Train LB = -390.225, Loss = 392.566
[2018-06-05 02:06] Train Step 64750, Epoch 60.0, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -395.535, Loss = 392.107
[2018-06-05 02:06] Train Step 64775, Epoch 60.0, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -400.505, Loss = 393.781
[2018-06-05 02:06] Train Step 64800, Epoch 60.0, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -416.530, Loss = 396.273
Performance on test set:
  Test Lower Bound = -447.621, Test Loss = 447.621
[2018-06-05 02:06] Train Step 64825, Epoch 60.0, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -381.378, Loss = 395.077
[2018-06-05 02:06] Train Step 64850, Epoch 60.0, Batch Size = 256, Examples/Sec = 3801.43, Train LB = -396.534, Loss = 394.107
[2018-06-05 02:06] Train Step 64875, Epoch 60.1, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -408.908, Loss = 393.379
[2018-06-05 02:06] Train Step 64900, Epoch 60.1, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -390.944, Loss = 392.515
[2018-06-05 02:06] Train Step 64925, Epoch 60.1, Batch Size = 256, Examples/Sec = 3842.35, Train LB = -392.478, Loss = 392.026
[2018-06-05 02:06] Train Step 64950, Epoch 60.1, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -401.373, Loss = 392.303
[2018-06-05 02:06] Train Step 64975, Epoch 60.2, Batch Size = 256, Examples/Sec = 3870.58, Train LB = -387.840, Loss = 393.885
[2018-06-05 02:06] Train Step 65000, Epoch 60.2, Batch Size = 256, Examples/Sec = 3851.31, Train LB = -428.039, Loss = 396.868
Performance on test set:
  Test Lower Bound = -448.792, Test Loss = 448.792
[2018-06-05 02:07] Train Step 65025, Epoch 60.2, Batch Size = 256, Examples/Sec = 3866.50, Train LB = -383.162, Loss = 396.086
[2018-06-05 02:07] Train Step 65050, Epoch 60.2, Batch Size = 256, Examples/Sec = 3872.27, Train LB = -378.609, Loss = 394.908
[2018-06-05 02:07] Train Step 65075, Epoch 60.3, Batch Size = 256, Examples/Sec = 3872.34, Train LB = -390.419, Loss = 394.271
[2018-06-05 02:07] Train Step 65100, Epoch 60.3, Batch Size = 256, Examples/Sec = 3836.59, Train LB = -385.113, Loss = 393.240
[2018-06-05 02:07] Train Step 65125, Epoch 60.3, Batch Size = 256, Examples/Sec = 3876.49, Train LB = -390.071, Loss = 392.420
[2018-06-05 02:07] Train Step 65150, Epoch 60.3, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -396.925, Loss = 392.158
[2018-06-05 02:07] Train Step 65175, Epoch 60.3, Batch Size = 256, Examples/Sec = 3867.89, Train LB = -399.419, Loss = 393.830
[2018-06-05 02:07] Train Step 65200, Epoch 60.4, Batch Size = 256, Examples/Sec = 3865.26, Train LB = -412.964, Loss = 396.734
Performance on test set:
  Test Lower Bound = -448.501, Test Loss = 448.501
[2018-06-05 02:07] Train Step 65225, Epoch 60.4, Batch Size = 256, Examples/Sec = 3884.68, Train LB = -398.460, Loss = 395.826
[2018-06-05 02:07] Train Step 65250, Epoch 60.4, Batch Size = 256, Examples/Sec = 3843.55, Train LB = -390.897, Loss = 394.536
[2018-06-05 02:07] Train Step 65275, Epoch 60.4, Batch Size = 256, Examples/Sec = 3845.63, Train LB = -403.151, Loss = 393.749
[2018-06-05 02:07] Train Step 65300, Epoch 60.5, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -370.513, Loss = 392.395
[2018-06-05 02:07] Train Step 65325, Epoch 60.5, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -390.304, Loss = 391.966
[2018-06-05 02:07] Train Step 65350, Epoch 60.5, Batch Size = 256, Examples/Sec = 3866.66, Train LB = -392.223, Loss = 392.257
[2018-06-05 02:07] Train Step 65375, Epoch 60.5, Batch Size = 256, Examples/Sec = 3863.23, Train LB = -413.636, Loss = 393.729
[2018-06-05 02:07] Train Step 65400, Epoch 60.6, Batch Size = 256, Examples/Sec = 3861.52, Train LB = -429.151, Loss = 396.545
Performance on test set:
  Test Lower Bound = -447.944, Test Loss = 447.944
[2018-06-05 02:07] Train Step 65425, Epoch 60.6, Batch Size = 256, Examples/Sec = 3878.26, Train LB = -406.301, Loss = 395.980
[2018-06-05 02:07] Train Step 65450, Epoch 60.6, Batch Size = 256, Examples/Sec = 3882.27, Train LB = -376.023, Loss = 394.539
[2018-06-05 02:07] Train Step 65475, Epoch 60.6, Batch Size = 256, Examples/Sec = 3848.29, Train LB = -386.052, Loss = 393.420
[2018-06-05 02:07] Train Step 65500, Epoch 60.6, Batch Size = 256, Examples/Sec = 3836.59, Train LB = -389.638, Loss = 392.377
[2018-06-05 02:07] Train Step 65525, Epoch 60.7, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -406.668, Loss = 391.793
[2018-06-05 02:07] Train Step 65550, Epoch 60.7, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -406.294, Loss = 392.192
[2018-06-05 02:07] Train Step 65575, Epoch 60.7, Batch Size = 256, Examples/Sec = 3865.68, Train LB = -421.068, Loss = 393.232
[2018-06-05 02:07] Train Step 65600, Epoch 60.7, Batch Size = 256, Examples/Sec = 3808.04, Train LB = -398.497, Loss = 396.453
Performance on test set:
  Test Lower Bound = -448.978, Test Loss = 448.978
[2018-06-05 02:07] Train Step 65625, Epoch 60.8, Batch Size = 256, Examples/Sec = 3841.02, Train LB = -388.442, Loss = 395.673
[2018-06-05 02:07] Train Step 65650, Epoch 60.8, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -381.003, Loss = 394.013
[2018-06-05 02:07] Train Step 65675, Epoch 60.8, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -388.897, Loss = 393.406
[2018-06-05 02:07] Train Step 65700, Epoch 60.8, Batch Size = 256, Examples/Sec = 3853.79, Train LB = -401.799, Loss = 392.324
[2018-06-05 02:08] Train Step 65725, Epoch 60.9, Batch Size = 256, Examples/Sec = 3857.23, Train LB = -397.413, Loss = 391.988
[2018-06-05 02:08] Train Step 65750, Epoch 60.9, Batch Size = 256, Examples/Sec = 3845.81, Train LB = -400.908, Loss = 392.371
[2018-06-05 02:08] Train Step 65775, Epoch 60.9, Batch Size = 256, Examples/Sec = 3869.87, Train LB = -403.594, Loss = 393.582
[2018-06-05 02:08] Train Step 65800, Epoch 60.9, Batch Size = 256, Examples/Sec = 3806.30, Train LB = -423.052, Loss = 396.945
Performance on test set:
  Test Lower Bound = -447.901, Test Loss = 447.901
[2018-06-05 02:08] Train Step 65825, Epoch 60.9, Batch Size = 256, Examples/Sec = 3808.66, Train LB = -386.812, Loss = 395.629
[2018-06-05 02:08] Train Step 65850, Epoch 61.0, Batch Size = 256, Examples/Sec = 3870.75, Train LB = -383.910, Loss = 394.306
[2018-06-05 02:08] Train Step 65875, Epoch 61.0, Batch Size = 256, Examples/Sec = 3850.48, Train LB = -390.955, Loss = 394.080
[2018-06-05 02:08] Train Step 65900, Epoch 61.0, Batch Size = 256, Examples/Sec = 3870.57, Train LB = -402.519, Loss = 392.533
[2018-06-05 02:08] Train Step 65925, Epoch 61.0, Batch Size = 256, Examples/Sec = 3859.15, Train LB = -392.943, Loss = 392.289
[2018-06-05 02:08] Train Step 65950, Epoch 61.1, Batch Size = 256, Examples/Sec = 3857.69, Train LB = -394.804, Loss = 392.332
[2018-06-05 02:08] Train Step 65975, Epoch 61.1, Batch Size = 256, Examples/Sec = 3871.63, Train LB = -396.279, Loss = 392.690
[2018-06-05 02:08] Train Step 66000, Epoch 61.1, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -408.528, Loss = 395.862
Performance on test set:
  Test Lower Bound = -449.392, Test Loss = 449.392
[2018-06-05 02:08] Train Step 66025, Epoch 61.1, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -387.847, Loss = 394.732
[2018-06-05 02:08] Train Step 66050, Epoch 61.2, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -378.925, Loss = 393.556
[2018-06-05 02:08] Train Step 66075, Epoch 61.2, Batch Size = 256, Examples/Sec = 3844.60, Train LB = -390.317, Loss = 393.225
[2018-06-05 02:08] Train Step 66100, Epoch 61.2, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -392.579, Loss = 392.600
[2018-06-05 02:08] Train Step 66125, Epoch 61.2, Batch Size = 256, Examples/Sec = 3778.53, Train LB = -385.238, Loss = 391.939
[2018-06-05 02:08] Train Step 66150, Epoch 61.2, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -389.062, Loss = 391.704
[2018-06-05 02:08] Train Step 66175, Epoch 61.3, Batch Size = 256, Examples/Sec = 3804.44, Train LB = -400.820, Loss = 393.337
[2018-06-05 02:08] Train Step 66200, Epoch 61.3, Batch Size = 256, Examples/Sec = 3845.57, Train LB = -422.215, Loss = 396.062
Performance on test set:
  Test Lower Bound = -448.885, Test Loss = 448.885
[2018-06-05 02:08] Train Step 66225, Epoch 61.3, Batch Size = 256, Examples/Sec = 3805.50, Train LB = -395.348, Loss = 395.579
[2018-06-05 02:08] Train Step 66250, Epoch 61.3, Batch Size = 256, Examples/Sec = 3856.11, Train LB = -398.126, Loss = 393.797
[2018-06-05 02:08] Train Step 66275, Epoch 61.4, Batch Size = 256, Examples/Sec = 3795.63, Train LB = -404.821, Loss = 392.972
[2018-06-05 02:08] Train Step 66300, Epoch 61.4, Batch Size = 256, Examples/Sec = 3854.95, Train LB = -402.557, Loss = 392.130
[2018-06-05 02:08] Train Step 66325, Epoch 61.4, Batch Size = 256, Examples/Sec = 3847.02, Train LB = -392.385, Loss = 391.788
[2018-06-05 02:08] Train Step 66350, Epoch 61.4, Batch Size = 256, Examples/Sec = 3879.91, Train LB = -402.866, Loss = 392.116
[2018-06-05 02:08] Train Step 66375, Epoch 61.5, Batch Size = 256, Examples/Sec = 3872.28, Train LB = -402.932, Loss = 392.891
[2018-06-05 02:08] Train Step 66400, Epoch 61.5, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -401.260, Loss = 395.956
Performance on test set:
  Test Lower Bound = -449.873, Test Loss = 449.873
[2018-06-05 02:09] Train Step 66425, Epoch 61.5, Batch Size = 256, Examples/Sec = 3865.09, Train LB = -419.818, Loss = 395.039
[2018-06-05 02:09] Train Step 66450, Epoch 61.5, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -395.746, Loss = 394.014
[2018-06-05 02:09] Train Step 66475, Epoch 61.6, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -391.767, Loss = 392.778
[2018-06-05 02:09] Train Step 66500, Epoch 61.6, Batch Size = 256, Examples/Sec = 3874.21, Train LB = -381.250, Loss = 392.522
[2018-06-05 02:09] Train Step 66525, Epoch 61.6, Batch Size = 256, Examples/Sec = 3847.43, Train LB = -392.930, Loss = 391.779
[2018-06-05 02:09] Train Step 66550, Epoch 61.6, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -402.999, Loss = 391.870
[2018-06-05 02:09] Train Step 66575, Epoch 61.6, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -389.860, Loss = 393.191
[2018-06-05 02:09] Train Step 66600, Epoch 61.7, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -416.593, Loss = 396.224
Performance on test set:
  Test Lower Bound = -449.425, Test Loss = 449.425
[2018-06-05 02:09] Train Step 66625, Epoch 61.7, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -407.731, Loss = 395.312
[2018-06-05 02:09] Train Step 66650, Epoch 61.7, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -385.144, Loss = 393.881
[2018-06-05 02:09] Train Step 66675, Epoch 61.7, Batch Size = 256, Examples/Sec = 3838.84, Train LB = -385.418, Loss = 393.180
[2018-06-05 02:09] Train Step 66700, Epoch 61.8, Batch Size = 256, Examples/Sec = 3857.34, Train LB = -395.687, Loss = 392.631
[2018-06-05 02:09] Train Step 66725, Epoch 61.8, Batch Size = 256, Examples/Sec = 3874.97, Train LB = -379.557, Loss = 391.361
[2018-06-05 02:09] Train Step 66750, Epoch 61.8, Batch Size = 256, Examples/Sec = 3785.91, Train LB = -397.571, Loss = 390.759
[2018-06-05 02:09] Train Step 66775, Epoch 61.8, Batch Size = 256, Examples/Sec = 3861.13, Train LB = -401.443, Loss = 392.046
[2018-06-05 02:09] Train Step 66800, Epoch 61.9, Batch Size = 256, Examples/Sec = 3847.08, Train LB = -411.838, Loss = 395.653
Performance on test set:
  Test Lower Bound = -450.286, Test Loss = 450.285
[2018-06-05 02:09] Train Step 66825, Epoch 61.9, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -396.096, Loss = 394.797
[2018-06-05 02:09] Train Step 66850, Epoch 61.9, Batch Size = 256, Examples/Sec = 3815.61, Train LB = -396.351, Loss = 393.544
[2018-06-05 02:09] Train Step 66875, Epoch 61.9, Batch Size = 256, Examples/Sec = 3874.27, Train LB = -396.725, Loss = 392.514
[2018-06-05 02:09] Train Step 66900, Epoch 61.9, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -384.793, Loss = 391.963
[2018-06-05 02:09] Train Step 66925, Epoch 62.0, Batch Size = 256, Examples/Sec = 3887.03, Train LB = -391.750, Loss = 392.721
[2018-06-05 02:09] Train Step 66950, Epoch 62.0, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -364.815, Loss = 392.639
[2018-06-05 02:09] Train Step 66975, Epoch 62.0, Batch Size = 256, Examples/Sec = 3838.19, Train LB = -401.283, Loss = 393.075
[2018-06-05 02:09] Train Step 67000, Epoch 62.0, Batch Size = 256, Examples/Sec = 3843.56, Train LB = -420.692, Loss = 395.882
Performance on test set:
  Test Lower Bound = -447.854, Test Loss = 447.854
[2018-06-05 02:09] Train Step 67025, Epoch 62.1, Batch Size = 256, Examples/Sec = 3864.16, Train LB = -382.066, Loss = 395.298
[2018-06-05 02:09] Train Step 67050, Epoch 62.1, Batch Size = 256, Examples/Sec = 3860.01, Train LB = -398.097, Loss = 393.437
[2018-06-05 02:09] Train Step 67075, Epoch 62.1, Batch Size = 256, Examples/Sec = 3847.76, Train LB = -366.462, Loss = 392.109
[2018-06-05 02:09] Train Step 67100, Epoch 62.1, Batch Size = 256, Examples/Sec = 3866.01, Train LB = -386.782, Loss = 391.157
[2018-06-05 02:09] Train Step 67125, Epoch 62.2, Batch Size = 256, Examples/Sec = 3855.36, Train LB = -402.400, Loss = 390.321
[2018-06-05 02:10] Train Step 67150, Epoch 62.2, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -394.696, Loss = 391.075
[2018-06-05 02:10] Train Step 67175, Epoch 62.2, Batch Size = 256, Examples/Sec = 3847.19, Train LB = -396.089, Loss = 392.171
[2018-06-05 02:10] Train Step 67200, Epoch 62.2, Batch Size = 256, Examples/Sec = 3810.72, Train LB = -413.107, Loss = 395.539
Performance on test set:
  Test Lower Bound = -451.101, Test Loss = 451.101
[2018-06-05 02:10] Train Step 67225, Epoch 62.2, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -384.189, Loss = 394.720
[2018-06-05 02:10] Train Step 67250, Epoch 62.3, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -388.901, Loss = 393.348
[2018-06-05 02:10] Train Step 67275, Epoch 62.3, Batch Size = 256, Examples/Sec = 3878.14, Train LB = -374.587, Loss = 392.204
[2018-06-05 02:10] Train Step 67300, Epoch 62.3, Batch Size = 256, Examples/Sec = 3828.26, Train LB = -399.533, Loss = 391.232
[2018-06-05 02:10] Train Step 67325, Epoch 62.3, Batch Size = 256, Examples/Sec = 3818.44, Train LB = -383.331, Loss = 390.821
[2018-06-05 02:10] Train Step 67350, Epoch 62.4, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -398.987, Loss = 391.314
[2018-06-05 02:10] Train Step 67375, Epoch 62.4, Batch Size = 256, Examples/Sec = 3871.04, Train LB = -390.794, Loss = 393.025
[2018-06-05 02:10] Train Step 67400, Epoch 62.4, Batch Size = 256, Examples/Sec = 3862.35, Train LB = -413.017, Loss = 396.083
Performance on test set:
  Test Lower Bound = -449.956, Test Loss = 449.956
[2018-06-05 02:10] Train Step 67425, Epoch 62.4, Batch Size = 256, Examples/Sec = 3812.35, Train LB = -389.141, Loss = 395.301
[2018-06-05 02:10] Train Step 67450, Epoch 62.5, Batch Size = 256, Examples/Sec = 3844.71, Train LB = -400.531, Loss = 393.865
[2018-06-05 02:10] Train Step 67475, Epoch 62.5, Batch Size = 256, Examples/Sec = 3834.57, Train LB = -392.822, Loss = 392.407
[2018-06-05 02:10] Train Step 67500, Epoch 62.5, Batch Size = 256, Examples/Sec = 3843.38, Train LB = -382.024, Loss = 391.316
[2018-06-05 02:10] Train Step 67525, Epoch 62.5, Batch Size = 256, Examples/Sec = 3872.27, Train LB = -392.858, Loss = 390.650
[2018-06-05 02:10] Train Step 67550, Epoch 62.5, Batch Size = 256, Examples/Sec = 3872.03, Train LB = -383.319, Loss = 391.661
[2018-06-05 02:10] Train Step 67575, Epoch 62.6, Batch Size = 256, Examples/Sec = 3807.49, Train LB = -405.647, Loss = 392.674
[2018-06-05 02:10] Train Step 67600, Epoch 62.6, Batch Size = 256, Examples/Sec = 3860.31, Train LB = -412.668, Loss = 396.140
Performance on test set:
  Test Lower Bound = -450.059, Test Loss = 450.059
[2018-06-05 02:10] Train Step 67625, Epoch 62.6, Batch Size = 256, Examples/Sec = 3878.13, Train LB = -379.605, Loss = 395.194
[2018-06-05 02:10] Train Step 67650, Epoch 62.6, Batch Size = 256, Examples/Sec = 3863.98, Train LB = -398.054, Loss = 393.416
[2018-06-05 02:10] Train Step 67675, Epoch 62.7, Batch Size = 256, Examples/Sec = 3782.62, Train LB = -381.446, Loss = 393.126
[2018-06-05 02:10] Train Step 67700, Epoch 62.7, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -381.711, Loss = 391.841
[2018-06-05 02:10] Train Step 67725, Epoch 62.7, Batch Size = 256, Examples/Sec = 3865.73, Train LB = -394.152, Loss = 391.015
[2018-06-05 02:10] Train Step 67750, Epoch 62.7, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -390.630, Loss = 391.226
[2018-06-05 02:10] Train Step 67775, Epoch 62.8, Batch Size = 256, Examples/Sec = 3806.46, Train LB = -403.182, Loss = 392.955
[2018-06-05 02:10] Train Step 67800, Epoch 62.8, Batch Size = 256, Examples/Sec = 3876.38, Train LB = -409.732, Loss = 396.561
Performance on test set:
  Test Lower Bound = -447.900, Test Loss = 447.900
[2018-06-05 02:10] Train Step 67825, Epoch 62.8, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -388.950, Loss = 395.302
[2018-06-05 02:11] Train Step 67850, Epoch 62.8, Batch Size = 256, Examples/Sec = 3866.02, Train LB = -394.941, Loss = 393.357
[2018-06-05 02:11] Train Step 67875, Epoch 62.8, Batch Size = 256, Examples/Sec = 3856.60, Train LB = -395.155, Loss = 392.162
[2018-06-05 02:11] Train Step 67900, Epoch 62.9, Batch Size = 256, Examples/Sec = 3842.86, Train LB = -381.233, Loss = 391.857
[2018-06-05 02:11] Train Step 67925, Epoch 62.9, Batch Size = 256, Examples/Sec = 3874.98, Train LB = -395.646, Loss = 391.365
[2018-06-05 02:11] Train Step 67950, Epoch 62.9, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -403.946, Loss = 391.049
[2018-06-05 02:11] Train Step 67975, Epoch 62.9, Batch Size = 256, Examples/Sec = 3870.29, Train LB = -400.456, Loss = 392.327
[2018-06-05 02:11] Train Step 68000, Epoch 63.0, Batch Size = 256, Examples/Sec = 3851.30, Train LB = -421.366, Loss = 395.645
Performance on test set:
  Test Lower Bound = -449.886, Test Loss = 449.886
[2018-06-05 02:11] Train Step 68025, Epoch 63.0, Batch Size = 256, Examples/Sec = 3850.72, Train LB = -385.345, Loss = 394.929
[2018-06-05 02:11] Train Step 68050, Epoch 63.0, Batch Size = 256, Examples/Sec = 3869.17, Train LB = -388.316, Loss = 393.759
[2018-06-05 02:11] Train Step 68075, Epoch 63.0, Batch Size = 256, Examples/Sec = 3845.75, Train LB = -394.154, Loss = 393.015
[2018-06-05 02:11] Train Step 68100, Epoch 63.1, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -380.993, Loss = 391.841
[2018-06-05 02:11] Train Step 68125, Epoch 63.1, Batch Size = 256, Examples/Sec = 3829.87, Train LB = -372.758, Loss = 391.172
[2018-06-05 02:11] Train Step 68150, Epoch 63.1, Batch Size = 256, Examples/Sec = 3803.75, Train LB = -391.635, Loss = 390.833
[2018-06-05 02:11] Train Step 68175, Epoch 63.1, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -412.842, Loss = 392.413
[2018-06-05 02:11] Train Step 68200, Epoch 63.1, Batch Size = 256, Examples/Sec = 3861.76, Train LB = -425.373, Loss = 395.293
Performance on test set:
  Test Lower Bound = -449.789, Test Loss = 449.789
[2018-06-05 02:11] Train Step 68225, Epoch 63.2, Batch Size = 256, Examples/Sec = 3864.60, Train LB = -383.886, Loss = 394.577
[2018-06-05 02:11] Train Step 68250, Epoch 63.2, Batch Size = 256, Examples/Sec = 3824.21, Train LB = -397.915, Loss = 393.469
[2018-06-05 02:11] Train Step 68275, Epoch 63.2, Batch Size = 256, Examples/Sec = 3873.61, Train LB = -393.025, Loss = 392.837
[2018-06-05 02:11] Train Step 68300, Epoch 63.2, Batch Size = 256, Examples/Sec = 3874.91, Train LB = -384.136, Loss = 391.712
[2018-06-05 02:11] Train Step 68325, Epoch 63.3, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -403.778, Loss = 391.352
[2018-06-05 02:11] Train Step 68350, Epoch 63.3, Batch Size = 256, Examples/Sec = 3854.67, Train LB = -402.072, Loss = 391.248
[2018-06-05 02:11] Train Step 68375, Epoch 63.3, Batch Size = 256, Examples/Sec = 3870.29, Train LB = -389.252, Loss = 392.370
[2018-06-05 02:11] Train Step 68400, Epoch 63.3, Batch Size = 256, Examples/Sec = 3861.48, Train LB = -394.192, Loss = 394.907
Performance on test set:
  Test Lower Bound = -449.113, Test Loss = 449.113
[2018-06-05 02:11] Train Step 68425, Epoch 63.4, Batch Size = 256, Examples/Sec = 3841.83, Train LB = -382.576, Loss = 393.996
[2018-06-05 02:11] Train Step 68450, Epoch 63.4, Batch Size = 256, Examples/Sec = 3875.14, Train LB = -396.932, Loss = 393.083
[2018-06-05 02:11] Train Step 68475, Epoch 63.4, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -397.754, Loss = 391.906
[2018-06-05 02:11] Train Step 68500, Epoch 63.4, Batch Size = 256, Examples/Sec = 3877.02, Train LB = -396.399, Loss = 391.087
[2018-06-05 02:11] Train Step 68525, Epoch 63.4, Batch Size = 256, Examples/Sec = 3884.02, Train LB = -375.131, Loss = 390.440
[2018-06-05 02:11] Train Step 68550, Epoch 63.5, Batch Size = 256, Examples/Sec = 3882.20, Train LB = -404.447, Loss = 390.417
[2018-06-05 02:12] Train Step 68575, Epoch 63.5, Batch Size = 256, Examples/Sec = 3853.73, Train LB = -413.428, Loss = 392.051
[2018-06-05 02:12] Train Step 68600, Epoch 63.5, Batch Size = 256, Examples/Sec = 3890.21, Train LB = -429.499, Loss = 395.014
Performance on test set:
  Test Lower Bound = -449.918, Test Loss = 449.918
[2018-06-05 02:12] Train Step 68625, Epoch 63.5, Batch Size = 256, Examples/Sec = 3847.67, Train LB = -391.531, Loss = 394.370
[2018-06-05 02:12] Train Step 68650, Epoch 63.6, Batch Size = 256, Examples/Sec = 3796.30, Train LB = -389.227, Loss = 393.117
[2018-06-05 02:12] Train Step 68675, Epoch 63.6, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -394.371, Loss = 392.515
[2018-06-05 02:12] Train Step 68700, Epoch 63.6, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -386.865, Loss = 391.759
[2018-06-05 02:12] Train Step 68725, Epoch 63.6, Batch Size = 256, Examples/Sec = 3803.91, Train LB = -387.912, Loss = 391.683
[2018-06-05 02:12] Train Step 68750, Epoch 63.7, Batch Size = 256, Examples/Sec = 3857.82, Train LB = -394.127, Loss = 391.946
[2018-06-05 02:12] Train Step 68775, Epoch 63.7, Batch Size = 256, Examples/Sec = 3847.02, Train LB = -409.088, Loss = 392.819
[2018-06-05 02:12] Train Step 68800, Epoch 63.7, Batch Size = 256, Examples/Sec = 3853.68, Train LB = -406.672, Loss = 395.818
Performance on test set:
  Test Lower Bound = -448.173, Test Loss = 448.173
[2018-06-05 02:12] Train Step 68825, Epoch 63.7, Batch Size = 256, Examples/Sec = 3790.23, Train LB = -385.855, Loss = 394.677
[2018-06-05 02:12] Train Step 68850, Epoch 63.8, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -384.912, Loss = 393.826
[2018-06-05 02:12] Train Step 68875, Epoch 63.8, Batch Size = 256, Examples/Sec = 3863.62, Train LB = -393.806, Loss = 392.482
[2018-06-05 02:12] Train Step 68900, Epoch 63.8, Batch Size = 256, Examples/Sec = 3845.46, Train LB = -391.632, Loss = 391.354
[2018-06-05 02:12] Train Step 68925, Epoch 63.8, Batch Size = 256, Examples/Sec = 3847.60, Train LB = -395.309, Loss = 390.489
[2018-06-05 02:12] Train Step 68950, Epoch 63.8, Batch Size = 256, Examples/Sec = 3879.60, Train LB = -374.724, Loss = 391.112
[2018-06-05 02:12] Train Step 68975, Epoch 63.9, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -410.266, Loss = 391.965
[2018-06-05 02:12] Train Step 69000, Epoch 63.9, Batch Size = 256, Examples/Sec = 3874.32, Train LB = -398.820, Loss = 395.762
Performance on test set:
  Test Lower Bound = -450.601, Test Loss = 450.601
[2018-06-05 02:12] Train Step 69025, Epoch 63.9, Batch Size = 256, Examples/Sec = 3873.81, Train LB = -393.518, Loss = 395.302
[2018-06-05 02:12] Train Step 69050, Epoch 63.9, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -388.917, Loss = 393.835
[2018-06-05 02:12] Train Step 69075, Epoch 64.0, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -381.930, Loss = 392.468
[2018-06-05 02:12] Train Step 69100, Epoch 64.0, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -387.048, Loss = 391.313
[2018-06-05 02:12] Train Step 69125, Epoch 64.0, Batch Size = 256, Examples/Sec = 3871.87, Train LB = -385.073, Loss = 390.392
[2018-06-05 02:12] Train Step 69150, Epoch 64.0, Batch Size = 256, Examples/Sec = 3876.55, Train LB = -415.962, Loss = 390.222
[2018-06-05 02:12] Train Step 69175, Epoch 64.1, Batch Size = 256, Examples/Sec = 3840.66, Train LB = -395.401, Loss = 391.688
[2018-06-05 02:12] Train Step 69200, Epoch 64.1, Batch Size = 256, Examples/Sec = 3847.82, Train LB = -432.473, Loss = 394.960
Performance on test set:
  Test Lower Bound = -451.504, Test Loss = 451.504
[2018-06-05 02:12] Train Step 69225, Epoch 64.1, Batch Size = 256, Examples/Sec = 3869.34, Train LB = -400.899, Loss = 394.361
[2018-06-05 02:12] Train Step 69250, Epoch 64.1, Batch Size = 256, Examples/Sec = 3875.33, Train LB = -395.910, Loss = 393.158
[2018-06-05 02:13] Train Step 69275, Epoch 64.1, Batch Size = 256, Examples/Sec = 3846.15, Train LB = -382.679, Loss = 392.172
[2018-06-05 02:13] Train Step 69300, Epoch 64.2, Batch Size = 256, Examples/Sec = 3867.54, Train LB = -369.583, Loss = 391.637
[2018-06-05 02:13] Train Step 69325, Epoch 64.2, Batch Size = 256, Examples/Sec = 3882.86, Train LB = -387.694, Loss = 390.695
[2018-06-05 02:13] Train Step 69350, Epoch 64.2, Batch Size = 256, Examples/Sec = 3848.87, Train LB = -400.027, Loss = 391.052
[2018-06-05 02:13] Train Step 69375, Epoch 64.2, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -393.777, Loss = 391.996
[2018-06-05 02:13] Train Step 69400, Epoch 64.3, Batch Size = 256, Examples/Sec = 3854.60, Train LB = -406.474, Loss = 395.510
Performance on test set:
  Test Lower Bound = -449.081, Test Loss = 449.081
[2018-06-05 02:13] Train Step 69425, Epoch 64.3, Batch Size = 256, Examples/Sec = 3847.25, Train LB = -382.977, Loss = 394.055
[2018-06-05 02:13] Train Step 69450, Epoch 64.3, Batch Size = 256, Examples/Sec = 3873.32, Train LB = -386.921, Loss = 392.743
[2018-06-05 02:13] Train Step 69475, Epoch 64.3, Batch Size = 256, Examples/Sec = 3832.85, Train LB = -380.581, Loss = 391.936
[2018-06-05 02:13] Train Step 69500, Epoch 64.4, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -387.037, Loss = 390.919
[2018-06-05 02:13] Train Step 69525, Epoch 64.4, Batch Size = 256, Examples/Sec = 3846.15, Train LB = -389.507, Loss = 390.913
[2018-06-05 02:13] Train Step 69550, Epoch 64.4, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -374.957, Loss = 391.585
[2018-06-05 02:13] Train Step 69575, Epoch 64.4, Batch Size = 256, Examples/Sec = 3845.11, Train LB = -395.325, Loss = 392.208
[2018-06-05 02:13] Train Step 69600, Epoch 64.4, Batch Size = 256, Examples/Sec = 3877.91, Train LB = -420.415, Loss = 395.311
Performance on test set:
  Test Lower Bound = -450.588, Test Loss = 450.588
[2018-06-05 02:13] Train Step 69625, Epoch 64.5, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -389.646, Loss = 394.976
[2018-06-05 02:13] Train Step 69650, Epoch 64.5, Batch Size = 256, Examples/Sec = 3811.85, Train LB = -403.128, Loss = 392.894
[2018-06-05 02:13] Train Step 69675, Epoch 64.5, Batch Size = 256, Examples/Sec = 3822.95, Train LB = -383.347, Loss = 392.054
[2018-06-05 02:13] Train Step 69700, Epoch 64.5, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -385.996, Loss = 391.500
[2018-06-05 02:13] Train Step 69725, Epoch 64.6, Batch Size = 256, Examples/Sec = 3806.12, Train LB = -385.708, Loss = 390.413
[2018-06-05 02:13] Train Step 69750, Epoch 64.6, Batch Size = 256, Examples/Sec = 3870.80, Train LB = -388.506, Loss = 390.452
[2018-06-05 02:13] Train Step 69775, Epoch 64.6, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -391.687, Loss = 391.840
[2018-06-05 02:13] Train Step 69800, Epoch 64.6, Batch Size = 256, Examples/Sec = 3828.16, Train LB = -420.566, Loss = 395.091
Performance on test set:
  Test Lower Bound = -449.915, Test Loss = 449.915
[2018-06-05 02:13] Train Step 69825, Epoch 64.7, Batch Size = 256, Examples/Sec = 3798.95, Train LB = -388.339, Loss = 394.178
[2018-06-05 02:13] Train Step 69850, Epoch 64.7, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -393.918, Loss = 392.657
[2018-06-05 02:13] Train Step 69875, Epoch 64.7, Batch Size = 256, Examples/Sec = 3841.08, Train LB = -373.382, Loss = 391.694
[2018-06-05 02:13] Train Step 69900, Epoch 64.7, Batch Size = 256, Examples/Sec = 3812.19, Train LB = -383.588, Loss = 390.096
[2018-06-05 02:13] Train Step 69925, Epoch 64.7, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -372.606, Loss = 389.970
[2018-06-05 02:13] Train Step 69950, Epoch 64.8, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -388.318, Loss = 390.454
[2018-06-05 02:13] Train Step 69975, Epoch 64.8, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -412.424, Loss = 391.733
[2018-06-05 02:13] Train Step 70000, Epoch 64.8, Batch Size = 256, Examples/Sec = 3872.51, Train LB = -416.254, Loss = 394.822
Performance on test set:
  Test Lower Bound = -451.086, Test Loss = 451.086
[2018-06-05 02:14] Train Step 70025, Epoch 64.8, Batch Size = 256, Examples/Sec = 3850.33, Train LB = -398.602, Loss = 393.748
[2018-06-05 02:14] Train Step 70050, Epoch 64.9, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -393.151, Loss = 392.785
[2018-06-05 02:14] Train Step 70075, Epoch 64.9, Batch Size = 256, Examples/Sec = 3845.74, Train LB = -397.864, Loss = 391.397
[2018-06-05 02:14] Train Step 70100, Epoch 64.9, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -380.071, Loss = 390.589
[2018-06-05 02:14] Train Step 70125, Epoch 64.9, Batch Size = 256, Examples/Sec = 3869.17, Train LB = -383.123, Loss = 390.320
[2018-06-05 02:14] Train Step 70150, Epoch 65.0, Batch Size = 256, Examples/Sec = 3874.21, Train LB = -388.486, Loss = 389.704
[2018-06-05 02:14] Train Step 70175, Epoch 65.0, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -400.444, Loss = 391.608
[2018-06-05 02:14] Train Step 70200, Epoch 65.0, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -416.081, Loss = 395.227
Performance on test set:
  Test Lower Bound = -450.820, Test Loss = 450.820
[2018-06-05 02:14] Train Step 70225, Epoch 65.0, Batch Size = 256, Examples/Sec = 3852.64, Train LB = -387.799, Loss = 393.489
[2018-06-05 02:14] Train Step 70250, Epoch 65.0, Batch Size = 256, Examples/Sec = 3873.09, Train LB = -400.136, Loss = 392.619
[2018-06-05 02:14] Train Step 70275, Epoch 65.1, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -391.642, Loss = 391.545
[2018-06-05 02:14] Train Step 70300, Epoch 65.1, Batch Size = 256, Examples/Sec = 3792.53, Train LB = -395.429, Loss = 390.853
[2018-06-05 02:14] Train Step 70325, Epoch 65.1, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -399.209, Loss = 390.474
[2018-06-05 02:14] Train Step 70350, Epoch 65.1, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -394.364, Loss = 390.342
[2018-06-05 02:14] Train Step 70375, Epoch 65.2, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -405.372, Loss = 391.350
[2018-06-05 02:14] Train Step 70400, Epoch 65.2, Batch Size = 256, Examples/Sec = 3866.37, Train LB = -415.543, Loss = 394.534
Performance on test set:
  Test Lower Bound = -449.312, Test Loss = 449.312
[2018-06-05 02:14] Train Step 70425, Epoch 65.2, Batch Size = 256, Examples/Sec = 3874.86, Train LB = -394.367, Loss = 393.772
[2018-06-05 02:14] Train Step 70450, Epoch 65.2, Batch Size = 256, Examples/Sec = 3849.67, Train LB = -387.831, Loss = 392.609
[2018-06-05 02:14] Train Step 70475, Epoch 65.3, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -395.614, Loss = 391.640
[2018-06-05 02:14] Train Step 70500, Epoch 65.3, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -390.950, Loss = 390.854
[2018-06-05 02:14] Train Step 70525, Epoch 65.3, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -387.905, Loss = 390.570
[2018-06-05 02:14] Train Step 70550, Epoch 65.3, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -385.502, Loss = 390.001
[2018-06-05 02:14] Train Step 70575, Epoch 65.3, Batch Size = 256, Examples/Sec = 3877.08, Train LB = -392.157, Loss = 391.449
[2018-06-05 02:14] Train Step 70600, Epoch 65.4, Batch Size = 256, Examples/Sec = 3832.34, Train LB = -412.005, Loss = 394.964
Performance on test set:
  Test Lower Bound = -450.263, Test Loss = 450.263
[2018-06-05 02:14] Train Step 70625, Epoch 65.4, Batch Size = 256, Examples/Sec = 3853.92, Train LB = -384.749, Loss = 394.016
[2018-06-05 02:14] Train Step 70650, Epoch 65.4, Batch Size = 256, Examples/Sec = 3873.44, Train LB = -398.738, Loss = 392.582
[2018-06-05 02:14] Train Step 70675, Epoch 65.4, Batch Size = 256, Examples/Sec = 3881.02, Train LB = -391.008, Loss = 392.258
[2018-06-05 02:14] Train Step 70700, Epoch 65.5, Batch Size = 256, Examples/Sec = 3877.14, Train LB = -388.191, Loss = 391.468
[2018-06-05 02:15] Train Step 70725, Epoch 65.5, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -385.744, Loss = 390.748
[2018-06-05 02:15] Train Step 70750, Epoch 65.5, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -401.480, Loss = 391.090
[2018-06-05 02:15] Train Step 70775, Epoch 65.5, Batch Size = 256, Examples/Sec = 3876.25, Train LB = -389.550, Loss = 391.888
[2018-06-05 02:15] Train Step 70800, Epoch 65.6, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -416.240, Loss = 394.859
Performance on test set:
  Test Lower Bound = -449.401, Test Loss = 449.401
[2018-06-05 02:15] Train Step 70825, Epoch 65.6, Batch Size = 256, Examples/Sec = 3888.21, Train LB = -369.083, Loss = 394.300
[2018-06-05 02:15] Train Step 70850, Epoch 65.6, Batch Size = 256, Examples/Sec = 3818.85, Train LB = -387.597, Loss = 392.774
[2018-06-05 02:15] Train Step 70875, Epoch 65.6, Batch Size = 256, Examples/Sec = 3807.10, Train LB = -378.751, Loss = 392.115
[2018-06-05 02:15] Train Step 70900, Epoch 65.6, Batch Size = 256, Examples/Sec = 3846.21, Train LB = -391.473, Loss = 390.544
[2018-06-05 02:15] Train Step 70925, Epoch 65.7, Batch Size = 256, Examples/Sec = 3842.16, Train LB = -384.553, Loss = 389.725
[2018-06-05 02:15] Train Step 70950, Epoch 65.7, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -379.379, Loss = 389.683
[2018-06-05 02:15] Train Step 70975, Epoch 65.7, Batch Size = 256, Examples/Sec = 3868.95, Train LB = -409.518, Loss = 391.151
[2018-06-05 02:15] Train Step 71000, Epoch 65.7, Batch Size = 256, Examples/Sec = 3873.56, Train LB = -409.318, Loss = 394.137
Performance on test set:
  Test Lower Bound = -449.271, Test Loss = 449.271
[2018-06-05 02:15] Train Step 71025, Epoch 65.8, Batch Size = 256, Examples/Sec = 3858.55, Train LB = -393.507, Loss = 393.127
[2018-06-05 02:15] Train Step 71050, Epoch 65.8, Batch Size = 256, Examples/Sec = 3854.02, Train LB = -372.777, Loss = 392.277
[2018-06-05 02:15] Train Step 71075, Epoch 65.8, Batch Size = 256, Examples/Sec = 3857.57, Train LB = -405.379, Loss = 391.334
[2018-06-05 02:15] Train Step 71100, Epoch 65.8, Batch Size = 256, Examples/Sec = 3858.38, Train LB = -391.726, Loss = 390.212
[2018-06-05 02:15] Train Step 71125, Epoch 65.9, Batch Size = 256, Examples/Sec = 3859.38, Train LB = -391.282, Loss = 389.548
[2018-06-05 02:15] Train Step 71150, Epoch 65.9, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -398.239, Loss = 389.615
[2018-06-05 02:15] Train Step 71175, Epoch 65.9, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -393.359, Loss = 391.212
[2018-06-05 02:15] Train Step 71200, Epoch 65.9, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -409.779, Loss = 394.984
Performance on test set:
  Test Lower Bound = -450.290, Test Loss = 450.290
[2018-06-05 02:15] Train Step 71225, Epoch 65.9, Batch Size = 256, Examples/Sec = 3863.85, Train LB = -381.882, Loss = 393.747
[2018-06-05 02:15] Train Step 71250, Epoch 66.0, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -380.110, Loss = 392.433
[2018-06-05 02:15] Train Step 71275, Epoch 66.0, Batch Size = 256, Examples/Sec = 3876.90, Train LB = -377.692, Loss = 392.258
[2018-06-05 02:15] Train Step 71300, Epoch 66.0, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -381.526, Loss = 391.220
[2018-06-05 02:15] Train Step 71325, Epoch 66.0, Batch Size = 256, Examples/Sec = 3875.68, Train LB = -379.814, Loss = 390.040
[2018-06-05 02:15] Train Step 71350, Epoch 66.1, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -393.387, Loss = 389.782
[2018-06-05 02:15] Train Step 71375, Epoch 66.1, Batch Size = 256, Examples/Sec = 3859.20, Train LB = -407.977, Loss = 391.313
[2018-06-05 02:15] Train Step 71400, Epoch 66.1, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -414.092, Loss = 395.007
Performance on test set:
  Test Lower Bound = -451.856, Test Loss = 451.856
[2018-06-05 02:16] Train Step 71425, Epoch 66.1, Batch Size = 256, Examples/Sec = 3848.63, Train LB = -389.875, Loss = 394.050
[2018-06-05 02:16] Train Step 71450, Epoch 66.2, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -385.463, Loss = 393.007
[2018-06-05 02:16] Train Step 71475, Epoch 66.2, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -382.504, Loss = 391.838
[2018-06-05 02:16] Train Step 71500, Epoch 66.2, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -378.322, Loss = 390.674
[2018-06-05 02:16] Train Step 71525, Epoch 66.2, Batch Size = 256, Examples/Sec = 3817.12, Train LB = -391.463, Loss = 389.990
[2018-06-05 02:16] Train Step 71550, Epoch 66.2, Batch Size = 256, Examples/Sec = 3841.65, Train LB = -405.606, Loss = 389.789
[2018-06-05 02:16] Train Step 71575, Epoch 66.3, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -400.667, Loss = 391.163
[2018-06-05 02:16] Train Step 71600, Epoch 66.3, Batch Size = 256, Examples/Sec = 3869.35, Train LB = -415.182, Loss = 394.217
Performance on test set:
  Test Lower Bound = -452.611, Test Loss = 452.611
[2018-06-05 02:16] Train Step 71625, Epoch 66.3, Batch Size = 256, Examples/Sec = 3849.57, Train LB = -391.299, Loss = 393.424
[2018-06-05 02:16] Train Step 71650, Epoch 66.3, Batch Size = 256, Examples/Sec = 3844.94, Train LB = -396.483, Loss = 392.358
[2018-06-05 02:16] Train Step 71675, Epoch 66.4, Batch Size = 256, Examples/Sec = 3875.50, Train LB = -390.638, Loss = 391.284
[2018-06-05 02:16] Train Step 71700, Epoch 66.4, Batch Size = 256, Examples/Sec = 3837.33, Train LB = -376.095, Loss = 389.660
[2018-06-05 02:16] Train Step 71725, Epoch 66.4, Batch Size = 256, Examples/Sec = 3867.43, Train LB = -394.699, Loss = 389.822
[2018-06-05 02:16] Train Step 71750, Epoch 66.4, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -388.019, Loss = 390.010
[2018-06-05 02:16] Train Step 71775, Epoch 66.5, Batch Size = 256, Examples/Sec = 3861.87, Train LB = -408.188, Loss = 390.790
[2018-06-05 02:16] Train Step 71800, Epoch 66.5, Batch Size = 256, Examples/Sec = 3856.65, Train LB = -404.767, Loss = 393.994
Performance on test set:
  Test Lower Bound = -451.517, Test Loss = 451.517
[2018-06-05 02:16] Train Step 71825, Epoch 66.5, Batch Size = 256, Examples/Sec = 3850.66, Train LB = -388.753, Loss = 393.360
[2018-06-05 02:16] Train Step 71850, Epoch 66.5, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -391.023, Loss = 392.125
[2018-06-05 02:16] Train Step 71875, Epoch 66.6, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -377.444, Loss = 390.690
[2018-06-05 02:16] Train Step 71900, Epoch 66.6, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -403.540, Loss = 390.094
[2018-06-05 02:16] Train Step 71925, Epoch 66.6, Batch Size = 256, Examples/Sec = 3863.67, Train LB = -387.065, Loss = 389.754
[2018-06-05 02:16] Train Step 71950, Epoch 66.6, Batch Size = 256, Examples/Sec = 3875.74, Train LB = -391.581, Loss = 390.007
[2018-06-05 02:16] Train Step 71975, Epoch 66.6, Batch Size = 256, Examples/Sec = 3858.74, Train LB = -399.380, Loss = 390.683
[2018-06-05 02:16] Train Step 72000, Epoch 66.7, Batch Size = 256, Examples/Sec = 3820.15, Train LB = -406.852, Loss = 393.903
Performance on test set:
  Test Lower Bound = -452.540, Test Loss = 452.540
[2018-06-05 02:16] Train Step 72025, Epoch 66.7, Batch Size = 256, Examples/Sec = 3797.78, Train LB = -392.912, Loss = 392.859
[2018-06-05 02:16] Train Step 72050, Epoch 66.7, Batch Size = 256, Examples/Sec = 3848.05, Train LB = -388.002, Loss = 391.854
[2018-06-05 02:16] Train Step 72075, Epoch 66.7, Batch Size = 256, Examples/Sec = 3860.59, Train LB = -386.069, Loss = 390.905
[2018-06-05 02:16] Train Step 72100, Epoch 66.8, Batch Size = 256, Examples/Sec = 3816.68, Train LB = -375.845, Loss = 390.016
[2018-06-05 02:16] Train Step 72125, Epoch 66.8, Batch Size = 256, Examples/Sec = 3871.68, Train LB = -395.120, Loss = 389.339
[2018-06-05 02:17] Train Step 72150, Epoch 66.8, Batch Size = 256, Examples/Sec = 3856.42, Train LB = -377.573, Loss = 389.337
[2018-06-05 02:17] Train Step 72175, Epoch 66.8, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -386.754, Loss = 390.465
[2018-06-05 02:17] Train Step 72200, Epoch 66.9, Batch Size = 256, Examples/Sec = 3864.22, Train LB = -408.898, Loss = 394.033
Performance on test set:
  Test Lower Bound = -448.975, Test Loss = 448.975
[2018-06-05 02:17] Train Step 72225, Epoch 66.9, Batch Size = 256, Examples/Sec = 3849.86, Train LB = -374.102, Loss = 393.199
[2018-06-05 02:17] Train Step 72250, Epoch 66.9, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -384.617, Loss = 391.888
[2018-06-05 02:17] Train Step 72275, Epoch 66.9, Batch Size = 256, Examples/Sec = 3855.76, Train LB = -379.155, Loss = 391.072
[2018-06-05 02:17] Train Step 72300, Epoch 66.9, Batch Size = 256, Examples/Sec = 3879.43, Train LB = -378.112, Loss = 389.807
[2018-06-05 02:17] Train Step 72325, Epoch 67.0, Batch Size = 256, Examples/Sec = 3850.15, Train LB = -382.833, Loss = 389.740
[2018-06-05 02:17] Train Step 72350, Epoch 67.0, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -386.632, Loss = 389.526
[2018-06-05 02:17] Train Step 72375, Epoch 67.0, Batch Size = 256, Examples/Sec = 3839.87, Train LB = -408.651, Loss = 391.136
[2018-06-05 02:17] Train Step 72400, Epoch 67.0, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -412.108, Loss = 394.502
Performance on test set:
  Test Lower Bound = -450.859, Test Loss = 450.859
[2018-06-05 02:17] Train Step 72425, Epoch 67.1, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -376.815, Loss = 393.136
[2018-06-05 02:17] Train Step 72450, Epoch 67.1, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -385.680, Loss = 391.924
[2018-06-05 02:17] Train Step 72475, Epoch 67.1, Batch Size = 256, Examples/Sec = 3852.57, Train LB = -385.035, Loss = 390.923
[2018-06-05 02:17] Train Step 72500, Epoch 67.1, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -389.959, Loss = 389.876
[2018-06-05 02:17] Train Step 72525, Epoch 67.2, Batch Size = 256, Examples/Sec = 3867.07, Train LB = -378.568, Loss = 389.910
[2018-06-05 02:17] Train Step 72550, Epoch 67.2, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -373.579, Loss = 390.174
[2018-06-05 02:17] Train Step 72575, Epoch 67.2, Batch Size = 256, Examples/Sec = 3818.28, Train LB = -407.194, Loss = 391.418
[2018-06-05 02:17] Train Step 72600, Epoch 67.2, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -411.076, Loss = 394.460
Performance on test set:
  Test Lower Bound = -451.860, Test Loss = 451.860
[2018-06-05 02:17] Train Step 72625, Epoch 67.2, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -383.942, Loss = 393.438
[2018-06-05 02:17] Train Step 72650, Epoch 67.3, Batch Size = 256, Examples/Sec = 3819.81, Train LB = -389.401, Loss = 391.866
[2018-06-05 02:17] Train Step 72675, Epoch 67.3, Batch Size = 256, Examples/Sec = 3831.75, Train LB = -379.384, Loss = 391.342
[2018-06-05 02:17] Train Step 72700, Epoch 67.3, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -383.246, Loss = 390.489
[2018-06-05 02:17] Train Step 72725, Epoch 67.3, Batch Size = 256, Examples/Sec = 3870.64, Train LB = -388.888, Loss = 389.314
[2018-06-05 02:17] Train Step 72750, Epoch 67.4, Batch Size = 256, Examples/Sec = 3840.28, Train LB = -393.367, Loss = 390.099
[2018-06-05 02:17] Train Step 72775, Epoch 67.4, Batch Size = 256, Examples/Sec = 3860.49, Train LB = -417.972, Loss = 390.980
[2018-06-05 02:17] Train Step 72800, Epoch 67.4, Batch Size = 256, Examples/Sec = 3876.49, Train LB = -415.956, Loss = 393.822
Performance on test set:
  Test Lower Bound = -451.491, Test Loss = 451.491
[2018-06-05 02:17] Train Step 72825, Epoch 67.4, Batch Size = 256, Examples/Sec = 3875.67, Train LB = -394.658, Loss = 392.622
[2018-06-05 02:18] Train Step 72850, Epoch 67.5, Batch Size = 256, Examples/Sec = 3848.94, Train LB = -387.514, Loss = 391.466
[2018-06-05 02:18] Train Step 72875, Epoch 67.5, Batch Size = 256, Examples/Sec = 3842.41, Train LB = -390.008, Loss = 390.428
[2018-06-05 02:18] Train Step 72900, Epoch 67.5, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -385.484, Loss = 389.974
[2018-06-05 02:18] Train Step 72925, Epoch 67.5, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -385.417, Loss = 389.596
[2018-06-05 02:18] Train Step 72950, Epoch 67.5, Batch Size = 256, Examples/Sec = 3839.74, Train LB = -386.688, Loss = 389.410
[2018-06-05 02:18] Train Step 72975, Epoch 67.6, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -394.313, Loss = 390.965
[2018-06-05 02:18] Train Step 73000, Epoch 67.6, Batch Size = 256, Examples/Sec = 3872.97, Train LB = -424.845, Loss = 394.231
Performance on test set:
  Test Lower Bound = -451.362, Test Loss = 451.362
[2018-06-05 02:18] Train Step 73025, Epoch 67.6, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -379.906, Loss = 393.661
[2018-06-05 02:18] Train Step 73050, Epoch 67.6, Batch Size = 256, Examples/Sec = 3852.46, Train LB = -383.349, Loss = 391.958
[2018-06-05 02:18] Train Step 73075, Epoch 67.7, Batch Size = 256, Examples/Sec = 3869.70, Train LB = -401.095, Loss = 391.351
[2018-06-05 02:18] Train Step 73100, Epoch 67.7, Batch Size = 256, Examples/Sec = 3850.68, Train LB = -396.105, Loss = 389.805
[2018-06-05 02:18] Train Step 73125, Epoch 67.7, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -397.068, Loss = 389.264
[2018-06-05 02:18] Train Step 73150, Epoch 67.7, Batch Size = 256, Examples/Sec = 3809.42, Train LB = -384.910, Loss = 389.326
[2018-06-05 02:18] Train Step 73175, Epoch 67.8, Batch Size = 256, Examples/Sec = 3828.43, Train LB = -392.065, Loss = 390.576
[2018-06-05 02:18] Train Step 73200, Epoch 67.8, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -428.758, Loss = 394.027
Performance on test set:
  Test Lower Bound = -450.773, Test Loss = 450.773
[2018-06-05 02:18] Train Step 73225, Epoch 67.8, Batch Size = 256, Examples/Sec = 3852.28, Train LB = -378.009, Loss = 393.682
[2018-06-05 02:18] Train Step 73250, Epoch 67.8, Batch Size = 256, Examples/Sec = 3817.30, Train LB = -386.494, Loss = 392.091
[2018-06-05 02:18] Train Step 73275, Epoch 67.8, Batch Size = 256, Examples/Sec = 3864.90, Train LB = -380.856, Loss = 391.191
[2018-06-05 02:18] Train Step 73300, Epoch 67.9, Batch Size = 256, Examples/Sec = 3856.75, Train LB = -379.255, Loss = 389.413
[2018-06-05 02:18] Train Step 73325, Epoch 67.9, Batch Size = 256, Examples/Sec = 3864.90, Train LB = -393.803, Loss = 388.557
[2018-06-05 02:18] Train Step 73350, Epoch 67.9, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -395.995, Loss = 388.579
[2018-06-05 02:18] Train Step 73375, Epoch 67.9, Batch Size = 256, Examples/Sec = 3866.61, Train LB = -398.188, Loss = 390.355
[2018-06-05 02:18] Train Step 73400, Epoch 68.0, Batch Size = 256, Examples/Sec = 3866.25, Train LB = -423.648, Loss = 393.427
Performance on test set:
  Test Lower Bound = -452.059, Test Loss = 452.059
[2018-06-05 02:18] Train Step 73425, Epoch 68.0, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -371.132, Loss = 392.668
[2018-06-05 02:18] Train Step 73450, Epoch 68.0, Batch Size = 256, Examples/Sec = 3861.53, Train LB = -389.847, Loss = 391.471
[2018-06-05 02:18] Train Step 73475, Epoch 68.0, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -387.863, Loss = 390.480
[2018-06-05 02:18] Train Step 73500, Epoch 68.1, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -389.853, Loss = 389.356
[2018-06-05 02:18] Train Step 73525, Epoch 68.1, Batch Size = 256, Examples/Sec = 3866.02, Train LB = -377.364, Loss = 388.260
[2018-06-05 02:18] Train Step 73550, Epoch 68.1, Batch Size = 256, Examples/Sec = 3866.59, Train LB = -390.493, Loss = 388.103
[2018-06-05 02:18] Train Step 73575, Epoch 68.1, Batch Size = 256, Examples/Sec = 3860.60, Train LB = -395.624, Loss = 389.457
[2018-06-05 02:19] Train Step 73600, Epoch 68.1, Batch Size = 256, Examples/Sec = 3872.38, Train LB = -410.632, Loss = 393.436
Performance on test set:
  Test Lower Bound = -451.300, Test Loss = 451.300
[2018-06-05 02:19] Train Step 73625, Epoch 68.2, Batch Size = 256, Examples/Sec = 3848.76, Train LB = -381.896, Loss = 392.234
[2018-06-05 02:19] Train Step 73650, Epoch 68.2, Batch Size = 256, Examples/Sec = 3835.26, Train LB = -382.119, Loss = 390.856
[2018-06-05 02:19] Train Step 73675, Epoch 68.2, Batch Size = 256, Examples/Sec = 3861.76, Train LB = -402.448, Loss = 390.111
[2018-06-05 02:19] Train Step 73700, Epoch 68.2, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -382.960, Loss = 389.604
[2018-06-05 02:19] Train Step 73725, Epoch 68.3, Batch Size = 256, Examples/Sec = 3775.04, Train LB = -383.168, Loss = 389.183
[2018-06-05 02:19] Train Step 73750, Epoch 68.3, Batch Size = 256, Examples/Sec = 3873.50, Train LB = -398.631, Loss = 389.495
[2018-06-05 02:19] Train Step 73775, Epoch 68.3, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -401.755, Loss = 391.375
[2018-06-05 02:19] Train Step 73800, Epoch 68.3, Batch Size = 256, Examples/Sec = 3845.97, Train LB = -425.131, Loss = 394.227
Performance on test set:
  Test Lower Bound = -452.765, Test Loss = 452.765
[2018-06-05 02:19] Train Step 73825, Epoch 68.4, Batch Size = 256, Examples/Sec = 3806.97, Train LB = -387.336, Loss = 392.624
[2018-06-05 02:19] Train Step 73850, Epoch 68.4, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -397.754, Loss = 391.976
[2018-06-05 02:19] Train Step 73875, Epoch 68.4, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -380.065, Loss = 390.816
[2018-06-05 02:19] Train Step 73900, Epoch 68.4, Batch Size = 256, Examples/Sec = 3849.74, Train LB = -376.534, Loss = 390.027
[2018-06-05 02:19] Train Step 73925, Epoch 68.4, Batch Size = 256, Examples/Sec = 3844.60, Train LB = -387.766, Loss = 389.118
[2018-06-05 02:19] Train Step 73950, Epoch 68.5, Batch Size = 256, Examples/Sec = 3819.53, Train LB = -388.410, Loss = 389.095
[2018-06-05 02:19] Train Step 73975, Epoch 68.5, Batch Size = 256, Examples/Sec = 3842.05, Train LB = -411.477, Loss = 390.265
[2018-06-05 02:19] Train Step 74000, Epoch 68.5, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -406.753, Loss = 393.559
Performance on test set:
  Test Lower Bound = -452.051, Test Loss = 452.051
[2018-06-05 02:19] Train Step 74025, Epoch 68.5, Batch Size = 256, Examples/Sec = 3842.99, Train LB = -386.120, Loss = 392.616
[2018-06-05 02:19] Train Step 74050, Epoch 68.6, Batch Size = 256, Examples/Sec = 3822.78, Train LB = -385.604, Loss = 391.358
[2018-06-05 02:19] Train Step 74075, Epoch 68.6, Batch Size = 256, Examples/Sec = 3882.80, Train LB = -387.781, Loss = 390.130
[2018-06-05 02:19] Train Step 74100, Epoch 68.6, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -383.357, Loss = 389.733
[2018-06-05 02:19] Train Step 74125, Epoch 68.6, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -375.777, Loss = 388.765
[2018-06-05 02:19] Train Step 74150, Epoch 68.7, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -385.041, Loss = 388.961
[2018-06-05 02:19] Train Step 74175, Epoch 68.7, Batch Size = 256, Examples/Sec = 3833.26, Train LB = -398.542, Loss = 390.856
[2018-06-05 02:19] Train Step 74200, Epoch 68.7, Batch Size = 256, Examples/Sec = 3845.00, Train LB = -412.234, Loss = 393.955
Performance on test set:
  Test Lower Bound = -452.438, Test Loss = 452.438
[2018-06-05 02:19] Train Step 74225, Epoch 68.7, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -386.111, Loss = 393.371
[2018-06-05 02:19] Train Step 74250, Epoch 68.8, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -384.690, Loss = 392.141
[2018-06-05 02:20] Train Step 74275, Epoch 68.8, Batch Size = 256, Examples/Sec = 3804.44, Train LB = -378.141, Loss = 390.763
[2018-06-05 02:20] Train Step 74300, Epoch 68.8, Batch Size = 256, Examples/Sec = 3784.58, Train LB = -388.340, Loss = 389.116
[2018-06-05 02:20] Train Step 74325, Epoch 68.8, Batch Size = 256, Examples/Sec = 3883.26, Train LB = -408.754, Loss = 388.902
[2018-06-05 02:20] Train Step 74350, Epoch 68.8, Batch Size = 256, Examples/Sec = 3868.94, Train LB = -393.087, Loss = 389.388
[2018-06-05 02:20] Train Step 74375, Epoch 68.9, Batch Size = 256, Examples/Sec = 3855.76, Train LB = -396.483, Loss = 389.979
[2018-06-05 02:20] Train Step 74400, Epoch 68.9, Batch Size = 256, Examples/Sec = 3840.57, Train LB = -411.082, Loss = 393.680
Performance on test set:
  Test Lower Bound = -452.103, Test Loss = 452.103
[2018-06-05 02:20] Train Step 74425, Epoch 68.9, Batch Size = 256, Examples/Sec = 3868.71, Train LB = -389.065, Loss = 392.648
[2018-06-05 02:20] Train Step 74450, Epoch 68.9, Batch Size = 256, Examples/Sec = 3837.62, Train LB = -367.923, Loss = 391.698
[2018-06-05 02:20] Train Step 74475, Epoch 69.0, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -394.813, Loss = 390.642
[2018-06-05 02:20] Train Step 74500, Epoch 69.0, Batch Size = 256, Examples/Sec = 3866.85, Train LB = -381.973, Loss = 390.347
[2018-06-05 02:20] Train Step 74525, Epoch 69.0, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -388.128, Loss = 389.455
[2018-06-05 02:20] Train Step 74550, Epoch 69.0, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -382.676, Loss = 389.161
[2018-06-05 02:20] Train Step 74575, Epoch 69.1, Batch Size = 256, Examples/Sec = 3888.34, Train LB = -391.852, Loss = 390.286
[2018-06-05 02:20] Train Step 74600, Epoch 69.1, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -415.107, Loss = 393.391
Performance on test set:
  Test Lower Bound = -452.595, Test Loss = 452.595
[2018-06-05 02:20] Train Step 74625, Epoch 69.1, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -393.571, Loss = 392.764
[2018-06-05 02:20] Train Step 74650, Epoch 69.1, Batch Size = 256, Examples/Sec = 3845.28, Train LB = -390.910, Loss = 391.017
[2018-06-05 02:20] Train Step 74675, Epoch 69.1, Batch Size = 256, Examples/Sec = 3880.68, Train LB = -387.460, Loss = 390.719
[2018-06-05 02:20] Train Step 74700, Epoch 69.2, Batch Size = 256, Examples/Sec = 3872.56, Train LB = -391.530, Loss = 389.338
[2018-06-05 02:20] Train Step 74725, Epoch 69.2, Batch Size = 256, Examples/Sec = 3854.84, Train LB = -392.871, Loss = 388.855
[2018-06-05 02:20] Train Step 74750, Epoch 69.2, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -391.483, Loss = 388.658
[2018-06-05 02:20] Train Step 74775, Epoch 69.2, Batch Size = 256, Examples/Sec = 3866.36, Train LB = -414.324, Loss = 390.128
[2018-06-05 02:20] Train Step 74800, Epoch 69.3, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -406.649, Loss = 393.608
Performance on test set:
  Test Lower Bound = -450.916, Test Loss = 450.916
[2018-06-05 02:20] Train Step 74825, Epoch 69.3, Batch Size = 256, Examples/Sec = 3873.15, Train LB = -394.015, Loss = 392.626
[2018-06-05 02:20] Train Step 74850, Epoch 69.3, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -394.505, Loss = 390.584
[2018-06-05 02:20] Train Step 74875, Epoch 69.3, Batch Size = 256, Examples/Sec = 3800.87, Train LB = -386.313, Loss = 390.128
[2018-06-05 02:20] Train Step 74900, Epoch 69.4, Batch Size = 256, Examples/Sec = 3795.68, Train LB = -390.414, Loss = 389.318
[2018-06-05 02:20] Train Step 74925, Epoch 69.4, Batch Size = 256, Examples/Sec = 3858.20, Train LB = -378.330, Loss = 389.291
[2018-06-05 02:20] Train Step 74950, Epoch 69.4, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -387.550, Loss = 388.491
[2018-06-05 02:20] Train Step 74975, Epoch 69.4, Batch Size = 256, Examples/Sec = 3849.21, Train LB = -402.679, Loss = 389.634
[2018-06-05 02:20] Train Step 75000, Epoch 69.4, Batch Size = 256, Examples/Sec = 3831.19, Train LB = -415.746, Loss = 393.068
Performance on test set:
  Test Lower Bound = -451.888, Test Loss = 451.888
[2018-06-05 02:21] Train Step 75025, Epoch 69.5, Batch Size = 256, Examples/Sec = 3852.40, Train LB = -370.504, Loss = 392.256
[2018-06-05 02:21] Train Step 75050, Epoch 69.5, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -390.122, Loss = 390.695
[2018-06-05 02:21] Train Step 75075, Epoch 69.5, Batch Size = 256, Examples/Sec = 3875.15, Train LB = -372.917, Loss = 390.575
[2018-06-05 02:21] Train Step 75100, Epoch 69.5, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -393.435, Loss = 389.415
[2018-06-05 02:21] Train Step 75125, Epoch 69.6, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -397.551, Loss = 388.505
[2018-06-05 02:21] Train Step 75150, Epoch 69.6, Batch Size = 256, Examples/Sec = 3861.99, Train LB = -378.690, Loss = 388.685
[2018-06-05 02:21] Train Step 75175, Epoch 69.6, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -406.065, Loss = 390.108
[2018-06-05 02:21] Train Step 75200, Epoch 69.6, Batch Size = 256, Examples/Sec = 3807.42, Train LB = -419.444, Loss = 393.212
Performance on test set:
  Test Lower Bound = -451.970, Test Loss = 451.970
[2018-06-05 02:21] Train Step 75225, Epoch 69.7, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -383.967, Loss = 392.484
[2018-06-05 02:21] Train Step 75250, Epoch 69.7, Batch Size = 256, Examples/Sec = 3865.37, Train LB = -397.063, Loss = 390.567
[2018-06-05 02:21] Train Step 75275, Epoch 69.7, Batch Size = 256, Examples/Sec = 3876.90, Train LB = -386.048, Loss = 390.099
[2018-06-05 02:21] Train Step 75300, Epoch 69.7, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -399.182, Loss = 388.860
[2018-06-05 02:21] Train Step 75325, Epoch 69.7, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -388.920, Loss = 388.967
[2018-06-05 02:21] Train Step 75350, Epoch 69.8, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -392.519, Loss = 388.883
[2018-06-05 02:21] Train Step 75375, Epoch 69.8, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -413.379, Loss = 389.849
[2018-06-05 02:21] Train Step 75400, Epoch 69.8, Batch Size = 256, Examples/Sec = 3850.44, Train LB = -426.523, Loss = 393.256
Performance on test set:
  Test Lower Bound = -451.796, Test Loss = 451.796
[2018-06-05 02:21] Train Step 75425, Epoch 69.8, Batch Size = 256, Examples/Sec = 3889.16, Train LB = -381.855, Loss = 392.836
[2018-06-05 02:21] Train Step 75450, Epoch 69.9, Batch Size = 256, Examples/Sec = 3810.82, Train LB = -409.071, Loss = 391.481
[2018-06-05 02:21] Train Step 75475, Epoch 69.9, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -382.491, Loss = 390.352
[2018-06-05 02:21] Train Step 75500, Epoch 69.9, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -387.374, Loss = 388.933
[2018-06-05 02:21] Train Step 75525, Epoch 69.9, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -393.165, Loss = 388.671
[2018-06-05 02:21] Train Step 75550, Epoch 70.0, Batch Size = 256, Examples/Sec = 3864.49, Train LB = -383.956, Loss = 388.401
[2018-06-05 02:21] Train Step 75575, Epoch 70.0, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -403.831, Loss = 389.460
[2018-06-05 02:21] Train Step 75600, Epoch 70.0, Batch Size = 256, Examples/Sec = 3828.72, Train LB = -405.369, Loss = 393.076
Performance on test set:
  Test Lower Bound = -453.118, Test Loss = 453.118
[2018-06-05 02:21] Train Step 75625, Epoch 70.0, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -384.509, Loss = 391.883
[2018-06-05 02:21] Train Step 75650, Epoch 70.0, Batch Size = 256, Examples/Sec = 3879.50, Train LB = -374.810, Loss = 390.733
[2018-06-05 02:21] Train Step 75675, Epoch 70.1, Batch Size = 256, Examples/Sec = 3798.05, Train LB = -388.315, Loss = 389.699
[2018-06-05 02:21] Train Step 75700, Epoch 70.1, Batch Size = 256, Examples/Sec = 3854.02, Train LB = -392.608, Loss = 389.132
[2018-06-05 02:22] Train Step 75725, Epoch 70.1, Batch Size = 256, Examples/Sec = 3864.49, Train LB = -388.266, Loss = 388.456
[2018-06-05 02:22] Train Step 75750, Epoch 70.1, Batch Size = 256, Examples/Sec = 3802.79, Train LB = -405.606, Loss = 388.665
[2018-06-05 02:22] Train Step 75775, Epoch 70.2, Batch Size = 256, Examples/Sec = 3846.79, Train LB = -415.460, Loss = 390.315
[2018-06-05 02:22] Train Step 75800, Epoch 70.2, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -406.096, Loss = 393.156
Performance on test set:
  Test Lower Bound = -452.614, Test Loss = 452.614
[2018-06-05 02:22] Train Step 75825, Epoch 70.2, Batch Size = 256, Examples/Sec = 3868.48, Train LB = -381.569, Loss = 392.339
[2018-06-05 02:22] Train Step 75850, Epoch 70.2, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -383.388, Loss = 391.038
[2018-06-05 02:22] Train Step 75875, Epoch 70.3, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -400.510, Loss = 389.688
[2018-06-05 02:22] Train Step 75900, Epoch 70.3, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -387.858, Loss = 388.461
[2018-06-05 02:22] Train Step 75925, Epoch 70.3, Batch Size = 256, Examples/Sec = 3800.65, Train LB = -383.758, Loss = 387.397
[2018-06-05 02:22] Train Step 75950, Epoch 70.3, Batch Size = 256, Examples/Sec = 3850.39, Train LB = -402.655, Loss = 387.213
[2018-06-05 02:22] Train Step 75975, Epoch 70.3, Batch Size = 256, Examples/Sec = 3844.36, Train LB = -401.682, Loss = 389.241
[2018-06-05 02:22] Train Step 76000, Epoch 70.4, Batch Size = 256, Examples/Sec = 3843.38, Train LB = -414.384, Loss = 392.640
Performance on test set:
  Test Lower Bound = -453.972, Test Loss = 453.972
[2018-06-05 02:22] Train Step 76025, Epoch 70.4, Batch Size = 256, Examples/Sec = 3806.23, Train LB = -388.459, Loss = 391.335
[2018-06-05 02:22] Train Step 76050, Epoch 70.4, Batch Size = 256, Examples/Sec = 3850.50, Train LB = -385.134, Loss = 390.065
[2018-06-05 02:22] Train Step 76075, Epoch 70.4, Batch Size = 256, Examples/Sec = 3858.27, Train LB = -375.134, Loss = 389.750
[2018-06-05 02:22] Train Step 76100, Epoch 70.5, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -377.108, Loss = 388.499
[2018-06-05 02:22] Train Step 76125, Epoch 70.5, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -369.344, Loss = 388.655
[2018-06-05 02:22] Train Step 76150, Epoch 70.5, Batch Size = 256, Examples/Sec = 3874.74, Train LB = -387.778, Loss = 388.129
[2018-06-05 02:22] Train Step 76175, Epoch 70.5, Batch Size = 256, Examples/Sec = 3851.08, Train LB = -411.607, Loss = 390.121
[2018-06-05 02:22] Train Step 76200, Epoch 70.6, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -419.057, Loss = 393.280
Performance on test set:
  Test Lower Bound = -451.432, Test Loss = 451.432
[2018-06-05 02:22] Train Step 76225, Epoch 70.6, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -393.450, Loss = 392.440
[2018-06-05 02:22] Train Step 76250, Epoch 70.6, Batch Size = 256, Examples/Sec = 3846.66, Train LB = -370.080, Loss = 390.699
[2018-06-05 02:22] Train Step 76275, Epoch 70.6, Batch Size = 256, Examples/Sec = 3885.55, Train LB = -377.869, Loss = 390.219
[2018-06-05 02:22] Train Step 76300, Epoch 70.6, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -386.449, Loss = 389.310
[2018-06-05 02:22] Train Step 76325, Epoch 70.7, Batch Size = 256, Examples/Sec = 3846.21, Train LB = -391.418, Loss = 388.027
[2018-06-05 02:22] Train Step 76350, Epoch 70.7, Batch Size = 256, Examples/Sec = 3830.33, Train LB = -390.295, Loss = 388.113
[2018-06-05 02:22] Train Step 76375, Epoch 70.7, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -411.319, Loss = 388.880
[2018-06-05 02:22] Train Step 76400, Epoch 70.7, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -422.277, Loss = 392.687
Performance on test set:
  Test Lower Bound = -453.633, Test Loss = 453.633
[2018-06-05 02:23] Train Step 76425, Epoch 70.8, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -372.839, Loss = 391.744
[2018-06-05 02:23] Train Step 76450, Epoch 70.8, Batch Size = 256, Examples/Sec = 3844.36, Train LB = -395.807, Loss = 390.282
[2018-06-05 02:23] Train Step 76475, Epoch 70.8, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -383.843, Loss = 389.193
[2018-06-05 02:23] Train Step 76500, Epoch 70.8, Batch Size = 256, Examples/Sec = 3852.46, Train LB = -404.474, Loss = 388.657
[2018-06-05 02:23] Train Step 76525, Epoch 70.9, Batch Size = 256, Examples/Sec = 3843.91, Train LB = -391.709, Loss = 388.172
[2018-06-05 02:23] Train Step 76550, Epoch 70.9, Batch Size = 256, Examples/Sec = 3868.13, Train LB = -386.872, Loss = 389.044
[2018-06-05 02:23] Train Step 76575, Epoch 70.9, Batch Size = 256, Examples/Sec = 3791.92, Train LB = -401.941, Loss = 389.925
[2018-06-05 02:23] Train Step 76600, Epoch 70.9, Batch Size = 256, Examples/Sec = 3857.69, Train LB = -405.556, Loss = 393.355
Performance on test set:
  Test Lower Bound = -452.653, Test Loss = 452.653
[2018-06-05 02:23] Train Step 76625, Epoch 70.9, Batch Size = 256, Examples/Sec = 3845.16, Train LB = -394.381, Loss = 392.513
[2018-06-05 02:23] Train Step 76650, Epoch 71.0, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -380.088, Loss = 390.869
[2018-06-05 02:23] Train Step 76675, Epoch 71.0, Batch Size = 256, Examples/Sec = 3806.23, Train LB = -384.824, Loss = 389.232
[2018-06-05 02:23] Train Step 76700, Epoch 71.0, Batch Size = 256, Examples/Sec = 3861.81, Train LB = -397.581, Loss = 388.456
[2018-06-05 02:23] Train Step 76725, Epoch 71.0, Batch Size = 256, Examples/Sec = 3868.13, Train LB = -385.423, Loss = 387.991
[2018-06-05 02:23] Train Step 76750, Epoch 71.1, Batch Size = 256, Examples/Sec = 3870.00, Train LB = -375.175, Loss = 388.183
[2018-06-05 02:23] Train Step 76775, Epoch 71.1, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -400.591, Loss = 389.238
[2018-06-05 02:23] Train Step 76800, Epoch 71.1, Batch Size = 256, Examples/Sec = 3845.70, Train LB = -401.740, Loss = 392.319
Performance on test set:
  Test Lower Bound = -454.438, Test Loss = 454.438
[2018-06-05 02:23] Train Step 76825, Epoch 71.1, Batch Size = 256, Examples/Sec = 3851.42, Train LB = -377.888, Loss = 390.873
[2018-06-05 02:23] Train Step 76850, Epoch 71.2, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -398.525, Loss = 389.755
[2018-06-05 02:23] Train Step 76875, Epoch 71.2, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -378.792, Loss = 388.315
[2018-06-05 02:23] Train Step 76900, Epoch 71.2, Batch Size = 256, Examples/Sec = 3862.98, Train LB = -386.003, Loss = 388.097
[2018-06-05 02:23] Train Step 76925, Epoch 71.2, Batch Size = 256, Examples/Sec = 3848.87, Train LB = -386.762, Loss = 387.650
[2018-06-05 02:23] Train Step 76950, Epoch 71.2, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -388.470, Loss = 388.235
[2018-06-05 02:23] Train Step 76975, Epoch 71.3, Batch Size = 256, Examples/Sec = 3857.62, Train LB = -398.995, Loss = 388.948
[2018-06-05 02:23] Train Step 77000, Epoch 71.3, Batch Size = 256, Examples/Sec = 3852.58, Train LB = -417.872, Loss = 392.373
Performance on test set:
  Test Lower Bound = -453.231, Test Loss = 453.231
[2018-06-05 02:23] Train Step 77025, Epoch 71.3, Batch Size = 256, Examples/Sec = 3821.92, Train LB = -372.680, Loss = 392.139
[2018-06-05 02:23] Train Step 77050, Epoch 71.3, Batch Size = 256, Examples/Sec = 3845.11, Train LB = -392.877, Loss = 390.310
[2018-06-05 02:23] Train Step 77075, Epoch 71.4, Batch Size = 256, Examples/Sec = 3854.89, Train LB = -383.482, Loss = 388.994
[2018-06-05 02:23] Train Step 77100, Epoch 71.4, Batch Size = 256, Examples/Sec = 3879.84, Train LB = -388.559, Loss = 387.886
[2018-06-05 02:23] Train Step 77125, Epoch 71.4, Batch Size = 256, Examples/Sec = 3849.10, Train LB = -384.223, Loss = 387.542
[2018-06-05 02:24] Train Step 77150, Epoch 71.4, Batch Size = 256, Examples/Sec = 3868.42, Train LB = -364.876, Loss = 387.998
[2018-06-05 02:24] Train Step 77175, Epoch 71.5, Batch Size = 256, Examples/Sec = 3847.89, Train LB = -403.725, Loss = 388.771
[2018-06-05 02:24] Train Step 77200, Epoch 71.5, Batch Size = 256, Examples/Sec = 3859.67, Train LB = -414.895, Loss = 392.459
Performance on test set:
  Test Lower Bound = -452.571, Test Loss = 452.571
[2018-06-05 02:24] Train Step 77225, Epoch 71.5, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -387.716, Loss = 391.598
[2018-06-05 02:24] Train Step 77250, Epoch 71.5, Batch Size = 256, Examples/Sec = 3806.92, Train LB = -384.706, Loss = 390.279
[2018-06-05 02:24] Train Step 77275, Epoch 71.6, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -381.999, Loss = 389.308
[2018-06-05 02:24] Train Step 77300, Epoch 71.6, Batch Size = 256, Examples/Sec = 3801.89, Train LB = -385.908, Loss = 388.142
[2018-06-05 02:24] Train Step 77325, Epoch 71.6, Batch Size = 256, Examples/Sec = 3879.08, Train LB = -373.721, Loss = 387.473
[2018-06-05 02:24] Train Step 77350, Epoch 71.6, Batch Size = 256, Examples/Sec = 3834.40, Train LB = -385.705, Loss = 387.758
[2018-06-05 02:24] Train Step 77375, Epoch 71.6, Batch Size = 256, Examples/Sec = 3864.15, Train LB = -394.770, Loss = 389.572
[2018-06-05 02:24] Train Step 77400, Epoch 71.7, Batch Size = 256, Examples/Sec = 3865.73, Train LB = -417.154, Loss = 393.202
Performance on test set:
  Test Lower Bound = -453.074, Test Loss = 453.074
[2018-06-05 02:24] Train Step 77425, Epoch 71.7, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -382.794, Loss = 391.904
[2018-06-05 02:24] Train Step 77450, Epoch 71.7, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -394.770, Loss = 390.194
[2018-06-05 02:24] Train Step 77475, Epoch 71.7, Batch Size = 256, Examples/Sec = 3841.94, Train LB = -380.542, Loss = 388.872
[2018-06-05 02:24] Train Step 77500, Epoch 71.8, Batch Size = 256, Examples/Sec = 3878.09, Train LB = -387.900, Loss = 388.521
[2018-06-05 02:24] Train Step 77525, Epoch 71.8, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -392.302, Loss = 387.706
[2018-06-05 02:24] Train Step 77550, Epoch 71.8, Batch Size = 256, Examples/Sec = 3860.30, Train LB = -376.075, Loss = 387.686
[2018-06-05 02:24] Train Step 77575, Epoch 71.8, Batch Size = 256, Examples/Sec = 3872.51, Train LB = -395.294, Loss = 389.356
[2018-06-05 02:24] Train Step 77600, Epoch 71.9, Batch Size = 256, Examples/Sec = 3874.80, Train LB = -422.511, Loss = 392.877
Performance on test set:
  Test Lower Bound = -452.369, Test Loss = 452.369
[2018-06-05 02:24] Train Step 77625, Epoch 71.9, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -380.259, Loss = 391.801
[2018-06-05 02:24] Train Step 77650, Epoch 71.9, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -386.885, Loss = 390.270
[2018-06-05 02:24] Train Step 77675, Epoch 71.9, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -378.087, Loss = 389.473
[2018-06-05 02:24] Train Step 77700, Epoch 71.9, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -394.884, Loss = 388.803
[2018-06-05 02:24] Train Step 77725, Epoch 72.0, Batch Size = 256, Examples/Sec = 3819.42, Train LB = -381.222, Loss = 388.178
[2018-06-05 02:24] Train Step 77750, Epoch 72.0, Batch Size = 256, Examples/Sec = 3874.27, Train LB = -396.959, Loss = 388.142
[2018-06-05 02:24] Train Step 77775, Epoch 72.0, Batch Size = 256, Examples/Sec = 3807.65, Train LB = -395.662, Loss = 388.826
[2018-06-05 02:24] Train Step 77800, Epoch 72.0, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -402.148, Loss = 392.225
Performance on test set:
  Test Lower Bound = -454.341, Test Loss = 454.341
[2018-06-05 02:24] Train Step 77825, Epoch 72.1, Batch Size = 256, Examples/Sec = 3824.03, Train LB = -383.198, Loss = 391.013
[2018-06-05 02:25] Train Step 77850, Epoch 72.1, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -374.482, Loss = 389.657
[2018-06-05 02:25] Train Step 77875, Epoch 72.1, Batch Size = 256, Examples/Sec = 3834.00, Train LB = -366.988, Loss = 389.398
[2018-06-05 02:25] Train Step 77900, Epoch 72.1, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -392.232, Loss = 388.013
[2018-06-05 02:25] Train Step 77925, Epoch 72.2, Batch Size = 256, Examples/Sec = 3861.52, Train LB = -392.638, Loss = 387.257
[2018-06-05 02:25] Train Step 77950, Epoch 72.2, Batch Size = 256, Examples/Sec = 3859.42, Train LB = -397.169, Loss = 388.173
[2018-06-05 02:25] Train Step 77975, Epoch 72.2, Batch Size = 256, Examples/Sec = 3857.33, Train LB = -416.853, Loss = 389.544
[2018-06-05 02:25] Train Step 78000, Epoch 72.2, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -413.449, Loss = 392.953
Performance on test set:
  Test Lower Bound = -453.477, Test Loss = 453.477
[2018-06-05 02:25] Train Step 78025, Epoch 72.2, Batch Size = 256, Examples/Sec = 3862.98, Train LB = -376.123, Loss = 392.033
[2018-06-05 02:25] Train Step 78050, Epoch 72.3, Batch Size = 256, Examples/Sec = 3836.81, Train LB = -383.715, Loss = 390.430
[2018-06-05 02:25] Train Step 78075, Epoch 72.3, Batch Size = 256, Examples/Sec = 3869.65, Train LB = -385.618, Loss = 389.107
[2018-06-05 02:25] Train Step 78100, Epoch 72.3, Batch Size = 256, Examples/Sec = 3842.05, Train LB = -391.744, Loss = 387.962
[2018-06-05 02:25] Train Step 78125, Epoch 72.3, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -397.246, Loss = 387.386
[2018-06-05 02:25] Train Step 78150, Epoch 72.4, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -367.718, Loss = 387.987
[2018-06-05 02:25] Train Step 78175, Epoch 72.4, Batch Size = 256, Examples/Sec = 3848.58, Train LB = -386.374, Loss = 389.915
[2018-06-05 02:25] Train Step 78200, Epoch 72.4, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -421.914, Loss = 393.071
Performance on test set:
  Test Lower Bound = -453.195, Test Loss = 453.195
[2018-06-05 02:25] Train Step 78225, Epoch 72.4, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -392.209, Loss = 392.246
[2018-06-05 02:25] Train Step 78250, Epoch 72.5, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -377.836, Loss = 390.433
[2018-06-05 02:25] Train Step 78275, Epoch 72.5, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -387.514, Loss = 389.098
[2018-06-05 02:25] Train Step 78300, Epoch 72.5, Batch Size = 256, Examples/Sec = 3824.33, Train LB = -387.198, Loss = 388.303
[2018-06-05 02:25] Train Step 78325, Epoch 72.5, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -380.681, Loss = 387.769
[2018-06-05 02:25] Train Step 78350, Epoch 72.5, Batch Size = 256, Examples/Sec = 3881.68, Train LB = -371.367, Loss = 387.819
[2018-06-05 02:25] Train Step 78375, Epoch 72.6, Batch Size = 256, Examples/Sec = 3881.66, Train LB = -394.250, Loss = 388.973
[2018-06-05 02:25] Train Step 78400, Epoch 72.6, Batch Size = 256, Examples/Sec = 3822.95, Train LB = -406.467, Loss = 393.039
Performance on test set:
  Test Lower Bound = -453.033, Test Loss = 453.033
[2018-06-05 02:25] Train Step 78425, Epoch 72.6, Batch Size = 256, Examples/Sec = 3852.69, Train LB = -377.439, Loss = 392.237
[2018-06-05 02:25] Train Step 78450, Epoch 72.6, Batch Size = 256, Examples/Sec = 3850.21, Train LB = -382.010, Loss = 390.556
[2018-06-05 02:25] Train Step 78475, Epoch 72.7, Batch Size = 256, Examples/Sec = 3865.13, Train LB = -385.304, Loss = 389.914
[2018-06-05 02:25] Train Step 78500, Epoch 72.7, Batch Size = 256, Examples/Sec = 3859.73, Train LB = -375.193, Loss = 388.406
[2018-06-05 02:25] Train Step 78525, Epoch 72.7, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -376.179, Loss = 387.690
[2018-06-05 02:25] Train Step 78550, Epoch 72.7, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -392.077, Loss = 387.474
[2018-06-05 02:25] Train Step 78575, Epoch 72.8, Batch Size = 256, Examples/Sec = 3847.02, Train LB = -404.704, Loss = 388.597
[2018-06-05 02:26] Train Step 78600, Epoch 72.8, Batch Size = 256, Examples/Sec = 3859.78, Train LB = -424.944, Loss = 392.426
Performance on test set:
  Test Lower Bound = -455.733, Test Loss = 455.733
[2018-06-05 02:26] Train Step 78625, Epoch 72.8, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -385.371, Loss = 391.710
[2018-06-05 02:26] Train Step 78650, Epoch 72.8, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -392.234, Loss = 390.139
[2018-06-05 02:26] Train Step 78675, Epoch 72.8, Batch Size = 256, Examples/Sec = 3864.16, Train LB = -379.047, Loss = 389.290
[2018-06-05 02:26] Train Step 78700, Epoch 72.9, Batch Size = 256, Examples/Sec = 3883.67, Train LB = -396.336, Loss = 387.630
[2018-06-05 02:26] Train Step 78725, Epoch 72.9, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -390.801, Loss = 387.502
[2018-06-05 02:26] Train Step 78750, Epoch 72.9, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -379.482, Loss = 387.787
[2018-06-05 02:26] Train Step 78775, Epoch 72.9, Batch Size = 256, Examples/Sec = 3861.48, Train LB = -398.429, Loss = 389.051
[2018-06-05 02:26] Train Step 78800, Epoch 73.0, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -398.783, Loss = 392.384
Performance on test set:
  Test Lower Bound = -454.129, Test Loss = 454.129
[2018-06-05 02:26] Train Step 78825, Epoch 73.0, Batch Size = 256, Examples/Sec = 3860.02, Train LB = -379.029, Loss = 391.351
[2018-06-05 02:26] Train Step 78850, Epoch 73.0, Batch Size = 256, Examples/Sec = 3857.58, Train LB = -385.065, Loss = 389.843
[2018-06-05 02:26] Train Step 78875, Epoch 73.0, Batch Size = 256, Examples/Sec = 3815.61, Train LB = -395.556, Loss = 389.177
[2018-06-05 02:26] Train Step 78900, Epoch 73.1, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -396.602, Loss = 388.081
[2018-06-05 02:26] Train Step 78925, Epoch 73.1, Batch Size = 256, Examples/Sec = 3874.04, Train LB = -395.620, Loss = 387.136
[2018-06-05 02:26] Train Step 78950, Epoch 73.1, Batch Size = 256, Examples/Sec = 3808.11, Train LB = -397.250, Loss = 387.867
[2018-06-05 02:26] Train Step 78975, Epoch 73.1, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -405.457, Loss = 388.771
[2018-06-05 02:26] Train Step 79000, Epoch 73.1, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -426.306, Loss = 392.183
Performance on test set:
  Test Lower Bound = -454.152, Test Loss = 454.152
[2018-06-05 02:26] Train Step 79025, Epoch 73.2, Batch Size = 256, Examples/Sec = 3880.61, Train LB = -386.595, Loss = 391.455
[2018-06-05 02:26] Train Step 79050, Epoch 73.2, Batch Size = 256, Examples/Sec = 3813.15, Train LB = -384.680, Loss = 390.062
[2018-06-05 02:26] Train Step 79075, Epoch 73.2, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -403.690, Loss = 389.032
[2018-06-05 02:26] Train Step 79100, Epoch 73.2, Batch Size = 256, Examples/Sec = 3836.93, Train LB = -391.596, Loss = 387.521
[2018-06-05 02:26] Train Step 79125, Epoch 73.3, Batch Size = 256, Examples/Sec = 3855.36, Train LB = -387.870, Loss = 386.202
[2018-06-05 02:26] Train Step 79150, Epoch 73.3, Batch Size = 256, Examples/Sec = 3848.81, Train LB = -394.983, Loss = 386.735
[2018-06-05 02:26] Train Step 79175, Epoch 73.3, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -411.125, Loss = 387.843
[2018-06-05 02:26] Train Step 79200, Epoch 73.3, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -418.605, Loss = 391.737
Performance on test set:
  Test Lower Bound = -454.350, Test Loss = 454.350
[2018-06-05 02:26] Train Step 79225, Epoch 73.4, Batch Size = 256, Examples/Sec = 3870.40, Train LB = -376.265, Loss = 391.176
[2018-06-05 02:26] Train Step 79250, Epoch 73.4, Batch Size = 256, Examples/Sec = 3840.55, Train LB = -377.627, Loss = 389.882
[2018-06-05 02:26] Train Step 79275, Epoch 73.4, Batch Size = 256, Examples/Sec = 3855.36, Train LB = -382.160, Loss = 389.010
[2018-06-05 02:27] Train Step 79300, Epoch 73.4, Batch Size = 256, Examples/Sec = 3849.10, Train LB = -388.792, Loss = 388.512
[2018-06-05 02:27] Train Step 79325, Epoch 73.4, Batch Size = 256, Examples/Sec = 3871.15, Train LB = -385.654, Loss = 387.492
[2018-06-05 02:27] Train Step 79350, Epoch 73.5, Batch Size = 256, Examples/Sec = 3847.42, Train LB = -385.882, Loss = 388.102
[2018-06-05 02:27] Train Step 79375, Epoch 73.5, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -395.706, Loss = 388.797
[2018-06-05 02:27] Train Step 79400, Epoch 73.5, Batch Size = 256, Examples/Sec = 3846.04, Train LB = -414.282, Loss = 392.163
Performance on test set:
  Test Lower Bound = -455.066, Test Loss = 455.066
[2018-06-05 02:27] Train Step 79425, Epoch 73.5, Batch Size = 256, Examples/Sec = 3861.99, Train LB = -375.217, Loss = 390.967
[2018-06-05 02:27] Train Step 79450, Epoch 73.6, Batch Size = 256, Examples/Sec = 3788.32, Train LB = -378.829, Loss = 389.535
[2018-06-05 02:27] Train Step 79475, Epoch 73.6, Batch Size = 256, Examples/Sec = 3877.08, Train LB = -382.910, Loss = 388.916
[2018-06-05 02:27] Train Step 79500, Epoch 73.6, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -374.220, Loss = 387.438
[2018-06-05 02:27] Train Step 79525, Epoch 73.6, Batch Size = 256, Examples/Sec = 3862.80, Train LB = -391.519, Loss = 387.154
[2018-06-05 02:27] Train Step 79550, Epoch 73.7, Batch Size = 256, Examples/Sec = 3860.37, Train LB = -379.445, Loss = 387.117
[2018-06-05 02:27] Train Step 79575, Epoch 73.7, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -381.843, Loss = 388.803
[2018-06-05 02:27] Train Step 79600, Epoch 73.7, Batch Size = 256, Examples/Sec = 3855.72, Train LB = -431.947, Loss = 392.403
Performance on test set:
  Test Lower Bound = -453.115, Test Loss = 453.115
[2018-06-05 02:27] Train Step 79625, Epoch 73.7, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -384.744, Loss = 391.030
[2018-06-05 02:27] Train Step 79650, Epoch 73.8, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -387.947, Loss = 389.729
[2018-06-05 02:27] Train Step 79675, Epoch 73.8, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -384.964, Loss = 388.895
[2018-06-05 02:27] Train Step 79700, Epoch 73.8, Batch Size = 256, Examples/Sec = 3870.57, Train LB = -378.371, Loss = 387.739
[2018-06-05 02:27] Train Step 79725, Epoch 73.8, Batch Size = 256, Examples/Sec = 3853.74, Train LB = -373.606, Loss = 387.552
[2018-06-05 02:27] Train Step 79750, Epoch 73.8, Batch Size = 256, Examples/Sec = 3862.17, Train LB = -382.288, Loss = 387.256
[2018-06-05 02:27] Train Step 79775, Epoch 73.9, Batch Size = 256, Examples/Sec = 3844.65, Train LB = -405.861, Loss = 388.945
[2018-06-05 02:27] Train Step 79800, Epoch 73.9, Batch Size = 256, Examples/Sec = 3792.25, Train LB = -416.324, Loss = 392.613
Performance on test set:
  Test Lower Bound = -454.463, Test Loss = 454.463
[2018-06-05 02:27] Train Step 79825, Epoch 73.9, Batch Size = 256, Examples/Sec = 3846.21, Train LB = -378.501, Loss = 391.429
[2018-06-05 02:27] Train Step 79850, Epoch 73.9, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -389.159, Loss = 389.753
[2018-06-05 02:27] Train Step 79875, Epoch 74.0, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -387.278, Loss = 388.351
[2018-06-05 02:27] Train Step 79900, Epoch 74.0, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -379.176, Loss = 387.565
[2018-06-05 02:27] Train Step 79925, Epoch 74.0, Batch Size = 256, Examples/Sec = 3853.97, Train LB = -376.139, Loss = 386.762
[2018-06-05 02:27] Train Step 79950, Epoch 74.0, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -399.078, Loss = 386.762
[2018-06-05 02:27] Train Step 79975, Epoch 74.1, Batch Size = 256, Examples/Sec = 3844.07, Train LB = -401.288, Loss = 388.652
[2018-06-05 02:27] Train Step 80000, Epoch 74.1, Batch Size = 256, Examples/Sec = 3857.97, Train LB = -414.331, Loss = 392.069
Performance on test set:
  Test Lower Bound = -453.758, Test Loss = 453.758
[2018-06-05 02:28] Train Step 80025, Epoch 74.1, Batch Size = 256, Examples/Sec = 3812.71, Train LB = -384.190, Loss = 390.650
[2018-06-05 02:28] Train Step 80050, Epoch 74.1, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -385.124, Loss = 389.210
[2018-06-05 02:28] Train Step 80075, Epoch 74.1, Batch Size = 256, Examples/Sec = 3863.09, Train LB = -393.284, Loss = 388.252
[2018-06-05 02:28] Train Step 80100, Epoch 74.2, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -403.814, Loss = 387.048
[2018-06-05 02:28] Train Step 80125, Epoch 74.2, Batch Size = 256, Examples/Sec = 3877.96, Train LB = -384.590, Loss = 386.921
[2018-06-05 02:28] Train Step 80150, Epoch 74.2, Batch Size = 256, Examples/Sec = 3874.45, Train LB = -398.679, Loss = 386.962
[2018-06-05 02:28] Train Step 80175, Epoch 74.2, Batch Size = 256, Examples/Sec = 3854.38, Train LB = -384.863, Loss = 388.203
[2018-06-05 02:28] Train Step 80200, Epoch 74.3, Batch Size = 256, Examples/Sec = 3867.29, Train LB = -389.935, Loss = 392.354
Performance on test set:
  Test Lower Bound = -454.154, Test Loss = 454.154
[2018-06-05 02:28] Train Step 80225, Epoch 74.3, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -379.020, Loss = 391.062
[2018-06-05 02:28] Train Step 80250, Epoch 74.3, Batch Size = 256, Examples/Sec = 3864.22, Train LB = -392.214, Loss = 389.653
[2018-06-05 02:28] Train Step 80275, Epoch 74.3, Batch Size = 256, Examples/Sec = 3856.35, Train LB = -389.786, Loss = 388.476
[2018-06-05 02:28] Train Step 80300, Epoch 74.4, Batch Size = 256, Examples/Sec = 3866.94, Train LB = -376.338, Loss = 387.514
[2018-06-05 02:28] Train Step 80325, Epoch 74.4, Batch Size = 256, Examples/Sec = 3840.10, Train LB = -388.134, Loss = 386.933
[2018-06-05 02:28] Train Step 80350, Epoch 74.4, Batch Size = 256, Examples/Sec = 3801.21, Train LB = -389.595, Loss = 386.941
[2018-06-05 02:28] Train Step 80375, Epoch 74.4, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -401.611, Loss = 388.221
[2018-06-05 02:28] Train Step 80400, Epoch 74.4, Batch Size = 256, Examples/Sec = 3849.27, Train LB = -423.979, Loss = 392.099
Performance on test set:
  Test Lower Bound = -454.324, Test Loss = 454.324
[2018-06-05 02:28] Train Step 80425, Epoch 74.5, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -384.604, Loss = 391.085
[2018-06-05 02:28] Train Step 80450, Epoch 74.5, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -386.677, Loss = 389.601
[2018-06-05 02:28] Train Step 80475, Epoch 74.5, Batch Size = 256, Examples/Sec = 3876.73, Train LB = -384.512, Loss = 389.096
[2018-06-05 02:28] Train Step 80500, Epoch 74.5, Batch Size = 256, Examples/Sec = 3819.01, Train LB = -381.143, Loss = 387.219
[2018-06-05 02:28] Train Step 80525, Epoch 74.6, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -383.801, Loss = 386.903
[2018-06-05 02:28] Train Step 80550, Epoch 74.6, Batch Size = 256, Examples/Sec = 3844.77, Train LB = -375.743, Loss = 386.805
[2018-06-05 02:28] Train Step 80575, Epoch 74.6, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -389.963, Loss = 388.426
[2018-06-05 02:28] Train Step 80600, Epoch 74.6, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -423.250, Loss = 392.034
Performance on test set:
  Test Lower Bound = -455.429, Test Loss = 455.429
[2018-06-05 02:28] Train Step 80625, Epoch 74.7, Batch Size = 256, Examples/Sec = 3886.57, Train LB = -388.936, Loss = 391.395
[2018-06-05 02:28] Train Step 80650, Epoch 74.7, Batch Size = 256, Examples/Sec = 3854.21, Train LB = -387.063, Loss = 389.561
[2018-06-05 02:28] Train Step 80675, Epoch 74.7, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -388.165, Loss = 388.203
[2018-06-05 02:28] Train Step 80700, Epoch 74.7, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -371.244, Loss = 386.944
[2018-06-05 02:29] Train Step 80725, Epoch 74.7, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -375.901, Loss = 386.506
[2018-06-05 02:29] Train Step 80750, Epoch 74.8, Batch Size = 256, Examples/Sec = 3860.83, Train LB = -378.521, Loss = 387.030
[2018-06-05 02:29] Train Step 80775, Epoch 74.8, Batch Size = 256, Examples/Sec = 3860.59, Train LB = -400.295, Loss = 388.474
[2018-06-05 02:29] Train Step 80800, Epoch 74.8, Batch Size = 256, Examples/Sec = 3807.54, Train LB = -408.602, Loss = 391.594
Performance on test set:
  Test Lower Bound = -455.269, Test Loss = 455.269
[2018-06-05 02:29] Train Step 80825, Epoch 74.8, Batch Size = 256, Examples/Sec = 3865.61, Train LB = -382.229, Loss = 390.897
[2018-06-05 02:29] Train Step 80850, Epoch 74.9, Batch Size = 256, Examples/Sec = 3874.45, Train LB = -376.762, Loss = 389.276
[2018-06-05 02:29] Train Step 80875, Epoch 74.9, Batch Size = 256, Examples/Sec = 3866.65, Train LB = -376.181, Loss = 387.363
[2018-06-05 02:29] Train Step 80900, Epoch 74.9, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -391.757, Loss = 386.447
[2018-06-05 02:29] Train Step 80925, Epoch 74.9, Batch Size = 256, Examples/Sec = 3873.28, Train LB = -382.948, Loss = 386.257
[2018-06-05 02:29] Train Step 80950, Epoch 75.0, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -397.900, Loss = 386.240
[2018-06-05 02:29] Train Step 80975, Epoch 75.0, Batch Size = 256, Examples/Sec = 3809.99, Train LB = -408.537, Loss = 387.695
[2018-06-05 02:29] Train Step 81000, Epoch 75.0, Batch Size = 256, Examples/Sec = 3878.68, Train LB = -398.601, Loss = 391.329
Performance on test set:
  Test Lower Bound = -454.713, Test Loss = 454.713
[2018-06-05 02:29] Train Step 81025, Epoch 75.0, Batch Size = 256, Examples/Sec = 3869.59, Train LB = -393.794, Loss = 389.876
[2018-06-05 02:29] Train Step 81050, Epoch 75.0, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -393.016, Loss = 388.877
[2018-06-05 02:29] Train Step 81075, Epoch 75.1, Batch Size = 256, Examples/Sec = 3781.99, Train LB = -386.753, Loss = 387.750
[2018-06-05 02:29] Train Step 81100, Epoch 75.1, Batch Size = 256, Examples/Sec = 3873.02, Train LB = -410.473, Loss = 386.638
[2018-06-05 02:29] Train Step 81125, Epoch 75.1, Batch Size = 256, Examples/Sec = 3854.31, Train LB = -374.869, Loss = 386.293
[2018-06-05 02:29] Train Step 81150, Epoch 75.1, Batch Size = 256, Examples/Sec = 3878.61, Train LB = -384.924, Loss = 386.731
[2018-06-05 02:29] Train Step 81175, Epoch 75.2, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -406.255, Loss = 387.903
[2018-06-05 02:29] Train Step 81200, Epoch 75.2, Batch Size = 256, Examples/Sec = 3861.17, Train LB = -405.352, Loss = 391.956
Performance on test set:
  Test Lower Bound = -452.960, Test Loss = 452.960
[2018-06-05 02:29] Train Step 81225, Epoch 75.2, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -370.653, Loss = 390.645
[2018-06-05 02:29] Train Step 81250, Epoch 75.2, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -395.266, Loss = 389.657
[2018-06-05 02:29] Train Step 81275, Epoch 75.3, Batch Size = 256, Examples/Sec = 3872.63, Train LB = -369.965, Loss = 388.548
[2018-06-05 02:29] Train Step 81300, Epoch 75.3, Batch Size = 256, Examples/Sec = 3821.47, Train LB = -378.853, Loss = 387.462
[2018-06-05 02:29] Train Step 81325, Epoch 75.3, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -378.401, Loss = 386.601
[2018-06-05 02:29] Train Step 81350, Epoch 75.3, Batch Size = 256, Examples/Sec = 3881.31, Train LB = -390.705, Loss = 386.857
[2018-06-05 02:29] Train Step 81375, Epoch 75.3, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -395.756, Loss = 388.403
[2018-06-05 02:29] Train Step 81400, Epoch 75.4, Batch Size = 256, Examples/Sec = 3858.80, Train LB = -402.288, Loss = 391.686
Performance on test set:
  Test Lower Bound = -455.203, Test Loss = 455.203
[2018-06-05 02:30] Train Step 81425, Epoch 75.4, Batch Size = 256, Examples/Sec = 3871.98, Train LB = -386.593, Loss = 390.554
[2018-06-05 02:30] Train Step 81450, Epoch 75.4, Batch Size = 256, Examples/Sec = 3863.85, Train LB = -385.175, Loss = 389.535
[2018-06-05 02:30] Train Step 81475, Epoch 75.4, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -395.355, Loss = 387.837
[2018-06-05 02:30] Train Step 81500, Epoch 75.5, Batch Size = 256, Examples/Sec = 3871.39, Train LB = -370.945, Loss = 386.950
[2018-06-05 02:30] Train Step 81525, Epoch 75.5, Batch Size = 256, Examples/Sec = 3867.00, Train LB = -359.824, Loss = 386.333
[2018-06-05 02:30] Train Step 81550, Epoch 75.5, Batch Size = 256, Examples/Sec = 3879.49, Train LB = -386.063, Loss = 386.999
[2018-06-05 02:30] Train Step 81575, Epoch 75.5, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -407.955, Loss = 388.063
[2018-06-05 02:30] Train Step 81600, Epoch 75.6, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -409.675, Loss = 390.724
Performance on test set:
  Test Lower Bound = -457.211, Test Loss = 457.211
[2018-06-05 02:30] Train Step 81625, Epoch 75.6, Batch Size = 256, Examples/Sec = 3853.34, Train LB = -381.000, Loss = 390.687
[2018-06-05 02:30] Train Step 81650, Epoch 75.6, Batch Size = 256, Examples/Sec = 3853.16, Train LB = -389.287, Loss = 389.206
[2018-06-05 02:30] Train Step 81675, Epoch 75.6, Batch Size = 256, Examples/Sec = 3846.85, Train LB = -381.653, Loss = 388.506
[2018-06-05 02:30] Train Step 81700, Epoch 75.6, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -394.320, Loss = 387.639
[2018-06-05 02:30] Train Step 81725, Epoch 75.7, Batch Size = 256, Examples/Sec = 3790.23, Train LB = -375.036, Loss = 387.474
[2018-06-05 02:30] Train Step 81750, Epoch 75.7, Batch Size = 256, Examples/Sec = 3857.23, Train LB = -390.124, Loss = 387.054
[2018-06-05 02:30] Train Step 81775, Epoch 75.7, Batch Size = 256, Examples/Sec = 3854.15, Train LB = -401.117, Loss = 388.091
[2018-06-05 02:30] Train Step 81800, Epoch 75.7, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -413.406, Loss = 391.512
Performance on test set:
  Test Lower Bound = -457.620, Test Loss = 457.620
[2018-06-05 02:30] Train Step 81825, Epoch 75.8, Batch Size = 256, Examples/Sec = 3823.17, Train LB = -379.064, Loss = 390.328
[2018-06-05 02:30] Train Step 81850, Epoch 75.8, Batch Size = 256, Examples/Sec = 3815.98, Train LB = -381.480, Loss = 389.059
[2018-06-05 02:30] Train Step 81875, Epoch 75.8, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -380.850, Loss = 388.004
[2018-06-05 02:30] Train Step 81900, Epoch 75.8, Batch Size = 256, Examples/Sec = 3880.78, Train LB = -391.217, Loss = 386.643
[2018-06-05 02:30] Train Step 81925, Epoch 75.9, Batch Size = 256, Examples/Sec = 3871.98, Train LB = -386.252, Loss = 386.785
[2018-06-05 02:30] Train Step 81950, Epoch 75.9, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -379.861, Loss = 386.710
[2018-06-05 02:30] Train Step 81975, Epoch 75.9, Batch Size = 256, Examples/Sec = 3857.04, Train LB = -399.473, Loss = 387.799
[2018-06-05 02:30] Train Step 82000, Epoch 75.9, Batch Size = 256, Examples/Sec = 3863.46, Train LB = -409.206, Loss = 391.235
Performance on test set:
  Test Lower Bound = -455.126, Test Loss = 455.126
[2018-06-05 02:30] Train Step 82025, Epoch 75.9, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -384.942, Loss = 390.619
[2018-06-05 02:30] Train Step 82050, Epoch 76.0, Batch Size = 256, Examples/Sec = 3848.98, Train LB = -396.765, Loss = 389.152
[2018-06-05 02:30] Train Step 82075, Epoch 76.0, Batch Size = 256, Examples/Sec = 3864.84, Train LB = -385.748, Loss = 388.153
[2018-06-05 02:30] Train Step 82100, Epoch 76.0, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -377.639, Loss = 387.410
[2018-06-05 02:30] Train Step 82125, Epoch 76.0, Batch Size = 256, Examples/Sec = 3830.05, Train LB = -382.366, Loss = 386.315
[2018-06-05 02:30] Train Step 82150, Epoch 76.1, Batch Size = 256, Examples/Sec = 3866.94, Train LB = -402.736, Loss = 385.686
[2018-06-05 02:31] Train Step 82175, Epoch 76.1, Batch Size = 256, Examples/Sec = 3870.47, Train LB = -389.027, Loss = 387.947
[2018-06-05 02:31] Train Step 82200, Epoch 76.1, Batch Size = 256, Examples/Sec = 3799.90, Train LB = -411.861, Loss = 391.369
Performance on test set:
  Test Lower Bound = -455.628, Test Loss = 455.628
[2018-06-05 02:31] Train Step 82225, Epoch 76.1, Batch Size = 256, Examples/Sec = 3851.37, Train LB = -374.304, Loss = 390.672
[2018-06-05 02:31] Train Step 82250, Epoch 76.2, Batch Size = 256, Examples/Sec = 3861.17, Train LB = -392.280, Loss = 388.859
[2018-06-05 02:31] Train Step 82275, Epoch 76.2, Batch Size = 256, Examples/Sec = 3856.11, Train LB = -397.241, Loss = 388.152
[2018-06-05 02:31] Train Step 82300, Epoch 76.2, Batch Size = 256, Examples/Sec = 3799.17, Train LB = -382.683, Loss = 386.442
[2018-06-05 02:31] Train Step 82325, Epoch 76.2, Batch Size = 256, Examples/Sec = 3847.02, Train LB = -383.152, Loss = 385.970
[2018-06-05 02:31] Train Step 82350, Epoch 76.2, Batch Size = 256, Examples/Sec = 3840.86, Train LB = -392.479, Loss = 386.087
[2018-06-05 02:31] Train Step 82375, Epoch 76.3, Batch Size = 256, Examples/Sec = 3835.33, Train LB = -396.130, Loss = 387.029
[2018-06-05 02:31] Train Step 82400, Epoch 76.3, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -416.528, Loss = 391.174
Performance on test set:
  Test Lower Bound = -454.979, Test Loss = 454.979
[2018-06-05 02:31] Train Step 82425, Epoch 76.3, Batch Size = 256, Examples/Sec = 3876.03, Train LB = -388.617, Loss = 390.117
[2018-06-05 02:31] Train Step 82450, Epoch 76.3, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -403.172, Loss = 388.476
[2018-06-05 02:31] Train Step 82475, Epoch 76.4, Batch Size = 256, Examples/Sec = 3809.12, Train LB = -388.163, Loss = 387.626
[2018-06-05 02:31] Train Step 82500, Epoch 76.4, Batch Size = 256, Examples/Sec = 3875.44, Train LB = -384.707, Loss = 386.292
[2018-06-05 02:31] Train Step 82525, Epoch 76.4, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -378.346, Loss = 385.364
[2018-06-05 02:31] Train Step 82550, Epoch 76.4, Batch Size = 256, Examples/Sec = 3854.84, Train LB = -387.369, Loss = 386.392
[2018-06-05 02:31] Train Step 82575, Epoch 76.5, Batch Size = 256, Examples/Sec = 3866.37, Train LB = -398.842, Loss = 387.579
[2018-06-05 02:31] Train Step 82600, Epoch 76.5, Batch Size = 256, Examples/Sec = 3826.32, Train LB = -417.131, Loss = 391.427
Performance on test set:
  Test Lower Bound = -455.201, Test Loss = 455.201
[2018-06-05 02:31] Train Step 82625, Epoch 76.5, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -381.520, Loss = 390.420
[2018-06-05 02:31] Train Step 82650, Epoch 76.5, Batch Size = 256, Examples/Sec = 3850.15, Train LB = -383.448, Loss = 388.680
[2018-06-05 02:31] Train Step 82675, Epoch 76.6, Batch Size = 256, Examples/Sec = 3876.67, Train LB = -378.051, Loss = 387.777
[2018-06-05 02:31] Train Step 82700, Epoch 76.6, Batch Size = 256, Examples/Sec = 3852.47, Train LB = -388.153, Loss = 386.836
[2018-06-05 02:31] Train Step 82725, Epoch 76.6, Batch Size = 256, Examples/Sec = 3833.59, Train LB = -378.188, Loss = 385.707
[2018-06-05 02:31] Train Step 82750, Epoch 76.6, Batch Size = 256, Examples/Sec = 3859.13, Train LB = -378.833, Loss = 385.566
[2018-06-05 02:31] Train Step 82775, Epoch 76.6, Batch Size = 256, Examples/Sec = 3803.64, Train LB = -393.082, Loss = 387.184
[2018-06-05 02:31] Train Step 82800, Epoch 76.7, Batch Size = 256, Examples/Sec = 3874.16, Train LB = -400.483, Loss = 390.943
Performance on test set:
  Test Lower Bound = -456.163, Test Loss = 456.163
[2018-06-05 02:31] Train Step 82825, Epoch 76.7, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -390.906, Loss = 389.701
[2018-06-05 02:32] Train Step 82850, Epoch 76.7, Batch Size = 256, Examples/Sec = 3850.77, Train LB = -407.930, Loss = 388.366
[2018-06-05 02:32] Train Step 82875, Epoch 76.7, Batch Size = 256, Examples/Sec = 3813.15, Train LB = -382.296, Loss = 387.507
[2018-06-05 02:32] Train Step 82900, Epoch 76.8, Batch Size = 256, Examples/Sec = 3839.74, Train LB = -395.444, Loss = 386.540
[2018-06-05 02:32] Train Step 82925, Epoch 76.8, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -358.085, Loss = 386.122
[2018-06-05 02:32] Train Step 82950, Epoch 76.8, Batch Size = 256, Examples/Sec = 3855.36, Train LB = -389.292, Loss = 386.190
[2018-06-05 02:32] Train Step 82975, Epoch 76.8, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -400.423, Loss = 387.549
[2018-06-05 02:32] Train Step 83000, Epoch 76.9, Batch Size = 256, Examples/Sec = 3816.50, Train LB = -427.692, Loss = 391.086
Performance on test set:
  Test Lower Bound = -457.186, Test Loss = 457.186
[2018-06-05 02:32] Train Step 83025, Epoch 76.9, Batch Size = 256, Examples/Sec = 3864.74, Train LB = -388.555, Loss = 389.863
[2018-06-05 02:32] Train Step 83050, Epoch 76.9, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -372.860, Loss = 388.625
[2018-06-05 02:32] Train Step 83075, Epoch 76.9, Batch Size = 256, Examples/Sec = 3846.91, Train LB = -377.840, Loss = 387.761
[2018-06-05 02:32] Train Step 83100, Epoch 76.9, Batch Size = 256, Examples/Sec = 3807.77, Train LB = -380.349, Loss = 386.832
[2018-06-05 02:32] Train Step 83125, Epoch 77.0, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -396.895, Loss = 385.910
[2018-06-05 02:32] Train Step 83150, Epoch 77.0, Batch Size = 256, Examples/Sec = 3862.69, Train LB = -391.058, Loss = 386.611
[2018-06-05 02:32] Train Step 83175, Epoch 77.0, Batch Size = 256, Examples/Sec = 3843.26, Train LB = -397.671, Loss = 388.269
[2018-06-05 02:32] Train Step 83200, Epoch 77.0, Batch Size = 256, Examples/Sec = 3858.44, Train LB = -409.812, Loss = 392.072
Performance on test set:
  Test Lower Bound = -454.501, Test Loss = 454.501
[2018-06-05 02:32] Train Step 83225, Epoch 77.1, Batch Size = 256, Examples/Sec = 3860.31, Train LB = -389.113, Loss = 390.431
[2018-06-05 02:32] Train Step 83250, Epoch 77.1, Batch Size = 256, Examples/Sec = 3848.58, Train LB = -387.988, Loss = 389.484
[2018-06-05 02:32] Train Step 83275, Epoch 77.1, Batch Size = 256, Examples/Sec = 3838.30, Train LB = -384.496, Loss = 387.787
[2018-06-05 02:32] Train Step 83300, Epoch 77.1, Batch Size = 256, Examples/Sec = 3846.55, Train LB = -382.619, Loss = 386.841
[2018-06-05 02:32] Train Step 83325, Epoch 77.2, Batch Size = 256, Examples/Sec = 3850.48, Train LB = -376.352, Loss = 386.279
[2018-06-05 02:32] Train Step 83350, Epoch 77.2, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -399.938, Loss = 386.059
[2018-06-05 02:32] Train Step 83375, Epoch 77.2, Batch Size = 256, Examples/Sec = 3844.31, Train LB = -397.361, Loss = 387.631
[2018-06-05 02:32] Train Step 83400, Epoch 77.2, Batch Size = 256, Examples/Sec = 3829.42, Train LB = -422.881, Loss = 391.163
Performance on test set:
  Test Lower Bound = -454.453, Test Loss = 454.453
[2018-06-05 02:32] Train Step 83425, Epoch 77.2, Batch Size = 256, Examples/Sec = 3867.78, Train LB = -377.652, Loss = 390.300
[2018-06-05 02:32] Train Step 83450, Epoch 77.3, Batch Size = 256, Examples/Sec = 3820.74, Train LB = -373.519, Loss = 388.685
[2018-06-05 02:32] Train Step 83475, Epoch 77.3, Batch Size = 256, Examples/Sec = 3847.31, Train LB = -382.095, Loss = 387.569
[2018-06-05 02:32] Train Step 83500, Epoch 77.3, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -383.103, Loss = 386.440
[2018-06-05 02:32] Train Step 83525, Epoch 77.3, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -394.311, Loss = 385.593
[2018-06-05 02:32] Train Step 83550, Epoch 77.4, Batch Size = 256, Examples/Sec = 3836.88, Train LB = -386.294, Loss = 386.070
[2018-06-05 02:32] Train Step 83575, Epoch 77.4, Batch Size = 256, Examples/Sec = 3867.19, Train LB = -391.637, Loss = 386.965
[2018-06-05 02:33] Train Step 83600, Epoch 77.4, Batch Size = 256, Examples/Sec = 3852.46, Train LB = -420.870, Loss = 390.611
Performance on test set:
  Test Lower Bound = -456.676, Test Loss = 456.676
[2018-06-05 02:33] Train Step 83625, Epoch 77.4, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -382.789, Loss = 390.165
[2018-06-05 02:33] Train Step 83650, Epoch 77.5, Batch Size = 256, Examples/Sec = 3794.66, Train LB = -363.214, Loss = 388.238
[2018-06-05 02:33] Train Step 83675, Epoch 77.5, Batch Size = 256, Examples/Sec = 3848.65, Train LB = -393.386, Loss = 387.308
[2018-06-05 02:33] Train Step 83700, Epoch 77.5, Batch Size = 256, Examples/Sec = 3860.49, Train LB = -376.590, Loss = 386.498
[2018-06-05 02:33] Train Step 83725, Epoch 77.5, Batch Size = 256, Examples/Sec = 3841.89, Train LB = -370.811, Loss = 385.815
[2018-06-05 02:33] Train Step 83750, Epoch 77.5, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -377.762, Loss = 385.856
[2018-06-05 02:33] Train Step 83775, Epoch 77.6, Batch Size = 256, Examples/Sec = 3866.96, Train LB = -394.698, Loss = 387.090
[2018-06-05 02:33] Train Step 83800, Epoch 77.6, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -409.363, Loss = 390.867
Performance on test set:
  Test Lower Bound = -457.411, Test Loss = 457.411
[2018-06-05 02:33] Train Step 83825, Epoch 77.6, Batch Size = 256, Examples/Sec = 3862.76, Train LB = -368.157, Loss = 390.088
[2018-06-05 02:33] Train Step 83850, Epoch 77.6, Batch Size = 256, Examples/Sec = 3859.09, Train LB = -362.328, Loss = 388.194
[2018-06-05 02:33] Train Step 83875, Epoch 77.7, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -380.170, Loss = 386.714
[2018-06-05 02:33] Train Step 83900, Epoch 77.7, Batch Size = 256, Examples/Sec = 3853.40, Train LB = -375.233, Loss = 385.749
[2018-06-05 02:33] Train Step 83925, Epoch 77.7, Batch Size = 256, Examples/Sec = 3805.57, Train LB = -389.811, Loss = 385.144
[2018-06-05 02:33] Train Step 83950, Epoch 77.7, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -396.194, Loss = 385.584
[2018-06-05 02:33] Train Step 83975, Epoch 77.8, Batch Size = 256, Examples/Sec = 3882.14, Train LB = -396.249, Loss = 387.289
[2018-06-05 02:33] Train Step 84000, Epoch 77.8, Batch Size = 256, Examples/Sec = 3884.20, Train LB = -431.987, Loss = 390.255
Performance on test set:
  Test Lower Bound = -455.636, Test Loss = 455.636
[2018-06-05 02:33] Train Step 84025, Epoch 77.8, Batch Size = 256, Examples/Sec = 3810.59, Train LB = -377.840, Loss = 389.437
[2018-06-05 02:33] Train Step 84050, Epoch 77.8, Batch Size = 256, Examples/Sec = 3855.42, Train LB = -385.152, Loss = 388.538
[2018-06-05 02:33] Train Step 84075, Epoch 77.8, Batch Size = 256, Examples/Sec = 3853.69, Train LB = -370.058, Loss = 387.451
[2018-06-05 02:33] Train Step 84100, Epoch 77.9, Batch Size = 256, Examples/Sec = 3872.91, Train LB = -375.098, Loss = 385.405
[2018-06-05 02:33] Train Step 84125, Epoch 77.9, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -381.130, Loss = 385.755
[2018-06-05 02:33] Train Step 84150, Epoch 77.9, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -390.277, Loss = 386.228
[2018-06-05 02:33] Train Step 84175, Epoch 77.9, Batch Size = 256, Examples/Sec = 3832.34, Train LB = -400.135, Loss = 387.278
[2018-06-05 02:33] Train Step 84200, Epoch 78.0, Batch Size = 256, Examples/Sec = 3857.09, Train LB = -402.740, Loss = 390.774
Performance on test set:
  Test Lower Bound = -456.953, Test Loss = 456.953
[2018-06-05 02:33] Train Step 84225, Epoch 78.0, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -387.840, Loss = 389.992
[2018-06-05 02:33] Train Step 84250, Epoch 78.0, Batch Size = 256, Examples/Sec = 3847.89, Train LB = -392.839, Loss = 388.344
[2018-06-05 02:33] Train Step 84275, Epoch 78.0, Batch Size = 256, Examples/Sec = 3801.65, Train LB = -388.620, Loss = 387.403
[2018-06-05 02:34] Train Step 84300, Epoch 78.1, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -386.933, Loss = 385.955
[2018-06-05 02:34] Train Step 84325, Epoch 78.1, Batch Size = 256, Examples/Sec = 3864.55, Train LB = -386.167, Loss = 385.853
[2018-06-05 02:34] Train Step 84350, Epoch 78.1, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -383.860, Loss = 385.760
[2018-06-05 02:34] Train Step 84375, Epoch 78.1, Batch Size = 256, Examples/Sec = 3849.57, Train LB = -403.008, Loss = 386.461
[2018-06-05 02:34] Train Step 84400, Epoch 78.1, Batch Size = 256, Examples/Sec = 3872.98, Train LB = -414.185, Loss = 390.662
Performance on test set:
  Test Lower Bound = -456.784, Test Loss = 456.784
[2018-06-05 02:34] Train Step 84425, Epoch 78.2, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -388.501, Loss = 389.054
[2018-06-05 02:34] Train Step 84450, Epoch 78.2, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -378.855, Loss = 388.372
[2018-06-05 02:34] Train Step 84475, Epoch 78.2, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -390.045, Loss = 387.092
[2018-06-05 02:34] Train Step 84500, Epoch 78.2, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -393.857, Loss = 385.903
[2018-06-05 02:34] Train Step 84525, Epoch 78.3, Batch Size = 256, Examples/Sec = 3885.79, Train LB = -372.511, Loss = 385.577
[2018-06-05 02:34] Train Step 84550, Epoch 78.3, Batch Size = 256, Examples/Sec = 3867.82, Train LB = -392.019, Loss = 385.473
[2018-06-05 02:34] Train Step 84575, Epoch 78.3, Batch Size = 256, Examples/Sec = 3846.21, Train LB = -382.145, Loss = 386.994
[2018-06-05 02:34] Train Step 84600, Epoch 78.3, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -416.669, Loss = 390.539
Performance on test set:
  Test Lower Bound = -458.333, Test Loss = 458.333
[2018-06-05 02:34] Train Step 84625, Epoch 78.4, Batch Size = 256, Examples/Sec = 3875.04, Train LB = -384.325, Loss = 389.621
[2018-06-05 02:34] Train Step 84650, Epoch 78.4, Batch Size = 256, Examples/Sec = 3880.43, Train LB = -383.953, Loss = 388.468
[2018-06-05 02:34] Train Step 84675, Epoch 78.4, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -390.285, Loss = 387.094
[2018-06-05 02:34] Train Step 84700, Epoch 78.4, Batch Size = 256, Examples/Sec = 3861.17, Train LB = -383.893, Loss = 386.314
[2018-06-05 02:34] Train Step 84725, Epoch 78.4, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -373.241, Loss = 384.869
[2018-06-05 02:34] Train Step 84750, Epoch 78.5, Batch Size = 256, Examples/Sec = 3866.32, Train LB = -390.256, Loss = 385.439
[2018-06-05 02:34] Train Step 84775, Epoch 78.5, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -400.592, Loss = 386.235
[2018-06-05 02:34] Train Step 84800, Epoch 78.5, Batch Size = 256, Examples/Sec = 3866.07, Train LB = -414.216, Loss = 390.273
Performance on test set:
  Test Lower Bound = -456.772, Test Loss = 456.772
[2018-06-05 02:34] Train Step 84825, Epoch 78.5, Batch Size = 256, Examples/Sec = 3806.97, Train LB = -397.448, Loss = 389.621
[2018-06-05 02:34] Train Step 84850, Epoch 78.6, Batch Size = 256, Examples/Sec = 3873.68, Train LB = -377.624, Loss = 388.644
[2018-06-05 02:34] Train Step 84875, Epoch 78.6, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -381.376, Loss = 386.798
[2018-06-05 02:34] Train Step 84900, Epoch 78.6, Batch Size = 256, Examples/Sec = 3876.56, Train LB = -393.373, Loss = 385.639
[2018-06-05 02:34] Train Step 84925, Epoch 78.6, Batch Size = 256, Examples/Sec = 3861.30, Train LB = -376.151, Loss = 385.307
[2018-06-05 02:34] Train Step 84950, Epoch 78.7, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -385.271, Loss = 385.340
[2018-06-05 02:34] Train Step 84975, Epoch 78.7, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -387.043, Loss = 387.279
[2018-06-05 02:34] Train Step 85000, Epoch 78.7, Batch Size = 256, Examples/Sec = 3846.85, Train LB = -427.928, Loss = 390.292
Performance on test set:
  Test Lower Bound = -458.122, Test Loss = 458.122
[2018-06-05 02:35] Train Step 85025, Epoch 78.7, Batch Size = 256, Examples/Sec = 3850.32, Train LB = -385.316, Loss = 389.263
[2018-06-05 02:35] Train Step 85050, Epoch 78.8, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -384.940, Loss = 388.077
[2018-06-05 02:35] Train Step 85075, Epoch 78.8, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -367.395, Loss = 387.429
[2018-06-05 02:35] Train Step 85100, Epoch 78.8, Batch Size = 256, Examples/Sec = 3849.90, Train LB = -385.365, Loss = 385.922
[2018-06-05 02:35] Train Step 85125, Epoch 78.8, Batch Size = 256, Examples/Sec = 3879.38, Train LB = -383.943, Loss = 385.117
[2018-06-05 02:35] Train Step 85150, Epoch 78.8, Batch Size = 256, Examples/Sec = 3838.48, Train LB = -388.397, Loss = 385.912
[2018-06-05 02:35] Train Step 85175, Epoch 78.9, Batch Size = 256, Examples/Sec = 3862.74, Train LB = -406.252, Loss = 386.303
[2018-06-05 02:35] Train Step 85200, Epoch 78.9, Batch Size = 256, Examples/Sec = 3810.15, Train LB = -404.443, Loss = 389.894
Performance on test set:
  Test Lower Bound = -457.042, Test Loss = 457.042
[2018-06-05 02:35] Train Step 85225, Epoch 78.9, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -388.001, Loss = 388.605
[2018-06-05 02:35] Train Step 85250, Epoch 78.9, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -379.160, Loss = 387.712
[2018-06-05 02:35] Train Step 85275, Epoch 79.0, Batch Size = 256, Examples/Sec = 3858.85, Train LB = -370.451, Loss = 386.740
[2018-06-05 02:35] Train Step 85300, Epoch 79.0, Batch Size = 256, Examples/Sec = 3878.14, Train LB = -373.832, Loss = 385.312
[2018-06-05 02:35] Train Step 85325, Epoch 79.0, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -391.710, Loss = 385.006
[2018-06-05 02:35] Train Step 85350, Epoch 79.0, Batch Size = 256, Examples/Sec = 3841.47, Train LB = -382.303, Loss = 385.665
[2018-06-05 02:35] Train Step 85375, Epoch 79.1, Batch Size = 256, Examples/Sec = 3848.40, Train LB = -384.171, Loss = 386.796
[2018-06-05 02:35] Train Step 85400, Epoch 79.1, Batch Size = 256, Examples/Sec = 3825.46, Train LB = -406.809, Loss = 390.531
Performance on test set:
  Test Lower Bound = -457.222, Test Loss = 457.222
[2018-06-05 02:35] Train Step 85425, Epoch 79.1, Batch Size = 256, Examples/Sec = 3826.72, Train LB = -379.029, Loss = 389.731
[2018-06-05 02:35] Train Step 85450, Epoch 79.1, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -370.175, Loss = 387.855
[2018-06-05 02:35] Train Step 85475, Epoch 79.1, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -400.573, Loss = 386.459
[2018-06-05 02:35] Train Step 85500, Epoch 79.2, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -385.992, Loss = 386.064
[2018-06-05 02:35] Train Step 85525, Epoch 79.2, Batch Size = 256, Examples/Sec = 3819.01, Train LB = -380.385, Loss = 385.363
[2018-06-05 02:35] Train Step 85550, Epoch 79.2, Batch Size = 256, Examples/Sec = 3828.61, Train LB = -379.134, Loss = 385.402
[2018-06-05 02:35] Train Step 85575, Epoch 79.2, Batch Size = 256, Examples/Sec = 3869.19, Train LB = -409.324, Loss = 386.413
[2018-06-05 02:35] Train Step 85600, Epoch 79.3, Batch Size = 256, Examples/Sec = 3837.27, Train LB = -413.583, Loss = 389.887
Performance on test set:
  Test Lower Bound = -456.879, Test Loss = 456.879
[2018-06-05 02:35] Train Step 85625, Epoch 79.3, Batch Size = 256, Examples/Sec = 3855.43, Train LB = -392.545, Loss = 388.334
[2018-06-05 02:35] Train Step 85650, Epoch 79.3, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -396.147, Loss = 387.850
[2018-06-05 02:35] Train Step 85675, Epoch 79.3, Batch Size = 256, Examples/Sec = 3851.35, Train LB = -380.177, Loss = 386.814
[2018-06-05 02:35] Train Step 85700, Epoch 79.4, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -377.365, Loss = 385.549
[2018-06-05 02:36] Train Step 85725, Epoch 79.4, Batch Size = 256, Examples/Sec = 3854.71, Train LB = -372.060, Loss = 385.295
[2018-06-05 02:36] Train Step 85750, Epoch 79.4, Batch Size = 256, Examples/Sec = 3831.02, Train LB = -379.157, Loss = 385.420
[2018-06-05 02:36] Train Step 85775, Epoch 79.4, Batch Size = 256, Examples/Sec = 3886.57, Train LB = -393.080, Loss = 386.785
[2018-06-05 02:36] Train Step 85800, Epoch 79.4, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -422.792, Loss = 390.459
Performance on test set:
  Test Lower Bound = -456.135, Test Loss = 456.135
[2018-06-05 02:36] Train Step 85825, Epoch 79.5, Batch Size = 256, Examples/Sec = 3857.62, Train LB = -393.459, Loss = 389.603
[2018-06-05 02:36] Train Step 85850, Epoch 79.5, Batch Size = 256, Examples/Sec = 3848.18, Train LB = -376.046, Loss = 387.922
[2018-06-05 02:36] Train Step 85875, Epoch 79.5, Batch Size = 256, Examples/Sec = 3860.84, Train LB = -388.883, Loss = 386.867
[2018-06-05 02:36] Train Step 85900, Epoch 79.5, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -386.187, Loss = 385.559
[2018-06-05 02:36] Train Step 85925, Epoch 79.6, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -384.909, Loss = 384.946
[2018-06-05 02:36] Train Step 85950, Epoch 79.6, Batch Size = 256, Examples/Sec = 3871.75, Train LB = -385.822, Loss = 384.926
[2018-06-05 02:36] Train Step 85975, Epoch 79.6, Batch Size = 256, Examples/Sec = 3815.54, Train LB = -383.440, Loss = 386.354
[2018-06-05 02:36] Train Step 86000, Epoch 79.6, Batch Size = 256, Examples/Sec = 3860.55, Train LB = -412.925, Loss = 389.855
Performance on test set:
  Test Lower Bound = -456.901, Test Loss = 456.901
[2018-06-05 02:36] Train Step 86025, Epoch 79.7, Batch Size = 256, Examples/Sec = 3860.55, Train LB = -373.337, Loss = 388.750
[2018-06-05 02:36] Train Step 86050, Epoch 79.7, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -380.510, Loss = 387.313
[2018-06-05 02:36] Train Step 86075, Epoch 79.7, Batch Size = 256, Examples/Sec = 3800.13, Train LB = -388.640, Loss = 385.930
[2018-06-05 02:36] Train Step 86100, Epoch 79.7, Batch Size = 256, Examples/Sec = 3867.53, Train LB = -398.551, Loss = 384.661
[2018-06-05 02:36] Train Step 86125, Epoch 79.7, Batch Size = 256, Examples/Sec = 3876.62, Train LB = -401.831, Loss = 384.281
[2018-06-05 02:36] Train Step 86150, Epoch 79.8, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -390.741, Loss = 385.142
[2018-06-05 02:36] Train Step 86175, Epoch 79.8, Batch Size = 256, Examples/Sec = 3876.20, Train LB = -413.397, Loss = 386.138
[2018-06-05 02:36] Train Step 86200, Epoch 79.8, Batch Size = 256, Examples/Sec = 3859.09, Train LB = -409.044, Loss = 390.213
Performance on test set:
  Test Lower Bound = -457.331, Test Loss = 457.331
[2018-06-05 02:36] Train Step 86225, Epoch 79.8, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -380.674, Loss = 389.086
[2018-06-05 02:36] Train Step 86250, Epoch 79.9, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -385.970, Loss = 388.056
[2018-06-05 02:36] Train Step 86275, Epoch 79.9, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -384.855, Loss = 386.986
[2018-06-05 02:36] Train Step 86300, Epoch 79.9, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -363.034, Loss = 385.852
[2018-06-05 02:36] Train Step 86325, Epoch 79.9, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -391.780, Loss = 384.699
[2018-06-05 02:36] Train Step 86350, Epoch 80.0, Batch Size = 256, Examples/Sec = 3835.15, Train LB = -394.383, Loss = 384.353
[2018-06-05 02:36] Train Step 86375, Epoch 80.0, Batch Size = 256, Examples/Sec = 3815.09, Train LB = -389.050, Loss = 386.663
[2018-06-05 02:36] Train Step 86400, Epoch 80.0, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -412.567, Loss = 390.194
Performance on test set:
  Test Lower Bound = -457.265, Test Loss = 457.265
[2018-06-05 02:37] Train Step 86425, Epoch 80.0, Batch Size = 256, Examples/Sec = 3888.27, Train LB = -373.893, Loss = 389.251
[2018-06-05 02:37] Train Step 86450, Epoch 80.0, Batch Size = 256, Examples/Sec = 3887.09, Train LB = -380.081, Loss = 387.254
[2018-06-05 02:37] Train Step 86475, Epoch 80.1, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -387.600, Loss = 386.744
[2018-06-05 02:37] Train Step 86500, Epoch 80.1, Batch Size = 256, Examples/Sec = 3874.74, Train LB = -358.404, Loss = 385.728
[2018-06-05 02:37] Train Step 86525, Epoch 80.1, Batch Size = 256, Examples/Sec = 3854.44, Train LB = -376.954, Loss = 384.863
[2018-06-05 02:37] Train Step 86550, Epoch 80.1, Batch Size = 256, Examples/Sec = 3833.60, Train LB = -383.202, Loss = 385.010
[2018-06-05 02:37] Train Step 86575, Epoch 80.2, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -395.142, Loss = 386.569
[2018-06-05 02:37] Train Step 86600, Epoch 80.2, Batch Size = 256, Examples/Sec = 3850.73, Train LB = -409.285, Loss = 390.471
Performance on test set:
  Test Lower Bound = -457.454, Test Loss = 457.454
[2018-06-05 02:37] Train Step 86625, Epoch 80.2, Batch Size = 256, Examples/Sec = 3829.87, Train LB = -375.875, Loss = 389.438
[2018-06-05 02:37] Train Step 86650, Epoch 80.2, Batch Size = 256, Examples/Sec = 3826.66, Train LB = -376.904, Loss = 387.830
[2018-06-05 02:37] Train Step 86675, Epoch 80.3, Batch Size = 256, Examples/Sec = 3868.71, Train LB = -394.774, Loss = 386.196
[2018-06-05 02:37] Train Step 86700, Epoch 80.3, Batch Size = 256, Examples/Sec = 3846.80, Train LB = -386.428, Loss = 385.962
[2018-06-05 02:37] Train Step 86725, Epoch 80.3, Batch Size = 256, Examples/Sec = 3835.04, Train LB = -384.619, Loss = 384.748
[2018-06-05 02:37] Train Step 86750, Epoch 80.3, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -376.151, Loss = 385.682
[2018-06-05 02:37] Train Step 86775, Epoch 80.3, Batch Size = 256, Examples/Sec = 3879.49, Train LB = -402.339, Loss = 386.790
[2018-06-05 02:37] Train Step 86800, Epoch 80.4, Batch Size = 256, Examples/Sec = 3878.44, Train LB = -414.125, Loss = 389.866
Performance on test set:
  Test Lower Bound = -458.568, Test Loss = 458.568
[2018-06-05 02:37] Train Step 86825, Epoch 80.4, Batch Size = 256, Examples/Sec = 3847.82, Train LB = -388.413, Loss = 389.058
[2018-06-05 02:37] Train Step 86850, Epoch 80.4, Batch Size = 256, Examples/Sec = 3873.86, Train LB = -371.932, Loss = 387.843
[2018-06-05 02:37] Train Step 86875, Epoch 80.4, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -387.814, Loss = 386.260
[2018-06-05 02:37] Train Step 86900, Epoch 80.5, Batch Size = 256, Examples/Sec = 3854.84, Train LB = -388.211, Loss = 384.569
[2018-06-05 02:37] Train Step 86925, Epoch 80.5, Batch Size = 256, Examples/Sec = 3847.94, Train LB = -365.307, Loss = 384.717
[2018-06-05 02:37] Train Step 86950, Epoch 80.5, Batch Size = 256, Examples/Sec = 3843.89, Train LB = -396.738, Loss = 385.077
[2018-06-05 02:37] Train Step 86975, Epoch 80.5, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -408.146, Loss = 386.356
[2018-06-05 02:37] Train Step 87000, Epoch 80.6, Batch Size = 256, Examples/Sec = 3831.30, Train LB = -401.859, Loss = 389.495
Performance on test set:
  Test Lower Bound = -458.309, Test Loss = 458.309
[2018-06-05 02:37] Train Step 87025, Epoch 80.6, Batch Size = 256, Examples/Sec = 3854.85, Train LB = -370.499, Loss = 388.707
[2018-06-05 02:37] Train Step 87050, Epoch 80.6, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -399.430, Loss = 387.244
[2018-06-05 02:37] Train Step 87075, Epoch 80.6, Batch Size = 256, Examples/Sec = 3878.37, Train LB = -373.947, Loss = 385.462
[2018-06-05 02:37] Train Step 87100, Epoch 80.6, Batch Size = 256, Examples/Sec = 3877.85, Train LB = -381.331, Loss = 384.925
[2018-06-05 02:37] Train Step 87125, Epoch 80.7, Batch Size = 256, Examples/Sec = 3867.29, Train LB = -397.573, Loss = 384.048
[2018-06-05 02:37] Train Step 87150, Epoch 80.7, Batch Size = 256, Examples/Sec = 3848.59, Train LB = -410.861, Loss = 383.989
[2018-06-05 02:38] Train Step 87175, Epoch 80.7, Batch Size = 256, Examples/Sec = 3847.65, Train LB = -390.966, Loss = 386.001
[2018-06-05 02:38] Train Step 87200, Epoch 80.7, Batch Size = 256, Examples/Sec = 3851.55, Train LB = -392.952, Loss = 389.614
Performance on test set:
  Test Lower Bound = -456.846, Test Loss = 456.846
[2018-06-05 02:38] Train Step 87225, Epoch 80.8, Batch Size = 256, Examples/Sec = 3829.94, Train LB = -377.711, Loss = 389.011
[2018-06-05 02:38] Train Step 87250, Epoch 80.8, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -381.222, Loss = 388.148
[2018-06-05 02:38] Train Step 87275, Epoch 80.8, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -376.002, Loss = 386.457
[2018-06-05 02:38] Train Step 87300, Epoch 80.8, Batch Size = 256, Examples/Sec = 3848.70, Train LB = -394.595, Loss = 384.898
[2018-06-05 02:38] Train Step 87325, Epoch 80.9, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -377.401, Loss = 384.092
[2018-06-05 02:38] Train Step 87350, Epoch 80.9, Batch Size = 256, Examples/Sec = 3851.66, Train LB = -398.629, Loss = 384.707
[2018-06-05 02:38] Train Step 87375, Epoch 80.9, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -391.172, Loss = 385.846
[2018-06-05 02:38] Train Step 87400, Epoch 80.9, Batch Size = 256, Examples/Sec = 3867.67, Train LB = -404.676, Loss = 389.143
Performance on test set:
  Test Lower Bound = -457.536, Test Loss = 457.536
[2018-06-05 02:38] Train Step 87425, Epoch 80.9, Batch Size = 256, Examples/Sec = 3841.71, Train LB = -393.134, Loss = 387.372
[2018-06-05 02:38] Train Step 87450, Epoch 81.0, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -385.314, Loss = 386.606
[2018-06-05 02:38] Train Step 87475, Epoch 81.0, Batch Size = 256, Examples/Sec = 3845.23, Train LB = -375.095, Loss = 385.893
[2018-06-05 02:38] Train Step 87500, Epoch 81.0, Batch Size = 256, Examples/Sec = 3880.74, Train LB = -368.770, Loss = 385.320
[2018-06-05 02:38] Train Step 87525, Epoch 81.0, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -392.864, Loss = 384.850
[2018-06-05 02:38] Train Step 87550, Epoch 81.1, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -392.285, Loss = 384.717
[2018-06-05 02:38] Train Step 87575, Epoch 81.1, Batch Size = 256, Examples/Sec = 3870.40, Train LB = -404.566, Loss = 386.659
[2018-06-05 02:38] Train Step 87600, Epoch 81.1, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -405.931, Loss = 390.198
Performance on test set:
  Test Lower Bound = -457.764, Test Loss = 457.764
[2018-06-05 02:38] Train Step 87625, Epoch 81.1, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -383.259, Loss = 389.310
[2018-06-05 02:38] Train Step 87650, Epoch 81.2, Batch Size = 256, Examples/Sec = 3844.31, Train LB = -381.219, Loss = 387.607
[2018-06-05 02:38] Train Step 87675, Epoch 81.2, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -385.086, Loss = 386.639
[2018-06-05 02:38] Train Step 87700, Epoch 81.2, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -396.856, Loss = 385.153
[2018-06-05 02:38] Train Step 87725, Epoch 81.2, Batch Size = 256, Examples/Sec = 3879.27, Train LB = -376.033, Loss = 384.755
[2018-06-05 02:38] Train Step 87750, Epoch 81.2, Batch Size = 256, Examples/Sec = 3878.03, Train LB = -385.982, Loss = 384.412
[2018-06-05 02:38] Train Step 87775, Epoch 81.3, Batch Size = 256, Examples/Sec = 3846.97, Train LB = -386.438, Loss = 386.559
[2018-06-05 02:38] Train Step 87800, Epoch 81.3, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -419.940, Loss = 390.137
Performance on test set:
  Test Lower Bound = -456.444, Test Loss = 456.444
[2018-06-05 02:38] Train Step 87825, Epoch 81.3, Batch Size = 256, Examples/Sec = 3861.71, Train LB = -369.337, Loss = 389.207
[2018-06-05 02:38] Train Step 87850, Epoch 81.3, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -399.296, Loss = 387.781
[2018-06-05 02:39] Train Step 87875, Epoch 81.4, Batch Size = 256, Examples/Sec = 3874.80, Train LB = -379.726, Loss = 386.586
[2018-06-05 02:39] Train Step 87900, Epoch 81.4, Batch Size = 256, Examples/Sec = 3858.45, Train LB = -384.061, Loss = 385.361
[2018-06-05 02:39] Train Step 87925, Epoch 81.4, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -379.253, Loss = 384.739
[2018-06-05 02:39] Train Step 87950, Epoch 81.4, Batch Size = 256, Examples/Sec = 3849.03, Train LB = -389.822, Loss = 384.479
[2018-06-05 02:39] Train Step 87975, Epoch 81.5, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -412.453, Loss = 385.700
[2018-06-05 02:39] Train Step 88000, Epoch 81.5, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -412.148, Loss = 389.037
Performance on test set:
  Test Lower Bound = -458.068, Test Loss = 458.068
[2018-06-05 02:39] Train Step 88025, Epoch 81.5, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -371.439, Loss = 388.001
[2018-06-05 02:39] Train Step 88050, Epoch 81.5, Batch Size = 256, Examples/Sec = 3872.34, Train LB = -369.123, Loss = 386.479
[2018-06-05 02:39] Train Step 88075, Epoch 81.6, Batch Size = 256, Examples/Sec = 3864.20, Train LB = -386.511, Loss = 385.847
[2018-06-05 02:39] Train Step 88100, Epoch 81.6, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -395.269, Loss = 385.001
[2018-06-05 02:39] Train Step 88125, Epoch 81.6, Batch Size = 256, Examples/Sec = 3848.58, Train LB = -392.764, Loss = 384.763
[2018-06-05 02:39] Train Step 88150, Epoch 81.6, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -378.237, Loss = 384.616
[2018-06-05 02:39] Train Step 88175, Epoch 81.6, Batch Size = 256, Examples/Sec = 3857.97, Train LB = -395.489, Loss = 386.361
[2018-06-05 02:39] Train Step 88200, Epoch 81.7, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -404.821, Loss = 389.928
Performance on test set:
  Test Lower Bound = -458.309, Test Loss = 458.309
[2018-06-05 02:39] Train Step 88225, Epoch 81.7, Batch Size = 256, Examples/Sec = 3881.44, Train LB = -372.243, Loss = 389.036
[2018-06-05 02:39] Train Step 88250, Epoch 81.7, Batch Size = 256, Examples/Sec = 3865.66, Train LB = -374.881, Loss = 387.368
[2018-06-05 02:39] Train Step 88275, Epoch 81.7, Batch Size = 256, Examples/Sec = 3871.74, Train LB = -374.954, Loss = 386.332
[2018-06-05 02:39] Train Step 88300, Epoch 81.8, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -364.446, Loss = 385.797
[2018-06-05 02:39] Train Step 88325, Epoch 81.8, Batch Size = 256, Examples/Sec = 3828.09, Train LB = -377.829, Loss = 384.190
[2018-06-05 02:39] Train Step 88350, Epoch 81.8, Batch Size = 256, Examples/Sec = 3817.64, Train LB = -376.074, Loss = 384.261
[2018-06-05 02:39] Train Step 88375, Epoch 81.8, Batch Size = 256, Examples/Sec = 3844.25, Train LB = -404.617, Loss = 385.947
[2018-06-05 02:39] Train Step 88400, Epoch 81.9, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -410.104, Loss = 389.927
Performance on test set:
  Test Lower Bound = -456.496, Test Loss = 456.496
[2018-06-05 02:39] Train Step 88425, Epoch 81.9, Batch Size = 256, Examples/Sec = 3821.06, Train LB = -368.349, Loss = 389.004
[2018-06-05 02:39] Train Step 88450, Epoch 81.9, Batch Size = 256, Examples/Sec = 3832.16, Train LB = -372.885, Loss = 387.729
[2018-06-05 02:39] Train Step 88475, Epoch 81.9, Batch Size = 256, Examples/Sec = 3875.68, Train LB = -385.545, Loss = 386.763
[2018-06-05 02:39] Train Step 88500, Epoch 81.9, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -385.311, Loss = 385.319
[2018-06-05 02:39] Train Step 88525, Epoch 82.0, Batch Size = 256, Examples/Sec = 3855.76, Train LB = -376.468, Loss = 384.622
[2018-06-05 02:39] Train Step 88550, Epoch 82.0, Batch Size = 256, Examples/Sec = 3873.28, Train LB = -377.430, Loss = 384.446
[2018-06-05 02:39] Train Step 88575, Epoch 82.0, Batch Size = 256, Examples/Sec = 3848.54, Train LB = -398.050, Loss = 385.417
[2018-06-05 02:40] Train Step 88600, Epoch 82.0, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -414.967, Loss = 389.536
Performance on test set:
  Test Lower Bound = -456.217, Test Loss = 456.217
[2018-06-05 02:40] Train Step 88625, Epoch 82.1, Batch Size = 256, Examples/Sec = 3874.73, Train LB = -380.282, Loss = 388.758
[2018-06-05 02:40] Train Step 88650, Epoch 82.1, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -368.867, Loss = 387.520
[2018-06-05 02:40] Train Step 88675, Epoch 82.1, Batch Size = 256, Examples/Sec = 3867.18, Train LB = -369.370, Loss = 385.975
[2018-06-05 02:40] Train Step 88700, Epoch 82.1, Batch Size = 256, Examples/Sec = 3878.44, Train LB = -384.172, Loss = 384.093
[2018-06-05 02:40] Train Step 88725, Epoch 82.2, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -381.075, Loss = 383.868
[2018-06-05 02:40] Train Step 88750, Epoch 82.2, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -390.033, Loss = 384.052
[2018-06-05 02:40] Train Step 88775, Epoch 82.2, Batch Size = 256, Examples/Sec = 3880.61, Train LB = -384.744, Loss = 385.712
[2018-06-05 02:40] Train Step 88800, Epoch 82.2, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -407.861, Loss = 388.912
Performance on test set:
  Test Lower Bound = -457.913, Test Loss = 457.913
[2018-06-05 02:40] Train Step 88825, Epoch 82.2, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -377.418, Loss = 387.780
[2018-06-05 02:40] Train Step 88850, Epoch 82.3, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -385.754, Loss = 385.900
[2018-06-05 02:40] Train Step 88875, Epoch 82.3, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -381.903, Loss = 384.578
[2018-06-05 02:40] Train Step 88900, Epoch 82.3, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -387.731, Loss = 384.707
[2018-06-05 02:40] Train Step 88925, Epoch 82.3, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -395.084, Loss = 384.669
[2018-06-05 02:40] Train Step 88950, Epoch 82.4, Batch Size = 256, Examples/Sec = 3878.49, Train LB = -385.552, Loss = 384.731
[2018-06-05 02:40] Train Step 88975, Epoch 82.4, Batch Size = 256, Examples/Sec = 3860.49, Train LB = -421.114, Loss = 386.247
[2018-06-05 02:40] Train Step 89000, Epoch 82.4, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -405.260, Loss = 389.772
Performance on test set:
  Test Lower Bound = -459.355, Test Loss = 459.355
[2018-06-05 02:40] Train Step 89025, Epoch 82.4, Batch Size = 256, Examples/Sec = 3799.85, Train LB = -399.230, Loss = 388.886
[2018-06-05 02:40] Train Step 89050, Epoch 82.5, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -400.442, Loss = 387.344
[2018-06-05 02:40] Train Step 89075, Epoch 82.5, Batch Size = 256, Examples/Sec = 3879.14, Train LB = -384.238, Loss = 385.832
[2018-06-05 02:40] Train Step 89100, Epoch 82.5, Batch Size = 256, Examples/Sec = 3875.04, Train LB = -393.922, Loss = 384.343
[2018-06-05 02:40] Train Step 89125, Epoch 82.5, Batch Size = 256, Examples/Sec = 3809.92, Train LB = -397.520, Loss = 383.394
[2018-06-05 02:40] Train Step 89150, Epoch 82.5, Batch Size = 256, Examples/Sec = 3858.80, Train LB = -399.964, Loss = 383.901
[2018-06-05 02:40] Train Step 89175, Epoch 82.6, Batch Size = 256, Examples/Sec = 3856.17, Train LB = -390.932, Loss = 386.596
[2018-06-05 02:40] Train Step 89200, Epoch 82.6, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -410.943, Loss = 390.217
Performance on test set:
  Test Lower Bound = -457.959, Test Loss = 457.959
[2018-06-05 02:40] Train Step 89225, Epoch 82.6, Batch Size = 256, Examples/Sec = 3868.00, Train LB = -391.651, Loss = 389.514
[2018-06-05 02:40] Train Step 89250, Epoch 82.6, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -386.768, Loss = 387.775
[2018-06-05 02:40] Train Step 89275, Epoch 82.7, Batch Size = 256, Examples/Sec = 3850.61, Train LB = -379.913, Loss = 386.105
[2018-06-05 02:41] Train Step 89300, Epoch 82.7, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -379.873, Loss = 384.494
[2018-06-05 02:41] Train Step 89325, Epoch 82.7, Batch Size = 256, Examples/Sec = 3839.17, Train LB = -374.306, Loss = 383.927
[2018-06-05 02:41] Train Step 89350, Epoch 82.7, Batch Size = 256, Examples/Sec = 3816.85, Train LB = -403.307, Loss = 383.851
[2018-06-05 02:41] Train Step 89375, Epoch 82.8, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -393.087, Loss = 385.207
[2018-06-05 02:41] Train Step 89400, Epoch 82.8, Batch Size = 256, Examples/Sec = 3853.50, Train LB = -408.236, Loss = 389.695
Performance on test set:
  Test Lower Bound = -457.812, Test Loss = 457.812
[2018-06-05 02:41] Train Step 89425, Epoch 82.8, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -385.993, Loss = 388.224
[2018-06-05 02:41] Train Step 89450, Epoch 82.8, Batch Size = 256, Examples/Sec = 3845.28, Train LB = -386.696, Loss = 387.175
[2018-06-05 02:41] Train Step 89475, Epoch 82.8, Batch Size = 256, Examples/Sec = 3884.96, Train LB = -380.809, Loss = 385.848
[2018-06-05 02:41] Train Step 89500, Epoch 82.9, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -390.022, Loss = 384.698
[2018-06-05 02:41] Train Step 89525, Epoch 82.9, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -397.243, Loss = 383.701
[2018-06-05 02:41] Train Step 89550, Epoch 82.9, Batch Size = 256, Examples/Sec = 3850.50, Train LB = -391.664, Loss = 384.548
[2018-06-05 02:41] Train Step 89575, Epoch 82.9, Batch Size = 256, Examples/Sec = 3824.89, Train LB = -398.443, Loss = 385.533
[2018-06-05 02:41] Train Step 89600, Epoch 83.0, Batch Size = 256, Examples/Sec = 3870.53, Train LB = -405.097, Loss = 389.282
Performance on test set:
  Test Lower Bound = -458.096, Test Loss = 458.096
[2018-06-05 02:41] Train Step 89625, Epoch 83.0, Batch Size = 256, Examples/Sec = 3864.26, Train LB = -380.600, Loss = 388.417
[2018-06-05 02:41] Train Step 89650, Epoch 83.0, Batch Size = 256, Examples/Sec = 3875.26, Train LB = -375.502, Loss = 386.698
[2018-06-05 02:41] Train Step 89675, Epoch 83.0, Batch Size = 256, Examples/Sec = 3826.39, Train LB = -377.830, Loss = 385.455
[2018-06-05 02:41] Train Step 89700, Epoch 83.1, Batch Size = 256, Examples/Sec = 3849.57, Train LB = -377.388, Loss = 383.318
[2018-06-05 02:41] Train Step 89725, Epoch 83.1, Batch Size = 256, Examples/Sec = 3839.87, Train LB = -372.551, Loss = 382.881
[2018-06-05 02:41] Train Step 89750, Epoch 83.1, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -387.230, Loss = 383.848
[2018-06-05 02:41] Train Step 89775, Epoch 83.1, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -388.971, Loss = 385.628
[2018-06-05 02:41] Train Step 89800, Epoch 83.1, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -406.056, Loss = 389.134
Performance on test set:
  Test Lower Bound = -458.808, Test Loss = 458.808
[2018-06-05 02:41] Train Step 89825, Epoch 83.2, Batch Size = 256, Examples/Sec = 3870.76, Train LB = -389.065, Loss = 387.520
[2018-06-05 02:41] Train Step 89850, Epoch 83.2, Batch Size = 256, Examples/Sec = 3865.15, Train LB = -387.598, Loss = 386.406
[2018-06-05 02:41] Train Step 89875, Epoch 83.2, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -366.706, Loss = 385.777
[2018-06-05 02:41] Train Step 89900, Epoch 83.2, Batch Size = 256, Examples/Sec = 3853.38, Train LB = -382.278, Loss = 384.132
[2018-06-05 02:41] Train Step 89925, Epoch 83.3, Batch Size = 256, Examples/Sec = 3851.12, Train LB = -402.493, Loss = 383.699
[2018-06-05 02:41] Train Step 89950, Epoch 83.3, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -385.978, Loss = 384.244
[2018-06-05 02:41] Train Step 89975, Epoch 83.3, Batch Size = 256, Examples/Sec = 3825.35, Train LB = -382.162, Loss = 385.710
[2018-06-05 02:41] Train Step 90000, Epoch 83.3, Batch Size = 256, Examples/Sec = 3873.33, Train LB = -421.022, Loss = 389.162
Performance on test set:
  Test Lower Bound = -458.875, Test Loss = 458.875
[2018-06-05 02:42] Train Step 90025, Epoch 83.4, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -377.153, Loss = 387.861
[2018-06-05 02:42] Train Step 90050, Epoch 83.4, Batch Size = 256, Examples/Sec = 3870.12, Train LB = -389.912, Loss = 386.909
[2018-06-05 02:42] Train Step 90075, Epoch 83.4, Batch Size = 256, Examples/Sec = 3802.23, Train LB = -383.624, Loss = 386.061
[2018-06-05 02:42] Train Step 90100, Epoch 83.4, Batch Size = 256, Examples/Sec = 3877.85, Train LB = -381.563, Loss = 384.269
[2018-06-05 02:42] Train Step 90125, Epoch 83.4, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -374.257, Loss = 384.064
[2018-06-05 02:42] Train Step 90150, Epoch 83.5, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -388.110, Loss = 384.344
[2018-06-05 02:42] Train Step 90175, Epoch 83.5, Batch Size = 256, Examples/Sec = 3857.93, Train LB = -386.081, Loss = 385.897
[2018-06-05 02:42] Train Step 90200, Epoch 83.5, Batch Size = 256, Examples/Sec = 3793.15, Train LB = -420.880, Loss = 389.425
Performance on test set:
  Test Lower Bound = -458.437, Test Loss = 458.437
[2018-06-05 02:42] Train Step 90225, Epoch 83.5, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -408.288, Loss = 388.312
[2018-06-05 02:42] Train Step 90250, Epoch 83.6, Batch Size = 256, Examples/Sec = 3860.30, Train LB = -392.239, Loss = 386.290
[2018-06-05 02:42] Train Step 90275, Epoch 83.6, Batch Size = 256, Examples/Sec = 3857.51, Train LB = -389.950, Loss = 385.584
[2018-06-05 02:42] Train Step 90300, Epoch 83.6, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -372.784, Loss = 384.554
[2018-06-05 02:42] Train Step 90325, Epoch 83.6, Batch Size = 256, Examples/Sec = 3849.27, Train LB = -381.572, Loss = 383.222
[2018-06-05 02:42] Train Step 90350, Epoch 83.7, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -378.853, Loss = 383.753
[2018-06-05 02:42] Train Step 90375, Epoch 83.7, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -397.815, Loss = 385.302
[2018-06-05 02:42] Train Step 90400, Epoch 83.7, Batch Size = 256, Examples/Sec = 3873.56, Train LB = -417.843, Loss = 389.354
Performance on test set:
  Test Lower Bound = -458.403, Test Loss = 458.403
[2018-06-05 02:42] Train Step 90425, Epoch 83.7, Batch Size = 256, Examples/Sec = 3870.82, Train LB = -385.144, Loss = 388.531
[2018-06-05 02:42] Train Step 90450, Epoch 83.8, Batch Size = 256, Examples/Sec = 3852.40, Train LB = -386.675, Loss = 387.148
[2018-06-05 02:42] Train Step 90475, Epoch 83.8, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -363.072, Loss = 385.830
[2018-06-05 02:42] Train Step 90500, Epoch 83.8, Batch Size = 256, Examples/Sec = 3876.56, Train LB = -383.020, Loss = 384.439
[2018-06-05 02:42] Train Step 90525, Epoch 83.8, Batch Size = 256, Examples/Sec = 3833.42, Train LB = -395.998, Loss = 383.533
[2018-06-05 02:42] Train Step 90550, Epoch 83.8, Batch Size = 256, Examples/Sec = 3863.81, Train LB = -397.258, Loss = 383.985
[2018-06-05 02:42] Train Step 90575, Epoch 83.9, Batch Size = 256, Examples/Sec = 3843.49, Train LB = -395.611, Loss = 385.221
[2018-06-05 02:42] Train Step 90600, Epoch 83.9, Batch Size = 256, Examples/Sec = 3879.08, Train LB = -401.543, Loss = 388.912
Performance on test set:
  Test Lower Bound = -458.013, Test Loss = 458.013
[2018-06-05 02:42] Train Step 90625, Epoch 83.9, Batch Size = 256, Examples/Sec = 3850.04, Train LB = -373.172, Loss = 388.135
[2018-06-05 02:42] Train Step 90650, Epoch 83.9, Batch Size = 256, Examples/Sec = 3780.71, Train LB = -384.458, Loss = 386.642
[2018-06-05 02:42] Train Step 90675, Epoch 84.0, Batch Size = 256, Examples/Sec = 3816.22, Train LB = -380.651, Loss = 385.175
[2018-06-05 02:42] Train Step 90700, Epoch 84.0, Batch Size = 256, Examples/Sec = 3882.49, Train LB = -364.706, Loss = 383.827
[2018-06-05 02:42] Train Step 90725, Epoch 84.0, Batch Size = 256, Examples/Sec = 3856.71, Train LB = -384.712, Loss = 383.408
[2018-06-05 02:43] Train Step 90750, Epoch 84.0, Batch Size = 256, Examples/Sec = 3857.93, Train LB = -382.827, Loss = 383.030
[2018-06-05 02:43] Train Step 90775, Epoch 84.1, Batch Size = 256, Examples/Sec = 3883.43, Train LB = -399.125, Loss = 385.041
[2018-06-05 02:43] Train Step 90800, Epoch 84.1, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -413.821, Loss = 388.637
Performance on test set:
  Test Lower Bound = -459.153, Test Loss = 459.153
[2018-06-05 02:43] Train Step 90825, Epoch 84.1, Batch Size = 256, Examples/Sec = 3846.68, Train LB = -375.633, Loss = 387.836
[2018-06-05 02:43] Train Step 90850, Epoch 84.1, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -372.736, Loss = 387.005
[2018-06-05 02:43] Train Step 90875, Epoch 84.1, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -373.553, Loss = 385.149
[2018-06-05 02:43] Train Step 90900, Epoch 84.2, Batch Size = 256, Examples/Sec = 3875.85, Train LB = -365.508, Loss = 384.194
[2018-06-05 02:43] Train Step 90925, Epoch 84.2, Batch Size = 256, Examples/Sec = 3876.44, Train LB = -375.669, Loss = 383.595
[2018-06-05 02:43] Train Step 90950, Epoch 84.2, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -377.372, Loss = 383.514
[2018-06-05 02:43] Train Step 90975, Epoch 84.2, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -399.444, Loss = 384.935
[2018-06-05 02:43] Train Step 91000, Epoch 84.3, Batch Size = 256, Examples/Sec = 3848.92, Train LB = -407.346, Loss = 388.662
Performance on test set:
  Test Lower Bound = -459.633, Test Loss = 459.633
[2018-06-05 02:43] Train Step 91025, Epoch 84.3, Batch Size = 256, Examples/Sec = 3877.14, Train LB = -375.051, Loss = 387.809
[2018-06-05 02:43] Train Step 91050, Epoch 84.3, Batch Size = 256, Examples/Sec = 3887.92, Train LB = -385.166, Loss = 386.622
[2018-06-05 02:43] Train Step 91075, Epoch 84.3, Batch Size = 256, Examples/Sec = 3814.01, Train LB = -380.735, Loss = 385.081
[2018-06-05 02:43] Train Step 91100, Epoch 84.4, Batch Size = 256, Examples/Sec = 3860.66, Train LB = -377.327, Loss = 384.102
[2018-06-05 02:43] Train Step 91125, Epoch 84.4, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -381.572, Loss = 383.333
[2018-06-05 02:43] Train Step 91150, Epoch 84.4, Batch Size = 256, Examples/Sec = 3853.62, Train LB = -399.108, Loss = 384.061
[2018-06-05 02:43] Train Step 91175, Epoch 84.4, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -386.661, Loss = 384.650
[2018-06-05 02:43] Train Step 91200, Epoch 84.4, Batch Size = 256, Examples/Sec = 3836.30, Train LB = -411.362, Loss = 388.318
Performance on test set:
  Test Lower Bound = -458.898, Test Loss = 458.898
[2018-06-05 02:43] Train Step 91225, Epoch 84.5, Batch Size = 256, Examples/Sec = 3865.26, Train LB = -393.952, Loss = 387.248
[2018-06-05 02:43] Train Step 91250, Epoch 84.5, Batch Size = 256, Examples/Sec = 3860.01, Train LB = -396.976, Loss = 385.835
[2018-06-05 02:43] Train Step 91275, Epoch 84.5, Batch Size = 256, Examples/Sec = 3874.74, Train LB = -366.422, Loss = 385.345
[2018-06-05 02:43] Train Step 91300, Epoch 84.5, Batch Size = 256, Examples/Sec = 3782.50, Train LB = -382.057, Loss = 384.926
[2018-06-05 02:43] Train Step 91325, Epoch 84.6, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -378.142, Loss = 384.455
[2018-06-05 02:43] Train Step 91350, Epoch 84.6, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -379.121, Loss = 384.835
[2018-06-05 02:43] Train Step 91375, Epoch 84.6, Batch Size = 256, Examples/Sec = 3830.96, Train LB = -403.513, Loss = 385.421
[2018-06-05 02:43] Train Step 91400, Epoch 84.6, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -411.226, Loss = 388.452
Performance on test set:
  Test Lower Bound = -458.648, Test Loss = 458.648
[2018-06-05 02:44] Train Step 91425, Epoch 84.7, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -382.990, Loss = 387.387
[2018-06-05 02:44] Train Step 91450, Epoch 84.7, Batch Size = 256, Examples/Sec = 3851.64, Train LB = -377.030, Loss = 386.420
[2018-06-05 02:44] Train Step 91475, Epoch 84.7, Batch Size = 256, Examples/Sec = 3860.30, Train LB = -370.572, Loss = 385.027
[2018-06-05 02:44] Train Step 91500, Epoch 84.7, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -385.272, Loss = 383.984
[2018-06-05 02:44] Train Step 91525, Epoch 84.7, Batch Size = 256, Examples/Sec = 3842.52, Train LB = -380.766, Loss = 383.809
[2018-06-05 02:44] Train Step 91550, Epoch 84.8, Batch Size = 256, Examples/Sec = 3882.27, Train LB = -381.020, Loss = 383.511
[2018-06-05 02:44] Train Step 91575, Epoch 84.8, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -399.057, Loss = 384.738
[2018-06-05 02:44] Train Step 91600, Epoch 84.8, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -418.388, Loss = 389.206
Performance on test set:
  Test Lower Bound = -458.151, Test Loss = 458.152
[2018-06-05 02:44] Train Step 91625, Epoch 84.8, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -389.139, Loss = 388.601
[2018-06-05 02:44] Train Step 91650, Epoch 84.9, Batch Size = 256, Examples/Sec = 3889.64, Train LB = -376.903, Loss = 387.086
[2018-06-05 02:44] Train Step 91675, Epoch 84.9, Batch Size = 256, Examples/Sec = 3875.85, Train LB = -386.246, Loss = 385.320
[2018-06-05 02:44] Train Step 91700, Epoch 84.9, Batch Size = 256, Examples/Sec = 3805.06, Train LB = -371.624, Loss = 384.027
[2018-06-05 02:44] Train Step 91725, Epoch 84.9, Batch Size = 256, Examples/Sec = 3879.31, Train LB = -364.668, Loss = 382.994
[2018-06-05 02:44] Train Step 91750, Epoch 85.0, Batch Size = 256, Examples/Sec = 3845.35, Train LB = -390.982, Loss = 382.856
[2018-06-05 02:44] Train Step 91775, Epoch 85.0, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -403.797, Loss = 385.016
[2018-06-05 02:44] Train Step 91800, Epoch 85.0, Batch Size = 256, Examples/Sec = 3873.50, Train LB = -417.483, Loss = 388.877
Performance on test set:
  Test Lower Bound = -458.056, Test Loss = 458.056
[2018-06-05 02:44] Train Step 91825, Epoch 85.0, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -378.957, Loss = 387.658
[2018-06-05 02:44] Train Step 91850, Epoch 85.0, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -394.438, Loss = 386.437
[2018-06-05 02:44] Train Step 91875, Epoch 85.1, Batch Size = 256, Examples/Sec = 3811.28, Train LB = -379.936, Loss = 385.490
[2018-06-05 02:44] Train Step 91900, Epoch 85.1, Batch Size = 256, Examples/Sec = 3845.17, Train LB = -383.493, Loss = 384.597
[2018-06-05 02:44] Train Step 91925, Epoch 85.1, Batch Size = 256, Examples/Sec = 3867.76, Train LB = -378.692, Loss = 384.501
[2018-06-05 02:44] Train Step 91950, Epoch 85.1, Batch Size = 256, Examples/Sec = 3859.48, Train LB = -381.511, Loss = 384.527
[2018-06-05 02:44] Train Step 91975, Epoch 85.2, Batch Size = 256, Examples/Sec = 3854.67, Train LB = -395.518, Loss = 385.209
[2018-06-05 02:44] Train Step 92000, Epoch 85.2, Batch Size = 256, Examples/Sec = 3848.41, Train LB = -416.635, Loss = 389.132
Performance on test set:
  Test Lower Bound = -459.033, Test Loss = 459.033
[2018-06-05 02:44] Train Step 92025, Epoch 85.2, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -381.721, Loss = 387.771
[2018-06-05 02:44] Train Step 92050, Epoch 85.2, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -379.605, Loss = 386.141
[2018-06-05 02:44] Train Step 92075, Epoch 85.3, Batch Size = 256, Examples/Sec = 3826.43, Train LB = -365.742, Loss = 384.792
[2018-06-05 02:44] Train Step 92100, Epoch 85.3, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -366.834, Loss = 383.521
[2018-06-05 02:44] Train Step 92125, Epoch 85.3, Batch Size = 256, Examples/Sec = 3876.73, Train LB = -391.013, Loss = 383.050
[2018-06-05 02:44] Train Step 92150, Epoch 85.3, Batch Size = 256, Examples/Sec = 3875.92, Train LB = -378.233, Loss = 383.955
[2018-06-05 02:45] Train Step 92175, Epoch 85.3, Batch Size = 256, Examples/Sec = 3882.56, Train LB = -393.636, Loss = 384.986
[2018-06-05 02:45] Train Step 92200, Epoch 85.4, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -408.127, Loss = 388.636
Performance on test set:
  Test Lower Bound = -459.467, Test Loss = 459.467
[2018-06-05 02:45] Train Step 92225, Epoch 85.4, Batch Size = 256, Examples/Sec = 3879.56, Train LB = -386.328, Loss = 387.389
[2018-06-05 02:45] Train Step 92250, Epoch 85.4, Batch Size = 256, Examples/Sec = 3836.35, Train LB = -389.424, Loss = 386.020
[2018-06-05 02:45] Train Step 92275, Epoch 85.4, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -392.823, Loss = 385.379
[2018-06-05 02:45] Train Step 92300, Epoch 85.5, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -376.908, Loss = 384.035
[2018-06-05 02:45] Train Step 92325, Epoch 85.5, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -375.062, Loss = 383.242
[2018-06-05 02:45] Train Step 92350, Epoch 85.5, Batch Size = 256, Examples/Sec = 3854.91, Train LB = -379.203, Loss = 383.497
[2018-06-05 02:45] Train Step 92375, Epoch 85.5, Batch Size = 256, Examples/Sec = 3886.09, Train LB = -405.309, Loss = 384.931
[2018-06-05 02:45] Train Step 92400, Epoch 85.6, Batch Size = 256, Examples/Sec = 3860.55, Train LB = -420.655, Loss = 388.053
Performance on test set:
  Test Lower Bound = -459.904, Test Loss = 459.904
[2018-06-05 02:45] Train Step 92425, Epoch 85.6, Batch Size = 256, Examples/Sec = 3854.84, Train LB = -378.509, Loss = 387.246
[2018-06-05 02:45] Train Step 92450, Epoch 85.6, Batch Size = 256, Examples/Sec = 3844.24, Train LB = -388.984, Loss = 386.250
[2018-06-05 02:45] Train Step 92475, Epoch 85.6, Batch Size = 256, Examples/Sec = 3832.06, Train LB = -388.537, Loss = 384.551
[2018-06-05 02:45] Train Step 92500, Epoch 85.6, Batch Size = 256, Examples/Sec = 3852.22, Train LB = -382.895, Loss = 383.759
[2018-06-05 02:45] Train Step 92525, Epoch 85.7, Batch Size = 256, Examples/Sec = 3824.89, Train LB = -372.255, Loss = 383.164
[2018-06-05 02:45] Train Step 92550, Epoch 85.7, Batch Size = 256, Examples/Sec = 3854.91, Train LB = -383.618, Loss = 383.722
[2018-06-05 02:45] Train Step 92575, Epoch 85.7, Batch Size = 256, Examples/Sec = 3854.89, Train LB = -393.242, Loss = 385.733
[2018-06-05 02:45] Train Step 92600, Epoch 85.7, Batch Size = 256, Examples/Sec = 3880.85, Train LB = -411.737, Loss = 389.222
Performance on test set:
  Test Lower Bound = -459.732, Test Loss = 459.732
[2018-06-05 02:45] Train Step 92625, Epoch 85.8, Batch Size = 256, Examples/Sec = 3812.30, Train LB = -396.413, Loss = 387.896
[2018-06-05 02:45] Train Step 92650, Epoch 85.8, Batch Size = 256, Examples/Sec = 3814.74, Train LB = -394.137, Loss = 386.190
[2018-06-05 02:45] Train Step 92675, Epoch 85.8, Batch Size = 256, Examples/Sec = 3846.68, Train LB = -365.089, Loss = 385.117
[2018-06-05 02:45] Train Step 92700, Epoch 85.8, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -384.561, Loss = 384.215
[2018-06-05 02:45] Train Step 92725, Epoch 85.9, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -364.697, Loss = 384.618
[2018-06-05 02:45] Train Step 92750, Epoch 85.9, Batch Size = 256, Examples/Sec = 3854.56, Train LB = -378.066, Loss = 383.778
[2018-06-05 02:45] Train Step 92775, Epoch 85.9, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -403.251, Loss = 384.989
[2018-06-05 02:45] Train Step 92800, Epoch 85.9, Batch Size = 256, Examples/Sec = 3828.15, Train LB = -411.885, Loss = 387.851
Performance on test set:
  Test Lower Bound = -460.536, Test Loss = 460.536
[2018-06-05 02:45] Train Step 92825, Epoch 85.9, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -395.439, Loss = 387.092
[2018-06-05 02:45] Train Step 92850, Epoch 86.0, Batch Size = 256, Examples/Sec = 3870.22, Train LB = -397.685, Loss = 385.547
[2018-06-05 02:46] Train Step 92875, Epoch 86.0, Batch Size = 256, Examples/Sec = 3870.16, Train LB = -372.497, Loss = 384.052
[2018-06-05 02:46] Train Step 92900, Epoch 86.0, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -390.785, Loss = 382.854
[2018-06-05 02:46] Train Step 92925, Epoch 86.0, Batch Size = 256, Examples/Sec = 3848.65, Train LB = -379.614, Loss = 382.663
[2018-06-05 02:46] Train Step 92950, Epoch 86.1, Batch Size = 256, Examples/Sec = 3856.06, Train LB = -379.730, Loss = 383.205
[2018-06-05 02:46] Train Step 92975, Epoch 86.1, Batch Size = 256, Examples/Sec = 3877.15, Train LB = -379.079, Loss = 384.304
[2018-06-05 02:46] Train Step 93000, Epoch 86.1, Batch Size = 256, Examples/Sec = 3861.99, Train LB = -407.819, Loss = 387.903
Performance on test set:
  Test Lower Bound = -458.922, Test Loss = 458.922
[2018-06-05 02:46] Train Step 93025, Epoch 86.1, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -388.385, Loss = 386.653
[2018-06-05 02:46] Train Step 93050, Epoch 86.2, Batch Size = 256, Examples/Sec = 3868.94, Train LB = -396.994, Loss = 385.620
[2018-06-05 02:46] Train Step 93075, Epoch 86.2, Batch Size = 256, Examples/Sec = 3873.81, Train LB = -384.077, Loss = 384.392
[2018-06-05 02:46] Train Step 93100, Epoch 86.2, Batch Size = 256, Examples/Sec = 3851.88, Train LB = -376.463, Loss = 383.169
[2018-06-05 02:46] Train Step 93125, Epoch 86.2, Batch Size = 256, Examples/Sec = 3871.04, Train LB = -386.073, Loss = 383.169
[2018-06-05 02:46] Train Step 93150, Epoch 86.2, Batch Size = 256, Examples/Sec = 3864.84, Train LB = -397.150, Loss = 383.327
[2018-06-05 02:46] Train Step 93175, Epoch 86.3, Batch Size = 256, Examples/Sec = 3896.79, Train LB = -374.621, Loss = 384.949
[2018-06-05 02:46] Train Step 93200, Epoch 86.3, Batch Size = 256, Examples/Sec = 3878.84, Train LB = -412.335, Loss = 387.885
Performance on test set:
  Test Lower Bound = -459.900, Test Loss = 459.900
[2018-06-05 02:46] Train Step 93225, Epoch 86.3, Batch Size = 256, Examples/Sec = 3770.13, Train LB = -390.775, Loss = 386.838
[2018-06-05 02:46] Train Step 93250, Epoch 86.3, Batch Size = 256, Examples/Sec = 3850.43, Train LB = -383.012, Loss = 385.755
[2018-06-05 02:46] Train Step 93275, Epoch 86.4, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -371.498, Loss = 384.772
[2018-06-05 02:46] Train Step 93300, Epoch 86.4, Batch Size = 256, Examples/Sec = 3871.45, Train LB = -376.727, Loss = 383.799
[2018-06-05 02:46] Train Step 93325, Epoch 86.4, Batch Size = 256, Examples/Sec = 3875.57, Train LB = -391.051, Loss = 383.218
[2018-06-05 02:46] Train Step 93350, Epoch 86.4, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -376.847, Loss = 383.363
[2018-06-05 02:46] Train Step 93375, Epoch 86.5, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -383.528, Loss = 384.752
[2018-06-05 02:46] Train Step 93400, Epoch 86.5, Batch Size = 256, Examples/Sec = 3863.03, Train LB = -408.454, Loss = 387.427
Performance on test set:
  Test Lower Bound = -461.072, Test Loss = 461.072
[2018-06-05 02:46] Train Step 93425, Epoch 86.5, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -380.344, Loss = 387.146
[2018-06-05 02:46] Train Step 93450, Epoch 86.5, Batch Size = 256, Examples/Sec = 3854.96, Train LB = -385.733, Loss = 385.835
[2018-06-05 02:46] Train Step 93475, Epoch 86.6, Batch Size = 256, Examples/Sec = 3869.88, Train LB = -391.153, Loss = 384.785
[2018-06-05 02:46] Train Step 93500, Epoch 86.6, Batch Size = 256, Examples/Sec = 3838.89, Train LB = -380.537, Loss = 383.761
[2018-06-05 02:46] Train Step 93525, Epoch 86.6, Batch Size = 256, Examples/Sec = 3874.10, Train LB = -400.346, Loss = 382.575
[2018-06-05 02:46] Train Step 93550, Epoch 86.6, Batch Size = 256, Examples/Sec = 3874.67, Train LB = -391.668, Loss = 382.638
[2018-06-05 02:46] Train Step 93575, Epoch 86.6, Batch Size = 256, Examples/Sec = 3882.55, Train LB = -378.778, Loss = 384.176
[2018-06-05 02:47] Train Step 93600, Epoch 86.7, Batch Size = 256, Examples/Sec = 3779.21, Train LB = -406.964, Loss = 388.384
Performance on test set:
  Test Lower Bound = -460.831, Test Loss = 460.831
[2018-06-05 02:47] Train Step 93625, Epoch 86.7, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -383.432, Loss = 387.504
[2018-06-05 02:47] Train Step 93650, Epoch 86.7, Batch Size = 256, Examples/Sec = 3876.38, Train LB = -388.234, Loss = 386.013
[2018-06-05 02:47] Train Step 93675, Epoch 86.7, Batch Size = 256, Examples/Sec = 3860.94, Train LB = -387.095, Loss = 384.519
[2018-06-05 02:47] Train Step 93700, Epoch 86.8, Batch Size = 256, Examples/Sec = 3824.60, Train LB = -395.051, Loss = 383.379
[2018-06-05 02:47] Train Step 93725, Epoch 86.8, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -378.957, Loss = 382.260
[2018-06-05 02:47] Train Step 93750, Epoch 86.8, Batch Size = 256, Examples/Sec = 3810.15, Train LB = -389.625, Loss = 382.427
[2018-06-05 02:47] Train Step 93775, Epoch 86.8, Batch Size = 256, Examples/Sec = 3871.39, Train LB = -389.570, Loss = 384.270
[2018-06-05 02:47] Train Step 93800, Epoch 86.9, Batch Size = 256, Examples/Sec = 3836.19, Train LB = -411.013, Loss = 388.282
Performance on test set:
  Test Lower Bound = -459.863, Test Loss = 459.863
[2018-06-05 02:47] Train Step 93825, Epoch 86.9, Batch Size = 256, Examples/Sec = 3863.56, Train LB = -381.225, Loss = 387.217
[2018-06-05 02:47] Train Step 93850, Epoch 86.9, Batch Size = 256, Examples/Sec = 3869.58, Train LB = -388.760, Loss = 385.847
[2018-06-05 02:47] Train Step 93875, Epoch 86.9, Batch Size = 256, Examples/Sec = 3872.23, Train LB = -399.548, Loss = 384.912
[2018-06-05 02:47] Train Step 93900, Epoch 86.9, Batch Size = 256, Examples/Sec = 3846.62, Train LB = -394.584, Loss = 383.631
[2018-06-05 02:47] Train Step 93925, Epoch 87.0, Batch Size = 256, Examples/Sec = 3847.48, Train LB = -388.163, Loss = 383.171
[2018-06-05 02:47] Train Step 93950, Epoch 87.0, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -396.503, Loss = 382.393
[2018-06-05 02:47] Train Step 93975, Epoch 87.0, Batch Size = 256, Examples/Sec = 3877.26, Train LB = -408.951, Loss = 384.002
[2018-06-05 02:47] Train Step 94000, Epoch 87.0, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -405.059, Loss = 388.085
Performance on test set:
  Test Lower Bound = -461.948, Test Loss = 461.948
[2018-06-05 02:47] Train Step 94025, Epoch 87.1, Batch Size = 256, Examples/Sec = 3873.74, Train LB = -385.138, Loss = 387.334
[2018-06-05 02:47] Train Step 94050, Epoch 87.1, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -388.397, Loss = 386.454
[2018-06-05 02:47] Train Step 94075, Epoch 87.1, Batch Size = 256, Examples/Sec = 3854.02, Train LB = -375.870, Loss = 385.407
[2018-06-05 02:47] Train Step 94100, Epoch 87.1, Batch Size = 256, Examples/Sec = 3852.40, Train LB = -382.548, Loss = 383.982
[2018-06-05 02:47] Train Step 94125, Epoch 87.2, Batch Size = 256, Examples/Sec = 3863.63, Train LB = -380.870, Loss = 383.113
[2018-06-05 02:47] Train Step 94150, Epoch 87.2, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -393.835, Loss = 382.930
[2018-06-05 02:47] Train Step 94175, Epoch 87.2, Batch Size = 256, Examples/Sec = 3816.80, Train LB = -390.731, Loss = 384.539
[2018-06-05 02:47] Train Step 94200, Epoch 87.2, Batch Size = 256, Examples/Sec = 3821.06, Train LB = -420.331, Loss = 388.052
Performance on test set:
  Test Lower Bound = -459.250, Test Loss = 459.250
[2018-06-05 02:47] Train Step 94225, Epoch 87.2, Batch Size = 256, Examples/Sec = 3806.02, Train LB = -395.744, Loss = 387.170
[2018-06-05 02:47] Train Step 94250, Epoch 87.3, Batch Size = 256, Examples/Sec = 3873.79, Train LB = -376.813, Loss = 385.723
[2018-06-05 02:47] Train Step 94275, Epoch 87.3, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -379.811, Loss = 384.385
[2018-06-05 02:48] Train Step 94300, Epoch 87.3, Batch Size = 256, Examples/Sec = 3825.07, Train LB = -389.648, Loss = 383.354
[2018-06-05 02:48] Train Step 94325, Epoch 87.3, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -383.336, Loss = 382.936
[2018-06-05 02:48] Train Step 94350, Epoch 87.4, Batch Size = 256, Examples/Sec = 3860.37, Train LB = -395.417, Loss = 383.062
[2018-06-05 02:48] Train Step 94375, Epoch 87.4, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -409.848, Loss = 384.644
[2018-06-05 02:48] Train Step 94400, Epoch 87.4, Batch Size = 256, Examples/Sec = 3876.73, Train LB = -408.032, Loss = 388.027
Performance on test set:
  Test Lower Bound = -459.795, Test Loss = 459.795
[2018-06-05 02:48] Train Step 94425, Epoch 87.4, Batch Size = 256, Examples/Sec = 3846.22, Train LB = -368.778, Loss = 387.119
[2018-06-05 02:48] Train Step 94450, Epoch 87.5, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -375.487, Loss = 385.507
[2018-06-05 02:48] Train Step 94475, Epoch 87.5, Batch Size = 256, Examples/Sec = 3855.43, Train LB = -374.287, Loss = 383.986
[2018-06-05 02:48] Train Step 94500, Epoch 87.5, Batch Size = 256, Examples/Sec = 3869.28, Train LB = -393.058, Loss = 382.486
[2018-06-05 02:48] Train Step 94525, Epoch 87.5, Batch Size = 256, Examples/Sec = 3878.20, Train LB = -390.536, Loss = 382.500
[2018-06-05 02:48] Train Step 94550, Epoch 87.5, Batch Size = 256, Examples/Sec = 3867.76, Train LB = -384.720, Loss = 382.774
[2018-06-05 02:48] Train Step 94575, Epoch 87.6, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -387.616, Loss = 384.409
[2018-06-05 02:48] Train Step 94600, Epoch 87.6, Batch Size = 256, Examples/Sec = 3871.87, Train LB = -398.062, Loss = 388.632
Performance on test set:
  Test Lower Bound = -458.539, Test Loss = 458.540
[2018-06-05 02:48] Train Step 94625, Epoch 87.6, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -374.586, Loss = 387.205
[2018-06-05 02:48] Train Step 94650, Epoch 87.6, Batch Size = 256, Examples/Sec = 3882.03, Train LB = -379.220, Loss = 385.743
[2018-06-05 02:48] Train Step 94675, Epoch 87.7, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -383.439, Loss = 384.700
[2018-06-05 02:48] Train Step 94700, Epoch 87.7, Batch Size = 256, Examples/Sec = 3868.31, Train LB = -378.036, Loss = 383.334
[2018-06-05 02:48] Train Step 94725, Epoch 87.7, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -385.266, Loss = 382.209
[2018-06-05 02:48] Train Step 94750, Epoch 87.7, Batch Size = 256, Examples/Sec = 3808.27, Train LB = -383.999, Loss = 382.839
[2018-06-05 02:48] Train Step 94775, Epoch 87.8, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -377.086, Loss = 384.173
[2018-06-05 02:48] Train Step 94800, Epoch 87.8, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -410.825, Loss = 388.226
Performance on test set:
  Test Lower Bound = -461.703, Test Loss = 461.703
[2018-06-05 02:48] Train Step 94825, Epoch 87.8, Batch Size = 256, Examples/Sec = 3856.60, Train LB = -393.484, Loss = 387.287
[2018-06-05 02:48] Train Step 94850, Epoch 87.8, Batch Size = 256, Examples/Sec = 3872.52, Train LB = -382.171, Loss = 385.647
[2018-06-05 02:48] Train Step 94875, Epoch 87.8, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -386.011, Loss = 384.441
[2018-06-05 02:48] Train Step 94900, Epoch 87.9, Batch Size = 256, Examples/Sec = 3874.38, Train LB = -370.239, Loss = 383.383
[2018-06-05 02:48] Train Step 94925, Epoch 87.9, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -387.047, Loss = 381.560
[2018-06-05 02:48] Train Step 94950, Epoch 87.9, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -375.832, Loss = 382.278
[2018-06-05 02:48] Train Step 94975, Epoch 87.9, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -388.517, Loss = 384.251
[2018-06-05 02:48] Train Step 95000, Epoch 88.0, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -412.697, Loss = 388.171
Performance on test set:
  Test Lower Bound = -459.795, Test Loss = 459.795
[2018-06-05 02:49] Train Step 95025, Epoch 88.0, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -374.261, Loss = 387.031
[2018-06-05 02:49] Train Step 95050, Epoch 88.0, Batch Size = 256, Examples/Sec = 3853.15, Train LB = -386.401, Loss = 385.539
[2018-06-05 02:49] Train Step 95075, Epoch 88.0, Batch Size = 256, Examples/Sec = 3876.31, Train LB = -373.064, Loss = 384.323
[2018-06-05 02:49] Train Step 95100, Epoch 88.1, Batch Size = 256, Examples/Sec = 3870.53, Train LB = -387.954, Loss = 383.049
[2018-06-05 02:49] Train Step 95125, Epoch 88.1, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -383.519, Loss = 383.108
[2018-06-05 02:49] Train Step 95150, Epoch 88.1, Batch Size = 256, Examples/Sec = 3866.65, Train LB = -388.273, Loss = 383.056
[2018-06-05 02:49] Train Step 95175, Epoch 88.1, Batch Size = 256, Examples/Sec = 3851.26, Train LB = -387.426, Loss = 384.456
[2018-06-05 02:49] Train Step 95200, Epoch 88.1, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -406.173, Loss = 388.320
Performance on test set:
  Test Lower Bound = -460.965, Test Loss = 460.965
[2018-06-05 02:49] Train Step 95225, Epoch 88.2, Batch Size = 256, Examples/Sec = 3866.26, Train LB = -396.842, Loss = 387.345
[2018-06-05 02:49] Train Step 95250, Epoch 88.2, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -388.087, Loss = 385.810
[2018-06-05 02:49] Train Step 95275, Epoch 88.2, Batch Size = 256, Examples/Sec = 3869.93, Train LB = -367.912, Loss = 384.328
[2018-06-05 02:49] Train Step 95300, Epoch 88.2, Batch Size = 256, Examples/Sec = 3821.06, Train LB = -384.320, Loss = 383.192
[2018-06-05 02:49] Train Step 95325, Epoch 88.3, Batch Size = 256, Examples/Sec = 3796.53, Train LB = -388.683, Loss = 382.732
[2018-06-05 02:49] Train Step 95350, Epoch 88.3, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -386.840, Loss = 382.858
[2018-06-05 02:49] Train Step 95375, Epoch 88.3, Batch Size = 256, Examples/Sec = 3878.49, Train LB = -400.436, Loss = 383.936
[2018-06-05 02:49] Train Step 95400, Epoch 88.3, Batch Size = 256, Examples/Sec = 3870.76, Train LB = -411.667, Loss = 388.559
Performance on test set:
  Test Lower Bound = -459.240, Test Loss = 459.240
[2018-06-05 02:49] Train Step 95425, Epoch 88.4, Batch Size = 256, Examples/Sec = 3865.72, Train LB = -373.717, Loss = 387.390
[2018-06-05 02:49] Train Step 95450, Epoch 88.4, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -374.996, Loss = 386.206
[2018-06-05 02:49] Train Step 95475, Epoch 88.4, Batch Size = 256, Examples/Sec = 3885.55, Train LB = -385.623, Loss = 385.265
[2018-06-05 02:49] Train Step 95500, Epoch 88.4, Batch Size = 256, Examples/Sec = 3858.62, Train LB = -382.001, Loss = 383.530
[2018-06-05 02:49] Train Step 95525, Epoch 88.4, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -375.793, Loss = 382.561
[2018-06-05 02:49] Train Step 95550, Epoch 88.5, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -373.666, Loss = 382.759
[2018-06-05 02:49] Train Step 95575, Epoch 88.5, Batch Size = 256, Examples/Sec = 3875.79, Train LB = -397.491, Loss = 384.108
[2018-06-05 02:49] Train Step 95600, Epoch 88.5, Batch Size = 256, Examples/Sec = 3874.27, Train LB = -397.272, Loss = 387.976
Performance on test set:
  Test Lower Bound = -459.977, Test Loss = 459.977
[2018-06-05 02:49] Train Step 95625, Epoch 88.5, Batch Size = 256, Examples/Sec = 3816.85, Train LB = -385.388, Loss = 386.924
[2018-06-05 02:49] Train Step 95650, Epoch 88.6, Batch Size = 256, Examples/Sec = 3873.39, Train LB = -365.928, Loss = 385.296
[2018-06-05 02:49] Train Step 95675, Epoch 88.6, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -380.788, Loss = 384.142
[2018-06-05 02:49] Train Step 95700, Epoch 88.6, Batch Size = 256, Examples/Sec = 3864.40, Train LB = -359.599, Loss = 383.312
[2018-06-05 02:49] Train Step 95725, Epoch 88.6, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -383.059, Loss = 382.508
[2018-06-05 02:50] Train Step 95750, Epoch 88.7, Batch Size = 256, Examples/Sec = 3831.07, Train LB = -395.207, Loss = 382.102
[2018-06-05 02:50] Train Step 95775, Epoch 88.7, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -392.142, Loss = 383.835
[2018-06-05 02:50] Train Step 95800, Epoch 88.7, Batch Size = 256, Examples/Sec = 3790.19, Train LB = -401.516, Loss = 387.324
Performance on test set:
  Test Lower Bound = -462.423, Test Loss = 462.423
[2018-06-05 02:50] Train Step 95825, Epoch 88.7, Batch Size = 256, Examples/Sec = 3863.81, Train LB = -380.995, Loss = 386.411
[2018-06-05 02:50] Train Step 95850, Epoch 88.8, Batch Size = 256, Examples/Sec = 3879.25, Train LB = -377.159, Loss = 384.706
[2018-06-05 02:50] Train Step 95875, Epoch 88.8, Batch Size = 256, Examples/Sec = 3878.79, Train LB = -384.787, Loss = 383.505
[2018-06-05 02:50] Train Step 95900, Epoch 88.8, Batch Size = 256, Examples/Sec = 3816.28, Train LB = -375.297, Loss = 382.942
[2018-06-05 02:50] Train Step 95925, Epoch 88.8, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -391.473, Loss = 382.537
[2018-06-05 02:50] Train Step 95950, Epoch 88.8, Batch Size = 256, Examples/Sec = 3871.10, Train LB = -389.457, Loss = 382.807
[2018-06-05 02:50] Train Step 95975, Epoch 88.9, Batch Size = 256, Examples/Sec = 3874.45, Train LB = -397.965, Loss = 383.980
[2018-06-05 02:50] Train Step 96000, Epoch 88.9, Batch Size = 256, Examples/Sec = 3870.58, Train LB = -411.194, Loss = 388.397
Performance on test set:
  Test Lower Bound = -460.435, Test Loss = 460.435
[2018-06-05 02:50] Train Step 96025, Epoch 88.9, Batch Size = 256, Examples/Sec = 3847.19, Train LB = -378.813, Loss = 387.625
[2018-06-05 02:50] Train Step 96050, Epoch 88.9, Batch Size = 256, Examples/Sec = 3888.80, Train LB = -366.070, Loss = 385.981
[2018-06-05 02:50] Train Step 96075, Epoch 89.0, Batch Size = 256, Examples/Sec = 3866.79, Train LB = -379.026, Loss = 384.079
[2018-06-05 02:50] Train Step 96100, Epoch 89.0, Batch Size = 256, Examples/Sec = 3866.32, Train LB = -388.426, Loss = 382.839
[2018-06-05 02:50] Train Step 96125, Epoch 89.0, Batch Size = 256, Examples/Sec = 3864.84, Train LB = -373.049, Loss = 382.284
[2018-06-05 02:50] Train Step 96150, Epoch 89.0, Batch Size = 256, Examples/Sec = 3854.67, Train LB = -395.237, Loss = 382.851
[2018-06-05 02:50] Train Step 96175, Epoch 89.1, Batch Size = 256, Examples/Sec = 3852.53, Train LB = -395.065, Loss = 384.440
[2018-06-05 02:50] Train Step 96200, Epoch 89.1, Batch Size = 256, Examples/Sec = 3873.68, Train LB = -409.984, Loss = 388.116
Performance on test set:
  Test Lower Bound = -459.741, Test Loss = 459.741
[2018-06-05 02:50] Train Step 96225, Epoch 89.1, Batch Size = 256, Examples/Sec = 3890.82, Train LB = -378.462, Loss = 386.735
[2018-06-05 02:50] Train Step 96250, Epoch 89.1, Batch Size = 256, Examples/Sec = 3865.62, Train LB = -374.959, Loss = 385.614
[2018-06-05 02:50] Train Step 96275, Epoch 89.1, Batch Size = 256, Examples/Sec = 3870.46, Train LB = -383.921, Loss = 384.533
[2018-06-05 02:50] Train Step 96300, Epoch 89.2, Batch Size = 256, Examples/Sec = 3806.46, Train LB = -376.600, Loss = 383.183
[2018-06-05 02:50] Train Step 96325, Epoch 89.2, Batch Size = 256, Examples/Sec = 3855.42, Train LB = -371.906, Loss = 382.204
[2018-06-05 02:50] Train Step 96350, Epoch 89.2, Batch Size = 256, Examples/Sec = 3860.99, Train LB = -379.373, Loss = 382.811
[2018-06-05 02:50] Train Step 96375, Epoch 89.2, Batch Size = 256, Examples/Sec = 3877.43, Train LB = -400.780, Loss = 384.149
[2018-06-05 02:50] Train Step 96400, Epoch 89.3, Batch Size = 256, Examples/Sec = 3869.35, Train LB = -408.328, Loss = 387.275
Performance on test set:
  Test Lower Bound = -461.741, Test Loss = 461.741
[2018-06-05 02:51] Train Step 96425, Epoch 89.3, Batch Size = 256, Examples/Sec = 3864.69, Train LB = -375.796, Loss = 386.278
[2018-06-05 02:51] Train Step 96450, Epoch 89.3, Batch Size = 256, Examples/Sec = 3877.50, Train LB = -390.832, Loss = 384.900
[2018-06-05 02:51] Train Step 96475, Epoch 89.3, Batch Size = 256, Examples/Sec = 3790.97, Train LB = -391.305, Loss = 383.827
[2018-06-05 02:51] Train Step 96500, Epoch 89.4, Batch Size = 256, Examples/Sec = 3884.91, Train LB = -394.260, Loss = 382.904
[2018-06-05 02:51] Train Step 96525, Epoch 89.4, Batch Size = 256, Examples/Sec = 3865.09, Train LB = -383.315, Loss = 381.868
[2018-06-05 02:51] Train Step 96550, Epoch 89.4, Batch Size = 256, Examples/Sec = 3863.21, Train LB = -387.449, Loss = 382.928
[2018-06-05 02:51] Train Step 96575, Epoch 89.4, Batch Size = 256, Examples/Sec = 3856.35, Train LB = -407.560, Loss = 384.028
[2018-06-05 02:51] Train Step 96600, Epoch 89.4, Batch Size = 256, Examples/Sec = 3863.98, Train LB = -410.412, Loss = 387.360
Performance on test set:
  Test Lower Bound = -459.939, Test Loss = 459.939
[2018-06-05 02:51] Train Step 96625, Epoch 89.5, Batch Size = 256, Examples/Sec = 3818.40, Train LB = -404.694, Loss = 386.170
[2018-06-05 02:51] Train Step 96650, Epoch 89.5, Batch Size = 256, Examples/Sec = 3873.04, Train LB = -370.057, Loss = 384.968
[2018-06-05 02:51] Train Step 96675, Epoch 89.5, Batch Size = 256, Examples/Sec = 3859.73, Train LB = -366.910, Loss = 383.770
[2018-06-05 02:51] Train Step 96700, Epoch 89.5, Batch Size = 256, Examples/Sec = 3881.14, Train LB = -382.085, Loss = 383.062
[2018-06-05 02:51] Train Step 96725, Epoch 89.6, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -375.625, Loss = 382.395
[2018-06-05 02:51] Train Step 96750, Epoch 89.6, Batch Size = 256, Examples/Sec = 3841.65, Train LB = -381.798, Loss = 382.194
[2018-06-05 02:51] Train Step 96775, Epoch 89.6, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -375.083, Loss = 383.701
[2018-06-05 02:51] Train Step 96800, Epoch 89.6, Batch Size = 256, Examples/Sec = 3845.75, Train LB = -409.215, Loss = 387.729
Performance on test set:
  Test Lower Bound = -460.383, Test Loss = 460.383
[2018-06-05 02:51] Train Step 96825, Epoch 89.7, Batch Size = 256, Examples/Sec = 3798.45, Train LB = -391.729, Loss = 386.079
[2018-06-05 02:51] Train Step 96850, Epoch 89.7, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -388.208, Loss = 384.984
[2018-06-05 02:51] Train Step 96875, Epoch 89.7, Batch Size = 256, Examples/Sec = 3855.78, Train LB = -380.891, Loss = 383.710
[2018-06-05 02:51] Train Step 96900, Epoch 89.7, Batch Size = 256, Examples/Sec = 3884.85, Train LB = -364.600, Loss = 382.684
[2018-06-05 02:51] Train Step 96925, Epoch 89.7, Batch Size = 256, Examples/Sec = 3815.71, Train LB = -376.822, Loss = 382.101
[2018-06-05 02:51] Train Step 96950, Epoch 89.8, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -396.360, Loss = 382.499
[2018-06-05 02:51] Train Step 96975, Epoch 89.8, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -400.626, Loss = 383.936
[2018-06-05 02:51] Train Step 97000, Epoch 89.8, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -417.080, Loss = 387.383
Performance on test set:
  Test Lower Bound = -461.064, Test Loss = 461.064
[2018-06-05 02:51] Train Step 97025, Epoch 89.8, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -379.908, Loss = 386.053
[2018-06-05 02:51] Train Step 97050, Epoch 89.9, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -383.927, Loss = 385.132
[2018-06-05 02:51] Train Step 97075, Epoch 89.9, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -381.170, Loss = 383.598
[2018-06-05 02:51] Train Step 97100, Epoch 89.9, Batch Size = 256, Examples/Sec = 3818.90, Train LB = -364.540, Loss = 382.806
[2018-06-05 02:51] Train Step 97125, Epoch 89.9, Batch Size = 256, Examples/Sec = 3851.89, Train LB = -376.395, Loss = 382.245
[2018-06-05 02:51] Train Step 97150, Epoch 90.0, Batch Size = 256, Examples/Sec = 3859.66, Train LB = -378.792, Loss = 382.544
[2018-06-05 02:52] Train Step 97175, Epoch 90.0, Batch Size = 256, Examples/Sec = 3864.26, Train LB = -392.872, Loss = 383.416
[2018-06-05 02:52] Train Step 97200, Epoch 90.0, Batch Size = 256, Examples/Sec = 3866.21, Train LB = -395.520, Loss = 387.532
Performance on test set:
  Test Lower Bound = -460.700, Test Loss = 460.700
[2018-06-05 02:52] Train Step 97225, Epoch 90.0, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -381.617, Loss = 386.320
[2018-06-05 02:52] Train Step 97250, Epoch 90.0, Batch Size = 256, Examples/Sec = 3878.31, Train LB = -383.363, Loss = 385.021
[2018-06-05 02:52] Train Step 97275, Epoch 90.1, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -377.709, Loss = 384.093
[2018-06-05 02:52] Train Step 97300, Epoch 90.1, Batch Size = 256, Examples/Sec = 3808.73, Train LB = -377.541, Loss = 382.409
[2018-06-05 02:52] Train Step 97325, Epoch 90.1, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -377.490, Loss = 381.794
[2018-06-05 02:52] Train Step 97350, Epoch 90.1, Batch Size = 256, Examples/Sec = 3881.37, Train LB = -377.716, Loss = 382.209
[2018-06-05 02:52] Train Step 97375, Epoch 90.2, Batch Size = 256, Examples/Sec = 3879.50, Train LB = -401.737, Loss = 383.153
[2018-06-05 02:52] Train Step 97400, Epoch 90.2, Batch Size = 256, Examples/Sec = 3850.33, Train LB = -404.410, Loss = 386.769
Performance on test set:
  Test Lower Bound = -460.122, Test Loss = 460.122
[2018-06-05 02:52] Train Step 97425, Epoch 90.2, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -364.455, Loss = 386.309
[2018-06-05 02:52] Train Step 97450, Epoch 90.2, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -389.225, Loss = 384.653
[2018-06-05 02:52] Train Step 97475, Epoch 90.3, Batch Size = 256, Examples/Sec = 3805.73, Train LB = -363.887, Loss = 383.011
[2018-06-05 02:52] Train Step 97500, Epoch 90.3, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -377.970, Loss = 382.021
[2018-06-05 02:52] Train Step 97525, Epoch 90.3, Batch Size = 256, Examples/Sec = 3850.44, Train LB = -378.167, Loss = 381.548
[2018-06-05 02:52] Train Step 97550, Epoch 90.3, Batch Size = 256, Examples/Sec = 3803.24, Train LB = -391.030, Loss = 381.749
[2018-06-05 02:52] Train Step 97575, Epoch 90.3, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -396.550, Loss = 383.214
[2018-06-05 02:52] Train Step 97600, Epoch 90.4, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -424.363, Loss = 386.929
Performance on test set:
  Test Lower Bound = -460.815, Test Loss = 460.815
[2018-06-05 02:52] Train Step 97625, Epoch 90.4, Batch Size = 256, Examples/Sec = 3851.02, Train LB = -398.787, Loss = 385.701
[2018-06-05 02:52] Train Step 97650, Epoch 90.4, Batch Size = 256, Examples/Sec = 3843.85, Train LB = -383.089, Loss = 384.606
[2018-06-05 02:52] Train Step 97675, Epoch 90.4, Batch Size = 256, Examples/Sec = 3865.37, Train LB = -381.997, Loss = 383.851
[2018-06-05 02:52] Train Step 97700, Epoch 90.5, Batch Size = 256, Examples/Sec = 3876.16, Train LB = -387.023, Loss = 382.300
[2018-06-05 02:52] Train Step 97725, Epoch 90.5, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -391.257, Loss = 381.135
[2018-06-05 02:52] Train Step 97750, Epoch 90.5, Batch Size = 256, Examples/Sec = 3851.64, Train LB = -384.615, Loss = 382.166
[2018-06-05 02:52] Train Step 97775, Epoch 90.5, Batch Size = 256, Examples/Sec = 3795.35, Train LB = -414.257, Loss = 383.612
[2018-06-05 02:52] Train Step 97800, Epoch 90.6, Batch Size = 256, Examples/Sec = 3878.20, Train LB = -419.665, Loss = 387.588
Performance on test set:
  Test Lower Bound = -459.722, Test Loss = 459.722
[2018-06-05 02:52] Train Step 97825, Epoch 90.6, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -394.893, Loss = 386.077
[2018-06-05 02:52] Train Step 97850, Epoch 90.6, Batch Size = 256, Examples/Sec = 3856.69, Train LB = -377.260, Loss = 384.555
[2018-06-05 02:53] Train Step 97875, Epoch 90.6, Batch Size = 256, Examples/Sec = 3835.15, Train LB = -384.945, Loss = 383.548
[2018-06-05 02:53] Train Step 97900, Epoch 90.6, Batch Size = 256, Examples/Sec = 3879.67, Train LB = -377.178, Loss = 382.842
[2018-06-05 02:53] Train Step 97925, Epoch 90.7, Batch Size = 256, Examples/Sec = 3837.27, Train LB = -383.149, Loss = 381.947
[2018-06-05 02:53] Train Step 97950, Epoch 90.7, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -379.381, Loss = 382.607
[2018-06-05 02:53] Train Step 97975, Epoch 90.7, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -386.788, Loss = 384.009
[2018-06-05 02:53] Train Step 98000, Epoch 90.7, Batch Size = 256, Examples/Sec = 3843.27, Train LB = -413.120, Loss = 387.465
Performance on test set:
  Test Lower Bound = -460.866, Test Loss = 460.866
[2018-06-05 02:53] Train Step 98025, Epoch 90.8, Batch Size = 256, Examples/Sec = 3815.93, Train LB = -376.176, Loss = 386.616
[2018-06-05 02:53] Train Step 98050, Epoch 90.8, Batch Size = 256, Examples/Sec = 3833.37, Train LB = -390.533, Loss = 384.205
[2018-06-05 02:53] Train Step 98075, Epoch 90.8, Batch Size = 256, Examples/Sec = 3849.45, Train LB = -370.672, Loss = 382.989
[2018-06-05 02:53] Train Step 98100, Epoch 90.8, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -401.184, Loss = 382.459
[2018-06-05 02:53] Train Step 98125, Epoch 90.9, Batch Size = 256, Examples/Sec = 3842.52, Train LB = -358.969, Loss = 382.286
[2018-06-05 02:53] Train Step 98150, Epoch 90.9, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -382.410, Loss = 381.736
[2018-06-05 02:53] Train Step 98175, Epoch 90.9, Batch Size = 256, Examples/Sec = 3868.70, Train LB = -415.588, Loss = 382.977
[2018-06-05 02:53] Train Step 98200, Epoch 90.9, Batch Size = 256, Examples/Sec = 3872.81, Train LB = -414.062, Loss = 387.143
Performance on test set:
  Test Lower Bound = -459.813, Test Loss = 459.813
[2018-06-05 02:53] Train Step 98225, Epoch 90.9, Batch Size = 256, Examples/Sec = 3858.55, Train LB = -371.808, Loss = 386.692
[2018-06-05 02:53] Train Step 98250, Epoch 91.0, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -370.577, Loss = 384.994
[2018-06-05 02:53] Train Step 98275, Epoch 91.0, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -397.216, Loss = 383.424
[2018-06-05 02:53] Train Step 98300, Epoch 91.0, Batch Size = 256, Examples/Sec = 3868.99, Train LB = -374.953, Loss = 383.070
[2018-06-05 02:53] Train Step 98325, Epoch 91.0, Batch Size = 256, Examples/Sec = 3846.10, Train LB = -358.856, Loss = 381.892
[2018-06-05 02:53] Train Step 98350, Epoch 91.1, Batch Size = 256, Examples/Sec = 3799.90, Train LB = -370.248, Loss = 382.427
[2018-06-05 02:53] Train Step 98375, Epoch 91.1, Batch Size = 256, Examples/Sec = 3859.20, Train LB = -396.053, Loss = 383.578
[2018-06-05 02:53] Train Step 98400, Epoch 91.1, Batch Size = 256, Examples/Sec = 3879.85, Train LB = -415.842, Loss = 386.944
Performance on test set:
  Test Lower Bound = -461.596, Test Loss = 461.596
[2018-06-05 02:53] Train Step 98425, Epoch 91.1, Batch Size = 256, Examples/Sec = 3836.59, Train LB = -375.592, Loss = 385.985
[2018-06-05 02:53] Train Step 98450, Epoch 91.2, Batch Size = 256, Examples/Sec = 3808.84, Train LB = -380.044, Loss = 385.048
[2018-06-05 02:53] Train Step 98475, Epoch 91.2, Batch Size = 256, Examples/Sec = 3862.94, Train LB = -376.791, Loss = 383.398
[2018-06-05 02:53] Train Step 98500, Epoch 91.2, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -400.516, Loss = 381.975
[2018-06-05 02:53] Train Step 98525, Epoch 91.2, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -379.738, Loss = 380.838
[2018-06-05 02:53] Train Step 98550, Epoch 91.2, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -385.814, Loss = 381.370
[2018-06-05 02:53] Train Step 98575, Epoch 91.3, Batch Size = 256, Examples/Sec = 3838.71, Train LB = -372.919, Loss = 383.451
[2018-06-05 02:53] Train Step 98600, Epoch 91.3, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -409.905, Loss = 386.876
Performance on test set:
  Test Lower Bound = -461.344, Test Loss = 461.344
[2018-06-05 02:54] Train Step 98625, Epoch 91.3, Batch Size = 256, Examples/Sec = 3876.27, Train LB = -393.187, Loss = 385.805
[2018-06-05 02:54] Train Step 98650, Epoch 91.3, Batch Size = 256, Examples/Sec = 3854.56, Train LB = -374.588, Loss = 384.560
[2018-06-05 02:54] Train Step 98675, Epoch 91.4, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -386.095, Loss = 383.582
[2018-06-05 02:54] Train Step 98700, Epoch 91.4, Batch Size = 256, Examples/Sec = 3879.38, Train LB = -386.995, Loss = 382.322
[2018-06-05 02:54] Train Step 98725, Epoch 91.4, Batch Size = 256, Examples/Sec = 3878.38, Train LB = -369.014, Loss = 382.029
[2018-06-05 02:54] Train Step 98750, Epoch 91.4, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -384.387, Loss = 382.259
[2018-06-05 02:54] Train Step 98775, Epoch 91.5, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -382.712, Loss = 383.448
[2018-06-05 02:54] Train Step 98800, Epoch 91.5, Batch Size = 256, Examples/Sec = 3837.34, Train LB = -422.546, Loss = 387.338
Performance on test set:
  Test Lower Bound = -462.955, Test Loss = 462.955
[2018-06-05 02:54] Train Step 98825, Epoch 91.5, Batch Size = 256, Examples/Sec = 3866.89, Train LB = -377.570, Loss = 386.334
[2018-06-05 02:54] Train Step 98850, Epoch 91.5, Batch Size = 256, Examples/Sec = 3847.54, Train LB = -376.891, Loss = 384.603
[2018-06-05 02:54] Train Step 98875, Epoch 91.6, Batch Size = 256, Examples/Sec = 3797.37, Train LB = -381.594, Loss = 383.552
[2018-06-05 02:54] Train Step 98900, Epoch 91.6, Batch Size = 256, Examples/Sec = 3875.67, Train LB = -368.682, Loss = 382.564
[2018-06-05 02:54] Train Step 98925, Epoch 91.6, Batch Size = 256, Examples/Sec = 3823.70, Train LB = -375.234, Loss = 381.417
[2018-06-05 02:54] Train Step 98950, Epoch 91.6, Batch Size = 256, Examples/Sec = 3809.36, Train LB = -407.433, Loss = 381.547
[2018-06-05 02:54] Train Step 98975, Epoch 91.6, Batch Size = 256, Examples/Sec = 3836.82, Train LB = -391.831, Loss = 383.152
[2018-06-05 02:54] Train Step 99000, Epoch 91.7, Batch Size = 256, Examples/Sec = 3844.72, Train LB = -414.002, Loss = 387.175
Performance on test set:
  Test Lower Bound = -462.230, Test Loss = 462.230
[2018-06-05 02:54] Train Step 99025, Epoch 91.7, Batch Size = 256, Examples/Sec = 3812.19, Train LB = -369.565, Loss = 385.782
[2018-06-05 02:54] Train Step 99050, Epoch 91.7, Batch Size = 256, Examples/Sec = 3885.22, Train LB = -376.099, Loss = 384.509
[2018-06-05 02:54] Train Step 99075, Epoch 91.7, Batch Size = 256, Examples/Sec = 3853.69, Train LB = -377.268, Loss = 383.293
[2018-06-05 02:54] Train Step 99100, Epoch 91.8, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -382.124, Loss = 382.359
[2018-06-05 02:54] Train Step 99125, Epoch 91.8, Batch Size = 256, Examples/Sec = 3884.68, Train LB = -384.852, Loss = 382.035
[2018-06-05 02:54] Train Step 99150, Epoch 91.8, Batch Size = 256, Examples/Sec = 3851.24, Train LB = -376.191, Loss = 382.350
[2018-06-05 02:54] Train Step 99175, Epoch 91.8, Batch Size = 256, Examples/Sec = 3865.02, Train LB = -398.252, Loss = 383.936
[2018-06-05 02:54] Train Step 99200, Epoch 91.9, Batch Size = 256, Examples/Sec = 3876.20, Train LB = -400.904, Loss = 387.495
Performance on test set:
  Test Lower Bound = -462.760, Test Loss = 462.760
[2018-06-05 02:54] Train Step 99225, Epoch 91.9, Batch Size = 256, Examples/Sec = 3884.74, Train LB = -382.433, Loss = 386.333
[2018-06-05 02:54] Train Step 99250, Epoch 91.9, Batch Size = 256, Examples/Sec = 3860.02, Train LB = -379.584, Loss = 384.729
[2018-06-05 02:54] Train Step 99275, Epoch 91.9, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -384.214, Loss = 383.312
[2018-06-05 02:55] Train Step 99300, Epoch 91.9, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -389.520, Loss = 381.558
[2018-06-05 02:55] Train Step 99325, Epoch 92.0, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -377.410, Loss = 381.303
[2018-06-05 02:55] Train Step 99350, Epoch 92.0, Batch Size = 256, Examples/Sec = 3862.46, Train LB = -368.750, Loss = 382.474
[2018-06-05 02:55] Train Step 99375, Epoch 92.0, Batch Size = 256, Examples/Sec = 3866.50, Train LB = -396.235, Loss = 382.796
[2018-06-05 02:55] Train Step 99400, Epoch 92.0, Batch Size = 256, Examples/Sec = 3805.22, Train LB = -434.490, Loss = 386.525
Performance on test set:
  Test Lower Bound = -462.806, Test Loss = 462.806
[2018-06-05 02:55] Train Step 99425, Epoch 92.1, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -383.548, Loss = 386.127
[2018-06-05 02:55] Train Step 99450, Epoch 92.1, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -378.813, Loss = 384.201
[2018-06-05 02:55] Train Step 99475, Epoch 92.1, Batch Size = 256, Examples/Sec = 3847.49, Train LB = -381.473, Loss = 383.173
[2018-06-05 02:55] Train Step 99500, Epoch 92.1, Batch Size = 256, Examples/Sec = 3798.34, Train LB = -368.758, Loss = 382.189
[2018-06-05 02:55] Train Step 99525, Epoch 92.2, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -381.583, Loss = 381.609
[2018-06-05 02:55] Train Step 99550, Epoch 92.2, Batch Size = 256, Examples/Sec = 3874.09, Train LB = -392.384, Loss = 382.195
[2018-06-05 02:55] Train Step 99575, Epoch 92.2, Batch Size = 256, Examples/Sec = 3860.59, Train LB = -386.037, Loss = 384.047
[2018-06-05 02:55] Train Step 99600, Epoch 92.2, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -405.886, Loss = 387.200
Performance on test set:
  Test Lower Bound = -461.436, Test Loss = 461.436
[2018-06-05 02:55] Train Step 99625, Epoch 92.2, Batch Size = 256, Examples/Sec = 3883.67, Train LB = -372.994, Loss = 385.965
[2018-06-05 02:55] Train Step 99650, Epoch 92.3, Batch Size = 256, Examples/Sec = 3868.71, Train LB = -389.468, Loss = 384.424
[2018-06-05 02:55] Train Step 99675, Epoch 92.3, Batch Size = 256, Examples/Sec = 3863.97, Train LB = -385.520, Loss = 382.624
[2018-06-05 02:55] Train Step 99700, Epoch 92.3, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -372.419, Loss = 381.720
[2018-06-05 02:55] Train Step 99725, Epoch 92.3, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -367.249, Loss = 381.047
[2018-06-05 02:55] Train Step 99750, Epoch 92.4, Batch Size = 256, Examples/Sec = 3870.75, Train LB = -397.784, Loss = 381.049
[2018-06-05 02:55] Train Step 99775, Epoch 92.4, Batch Size = 256, Examples/Sec = 3871.92, Train LB = -386.104, Loss = 383.503
[2018-06-05 02:55] Train Step 99800, Epoch 92.4, Batch Size = 256, Examples/Sec = 3886.20, Train LB = -409.441, Loss = 386.903
Performance on test set:
  Test Lower Bound = -463.909, Test Loss = 463.909
[2018-06-05 02:55] Train Step 99825, Epoch 92.4, Batch Size = 256, Examples/Sec = 3849.68, Train LB = -375.966, Loss = 386.080
[2018-06-05 02:55] Train Step 99850, Epoch 92.5, Batch Size = 256, Examples/Sec = 3847.31, Train LB = -378.797, Loss = 384.389
[2018-06-05 02:55] Train Step 99875, Epoch 92.5, Batch Size = 256, Examples/Sec = 3856.06, Train LB = -374.683, Loss = 382.930
[2018-06-05 02:55] Train Step 99900, Epoch 92.5, Batch Size = 256, Examples/Sec = 3848.29, Train LB = -354.922, Loss = 381.986
[2018-06-05 02:55] Train Step 99925, Epoch 92.5, Batch Size = 256, Examples/Sec = 3837.04, Train LB = -379.993, Loss = 380.743
[2018-06-05 02:55] Train Step 99950, Epoch 92.5, Batch Size = 256, Examples/Sec = 3854.42, Train LB = -387.764, Loss = 381.115
[2018-06-05 02:55] Train Step 99975, Epoch 92.6, Batch Size = 256, Examples/Sec = 3779.65, Train LB = -392.028, Loss = 382.355
[2018-06-05 02:55] Train Step 100000, Epoch 92.6, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -417.062, Loss = 386.428
Performance on test set:
  Test Lower Bound = -460.933, Test Loss = 460.933
[2018-06-05 02:56] Train Step 100025, Epoch 92.6, Batch Size = 256, Examples/Sec = 3871.33, Train LB = -390.147, Loss = 385.890
[2018-06-05 02:56] Train Step 100050, Epoch 92.6, Batch Size = 256, Examples/Sec = 3849.28, Train LB = -363.756, Loss = 384.157
[2018-06-05 02:56] Train Step 100075, Epoch 92.7, Batch Size = 256, Examples/Sec = 3832.34, Train LB = -372.315, Loss = 383.098
[2018-06-05 02:56] Train Step 100100, Epoch 92.7, Batch Size = 256, Examples/Sec = 3883.39, Train LB = -383.376, Loss = 381.251
[2018-06-05 02:56] Train Step 100125, Epoch 92.7, Batch Size = 256, Examples/Sec = 3849.90, Train LB = -378.552, Loss = 381.039
[2018-06-05 02:56] Train Step 100150, Epoch 92.7, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -381.434, Loss = 381.080
[2018-06-05 02:56] Train Step 100175, Epoch 92.8, Batch Size = 256, Examples/Sec = 3871.40, Train LB = -383.266, Loss = 383.158
[2018-06-05 02:56] Train Step 100200, Epoch 92.8, Batch Size = 256, Examples/Sec = 3879.08, Train LB = -413.913, Loss = 387.251
Performance on test set:
  Test Lower Bound = -462.317, Test Loss = 462.317
[2018-06-05 02:56] Train Step 100225, Epoch 92.8, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -368.958, Loss = 386.433
[2018-06-05 02:56] Train Step 100250, Epoch 92.8, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -369.031, Loss = 384.535
[2018-06-05 02:56] Train Step 100275, Epoch 92.8, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -390.234, Loss = 382.833
[2018-06-05 02:56] Train Step 100300, Epoch 92.9, Batch Size = 256, Examples/Sec = 3836.01, Train LB = -382.460, Loss = 381.781
[2018-06-05 02:56] Train Step 100325, Epoch 92.9, Batch Size = 256, Examples/Sec = 3852.91, Train LB = -400.100, Loss = 381.205
[2018-06-05 02:56] Train Step 100350, Epoch 92.9, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -386.555, Loss = 381.532
[2018-06-05 02:56] Train Step 100375, Epoch 92.9, Batch Size = 256, Examples/Sec = 3853.09, Train LB = -386.246, Loss = 383.115
[2018-06-05 02:56] Train Step 100400, Epoch 93.0, Batch Size = 256, Examples/Sec = 3851.12, Train LB = -399.901, Loss = 386.855
Performance on test set:
  Test Lower Bound = -463.009, Test Loss = 463.009
[2018-06-05 02:56] Train Step 100425, Epoch 93.0, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -382.116, Loss = 385.509
[2018-06-05 02:56] Train Step 100450, Epoch 93.0, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -389.986, Loss = 383.985
[2018-06-05 02:56] Train Step 100475, Epoch 93.0, Batch Size = 256, Examples/Sec = 3819.98, Train LB = -375.453, Loss = 382.925
[2018-06-05 02:56] Train Step 100500, Epoch 93.1, Batch Size = 256, Examples/Sec = 3853.97, Train LB = -386.112, Loss = 381.971
[2018-06-05 02:56] Train Step 100525, Epoch 93.1, Batch Size = 256, Examples/Sec = 3861.81, Train LB = -383.433, Loss = 381.580
[2018-06-05 02:56] Train Step 100550, Epoch 93.1, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -379.574, Loss = 381.319
[2018-06-05 02:56] Train Step 100575, Epoch 93.1, Batch Size = 256, Examples/Sec = 3879.90, Train LB = -387.840, Loss = 382.891
[2018-06-05 02:56] Train Step 100600, Epoch 93.1, Batch Size = 256, Examples/Sec = 3883.97, Train LB = -420.965, Loss = 386.833
Performance on test set:
  Test Lower Bound = -463.223, Test Loss = 463.223
[2018-06-05 02:56] Train Step 100625, Epoch 93.2, Batch Size = 256, Examples/Sec = 3843.55, Train LB = -394.553, Loss = 385.978
[2018-06-05 02:56] Train Step 100650, Epoch 93.2, Batch Size = 256, Examples/Sec = 3862.64, Train LB = -379.921, Loss = 384.745
[2018-06-05 02:56] Train Step 100675, Epoch 93.2, Batch Size = 256, Examples/Sec = 3866.66, Train LB = -374.031, Loss = 383.139
[2018-06-05 02:56] Train Step 100700, Epoch 93.2, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -384.542, Loss = 381.287
[2018-06-05 02:56] Train Step 100725, Epoch 93.3, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -371.204, Loss = 380.892
[2018-06-05 02:57] Train Step 100750, Epoch 93.3, Batch Size = 256, Examples/Sec = 3853.00, Train LB = -384.326, Loss = 381.220
[2018-06-05 02:57] Train Step 100775, Epoch 93.3, Batch Size = 256, Examples/Sec = 3851.35, Train LB = -405.369, Loss = 383.017
[2018-06-05 02:57] Train Step 100800, Epoch 93.3, Batch Size = 256, Examples/Sec = 3851.60, Train LB = -406.865, Loss = 387.145
Performance on test set:
  Test Lower Bound = -463.240, Test Loss = 463.240
[2018-06-05 02:57] Train Step 100825, Epoch 93.4, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -371.403, Loss = 385.432
[2018-06-05 02:57] Train Step 100850, Epoch 93.4, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -378.290, Loss = 384.215
[2018-06-05 02:57] Train Step 100875, Epoch 93.4, Batch Size = 256, Examples/Sec = 3846.55, Train LB = -382.205, Loss = 383.276
[2018-06-05 02:57] Train Step 100900, Epoch 93.4, Batch Size = 256, Examples/Sec = 3872.51, Train LB = -363.433, Loss = 381.694
[2018-06-05 02:57] Train Step 100925, Epoch 93.4, Batch Size = 256, Examples/Sec = 3876.91, Train LB = -384.071, Loss = 381.433
[2018-06-05 02:57] Train Step 100950, Epoch 93.5, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -398.867, Loss = 381.581
[2018-06-05 02:57] Train Step 100975, Epoch 93.5, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -375.216, Loss = 382.767
[2018-06-05 02:57] Train Step 101000, Epoch 93.5, Batch Size = 256, Examples/Sec = 3862.69, Train LB = -399.766, Loss = 387.085
Performance on test set:
  Test Lower Bound = -463.178, Test Loss = 463.178
[2018-06-05 02:57] Train Step 101025, Epoch 93.5, Batch Size = 256, Examples/Sec = 3880.72, Train LB = -402.287, Loss = 385.606
[2018-06-05 02:57] Train Step 101050, Epoch 93.6, Batch Size = 256, Examples/Sec = 3848.70, Train LB = -392.962, Loss = 384.180
[2018-06-05 02:57] Train Step 101075, Epoch 93.6, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -383.509, Loss = 383.040
[2018-06-05 02:57] Train Step 101100, Epoch 93.6, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -390.091, Loss = 381.938
[2018-06-05 02:57] Train Step 101125, Epoch 93.6, Batch Size = 256, Examples/Sec = 3860.64, Train LB = -371.973, Loss = 381.299
[2018-06-05 02:57] Train Step 101150, Epoch 93.7, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -380.875, Loss = 381.142
[2018-06-05 02:57] Train Step 101175, Epoch 93.7, Batch Size = 256, Examples/Sec = 3867.07, Train LB = -406.076, Loss = 382.629
[2018-06-05 02:57] Train Step 101200, Epoch 93.7, Batch Size = 256, Examples/Sec = 3843.22, Train LB = -416.094, Loss = 387.027
Performance on test set:
  Test Lower Bound = -462.955, Test Loss = 462.955
[2018-06-05 02:57] Train Step 101225, Epoch 93.7, Batch Size = 256, Examples/Sec = 3880.26, Train LB = -364.845, Loss = 385.910
[2018-06-05 02:57] Train Step 101250, Epoch 93.8, Batch Size = 256, Examples/Sec = 3861.99, Train LB = -374.557, Loss = 384.565
[2018-06-05 02:57] Train Step 101275, Epoch 93.8, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -396.904, Loss = 382.183
[2018-06-05 02:57] Train Step 101300, Epoch 93.8, Batch Size = 256, Examples/Sec = 3872.91, Train LB = -365.111, Loss = 381.236
[2018-06-05 02:57] Train Step 101325, Epoch 93.8, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -379.270, Loss = 380.834
[2018-06-05 02:57] Train Step 101350, Epoch 93.8, Batch Size = 256, Examples/Sec = 3807.38, Train LB = -393.351, Loss = 381.189
[2018-06-05 02:57] Train Step 101375, Epoch 93.9, Batch Size = 256, Examples/Sec = 3874.09, Train LB = -394.697, Loss = 383.002
[2018-06-05 02:57] Train Step 101400, Epoch 93.9, Batch Size = 256, Examples/Sec = 3863.33, Train LB = -423.267, Loss = 386.531
Performance on test set:
  Test Lower Bound = -463.063, Test Loss = 463.063
[2018-06-05 02:57] Train Step 101425, Epoch 93.9, Batch Size = 256, Examples/Sec = 3839.69, Train LB = -408.277, Loss = 385.708
[2018-06-05 02:58] Train Step 101450, Epoch 93.9, Batch Size = 256, Examples/Sec = 3870.76, Train LB = -390.338, Loss = 384.231
[2018-06-05 02:58] Train Step 101475, Epoch 94.0, Batch Size = 256, Examples/Sec = 3851.88, Train LB = -369.469, Loss = 382.045
[2018-06-05 02:58] Train Step 101500, Epoch 94.0, Batch Size = 256, Examples/Sec = 3879.55, Train LB = -384.703, Loss = 381.106
[2018-06-05 02:58] Train Step 101525, Epoch 94.0, Batch Size = 256, Examples/Sec = 3881.85, Train LB = -380.685, Loss = 380.483
[2018-06-05 02:58] Train Step 101550, Epoch 94.0, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -381.055, Loss = 380.872
[2018-06-05 02:58] Train Step 101575, Epoch 94.1, Batch Size = 256, Examples/Sec = 3857.57, Train LB = -391.904, Loss = 382.752
[2018-06-05 02:58] Train Step 101600, Epoch 94.1, Batch Size = 256, Examples/Sec = 3845.92, Train LB = -412.612, Loss = 386.489
Performance on test set:
  Test Lower Bound = -462.003, Test Loss = 462.003
[2018-06-05 02:58] Train Step 101625, Epoch 94.1, Batch Size = 256, Examples/Sec = 3811.45, Train LB = -369.891, Loss = 385.270
[2018-06-05 02:58] Train Step 101650, Epoch 94.1, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -384.960, Loss = 383.339
[2018-06-05 02:58] Train Step 101675, Epoch 94.1, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -375.797, Loss = 382.640
[2018-06-05 02:58] Train Step 101700, Epoch 94.2, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -388.709, Loss = 381.681
[2018-06-05 02:58] Train Step 101725, Epoch 94.2, Batch Size = 256, Examples/Sec = 3832.33, Train LB = -378.961, Loss = 381.279
[2018-06-05 02:58] Train Step 101750, Epoch 94.2, Batch Size = 256, Examples/Sec = 3868.06, Train LB = -388.961, Loss = 380.692
[2018-06-05 02:58] Train Step 101775, Epoch 94.2, Batch Size = 256, Examples/Sec = 3851.88, Train LB = -393.212, Loss = 382.288
[2018-06-05 02:58] Train Step 101800, Epoch 94.3, Batch Size = 256, Examples/Sec = 3825.57, Train LB = -407.092, Loss = 386.306
Performance on test set:
  Test Lower Bound = -464.174, Test Loss = 464.174
[2018-06-05 02:58] Train Step 101825, Epoch 94.3, Batch Size = 256, Examples/Sec = 3816.35, Train LB = -382.040, Loss = 385.647
[2018-06-05 02:58] Train Step 101850, Epoch 94.3, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -384.576, Loss = 384.041
[2018-06-05 02:58] Train Step 101875, Epoch 94.3, Batch Size = 256, Examples/Sec = 3861.81, Train LB = -386.259, Loss = 382.963
[2018-06-05 02:58] Train Step 101900, Epoch 94.4, Batch Size = 256, Examples/Sec = 3858.45, Train LB = -382.457, Loss = 382.062
[2018-06-05 02:58] Train Step 101925, Epoch 94.4, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -384.799, Loss = 381.002
[2018-06-05 02:58] Train Step 101950, Epoch 94.4, Batch Size = 256, Examples/Sec = 3869.28, Train LB = -378.896, Loss = 380.862
[2018-06-05 02:58] Train Step 101975, Epoch 94.4, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -409.452, Loss = 382.623
[2018-06-05 02:58] Train Step 102000, Epoch 94.4, Batch Size = 256, Examples/Sec = 3836.41, Train LB = -421.735, Loss = 386.530
Performance on test set:
  Test Lower Bound = -461.596, Test Loss = 461.596
[2018-06-05 02:58] Train Step 102025, Epoch 94.5, Batch Size = 256, Examples/Sec = 3866.32, Train LB = -387.292, Loss = 385.316
[2018-06-05 02:58] Train Step 102050, Epoch 94.5, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -368.487, Loss = 383.809
[2018-06-05 02:58] Train Step 102075, Epoch 94.5, Batch Size = 256, Examples/Sec = 3860.49, Train LB = -377.185, Loss = 382.417
[2018-06-05 02:58] Train Step 102100, Epoch 94.5, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -371.313, Loss = 381.377
[2018-06-05 02:58] Train Step 102125, Epoch 94.6, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -370.876, Loss = 380.383
[2018-06-05 02:58] Train Step 102150, Epoch 94.6, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -370.834, Loss = 380.882
[2018-06-05 02:59] Train Step 102175, Epoch 94.6, Batch Size = 256, Examples/Sec = 3715.42, Train LB = -393.141, Loss = 381.879
[2018-06-05 02:59] Train Step 102200, Epoch 94.6, Batch Size = 256, Examples/Sec = 3825.98, Train LB = -417.739, Loss = 386.473
Performance on test set:
  Test Lower Bound = -463.570, Test Loss = 463.570
[2018-06-05 02:59] Train Step 102225, Epoch 94.7, Batch Size = 256, Examples/Sec = 3811.34, Train LB = -374.560, Loss = 385.455
[2018-06-05 02:59] Train Step 102250, Epoch 94.7, Batch Size = 256, Examples/Sec = 3871.04, Train LB = -376.951, Loss = 384.264
[2018-06-05 02:59] Train Step 102275, Epoch 94.7, Batch Size = 256, Examples/Sec = 3827.23, Train LB = -386.640, Loss = 382.622
[2018-06-05 02:59] Train Step 102300, Epoch 94.7, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -376.119, Loss = 381.648
[2018-06-05 02:59] Train Step 102325, Epoch 94.7, Batch Size = 256, Examples/Sec = 3876.97, Train LB = -385.198, Loss = 381.298
[2018-06-05 02:59] Train Step 102350, Epoch 94.8, Batch Size = 256, Examples/Sec = 3853.44, Train LB = -373.902, Loss = 381.174
[2018-06-05 02:59] Train Step 102375, Epoch 94.8, Batch Size = 256, Examples/Sec = 3859.08, Train LB = -373.735, Loss = 382.756
[2018-06-05 02:59] Train Step 102400, Epoch 94.8, Batch Size = 256, Examples/Sec = 3871.22, Train LB = -405.835, Loss = 386.891
Performance on test set:
  Test Lower Bound = -464.133, Test Loss = 464.133
[2018-06-05 02:59] Train Step 102425, Epoch 94.8, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -399.114, Loss = 385.842
[2018-06-05 02:59] Train Step 102450, Epoch 94.9, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -381.460, Loss = 383.713
[2018-06-05 02:59] Train Step 102475, Epoch 94.9, Batch Size = 256, Examples/Sec = 3869.87, Train LB = -364.274, Loss = 383.138
[2018-06-05 02:59] Train Step 102500, Epoch 94.9, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -364.816, Loss = 381.926
[2018-06-05 02:59] Train Step 102525, Epoch 94.9, Batch Size = 256, Examples/Sec = 3844.94, Train LB = -384.080, Loss = 381.103
[2018-06-05 02:59] Train Step 102550, Epoch 95.0, Batch Size = 256, Examples/Sec = 3870.51, Train LB = -393.208, Loss = 381.306
[2018-06-05 02:59] Train Step 102575, Epoch 95.0, Batch Size = 256, Examples/Sec = 3843.44, Train LB = -392.025, Loss = 382.952
[2018-06-05 02:59] Train Step 102600, Epoch 95.0, Batch Size = 256, Examples/Sec = 3865.26, Train LB = -393.853, Loss = 386.882
Performance on test set:
  Test Lower Bound = -463.048, Test Loss = 463.048
[2018-06-05 02:59] Train Step 102625, Epoch 95.0, Batch Size = 256, Examples/Sec = 3899.88, Train LB = -368.252, Loss = 386.097
[2018-06-05 02:59] Train Step 102650, Epoch 95.0, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -367.123, Loss = 384.317
[2018-06-05 02:59] Train Step 102675, Epoch 95.1, Batch Size = 256, Examples/Sec = 3828.38, Train LB = -372.603, Loss = 382.604
[2018-06-05 02:59] Train Step 102700, Epoch 95.1, Batch Size = 256, Examples/Sec = 3845.97, Train LB = -384.025, Loss = 380.849
[2018-06-05 02:59] Train Step 102725, Epoch 95.1, Batch Size = 256, Examples/Sec = 3856.06, Train LB = -378.871, Loss = 380.565
[2018-06-05 02:59] Train Step 102750, Epoch 95.1, Batch Size = 256, Examples/Sec = 3804.37, Train LB = -380.955, Loss = 380.598
[2018-06-05 02:59] Train Step 102775, Epoch 95.2, Batch Size = 256, Examples/Sec = 3848.70, Train LB = -395.718, Loss = 382.170
[2018-06-05 02:59] Train Step 102800, Epoch 95.2, Batch Size = 256, Examples/Sec = 3854.26, Train LB = -416.922, Loss = 386.573
Performance on test set:
  Test Lower Bound = -463.023, Test Loss = 463.023
[2018-06-05 02:59] Train Step 102825, Epoch 95.2, Batch Size = 256, Examples/Sec = 3837.16, Train LB = -370.322, Loss = 385.736
[2018-06-05 02:59] Train Step 102850, Epoch 95.2, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -378.579, Loss = 383.941
[2018-06-05 03:00] Train Step 102875, Epoch 95.3, Batch Size = 256, Examples/Sec = 3880.85, Train LB = -363.343, Loss = 382.707
[2018-06-05 03:00] Train Step 102900, Epoch 95.3, Batch Size = 256, Examples/Sec = 3838.71, Train LB = -370.157, Loss = 381.907
[2018-06-05 03:00] Train Step 102925, Epoch 95.3, Batch Size = 256, Examples/Sec = 3804.49, Train LB = -374.743, Loss = 381.110
[2018-06-05 03:00] Train Step 102950, Epoch 95.3, Batch Size = 256, Examples/Sec = 3873.28, Train LB = -376.963, Loss = 381.318
[2018-06-05 03:00] Train Step 102975, Epoch 95.3, Batch Size = 256, Examples/Sec = 3835.15, Train LB = -382.228, Loss = 382.426
[2018-06-05 03:00] Train Step 103000, Epoch 95.4, Batch Size = 256, Examples/Sec = 3876.32, Train LB = -418.614, Loss = 386.268
Performance on test set:
  Test Lower Bound = -461.832, Test Loss = 461.832
[2018-06-05 03:00] Train Step 103025, Epoch 95.4, Batch Size = 256, Examples/Sec = 3873.63, Train LB = -390.480, Loss = 385.728
[2018-06-05 03:00] Train Step 103050, Epoch 95.4, Batch Size = 256, Examples/Sec = 3854.85, Train LB = -387.016, Loss = 384.233
[2018-06-05 03:00] Train Step 103075, Epoch 95.4, Batch Size = 256, Examples/Sec = 3886.27, Train LB = -397.937, Loss = 383.052
[2018-06-05 03:00] Train Step 103100, Epoch 95.5, Batch Size = 256, Examples/Sec = 3847.83, Train LB = -367.356, Loss = 382.092
[2018-06-05 03:00] Train Step 103125, Epoch 95.5, Batch Size = 256, Examples/Sec = 3803.86, Train LB = -385.373, Loss = 380.619
[2018-06-05 03:00] Train Step 103150, Epoch 95.5, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -371.782, Loss = 380.641
[2018-06-05 03:00] Train Step 103175, Epoch 95.5, Batch Size = 256, Examples/Sec = 3851.53, Train LB = -399.459, Loss = 381.950
[2018-06-05 03:00] Train Step 103200, Epoch 95.6, Batch Size = 256, Examples/Sec = 3819.31, Train LB = -411.063, Loss = 386.090
Performance on test set:
  Test Lower Bound = -464.754, Test Loss = 464.754
[2018-06-05 03:00] Train Step 103225, Epoch 95.6, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -382.565, Loss = 384.700
[2018-06-05 03:00] Train Step 103250, Epoch 95.6, Batch Size = 256, Examples/Sec = 3844.47, Train LB = -382.550, Loss = 383.508
[2018-06-05 03:00] Train Step 103275, Epoch 95.6, Batch Size = 256, Examples/Sec = 3875.39, Train LB = -379.420, Loss = 382.733
[2018-06-05 03:00] Train Step 103300, Epoch 95.6, Batch Size = 256, Examples/Sec = 3841.65, Train LB = -368.364, Loss = 380.737
[2018-06-05 03:00] Train Step 103325, Epoch 95.7, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -389.344, Loss = 379.961
[2018-06-05 03:00] Train Step 103350, Epoch 95.7, Batch Size = 256, Examples/Sec = 3856.40, Train LB = -390.765, Loss = 380.710
[2018-06-05 03:00] Train Step 103375, Epoch 95.7, Batch Size = 256, Examples/Sec = 3876.91, Train LB = -389.268, Loss = 382.773
[2018-06-05 03:00] Train Step 103400, Epoch 95.7, Batch Size = 256, Examples/Sec = 3820.55, Train LB = -403.735, Loss = 387.010
Performance on test set:
  Test Lower Bound = -461.702, Test Loss = 461.702
[2018-06-05 03:00] Train Step 103425, Epoch 95.8, Batch Size = 256, Examples/Sec = 3859.15, Train LB = -380.232, Loss = 385.752
[2018-06-05 03:00] Train Step 103450, Epoch 95.8, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -407.712, Loss = 384.231
[2018-06-05 03:00] Train Step 103475, Epoch 95.8, Batch Size = 256, Examples/Sec = 3867.24, Train LB = -388.786, Loss = 383.228
[2018-06-05 03:00] Train Step 103500, Epoch 95.8, Batch Size = 256, Examples/Sec = 3852.62, Train LB = -385.339, Loss = 381.716
[2018-06-05 03:00] Train Step 103525, Epoch 95.9, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -372.564, Loss = 380.747
[2018-06-05 03:00] Train Step 103550, Epoch 95.9, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -387.185, Loss = 380.947
[2018-06-05 03:00] Train Step 103575, Epoch 95.9, Batch Size = 256, Examples/Sec = 3863.98, Train LB = -384.346, Loss = 382.682
[2018-06-05 03:00] Train Step 103600, Epoch 95.9, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -410.935, Loss = 386.562
Performance on test set:
  Test Lower Bound = -463.282, Test Loss = 463.282
[2018-06-05 03:01] Train Step 103625, Epoch 95.9, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -390.029, Loss = 385.856
[2018-06-05 03:01] Train Step 103650, Epoch 96.0, Batch Size = 256, Examples/Sec = 3872.10, Train LB = -377.130, Loss = 383.734
[2018-06-05 03:01] Train Step 103675, Epoch 96.0, Batch Size = 256, Examples/Sec = 3870.11, Train LB = -385.318, Loss = 382.385
[2018-06-05 03:01] Train Step 103700, Epoch 96.0, Batch Size = 256, Examples/Sec = 3846.44, Train LB = -368.893, Loss = 380.744
[2018-06-05 03:01] Train Step 103725, Epoch 96.0, Batch Size = 256, Examples/Sec = 3875.02, Train LB = -369.741, Loss = 380.121
[2018-06-05 03:01] Train Step 103750, Epoch 96.1, Batch Size = 256, Examples/Sec = 3831.71, Train LB = -396.139, Loss = 380.763
[2018-06-05 03:01] Train Step 103775, Epoch 96.1, Batch Size = 256, Examples/Sec = 3858.49, Train LB = -385.318, Loss = 382.199
[2018-06-05 03:01] Train Step 103800, Epoch 96.1, Batch Size = 256, Examples/Sec = 3838.25, Train LB = -409.918, Loss = 385.671
Performance on test set:
  Test Lower Bound = -463.545, Test Loss = 463.545
[2018-06-05 03:01] Train Step 103825, Epoch 96.1, Batch Size = 256, Examples/Sec = 3886.62, Train LB = -384.962, Loss = 384.864
[2018-06-05 03:01] Train Step 103850, Epoch 96.2, Batch Size = 256, Examples/Sec = 3862.45, Train LB = -372.100, Loss = 383.046
[2018-06-05 03:01] Train Step 103875, Epoch 96.2, Batch Size = 256, Examples/Sec = 3875.08, Train LB = -382.548, Loss = 381.613
[2018-06-05 03:01] Train Step 103900, Epoch 96.2, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -381.728, Loss = 380.311
[2018-06-05 03:01] Train Step 103925, Epoch 96.2, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -383.047, Loss = 380.001
[2018-06-05 03:01] Train Step 103950, Epoch 96.2, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -402.077, Loss = 379.758
[2018-06-05 03:01] Train Step 103975, Epoch 96.3, Batch Size = 256, Examples/Sec = 3819.42, Train LB = -392.055, Loss = 381.185
[2018-06-05 03:01] Train Step 104000, Epoch 96.3, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -410.826, Loss = 386.081
Performance on test set:
  Test Lower Bound = -464.572, Test Loss = 464.572
[2018-06-05 03:01] Train Step 104025, Epoch 96.3, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -373.015, Loss = 385.383
[2018-06-05 03:01] Train Step 104050, Epoch 96.3, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -387.775, Loss = 383.570
[2018-06-05 03:01] Train Step 104075, Epoch 96.4, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -377.279, Loss = 382.127
[2018-06-05 03:01] Train Step 104100, Epoch 96.4, Batch Size = 256, Examples/Sec = 3876.25, Train LB = -375.736, Loss = 380.723
[2018-06-05 03:01] Train Step 104125, Epoch 96.4, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -374.206, Loss = 379.777
[2018-06-05 03:01] Train Step 104150, Epoch 96.4, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -386.205, Loss = 380.468
[2018-06-05 03:01] Train Step 104175, Epoch 96.5, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -393.921, Loss = 382.156
[2018-06-05 03:01] Train Step 104200, Epoch 96.5, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -410.803, Loss = 385.712
Performance on test set:
  Test Lower Bound = -463.436, Test Loss = 463.436
[2018-06-05 03:01] Train Step 104225, Epoch 96.5, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -370.260, Loss = 384.910
[2018-06-05 03:01] Train Step 104250, Epoch 96.5, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -365.613, Loss = 383.452
[2018-06-05 03:01] Train Step 104275, Epoch 96.6, Batch Size = 256, Examples/Sec = 3872.40, Train LB = -373.501, Loss = 382.113
[2018-06-05 03:01] Train Step 104300, Epoch 96.6, Batch Size = 256, Examples/Sec = 3816.23, Train LB = -381.206, Loss = 380.877
[2018-06-05 03:02] Train Step 104325, Epoch 96.6, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -360.725, Loss = 380.280
[2018-06-05 03:02] Train Step 104350, Epoch 96.6, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -389.075, Loss = 380.129
[2018-06-05 03:02] Train Step 104375, Epoch 96.6, Batch Size = 256, Examples/Sec = 3872.75, Train LB = -414.531, Loss = 382.245
[2018-06-05 03:02] Train Step 104400, Epoch 96.7, Batch Size = 256, Examples/Sec = 3817.42, Train LB = -411.968, Loss = 386.890
Performance on test set:
  Test Lower Bound = -467.285, Test Loss = 467.285
[2018-06-05 03:02] Train Step 104425, Epoch 96.7, Batch Size = 256, Examples/Sec = 3873.33, Train LB = -383.461, Loss = 385.505
[2018-06-05 03:02] Train Step 104450, Epoch 96.7, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -368.954, Loss = 384.000
[2018-06-05 03:02] Train Step 104475, Epoch 96.7, Batch Size = 256, Examples/Sec = 3849.52, Train LB = -388.908, Loss = 382.541
[2018-06-05 03:02] Train Step 104500, Epoch 96.8, Batch Size = 256, Examples/Sec = 3833.42, Train LB = -380.203, Loss = 380.949
[2018-06-05 03:02] Train Step 104525, Epoch 96.8, Batch Size = 256, Examples/Sec = 3856.75, Train LB = -372.325, Loss = 380.055
[2018-06-05 03:02] Train Step 104550, Epoch 96.8, Batch Size = 256, Examples/Sec = 3865.38, Train LB = -392.568, Loss = 380.913
[2018-06-05 03:02] Train Step 104575, Epoch 96.8, Batch Size = 256, Examples/Sec = 3879.50, Train LB = -388.562, Loss = 382.498
[2018-06-05 03:02] Train Step 104600, Epoch 96.9, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -416.009, Loss = 386.084
Performance on test set:
  Test Lower Bound = -462.384, Test Loss = 462.384
[2018-06-05 03:02] Train Step 104625, Epoch 96.9, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -381.465, Loss = 384.733
[2018-06-05 03:02] Train Step 104650, Epoch 96.9, Batch Size = 256, Examples/Sec = 3854.66, Train LB = -377.556, Loss = 383.202
[2018-06-05 03:02] Train Step 104675, Epoch 96.9, Batch Size = 256, Examples/Sec = 3891.88, Train LB = -385.130, Loss = 381.936
[2018-06-05 03:02] Train Step 104700, Epoch 96.9, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -386.468, Loss = 381.004
[2018-06-05 03:02] Train Step 104725, Epoch 97.0, Batch Size = 256, Examples/Sec = 3841.49, Train LB = -360.402, Loss = 380.397
[2018-06-05 03:02] Train Step 104750, Epoch 97.0, Batch Size = 256, Examples/Sec = 3836.12, Train LB = -395.606, Loss = 380.641
[2018-06-05 03:02] Train Step 104775, Epoch 97.0, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -393.345, Loss = 382.783
[2018-06-05 03:02] Train Step 104800, Epoch 97.0, Batch Size = 256, Examples/Sec = 3875.32, Train LB = -415.444, Loss = 386.731
Performance on test set:
  Test Lower Bound = -464.350, Test Loss = 464.350
[2018-06-05 03:02] Train Step 104825, Epoch 97.1, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -368.122, Loss = 385.389
[2018-06-05 03:02] Train Step 104850, Epoch 97.1, Batch Size = 256, Examples/Sec = 3860.84, Train LB = -387.822, Loss = 383.553
[2018-06-05 03:02] Train Step 104875, Epoch 97.1, Batch Size = 256, Examples/Sec = 3860.83, Train LB = -384.429, Loss = 381.992
[2018-06-05 03:02] Train Step 104900, Epoch 97.1, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -375.785, Loss = 380.921
[2018-06-05 03:02] Train Step 104925, Epoch 97.2, Batch Size = 256, Examples/Sec = 3839.80, Train LB = -403.475, Loss = 380.354
[2018-06-05 03:02] Train Step 104950, Epoch 97.2, Batch Size = 256, Examples/Sec = 3845.88, Train LB = -368.767, Loss = 380.476
[2018-06-05 03:02] Train Step 104975, Epoch 97.2, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -407.179, Loss = 381.603
[2018-06-05 03:02] Train Step 105000, Epoch 97.2, Batch Size = 256, Examples/Sec = 3876.97, Train LB = -399.218, Loss = 386.205
Performance on test set:
  Test Lower Bound = -467.190, Test Loss = 467.190
[2018-06-05 03:03] Train Step 105025, Epoch 97.2, Batch Size = 256, Examples/Sec = 3871.39, Train LB = -382.346, Loss = 384.602
[2018-06-05 03:03] Train Step 105050, Epoch 97.3, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -380.785, Loss = 383.373
[2018-06-05 03:03] Train Step 105075, Epoch 97.3, Batch Size = 256, Examples/Sec = 3885.50, Train LB = -376.453, Loss = 382.325
[2018-06-05 03:03] Train Step 105100, Epoch 97.3, Batch Size = 256, Examples/Sec = 3833.44, Train LB = -367.176, Loss = 381.038
[2018-06-05 03:03] Train Step 105125, Epoch 97.3, Batch Size = 256, Examples/Sec = 3842.74, Train LB = -387.263, Loss = 380.915
[2018-06-05 03:03] Train Step 105150, Epoch 97.4, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -396.745, Loss = 381.169
[2018-06-05 03:03] Train Step 105175, Epoch 97.4, Batch Size = 256, Examples/Sec = 3836.23, Train LB = -390.604, Loss = 382.306
[2018-06-05 03:03] Train Step 105200, Epoch 97.4, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -410.352, Loss = 386.413
Performance on test set:
  Test Lower Bound = -464.958, Test Loss = 464.958
[2018-06-05 03:03] Train Step 105225, Epoch 97.4, Batch Size = 256, Examples/Sec = 3838.26, Train LB = -373.977, Loss = 385.464
[2018-06-05 03:03] Train Step 105250, Epoch 97.5, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -373.059, Loss = 383.870
[2018-06-05 03:03] Train Step 105275, Epoch 97.5, Batch Size = 256, Examples/Sec = 3852.24, Train LB = -370.481, Loss = 382.206
[2018-06-05 03:03] Train Step 105300, Epoch 97.5, Batch Size = 256, Examples/Sec = 3853.68, Train LB = -361.740, Loss = 380.156
[2018-06-05 03:03] Train Step 105325, Epoch 97.5, Batch Size = 256, Examples/Sec = 3853.74, Train LB = -382.740, Loss = 379.816
[2018-06-05 03:03] Train Step 105350, Epoch 97.5, Batch Size = 256, Examples/Sec = 3870.18, Train LB = -383.329, Loss = 380.767
[2018-06-05 03:03] Train Step 105375, Epoch 97.6, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -404.412, Loss = 381.983
[2018-06-05 03:03] Train Step 105400, Epoch 97.6, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -412.355, Loss = 386.069
Performance on test set:
  Test Lower Bound = -462.955, Test Loss = 462.955
[2018-06-05 03:03] Train Step 105425, Epoch 97.6, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -358.076, Loss = 385.219
[2018-06-05 03:03] Train Step 105450, Epoch 97.6, Batch Size = 256, Examples/Sec = 3885.44, Train LB = -377.174, Loss = 383.586
[2018-06-05 03:03] Train Step 105475, Epoch 97.7, Batch Size = 256, Examples/Sec = 3874.38, Train LB = -394.871, Loss = 381.455
[2018-06-05 03:03] Train Step 105500, Epoch 97.7, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -387.158, Loss = 380.143
[2018-06-05 03:03] Train Step 105525, Epoch 97.7, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -373.927, Loss = 379.713
[2018-06-05 03:03] Train Step 105550, Epoch 97.7, Batch Size = 256, Examples/Sec = 3851.48, Train LB = -385.425, Loss = 380.318
[2018-06-05 03:03] Train Step 105575, Epoch 97.8, Batch Size = 256, Examples/Sec = 3853.98, Train LB = -391.109, Loss = 381.738
[2018-06-05 03:03] Train Step 105600, Epoch 97.8, Batch Size = 256, Examples/Sec = 3768.31, Train LB = -420.686, Loss = 385.435
Performance on test set:
  Test Lower Bound = -463.458, Test Loss = 463.458
[2018-06-05 03:03] Train Step 105625, Epoch 97.8, Batch Size = 256, Examples/Sec = 3822.61, Train LB = -388.947, Loss = 384.531
[2018-06-05 03:03] Train Step 105650, Epoch 97.8, Batch Size = 256, Examples/Sec = 3885.32, Train LB = -385.645, Loss = 382.607
[2018-06-05 03:03] Train Step 105675, Epoch 97.8, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -371.077, Loss = 381.152
[2018-06-05 03:03] Train Step 105700, Epoch 97.9, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -379.060, Loss = 380.245
[2018-06-05 03:03] Train Step 105725, Epoch 97.9, Batch Size = 256, Examples/Sec = 3885.61, Train LB = -388.778, Loss = 379.767
[2018-06-05 03:04] Train Step 105750, Epoch 97.9, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -393.816, Loss = 380.099
[2018-06-05 03:04] Train Step 105775, Epoch 97.9, Batch Size = 256, Examples/Sec = 3875.02, Train LB = -397.798, Loss = 381.571
[2018-06-05 03:04] Train Step 105800, Epoch 98.0, Batch Size = 256, Examples/Sec = 3862.76, Train LB = -419.259, Loss = 385.588
Performance on test set:
  Test Lower Bound = -463.759, Test Loss = 463.759
[2018-06-05 03:04] Train Step 105825, Epoch 98.0, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -373.665, Loss = 384.196
[2018-06-05 03:04] Train Step 105850, Epoch 98.0, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -370.505, Loss = 382.672
[2018-06-05 03:04] Train Step 105875, Epoch 98.0, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -379.469, Loss = 381.695
[2018-06-05 03:04] Train Step 105900, Epoch 98.1, Batch Size = 256, Examples/Sec = 3881.97, Train LB = -372.868, Loss = 380.548
[2018-06-05 03:04] Train Step 105925, Epoch 98.1, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -371.874, Loss = 379.854
[2018-06-05 03:04] Train Step 105950, Epoch 98.1, Batch Size = 256, Examples/Sec = 3865.26, Train LB = -403.620, Loss = 380.255
[2018-06-05 03:04] Train Step 105975, Epoch 98.1, Batch Size = 256, Examples/Sec = 3887.40, Train LB = -384.993, Loss = 381.317
[2018-06-05 03:04] Train Step 106000, Epoch 98.1, Batch Size = 256, Examples/Sec = 3872.33, Train LB = -412.911, Loss = 385.359
Performance on test set:
  Test Lower Bound = -466.078, Test Loss = 466.078
[2018-06-05 03:04] Train Step 106025, Epoch 98.2, Batch Size = 256, Examples/Sec = 3865.44, Train LB = -378.610, Loss = 384.584
[2018-06-05 03:04] Train Step 106050, Epoch 98.2, Batch Size = 256, Examples/Sec = 3855.24, Train LB = -373.546, Loss = 383.656
[2018-06-05 03:04] Train Step 106075, Epoch 98.2, Batch Size = 256, Examples/Sec = 3872.40, Train LB = -392.922, Loss = 381.675
[2018-06-05 03:04] Train Step 106100, Epoch 98.2, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -384.437, Loss = 380.663
[2018-06-05 03:04] Train Step 106125, Epoch 98.3, Batch Size = 256, Examples/Sec = 3877.37, Train LB = -372.532, Loss = 380.324
[2018-06-05 03:04] Train Step 106150, Epoch 98.3, Batch Size = 256, Examples/Sec = 3872.10, Train LB = -393.639, Loss = 380.847
[2018-06-05 03:04] Train Step 106175, Epoch 98.3, Batch Size = 256, Examples/Sec = 3823.98, Train LB = -398.972, Loss = 382.301
[2018-06-05 03:04] Train Step 106200, Epoch 98.3, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -395.592, Loss = 386.335
Performance on test set:
  Test Lower Bound = -464.072, Test Loss = 464.072
[2018-06-05 03:04] Train Step 106225, Epoch 98.4, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -385.587, Loss = 385.519
[2018-06-05 03:04] Train Step 106250, Epoch 98.4, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -358.324, Loss = 383.879
[2018-06-05 03:04] Train Step 106275, Epoch 98.4, Batch Size = 256, Examples/Sec = 3867.25, Train LB = -361.465, Loss = 382.268
[2018-06-05 03:04] Train Step 106300, Epoch 98.4, Batch Size = 256, Examples/Sec = 3879.43, Train LB = -377.091, Loss = 380.679
[2018-06-05 03:04] Train Step 106325, Epoch 98.4, Batch Size = 256, Examples/Sec = 3859.09, Train LB = -368.481, Loss = 380.139
[2018-06-05 03:04] Train Step 106350, Epoch 98.5, Batch Size = 256, Examples/Sec = 3840.15, Train LB = -395.703, Loss = 380.273
[2018-06-05 03:04] Train Step 106375, Epoch 98.5, Batch Size = 256, Examples/Sec = 3852.64, Train LB = -388.995, Loss = 381.848
[2018-06-05 03:04] Train Step 106400, Epoch 98.5, Batch Size = 256, Examples/Sec = 3884.50, Train LB = -412.955, Loss = 385.941
Performance on test set:
  Test Lower Bound = -462.788, Test Loss = 462.788
[2018-06-05 03:04] Train Step 106425, Epoch 98.5, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -383.322, Loss = 384.381
[2018-06-05 03:05] Train Step 106450, Epoch 98.6, Batch Size = 256, Examples/Sec = 3872.80, Train LB = -370.834, Loss = 383.175
[2018-06-05 03:05] Train Step 106475, Epoch 98.6, Batch Size = 256, Examples/Sec = 3830.67, Train LB = -373.240, Loss = 382.219
[2018-06-05 03:05] Train Step 106500, Epoch 98.6, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -375.961, Loss = 380.020
[2018-06-05 03:05] Train Step 106525, Epoch 98.6, Batch Size = 256, Examples/Sec = 3840.44, Train LB = -365.927, Loss = 379.384
[2018-06-05 03:05] Train Step 106550, Epoch 98.7, Batch Size = 256, Examples/Sec = 3878.33, Train LB = -398.176, Loss = 379.980
[2018-06-05 03:05] Train Step 106575, Epoch 98.7, Batch Size = 256, Examples/Sec = 3844.77, Train LB = -392.599, Loss = 382.435
[2018-06-05 03:05] Train Step 106600, Epoch 98.7, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -406.850, Loss = 386.251
Performance on test set:
  Test Lower Bound = -464.131, Test Loss = 464.131
[2018-06-05 03:05] Train Step 106625, Epoch 98.7, Batch Size = 256, Examples/Sec = 3842.63, Train LB = -371.031, Loss = 385.300
[2018-06-05 03:05] Train Step 106650, Epoch 98.8, Batch Size = 256, Examples/Sec = 3840.04, Train LB = -371.642, Loss = 383.785
[2018-06-05 03:05] Train Step 106675, Epoch 98.8, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -376.501, Loss = 382.024
[2018-06-05 03:05] Train Step 106700, Epoch 98.8, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -374.853, Loss = 380.932
[2018-06-05 03:05] Train Step 106725, Epoch 98.8, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -394.977, Loss = 379.982
[2018-06-05 03:05] Train Step 106750, Epoch 98.8, Batch Size = 256, Examples/Sec = 3834.12, Train LB = -380.759, Loss = 380.171
[2018-06-05 03:05] Train Step 106775, Epoch 98.9, Batch Size = 256, Examples/Sec = 3851.48, Train LB = -402.668, Loss = 381.285
[2018-06-05 03:05] Train Step 106800, Epoch 98.9, Batch Size = 256, Examples/Sec = 3875.79, Train LB = -398.707, Loss = 385.884
Performance on test set:
  Test Lower Bound = -463.204, Test Loss = 463.204
[2018-06-05 03:05] Train Step 106825, Epoch 98.9, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -373.612, Loss = 384.560
[2018-06-05 03:05] Train Step 106850, Epoch 98.9, Batch Size = 256, Examples/Sec = 3875.15, Train LB = -389.863, Loss = 382.856
[2018-06-05 03:05] Train Step 106875, Epoch 99.0, Batch Size = 256, Examples/Sec = 3841.71, Train LB = -382.846, Loss = 381.590
[2018-06-05 03:05] Train Step 106900, Epoch 99.0, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -369.651, Loss = 380.655
[2018-06-05 03:05] Train Step 106925, Epoch 99.0, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -376.161, Loss = 379.387
[2018-06-05 03:05] Train Step 106950, Epoch 99.0, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -401.649, Loss = 379.734
[2018-06-05 03:05] Train Step 106975, Epoch 99.1, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -387.921, Loss = 381.827
[2018-06-05 03:05] Train Step 107000, Epoch 99.1, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -409.916, Loss = 385.575
Performance on test set:
  Test Lower Bound = -463.046, Test Loss = 463.046
[2018-06-05 03:05] Train Step 107025, Epoch 99.1, Batch Size = 256, Examples/Sec = 3799.85, Train LB = -390.688, Loss = 384.652
[2018-06-05 03:05] Train Step 107050, Epoch 99.1, Batch Size = 256, Examples/Sec = 3862.41, Train LB = -381.057, Loss = 383.149
[2018-06-05 03:05] Train Step 107075, Epoch 99.1, Batch Size = 256, Examples/Sec = 3857.09, Train LB = -371.795, Loss = 381.252
[2018-06-05 03:05] Train Step 107100, Epoch 99.2, Batch Size = 256, Examples/Sec = 3878.33, Train LB = -370.203, Loss = 379.760
[2018-06-05 03:05] Train Step 107125, Epoch 99.2, Batch Size = 256, Examples/Sec = 3868.11, Train LB = -381.719, Loss = 379.960
[2018-06-05 03:05] Train Step 107150, Epoch 99.2, Batch Size = 256, Examples/Sec = 3842.23, Train LB = -372.887, Loss = 380.533
[2018-06-05 03:05] Train Step 107175, Epoch 99.2, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -391.851, Loss = 381.384
[2018-06-05 03:06] Train Step 107200, Epoch 99.3, Batch Size = 256, Examples/Sec = 3872.75, Train LB = -415.822, Loss = 385.565
Performance on test set:
  Test Lower Bound = -464.649, Test Loss = 464.649
[2018-06-05 03:06] Train Step 107225, Epoch 99.3, Batch Size = 256, Examples/Sec = 3872.87, Train LB = -378.540, Loss = 384.335
[2018-06-05 03:06] Train Step 107250, Epoch 99.3, Batch Size = 256, Examples/Sec = 3853.15, Train LB = -371.949, Loss = 383.241
[2018-06-05 03:06] Train Step 107275, Epoch 99.3, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -376.829, Loss = 381.639
[2018-06-05 03:06] Train Step 107300, Epoch 99.4, Batch Size = 256, Examples/Sec = 3868.60, Train LB = -368.218, Loss = 380.621
[2018-06-05 03:06] Train Step 107325, Epoch 99.4, Batch Size = 256, Examples/Sec = 3796.14, Train LB = -370.495, Loss = 379.952
[2018-06-05 03:06] Train Step 107350, Epoch 99.4, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -375.037, Loss = 380.073
[2018-06-05 03:06] Train Step 107375, Epoch 99.4, Batch Size = 256, Examples/Sec = 3873.61, Train LB = -399.549, Loss = 381.731
[2018-06-05 03:06] Train Step 107400, Epoch 99.4, Batch Size = 256, Examples/Sec = 3883.32, Train LB = -411.732, Loss = 385.873
Performance on test set:
  Test Lower Bound = -464.995, Test Loss = 464.995
[2018-06-05 03:06] Train Step 107425, Epoch 99.5, Batch Size = 256, Examples/Sec = 3832.06, Train LB = -367.849, Loss = 385.070
[2018-06-05 03:06] Train Step 107450, Epoch 99.5, Batch Size = 256, Examples/Sec = 3876.09, Train LB = -370.690, Loss = 383.011
[2018-06-05 03:06] Train Step 107475, Epoch 99.5, Batch Size = 256, Examples/Sec = 3849.79, Train LB = -365.808, Loss = 381.950
[2018-06-05 03:06] Train Step 107500, Epoch 99.5, Batch Size = 256, Examples/Sec = 3857.51, Train LB = -370.827, Loss = 380.684
[2018-06-05 03:06] Train Step 107525, Epoch 99.6, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -381.227, Loss = 379.916
[2018-06-05 03:06] Train Step 107550, Epoch 99.6, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -371.733, Loss = 379.383
[2018-06-05 03:06] Train Step 107575, Epoch 99.6, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -386.216, Loss = 381.357
[2018-06-05 03:06] Train Step 107600, Epoch 99.6, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -418.857, Loss = 385.385
Performance on test set:
  Test Lower Bound = -464.787, Test Loss = 464.787
[2018-06-05 03:06] Train Step 107625, Epoch 99.7, Batch Size = 256, Examples/Sec = 3887.86, Train LB = -371.098, Loss = 384.187
[2018-06-05 03:06] Train Step 107650, Epoch 99.7, Batch Size = 256, Examples/Sec = 3848.36, Train LB = -370.041, Loss = 381.996
[2018-06-05 03:06] Train Step 107675, Epoch 99.7, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -368.495, Loss = 380.837
[2018-06-05 03:06] Train Step 107700, Epoch 99.7, Batch Size = 256, Examples/Sec = 3842.81, Train LB = -381.099, Loss = 379.001
[2018-06-05 03:06] Train Step 107725, Epoch 99.7, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -380.723, Loss = 378.784
[2018-06-05 03:06] Train Step 107750, Epoch 99.8, Batch Size = 256, Examples/Sec = 3848.23, Train LB = -393.077, Loss = 378.987
[2018-06-05 03:06] Train Step 107775, Epoch 99.8, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -400.895, Loss = 380.917
[2018-06-05 03:06] Train Step 107800, Epoch 99.8, Batch Size = 256, Examples/Sec = 3862.41, Train LB = -407.982, Loss = 384.711
Performance on test set:
  Test Lower Bound = -467.293, Test Loss = 467.293
[2018-06-05 03:06] Train Step 107825, Epoch 99.8, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -369.989, Loss = 383.521
[2018-06-05 03:06] Train Step 107850, Epoch 99.9, Batch Size = 256, Examples/Sec = 3854.67, Train LB = -369.813, Loss = 382.333
[2018-06-05 03:07] Train Step 107875, Epoch 99.9, Batch Size = 256, Examples/Sec = 3775.20, Train LB = -367.965, Loss = 381.111
[2018-06-05 03:07] Train Step 107900, Epoch 99.9, Batch Size = 256, Examples/Sec = 3854.84, Train LB = -378.995, Loss = 379.645
[2018-06-05 03:07] Train Step 107925, Epoch 99.9, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -385.110, Loss = 379.495
[2018-06-05 03:07] Train Step 107950, Epoch 100.0, Batch Size = 256, Examples/Sec = 3884.26, Train LB = -378.918, Loss = 379.348
[2018-06-05 03:07] Train Step 107975, Epoch 100.0, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -396.258, Loss = 380.748
