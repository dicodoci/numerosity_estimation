training...
(276480, 30, 30, 1)
(30720, 30, 30, 1)
('x_minibatch', TensorShape([Dimension(None), Dimension(30), Dimension(30), Dimension(1)]))
[2018-06-04 18:41] Train Step 0000, Epoch 0.0, Batch Size = 256, Examples/Sec = 42.01, Train LB = -1389.258, Loss = 0.000
[2018-06-04 18:41] Train Step 0025, Epoch 0.0, Batch Size = 256, Examples/Sec = 3720.34, Train LB = -671.622, Loss = 999.853
[2018-06-04 18:41] Train Step 0050, Epoch 0.0, Batch Size = 256, Examples/Sec = 3893.29, Train LB = -590.123, Loss = 785.829
[2018-06-04 18:41] Train Step 0075, Epoch 0.1, Batch Size = 256, Examples/Sec = 3905.89, Train LB = -585.004, Loss = 703.533
[2018-06-04 18:41] Train Step 0100, Epoch 0.1, Batch Size = 256, Examples/Sec = 3922.83, Train LB = -574.390, Loss = 659.418
[2018-06-04 18:41] Train Step 0125, Epoch 0.1, Batch Size = 256, Examples/Sec = 3778.88, Train LB = -546.927, Loss = 629.208
[2018-06-04 18:41] Train Step 0150, Epoch 0.1, Batch Size = 256, Examples/Sec = 3913.48, Train LB = -518.701, Loss = 600.141
[2018-06-04 18:41] Train Step 0175, Epoch 0.2, Batch Size = 256, Examples/Sec = 3892.30, Train LB = -515.146, Loss = 576.821
[2018-06-04 18:41] Train Step 0200, Epoch 0.2, Batch Size = 256, Examples/Sec = 3884.78, Train LB = -539.682, Loss = 561.166
Performance on test set:
  Test Lower Bound = -533.454, Test Loss = 533.454
[2018-06-04 18:41] Train Step 0225, Epoch 0.2, Batch Size = 256, Examples/Sec = 3631.42, Train LB = -509.287, Loss = 549.144
[2018-06-04 18:41] Train Step 0250, Epoch 0.2, Batch Size = 256, Examples/Sec = 3902.86, Train LB = -497.814, Loss = 538.359
[2018-06-04 18:41] Train Step 0275, Epoch 0.3, Batch Size = 256, Examples/Sec = 3893.12, Train LB = -503.918, Loss = 529.147
[2018-06-04 18:41] Train Step 0300, Epoch 0.3, Batch Size = 256, Examples/Sec = 3878.68, Train LB = -498.774, Loss = 521.950
[2018-06-04 18:41] Train Step 0325, Epoch 0.3, Batch Size = 256, Examples/Sec = 3894.01, Train LB = -496.005, Loss = 516.073
[2018-06-04 18:42] Train Step 0350, Epoch 0.3, Batch Size = 256, Examples/Sec = 3863.09, Train LB = -491.509, Loss = 511.087
[2018-06-04 18:42] Train Step 0375, Epoch 0.3, Batch Size = 256, Examples/Sec = 3870.51, Train LB = -489.106, Loss = 506.471
[2018-06-04 18:42] Train Step 0400, Epoch 0.4, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -486.136, Loss = 502.795
Performance on test set:
  Test Lower Bound = -489.705, Test Loss = 489.705
[2018-06-04 18:42] Train Step 0425, Epoch 0.4, Batch Size = 256, Examples/Sec = 3893.18, Train LB = -482.671, Loss = 499.425
[2018-06-04 18:42] Train Step 0450, Epoch 0.4, Batch Size = 256, Examples/Sec = 3895.90, Train LB = -481.528, Loss = 496.762
[2018-06-04 18:42] Train Step 0475, Epoch 0.4, Batch Size = 256, Examples/Sec = 3889.21, Train LB = -479.426, Loss = 493.726
[2018-06-04 18:42] Train Step 0500, Epoch 0.5, Batch Size = 256, Examples/Sec = 3877.68, Train LB = -475.608, Loss = 491.407
[2018-06-04 18:42] Train Step 0525, Epoch 0.5, Batch Size = 256, Examples/Sec = 3877.67, Train LB = -479.796, Loss = 488.876
[2018-06-04 18:42] Train Step 0550, Epoch 0.5, Batch Size = 256, Examples/Sec = 3879.78, Train LB = -461.410, Loss = 486.254
[2018-06-04 18:42] Train Step 0575, Epoch 0.5, Batch Size = 256, Examples/Sec = 3884.85, Train LB = -479.584, Loss = 484.361
[2018-06-04 18:42] Train Step 0600, Epoch 0.6, Batch Size = 256, Examples/Sec = 3817.69, Train LB = -487.506, Loss = 482.583
Performance on test set:
  Test Lower Bound = -475.650, Test Loss = 475.650
[2018-06-04 18:42] Train Step 0625, Epoch 0.6, Batch Size = 256, Examples/Sec = 3889.45, Train LB = -479.636, Loss = 481.092
[2018-06-04 18:42] Train Step 0650, Epoch 0.6, Batch Size = 256, Examples/Sec = 3704.56, Train LB = -475.093, Loss = 479.586
[2018-06-04 18:42] Train Step 0675, Epoch 0.6, Batch Size = 256, Examples/Sec = 3891.75, Train LB = -464.210, Loss = 477.931
[2018-06-04 18:42] Train Step 0700, Epoch 0.6, Batch Size = 256, Examples/Sec = 3881.78, Train LB = -471.207, Loss = 475.546
[2018-06-04 18:42] Train Step 0725, Epoch 0.7, Batch Size = 256, Examples/Sec = 3779.93, Train LB = -473.929, Loss = 474.145
[2018-06-04 18:42] Train Step 0750, Epoch 0.7, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -481.409, Loss = 472.561
[2018-06-04 18:42] Train Step 0775, Epoch 0.7, Batch Size = 256, Examples/Sec = 3878.90, Train LB = -468.033, Loss = 471.495
[2018-06-04 18:42] Train Step 0800, Epoch 0.7, Batch Size = 256, Examples/Sec = 3864.49, Train LB = -463.188, Loss = 470.443
Performance on test set:
  Test Lower Bound = -466.134, Test Loss = 466.134
[2018-06-04 18:42] Train Step 0825, Epoch 0.8, Batch Size = 256, Examples/Sec = 3883.43, Train LB = -465.165, Loss = 469.136
[2018-06-04 18:42] Train Step 0850, Epoch 0.8, Batch Size = 256, Examples/Sec = 3873.28, Train LB = -462.766, Loss = 468.126
[2018-06-04 18:42] Train Step 0875, Epoch 0.8, Batch Size = 256, Examples/Sec = 3877.08, Train LB = -461.526, Loss = 467.263
[2018-06-04 18:42] Train Step 0900, Epoch 0.8, Batch Size = 256, Examples/Sec = 3847.08, Train LB = -453.016, Loss = 466.444
[2018-06-04 18:42] Train Step 0925, Epoch 0.9, Batch Size = 256, Examples/Sec = 3868.52, Train LB = -462.626, Loss = 465.887
[2018-06-04 18:42] Train Step 0950, Epoch 0.9, Batch Size = 256, Examples/Sec = 3870.29, Train LB = -463.192, Loss = 465.343
[2018-06-04 18:42] Train Step 0975, Epoch 0.9, Batch Size = 256, Examples/Sec = 3746.04, Train LB = -463.743, Loss = 464.519
[2018-06-04 18:42] Train Step 1000, Epoch 0.9, Batch Size = 256, Examples/Sec = 3774.42, Train LB = -460.659, Loss = 463.893
Performance on test set:
  Test Lower Bound = -460.374, Test Loss = 460.374
[2018-06-04 18:42] Train Step 1025, Epoch 0.9, Batch Size = 256, Examples/Sec = 3833.42, Train LB = -452.502, Loss = 463.046
[2018-06-04 18:43] Train Step 1050, Epoch 1.0, Batch Size = 256, Examples/Sec = 3873.22, Train LB = -462.792, Loss = 462.167
[2018-06-04 18:43] Train Step 1075, Epoch 1.0, Batch Size = 256, Examples/Sec = 3888.86, Train LB = -461.531, Loss = 461.151
[2018-06-04 18:43] Train Step 1100, Epoch 1.0, Batch Size = 256, Examples/Sec = 3864.80, Train LB = -449.077, Loss = 460.503
[2018-06-04 18:43] Train Step 1125, Epoch 1.0, Batch Size = 256, Examples/Sec = 3883.08, Train LB = -455.188, Loss = 459.297
[2018-06-04 18:43] Train Step 1150, Epoch 1.1, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -453.963, Loss = 458.333
[2018-06-04 18:43] Train Step 1175, Epoch 1.1, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -459.677, Loss = 457.290
[2018-06-04 18:43] Train Step 1200, Epoch 1.1, Batch Size = 256, Examples/Sec = 3882.62, Train LB = -446.675, Loss = 456.619
Performance on test set:
  Test Lower Bound = -452.683, Test Loss = 452.683
[2018-06-04 18:43] Train Step 1225, Epoch 1.1, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -461.830, Loss = 455.774
[2018-06-04 18:43] Train Step 1250, Epoch 1.2, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -434.088, Loss = 454.325
[2018-06-04 18:43] Train Step 1275, Epoch 1.2, Batch Size = 256, Examples/Sec = 3746.81, Train LB = -447.557, Loss = 453.096
[2018-06-04 18:43] Train Step 1300, Epoch 1.2, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -441.735, Loss = 451.482
[2018-06-04 18:43] Train Step 1325, Epoch 1.2, Batch Size = 256, Examples/Sec = 3781.22, Train LB = -439.311, Loss = 449.590
[2018-06-04 18:43] Train Step 1350, Epoch 1.2, Batch Size = 256, Examples/Sec = 3744.44, Train LB = -434.985, Loss = 448.318
[2018-06-04 18:43] Train Step 1375, Epoch 1.3, Batch Size = 256, Examples/Sec = 3847.53, Train LB = -442.853, Loss = 447.522
[2018-06-04 18:43] Train Step 1400, Epoch 1.3, Batch Size = 256, Examples/Sec = 3823.40, Train LB = -447.661, Loss = 446.776
Performance on test set:
  Test Lower Bound = -445.653, Test Loss = 445.653
[2018-06-04 18:43] Train Step 1425, Epoch 1.3, Batch Size = 256, Examples/Sec = 3870.62, Train LB = -425.847, Loss = 445.728
[2018-06-04 18:43] Train Step 1450, Epoch 1.3, Batch Size = 256, Examples/Sec = 3870.46, Train LB = -442.239, Loss = 444.928
[2018-06-04 18:43] Train Step 1475, Epoch 1.4, Batch Size = 256, Examples/Sec = 3799.63, Train LB = -432.589, Loss = 444.323
[2018-06-04 18:43] Train Step 1500, Epoch 1.4, Batch Size = 256, Examples/Sec = 3800.59, Train LB = -440.016, Loss = 443.738
[2018-06-04 18:43] Train Step 1525, Epoch 1.4, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -443.826, Loss = 443.050
[2018-06-04 18:43] Train Step 1550, Epoch 1.4, Batch Size = 256, Examples/Sec = 3816.16, Train LB = -435.132, Loss = 442.308
[2018-06-04 18:43] Train Step 1575, Epoch 1.5, Batch Size = 256, Examples/Sec = 3869.34, Train LB = -434.590, Loss = 441.652
[2018-06-04 18:43] Train Step 1600, Epoch 1.5, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -436.570, Loss = 441.125
Performance on test set:
  Test Lower Bound = -438.463, Test Loss = 438.463
[2018-06-04 18:43] Train Step 1625, Epoch 1.5, Batch Size = 256, Examples/Sec = 3882.03, Train LB = -429.999, Loss = 440.616
[2018-06-04 18:43] Train Step 1650, Epoch 1.5, Batch Size = 256, Examples/Sec = 3868.99, Train LB = -439.335, Loss = 440.062
[2018-06-04 18:43] Train Step 1675, Epoch 1.6, Batch Size = 256, Examples/Sec = 3846.15, Train LB = -437.022, Loss = 438.849
[2018-06-04 18:43] Train Step 1700, Epoch 1.6, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -434.856, Loss = 438.181
[2018-06-04 18:43] Train Step 1725, Epoch 1.6, Batch Size = 256, Examples/Sec = 3860.59, Train LB = -439.279, Loss = 437.538
[2018-06-04 18:43] Train Step 1750, Epoch 1.6, Batch Size = 256, Examples/Sec = 3855.13, Train LB = -440.772, Loss = 436.949
[2018-06-04 18:43] Train Step 1775, Epoch 1.6, Batch Size = 256, Examples/Sec = 3802.11, Train LB = -426.684, Loss = 437.095
[2018-06-04 18:44] Train Step 1800, Epoch 1.7, Batch Size = 256, Examples/Sec = 3873.85, Train LB = -441.440, Loss = 436.607
Performance on test set:
  Test Lower Bound = -436.511, Test Loss = 436.511
[2018-06-04 18:44] Train Step 1825, Epoch 1.7, Batch Size = 256, Examples/Sec = 3723.36, Train LB = -420.646, Loss = 435.938
[2018-06-04 18:44] Train Step 1850, Epoch 1.7, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -447.365, Loss = 435.277
[2018-06-04 18:44] Train Step 1875, Epoch 1.7, Batch Size = 256, Examples/Sec = 3873.44, Train LB = -443.819, Loss = 434.894
[2018-06-04 18:44] Train Step 1900, Epoch 1.8, Batch Size = 256, Examples/Sec = 3776.19, Train LB = -427.478, Loss = 434.925
[2018-06-04 18:44] Train Step 1925, Epoch 1.8, Batch Size = 256, Examples/Sec = 3838.66, Train LB = -437.013, Loss = 433.777
[2018-06-04 18:44] Train Step 1950, Epoch 1.8, Batch Size = 256, Examples/Sec = 3881.31, Train LB = -434.485, Loss = 433.648
[2018-06-04 18:44] Train Step 1975, Epoch 1.8, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -427.920, Loss = 433.541
[2018-06-04 18:44] Train Step 2000, Epoch 1.9, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -433.298, Loss = 433.853
Performance on test set:
  Test Lower Bound = -433.648, Test Loss = 433.648
[2018-06-04 18:44] Train Step 2025, Epoch 1.9, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -419.668, Loss = 433.255
[2018-06-04 18:44] Train Step 2050, Epoch 1.9, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -450.605, Loss = 432.896
[2018-06-04 18:44] Train Step 2075, Epoch 1.9, Batch Size = 256, Examples/Sec = 3837.33, Train LB = -431.273, Loss = 432.764
[2018-06-04 18:44] Train Step 2100, Epoch 1.9, Batch Size = 256, Examples/Sec = 3849.74, Train LB = -413.029, Loss = 432.173
[2018-06-04 18:44] Train Step 2125, Epoch 2.0, Batch Size = 256, Examples/Sec = 3862.69, Train LB = -431.441, Loss = 431.309
[2018-06-04 18:44] Train Step 2150, Epoch 2.0, Batch Size = 256, Examples/Sec = 3874.38, Train LB = -428.932, Loss = 431.156
[2018-06-04 18:44] Train Step 2175, Epoch 2.0, Batch Size = 256, Examples/Sec = 3873.09, Train LB = -433.020, Loss = 430.995
[2018-06-04 18:44] Train Step 2200, Epoch 2.0, Batch Size = 256, Examples/Sec = 3819.87, Train LB = -419.572, Loss = 431.020
Performance on test set:
  Test Lower Bound = -433.668, Test Loss = 433.668
[2018-06-04 18:44] Train Step 2225, Epoch 2.1, Batch Size = 256, Examples/Sec = 3790.74, Train LB = -426.123, Loss = 430.579
[2018-06-04 18:44] Train Step 2250, Epoch 2.1, Batch Size = 256, Examples/Sec = 3768.08, Train LB = -436.765, Loss = 430.038
[2018-06-04 18:44] Train Step 2275, Epoch 2.1, Batch Size = 256, Examples/Sec = 3850.43, Train LB = -418.388, Loss = 429.324
[2018-06-04 18:44] Train Step 2300, Epoch 2.1, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -428.932, Loss = 429.042
[2018-06-04 18:44] Train Step 2325, Epoch 2.2, Batch Size = 256, Examples/Sec = 3820.78, Train LB = -432.007, Loss = 428.470
[2018-06-04 18:44] Train Step 2350, Epoch 2.2, Batch Size = 256, Examples/Sec = 3892.34, Train LB = -428.361, Loss = 427.888
[2018-06-04 18:44] Train Step 2375, Epoch 2.2, Batch Size = 256, Examples/Sec = 3855.71, Train LB = -432.688, Loss = 427.879
[2018-06-04 18:44] Train Step 2400, Epoch 2.2, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -431.944, Loss = 428.207
Performance on test set:
  Test Lower Bound = -427.203, Test Loss = 427.203
[2018-06-04 18:44] Train Step 2425, Epoch 2.2, Batch Size = 256, Examples/Sec = 3885.62, Train LB = -434.917, Loss = 427.439
[2018-06-04 18:44] Train Step 2450, Epoch 2.3, Batch Size = 256, Examples/Sec = 3790.85, Train LB = -419.672, Loss = 428.321
[2018-06-04 18:45] Train Step 2475, Epoch 2.3, Batch Size = 256, Examples/Sec = 3839.87, Train LB = -435.800, Loss = 427.508
[2018-06-04 18:45] Train Step 2500, Epoch 2.3, Batch Size = 256, Examples/Sec = 3865.73, Train LB = -416.715, Loss = 427.554
[2018-06-04 18:45] Train Step 2525, Epoch 2.3, Batch Size = 256, Examples/Sec = 3786.19, Train LB = -417.730, Loss = 427.631
[2018-06-04 18:45] Train Step 2550, Epoch 2.4, Batch Size = 256, Examples/Sec = 3826.27, Train LB = -436.019, Loss = 427.006
[2018-06-04 18:45] Train Step 2575, Epoch 2.4, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -430.788, Loss = 426.961
[2018-06-04 18:45] Train Step 2600, Epoch 2.4, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -431.579, Loss = 426.905
Performance on test set:
  Test Lower Bound = -426.806, Test Loss = 426.806
[2018-06-04 18:45] Train Step 2625, Epoch 2.4, Batch Size = 256, Examples/Sec = 3873.46, Train LB = -415.724, Loss = 426.213
[2018-06-04 18:45] Train Step 2650, Epoch 2.5, Batch Size = 256, Examples/Sec = 3806.53, Train LB = -438.774, Loss = 426.457
[2018-06-04 18:45] Train Step 2675, Epoch 2.5, Batch Size = 256, Examples/Sec = 3866.89, Train LB = -402.189, Loss = 426.174
[2018-06-04 18:45] Train Step 2700, Epoch 2.5, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -416.803, Loss = 426.412
[2018-06-04 18:45] Train Step 2725, Epoch 2.5, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -417.910, Loss = 425.734
[2018-06-04 18:45] Train Step 2750, Epoch 2.5, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -432.196, Loss = 425.664
[2018-06-04 18:45] Train Step 2775, Epoch 2.6, Batch Size = 256, Examples/Sec = 3780.00, Train LB = -411.688, Loss = 425.733
[2018-06-04 18:45] Train Step 2800, Epoch 2.6, Batch Size = 256, Examples/Sec = 3856.46, Train LB = -425.784, Loss = 425.252
Performance on test set:
  Test Lower Bound = -424.414, Test Loss = 424.414
[2018-06-04 18:45] Train Step 2825, Epoch 2.6, Batch Size = 256, Examples/Sec = 3864.80, Train LB = -414.723, Loss = 424.832
[2018-06-04 18:45] Train Step 2850, Epoch 2.6, Batch Size = 256, Examples/Sec = 3885.50, Train LB = -426.701, Loss = 424.645
[2018-06-04 18:45] Train Step 2875, Epoch 2.7, Batch Size = 256, Examples/Sec = 3781.55, Train LB = -423.338, Loss = 424.793
[2018-06-04 18:45] Train Step 2900, Epoch 2.7, Batch Size = 256, Examples/Sec = 3843.67, Train LB = -418.395, Loss = 424.227
[2018-06-04 18:45] Train Step 2925, Epoch 2.7, Batch Size = 256, Examples/Sec = 3855.53, Train LB = -419.991, Loss = 424.071
[2018-06-04 18:45] Train Step 2950, Epoch 2.7, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -419.868, Loss = 424.074
[2018-06-04 18:45] Train Step 2975, Epoch 2.8, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -426.501, Loss = 423.437
[2018-06-04 18:45] Train Step 3000, Epoch 2.8, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -444.589, Loss = 423.637
Performance on test set:
  Test Lower Bound = -423.938, Test Loss = 423.938
[2018-06-04 18:45] Train Step 3025, Epoch 2.8, Batch Size = 256, Examples/Sec = 3812.35, Train LB = -433.519, Loss = 423.051
[2018-06-04 18:45] Train Step 3050, Epoch 2.8, Batch Size = 256, Examples/Sec = 3878.14, Train LB = -453.536, Loss = 423.104
[2018-06-04 18:45] Train Step 3075, Epoch 2.8, Batch Size = 256, Examples/Sec = 3528.51, Train LB = -409.487, Loss = 422.861
[2018-06-04 18:45] Train Step 3100, Epoch 2.9, Batch Size = 256, Examples/Sec = 3545.46, Train LB = -425.145, Loss = 422.648
[2018-06-04 18:45] Train Step 3125, Epoch 2.9, Batch Size = 256, Examples/Sec = 3504.30, Train LB = -414.301, Loss = 422.563
[2018-06-04 18:45] Train Step 3150, Epoch 2.9, Batch Size = 256, Examples/Sec = 3527.33, Train LB = -424.931, Loss = 422.500
[2018-06-04 18:45] Train Step 3175, Epoch 2.9, Batch Size = 256, Examples/Sec = 3510.80, Train LB = -409.929, Loss = 422.420
[2018-06-04 18:45] Train Step 3200, Epoch 3.0, Batch Size = 256, Examples/Sec = 3447.21, Train LB = -418.285, Loss = 422.662
Performance on test set:
  Test Lower Bound = -422.877, Test Loss = 422.877
[2018-06-04 18:46] Train Step 3225, Epoch 3.0, Batch Size = 256, Examples/Sec = 3876.03, Train LB = -428.169, Loss = 422.235
[2018-06-04 18:46] Train Step 3250, Epoch 3.0, Batch Size = 256, Examples/Sec = 3868.42, Train LB = -420.731, Loss = 422.527
[2018-06-04 18:46] Train Step 3275, Epoch 3.0, Batch Size = 256, Examples/Sec = 3879.21, Train LB = -422.139, Loss = 421.767
[2018-06-04 18:46] Train Step 3300, Epoch 3.1, Batch Size = 256, Examples/Sec = 3841.60, Train LB = -434.469, Loss = 421.813
[2018-06-04 18:46] Train Step 3325, Epoch 3.1, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -425.506, Loss = 420.990
[2018-06-04 18:46] Train Step 3350, Epoch 3.1, Batch Size = 256, Examples/Sec = 3856.75, Train LB = -432.964, Loss = 420.020
[2018-06-04 18:46] Train Step 3375, Epoch 3.1, Batch Size = 256, Examples/Sec = 3830.50, Train LB = -424.663, Loss = 420.576
[2018-06-04 18:46] Train Step 3400, Epoch 3.1, Batch Size = 256, Examples/Sec = 3843.85, Train LB = -417.044, Loss = 420.486
Performance on test set:
  Test Lower Bound = -422.190, Test Loss = 422.190
[2018-06-04 18:46] Train Step 3425, Epoch 3.2, Batch Size = 256, Examples/Sec = 3870.80, Train LB = -423.548, Loss = 419.886
[2018-06-04 18:46] Train Step 3450, Epoch 3.2, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -422.345, Loss = 420.261
[2018-06-04 18:46] Train Step 3475, Epoch 3.2, Batch Size = 256, Examples/Sec = 3870.99, Train LB = -407.399, Loss = 419.999
[2018-06-04 18:46] Train Step 3500, Epoch 3.2, Batch Size = 256, Examples/Sec = 3859.44, Train LB = -419.221, Loss = 419.938
[2018-06-04 18:46] Train Step 3525, Epoch 3.3, Batch Size = 256, Examples/Sec = 3830.50, Train LB = -403.111, Loss = 419.518
[2018-06-04 18:46] Train Step 3550, Epoch 3.3, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -409.574, Loss = 419.344
[2018-06-04 18:46] Train Step 3575, Epoch 3.3, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -428.721, Loss = 418.988
[2018-06-04 18:46] Train Step 3600, Epoch 3.3, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -432.736, Loss = 418.858
Performance on test set:
  Test Lower Bound = -418.256, Test Loss = 418.256
[2018-06-04 18:46] Train Step 3625, Epoch 3.4, Batch Size = 256, Examples/Sec = 3876.91, Train LB = -407.633, Loss = 418.933
[2018-06-04 18:46] Train Step 3650, Epoch 3.4, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -411.897, Loss = 418.616
[2018-06-04 18:46] Train Step 3675, Epoch 3.4, Batch Size = 256, Examples/Sec = 3862.35, Train LB = -417.392, Loss = 418.061
[2018-06-04 18:46] Train Step 3700, Epoch 3.4, Batch Size = 256, Examples/Sec = 3835.26, Train LB = -408.821, Loss = 417.772
[2018-06-04 18:46] Train Step 3725, Epoch 3.4, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -423.042, Loss = 417.798
[2018-06-04 18:46] Train Step 3750, Epoch 3.5, Batch Size = 256, Examples/Sec = 3873.11, Train LB = -412.173, Loss = 417.947
[2018-06-04 18:46] Train Step 3775, Epoch 3.5, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -432.304, Loss = 418.290
[2018-06-04 18:46] Train Step 3800, Epoch 3.5, Batch Size = 256, Examples/Sec = 3875.50, Train LB = -415.015, Loss = 419.066
Performance on test set:
  Test Lower Bound = -419.557, Test Loss = 419.557
[2018-06-04 18:46] Train Step 3825, Epoch 3.5, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -420.372, Loss = 418.948
[2018-06-04 18:46] Train Step 3850, Epoch 3.6, Batch Size = 256, Examples/Sec = 3760.94, Train LB = -407.306, Loss = 418.118
[2018-06-04 18:46] Train Step 3875, Epoch 3.6, Batch Size = 256, Examples/Sec = 3874.67, Train LB = -429.317, Loss = 417.436
[2018-06-04 18:47] Train Step 3900, Epoch 3.6, Batch Size = 256, Examples/Sec = 3860.48, Train LB = -412.312, Loss = 417.482
[2018-06-04 18:47] Train Step 3925, Epoch 3.6, Batch Size = 256, Examples/Sec = 3804.14, Train LB = -420.957, Loss = 418.096
[2018-06-04 18:47] Train Step 3950, Epoch 3.7, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -398.458, Loss = 418.081
[2018-06-04 18:47] Train Step 3975, Epoch 3.7, Batch Size = 256, Examples/Sec = 3864.40, Train LB = -421.088, Loss = 418.034
[2018-06-04 18:47] Train Step 4000, Epoch 3.7, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -428.391, Loss = 417.275
Performance on test set:
  Test Lower Bound = -417.652, Test Loss = 417.652
[2018-06-04 18:47] Train Step 4025, Epoch 3.7, Batch Size = 256, Examples/Sec = 3854.84, Train LB = -413.449, Loss = 417.157
[2018-06-04 18:47] Train Step 4050, Epoch 3.8, Batch Size = 256, Examples/Sec = 3870.75, Train LB = -426.091, Loss = 416.599
[2018-06-04 18:47] Train Step 4075, Epoch 3.8, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -420.280, Loss = 416.413
[2018-06-04 18:47] Train Step 4100, Epoch 3.8, Batch Size = 256, Examples/Sec = 3851.06, Train LB = -408.881, Loss = 416.026
[2018-06-04 18:47] Train Step 4125, Epoch 3.8, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -421.961, Loss = 415.840
[2018-06-04 18:47] Train Step 4150, Epoch 3.8, Batch Size = 256, Examples/Sec = 3881.73, Train LB = -411.458, Loss = 415.452
[2018-06-04 18:47] Train Step 4175, Epoch 3.9, Batch Size = 256, Examples/Sec = 3741.48, Train LB = -406.546, Loss = 416.003
[2018-06-04 18:47] Train Step 4200, Epoch 3.9, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -407.128, Loss = 416.151
Performance on test set:
  Test Lower Bound = -416.385, Test Loss = 416.385
[2018-06-04 18:47] Train Step 4225, Epoch 3.9, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -409.272, Loss = 415.698
[2018-06-04 18:47] Train Step 4250, Epoch 3.9, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -414.770, Loss = 415.507
[2018-06-04 18:47] Train Step 4275, Epoch 4.0, Batch Size = 256, Examples/Sec = 3860.83, Train LB = -417.332, Loss = 415.029
[2018-06-04 18:47] Train Step 4300, Epoch 4.0, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -409.933, Loss = 414.726
[2018-06-04 18:47] Train Step 4325, Epoch 4.0, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -414.851, Loss = 414.561
[2018-06-04 18:47] Train Step 4350, Epoch 4.0, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -424.558, Loss = 414.553
[2018-06-04 18:47] Train Step 4375, Epoch 4.1, Batch Size = 256, Examples/Sec = 3848.36, Train LB = -409.995, Loss = 414.696
[2018-06-04 18:47] Train Step 4400, Epoch 4.1, Batch Size = 256, Examples/Sec = 3845.97, Train LB = -398.654, Loss = 414.838
Performance on test set:
  Test Lower Bound = -416.406, Test Loss = 416.406
[2018-06-04 18:47] Train Step 4425, Epoch 4.1, Batch Size = 256, Examples/Sec = 3860.66, Train LB = -424.822, Loss = 414.709
[2018-06-04 18:47] Train Step 4450, Epoch 4.1, Batch Size = 256, Examples/Sec = 3854.85, Train LB = -420.200, Loss = 415.031
[2018-06-04 18:47] Train Step 4475, Epoch 4.1, Batch Size = 256, Examples/Sec = 3847.94, Train LB = -409.935, Loss = 414.949
[2018-06-04 18:47] Train Step 4500, Epoch 4.2, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -408.510, Loss = 414.226
[2018-06-04 18:47] Train Step 4525, Epoch 4.2, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -410.606, Loss = 414.113
[2018-06-04 18:47] Train Step 4550, Epoch 4.2, Batch Size = 256, Examples/Sec = 3858.85, Train LB = -410.110, Loss = 413.840
[2018-06-04 18:47] Train Step 4575, Epoch 4.2, Batch Size = 256, Examples/Sec = 3848.63, Train LB = -418.340, Loss = 413.845
[2018-06-04 18:47] Train Step 4600, Epoch 4.3, Batch Size = 256, Examples/Sec = 3874.14, Train LB = -404.699, Loss = 414.392
Performance on test set:
  Test Lower Bound = -416.086, Test Loss = 416.086
[2018-06-04 18:48] Train Step 4625, Epoch 4.3, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -412.810, Loss = 413.829
[2018-06-04 18:48] Train Step 4650, Epoch 4.3, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -408.923, Loss = 413.560
[2018-06-04 18:48] Train Step 4675, Epoch 4.3, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -406.171, Loss = 413.175
[2018-06-04 18:48] Train Step 4700, Epoch 4.4, Batch Size = 256, Examples/Sec = 3862.98, Train LB = -406.699, Loss = 413.094
[2018-06-04 18:48] Train Step 4725, Epoch 4.4, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -419.176, Loss = 413.102
[2018-06-04 18:48] Train Step 4750, Epoch 4.4, Batch Size = 256, Examples/Sec = 3872.34, Train LB = -408.323, Loss = 412.849
[2018-06-04 18:48] Train Step 4775, Epoch 4.4, Batch Size = 256, Examples/Sec = 3855.13, Train LB = -413.374, Loss = 412.453
[2018-06-04 18:48] Train Step 4800, Epoch 4.4, Batch Size = 256, Examples/Sec = 3870.22, Train LB = -410.854, Loss = 412.839
Performance on test set:
  Test Lower Bound = -414.908, Test Loss = 414.908
[2018-06-04 18:48] Train Step 4825, Epoch 4.5, Batch Size = 256, Examples/Sec = 3755.42, Train LB = -409.016, Loss = 412.211
[2018-06-04 18:48] Train Step 4850, Epoch 4.5, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -426.405, Loss = 412.497
[2018-06-04 18:48] Train Step 4875, Epoch 4.5, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -432.932, Loss = 412.311
[2018-06-04 18:48] Train Step 4900, Epoch 4.5, Batch Size = 256, Examples/Sec = 3769.58, Train LB = -410.895, Loss = 412.517
[2018-06-04 18:48] Train Step 4925, Epoch 4.6, Batch Size = 256, Examples/Sec = 3862.64, Train LB = -404.753, Loss = 412.236
[2018-06-04 18:48] Train Step 4950, Epoch 4.6, Batch Size = 256, Examples/Sec = 3795.19, Train LB = -422.254, Loss = 412.102
[2018-06-04 18:48] Train Step 4975, Epoch 4.6, Batch Size = 256, Examples/Sec = 3856.51, Train LB = -404.066, Loss = 411.712
[2018-06-04 18:48] Train Step 5000, Epoch 4.6, Batch Size = 256, Examples/Sec = 3866.96, Train LB = -403.308, Loss = 411.781
Performance on test set:
  Test Lower Bound = -414.895, Test Loss = 414.895
[2018-06-04 18:48] Train Step 5025, Epoch 4.7, Batch Size = 256, Examples/Sec = 3879.62, Train LB = -405.773, Loss = 411.401
[2018-06-04 18:48] Train Step 5050, Epoch 4.7, Batch Size = 256, Examples/Sec = 3879.84, Train LB = -406.470, Loss = 410.879
[2018-06-04 18:48] Train Step 5075, Epoch 4.7, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -416.956, Loss = 411.279
[2018-06-04 18:48] Train Step 5100, Epoch 4.7, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -401.788, Loss = 411.569
[2018-06-04 18:48] Train Step 5125, Epoch 4.7, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -425.266, Loss = 411.049
[2018-06-04 18:48] Train Step 5150, Epoch 4.8, Batch Size = 256, Examples/Sec = 3786.98, Train LB = -426.430, Loss = 411.138
[2018-06-04 18:48] Train Step 5175, Epoch 4.8, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -402.391, Loss = 411.572
[2018-06-04 18:48] Train Step 5200, Epoch 4.8, Batch Size = 256, Examples/Sec = 3860.35, Train LB = -405.725, Loss = 411.549
Performance on test set:
  Test Lower Bound = -412.236, Test Loss = 412.236
[2018-06-04 18:48] Train Step 5225, Epoch 4.8, Batch Size = 256, Examples/Sec = 3879.01, Train LB = -409.974, Loss = 411.336
[2018-06-04 18:48] Train Step 5250, Epoch 4.9, Batch Size = 256, Examples/Sec = 3870.16, Train LB = -398.795, Loss = 411.047
[2018-06-04 18:48] Train Step 5275, Epoch 4.9, Batch Size = 256, Examples/Sec = 3857.68, Train LB = -407.407, Loss = 410.466
[2018-06-04 18:48] Train Step 5300, Epoch 4.9, Batch Size = 256, Examples/Sec = 3849.28, Train LB = -421.716, Loss = 410.256
[2018-06-04 18:48] Train Step 5325, Epoch 4.9, Batch Size = 256, Examples/Sec = 3851.01, Train LB = -412.173, Loss = 410.351
[2018-06-04 18:49] Train Step 5350, Epoch 5.0, Batch Size = 256, Examples/Sec = 3838.37, Train LB = -411.937, Loss = 410.661
[2018-06-04 18:49] Train Step 5375, Epoch 5.0, Batch Size = 256, Examples/Sec = 3871.81, Train LB = -411.833, Loss = 410.493
[2018-06-04 18:49] Train Step 5400, Epoch 5.0, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -408.736, Loss = 410.108
Performance on test set:
  Test Lower Bound = -412.164, Test Loss = 412.164
[2018-06-04 18:49] Train Step 5425, Epoch 5.0, Batch Size = 256, Examples/Sec = 3882.20, Train LB = -390.012, Loss = 409.453
[2018-06-04 18:49] Train Step 5450, Epoch 5.0, Batch Size = 256, Examples/Sec = 3840.15, Train LB = -407.144, Loss = 409.936
[2018-06-04 18:49] Train Step 5475, Epoch 5.1, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -405.916, Loss = 409.790
[2018-06-04 18:49] Train Step 5500, Epoch 5.1, Batch Size = 256, Examples/Sec = 3887.97, Train LB = -406.449, Loss = 409.779
[2018-06-04 18:49] Train Step 5525, Epoch 5.1, Batch Size = 256, Examples/Sec = 3873.74, Train LB = -394.439, Loss = 409.537
[2018-06-04 18:49] Train Step 5550, Epoch 5.1, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -417.637, Loss = 409.508
[2018-06-04 18:49] Train Step 5575, Epoch 5.2, Batch Size = 256, Examples/Sec = 3880.48, Train LB = -397.523, Loss = 409.364
[2018-06-04 18:49] Train Step 5600, Epoch 5.2, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -409.248, Loss = 409.826
Performance on test set:
  Test Lower Bound = -410.560, Test Loss = 410.560
[2018-06-04 18:49] Train Step 5625, Epoch 5.2, Batch Size = 256, Examples/Sec = 3824.21, Train LB = -412.874, Loss = 409.391
[2018-06-04 18:49] Train Step 5650, Epoch 5.2, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -427.580, Loss = 409.080
[2018-06-04 18:49] Train Step 5675, Epoch 5.3, Batch Size = 256, Examples/Sec = 3863.28, Train LB = -415.496, Loss = 408.235
[2018-06-04 18:49] Train Step 5700, Epoch 5.3, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -408.485, Loss = 408.177
[2018-06-04 18:49] Train Step 5725, Epoch 5.3, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -425.572, Loss = 408.337
[2018-06-04 18:49] Train Step 5750, Epoch 5.3, Batch Size = 256, Examples/Sec = 3874.03, Train LB = -403.313, Loss = 409.528
[2018-06-04 18:49] Train Step 5775, Epoch 5.3, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -405.048, Loss = 409.546
[2018-06-04 18:49] Train Step 5800, Epoch 5.4, Batch Size = 256, Examples/Sec = 3872.05, Train LB = -411.203, Loss = 409.930
Performance on test set:
  Test Lower Bound = -409.695, Test Loss = 409.695
[2018-06-04 18:49] Train Step 5825, Epoch 5.4, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -413.396, Loss = 409.390
[2018-06-04 18:49] Train Step 5850, Epoch 5.4, Batch Size = 256, Examples/Sec = 3846.97, Train LB = -402.831, Loss = 408.642
[2018-06-04 18:49] Train Step 5875, Epoch 5.4, Batch Size = 256, Examples/Sec = 3840.33, Train LB = -404.614, Loss = 408.886
[2018-06-04 18:49] Train Step 5900, Epoch 5.5, Batch Size = 256, Examples/Sec = 3851.01, Train LB = -401.587, Loss = 408.270
[2018-06-04 18:49] Train Step 5925, Epoch 5.5, Batch Size = 256, Examples/Sec = 3837.04, Train LB = -391.145, Loss = 408.341
[2018-06-04 18:49] Train Step 5950, Epoch 5.5, Batch Size = 256, Examples/Sec = 3776.75, Train LB = -407.976, Loss = 408.158
[2018-06-04 18:49] Train Step 5975, Epoch 5.5, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -406.437, Loss = 408.108
[2018-06-04 18:49] Train Step 6000, Epoch 5.6, Batch Size = 256, Examples/Sec = 3873.79, Train LB = -404.806, Loss = 408.337
Performance on test set:
  Test Lower Bound = -411.111, Test Loss = 411.111
[2018-06-04 18:50] Train Step 6025, Epoch 5.6, Batch Size = 256, Examples/Sec = 3867.08, Train LB = -413.698, Loss = 408.018
[2018-06-04 18:50] Train Step 6050, Epoch 5.6, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -413.555, Loss = 407.971
[2018-06-04 18:50] Train Step 6075, Epoch 5.6, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -406.266, Loss = 407.734
[2018-06-04 18:50] Train Step 6100, Epoch 5.6, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -404.802, Loss = 407.253
[2018-06-04 18:50] Train Step 6125, Epoch 5.7, Batch Size = 256, Examples/Sec = 3850.61, Train LB = -406.513, Loss = 406.577
[2018-06-04 18:50] Train Step 6150, Epoch 5.7, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -409.257, Loss = 406.715
[2018-06-04 18:50] Train Step 6175, Epoch 5.7, Batch Size = 256, Examples/Sec = 3869.05, Train LB = -393.969, Loss = 407.163
[2018-06-04 18:50] Train Step 6200, Epoch 5.7, Batch Size = 256, Examples/Sec = 3835.38, Train LB = -411.093, Loss = 407.354
Performance on test set:
  Test Lower Bound = -409.498, Test Loss = 409.498
[2018-06-04 18:50] Train Step 6225, Epoch 5.8, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -427.158, Loss = 407.250
[2018-06-04 18:50] Train Step 6250, Epoch 5.8, Batch Size = 256, Examples/Sec = 3843.91, Train LB = -406.695, Loss = 407.250
[2018-06-04 18:50] Train Step 6275, Epoch 5.8, Batch Size = 256, Examples/Sec = 3858.84, Train LB = -415.606, Loss = 407.217
[2018-06-04 18:50] Train Step 6300, Epoch 5.8, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -403.181, Loss = 407.090
[2018-06-04 18:50] Train Step 6325, Epoch 5.9, Batch Size = 256, Examples/Sec = 3868.00, Train LB = -406.915, Loss = 406.740
[2018-06-04 18:50] Train Step 6350, Epoch 5.9, Batch Size = 256, Examples/Sec = 3836.88, Train LB = -406.668, Loss = 406.562
[2018-06-04 18:50] Train Step 6375, Epoch 5.9, Batch Size = 256, Examples/Sec = 3846.17, Train LB = -413.488, Loss = 406.393
[2018-06-04 18:50] Train Step 6400, Epoch 5.9, Batch Size = 256, Examples/Sec = 3856.76, Train LB = -419.788, Loss = 406.278
Performance on test set:
  Test Lower Bound = -408.922, Test Loss = 408.922
[2018-06-04 18:50] Train Step 6425, Epoch 5.9, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -415.332, Loss = 405.977
[2018-06-04 18:50] Train Step 6450, Epoch 6.0, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -418.475, Loss = 406.469
[2018-06-04 18:50] Train Step 6475, Epoch 6.0, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -405.086, Loss = 406.084
[2018-06-04 18:50] Train Step 6500, Epoch 6.0, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -392.825, Loss = 406.116
[2018-06-04 18:50] Train Step 6525, Epoch 6.0, Batch Size = 256, Examples/Sec = 3879.49, Train LB = -404.176, Loss = 405.772
[2018-06-04 18:50] Train Step 6550, Epoch 6.1, Batch Size = 256, Examples/Sec = 3843.32, Train LB = -412.690, Loss = 405.588
[2018-06-04 18:50] Train Step 6575, Epoch 6.1, Batch Size = 256, Examples/Sec = 3852.46, Train LB = -397.895, Loss = 405.545
[2018-06-04 18:50] Train Step 6600, Epoch 6.1, Batch Size = 256, Examples/Sec = 3814.13, Train LB = -402.600, Loss = 406.146
Performance on test set:
  Test Lower Bound = -411.323, Test Loss = 411.323
[2018-06-04 18:50] Train Step 6625, Epoch 6.1, Batch Size = 256, Examples/Sec = 3816.68, Train LB = -406.711, Loss = 406.619
[2018-06-04 18:50] Train Step 6650, Epoch 6.2, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -409.571, Loss = 406.492
[2018-06-04 18:50] Train Step 6675, Epoch 6.2, Batch Size = 256, Examples/Sec = 3747.95, Train LB = -422.157, Loss = 405.673
[2018-06-04 18:50] Train Step 6700, Epoch 6.2, Batch Size = 256, Examples/Sec = 3857.58, Train LB = -408.178, Loss = 405.169
[2018-06-04 18:50] Train Step 6725, Epoch 6.2, Batch Size = 256, Examples/Sec = 3852.64, Train LB = -414.718, Loss = 404.967
[2018-06-04 18:50] Train Step 6750, Epoch 6.2, Batch Size = 256, Examples/Sec = 3809.64, Train LB = -414.116, Loss = 404.825
[2018-06-04 18:51] Train Step 6775, Epoch 6.3, Batch Size = 256, Examples/Sec = 3857.63, Train LB = -396.294, Loss = 404.771
[2018-06-04 18:51] Train Step 6800, Epoch 6.3, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -414.716, Loss = 405.291
Performance on test set:
  Test Lower Bound = -408.875, Test Loss = 408.875
[2018-06-04 18:51] Train Step 6825, Epoch 6.3, Batch Size = 256, Examples/Sec = 3841.08, Train LB = -400.964, Loss = 405.102
[2018-06-04 18:51] Train Step 6850, Epoch 6.3, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -405.600, Loss = 405.109
[2018-06-04 18:51] Train Step 6875, Epoch 6.4, Batch Size = 256, Examples/Sec = 3881.68, Train LB = -410.527, Loss = 405.446
[2018-06-04 18:51] Train Step 6900, Epoch 6.4, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -419.615, Loss = 405.089
[2018-06-04 18:51] Train Step 6925, Epoch 6.4, Batch Size = 256, Examples/Sec = 3861.30, Train LB = -404.062, Loss = 405.008
[2018-06-04 18:51] Train Step 6950, Epoch 6.4, Batch Size = 256, Examples/Sec = 3848.81, Train LB = -401.244, Loss = 404.972
[2018-06-04 18:51] Train Step 6975, Epoch 6.5, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -398.749, Loss = 405.189
[2018-06-04 18:51] Train Step 7000, Epoch 6.5, Batch Size = 256, Examples/Sec = 3757.19, Train LB = -429.036, Loss = 405.596
Performance on test set:
  Test Lower Bound = -407.279, Test Loss = 407.279
[2018-06-04 18:51] Train Step 7025, Epoch 6.5, Batch Size = 256, Examples/Sec = 3886.97, Train LB = -396.949, Loss = 406.056
[2018-06-04 18:51] Train Step 7050, Epoch 6.5, Batch Size = 256, Examples/Sec = 3887.79, Train LB = -403.221, Loss = 405.576
[2018-06-04 18:51] Train Step 7075, Epoch 6.6, Batch Size = 256, Examples/Sec = 3872.75, Train LB = -414.783, Loss = 404.745
[2018-06-04 18:51] Train Step 7100, Epoch 6.6, Batch Size = 256, Examples/Sec = 3878.84, Train LB = -396.593, Loss = 404.353
[2018-06-04 18:51] Train Step 7125, Epoch 6.6, Batch Size = 256, Examples/Sec = 3852.17, Train LB = -410.503, Loss = 404.789
[2018-06-04 18:51] Train Step 7150, Epoch 6.6, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -397.371, Loss = 404.511
[2018-06-04 18:51] Train Step 7175, Epoch 6.6, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -411.883, Loss = 404.654
[2018-06-04 18:51] Train Step 7200, Epoch 6.7, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -400.566, Loss = 405.148
Performance on test set:
  Test Lower Bound = -405.980, Test Loss = 405.980
[2018-06-04 18:51] Train Step 7225, Epoch 6.7, Batch Size = 256, Examples/Sec = 3874.62, Train LB = -406.562, Loss = 404.637
[2018-06-04 18:51] Train Step 7250, Epoch 6.7, Batch Size = 256, Examples/Sec = 3809.12, Train LB = -395.801, Loss = 404.532
[2018-06-04 18:51] Train Step 7275, Epoch 6.7, Batch Size = 256, Examples/Sec = 3867.07, Train LB = -400.623, Loss = 404.290
[2018-06-04 18:51] Train Step 7300, Epoch 6.8, Batch Size = 256, Examples/Sec = 3866.94, Train LB = -412.994, Loss = 403.936
[2018-06-04 18:51] Train Step 7325, Epoch 6.8, Batch Size = 256, Examples/Sec = 3891.99, Train LB = -412.317, Loss = 404.314
[2018-06-04 18:51] Train Step 7350, Epoch 6.8, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -404.567, Loss = 404.516
[2018-06-04 18:51] Train Step 7375, Epoch 6.8, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -410.191, Loss = 404.401
[2018-06-04 18:51] Train Step 7400, Epoch 6.9, Batch Size = 256, Examples/Sec = 3835.08, Train LB = -402.783, Loss = 404.619
Performance on test set:
  Test Lower Bound = -406.403, Test Loss = 406.403
[2018-06-04 18:51] Train Step 7425, Epoch 6.9, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -403.404, Loss = 403.812
[2018-06-04 18:51] Train Step 7450, Epoch 6.9, Batch Size = 256, Examples/Sec = 3858.38, Train LB = -413.172, Loss = 404.701
[2018-06-04 18:52] Train Step 7475, Epoch 6.9, Batch Size = 256, Examples/Sec = 3879.03, Train LB = -396.345, Loss = 404.535
[2018-06-04 18:52] Train Step 7500, Epoch 6.9, Batch Size = 256, Examples/Sec = 3839.98, Train LB = -404.085, Loss = 404.414
[2018-06-04 18:52] Train Step 7525, Epoch 7.0, Batch Size = 256, Examples/Sec = 3868.75, Train LB = -395.381, Loss = 404.081
[2018-06-04 18:52] Train Step 7550, Epoch 7.0, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -425.678, Loss = 403.262
[2018-06-04 18:52] Train Step 7575, Epoch 7.0, Batch Size = 256, Examples/Sec = 3868.99, Train LB = -409.078, Loss = 403.480
[2018-06-04 18:52] Train Step 7600, Epoch 7.0, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -390.079, Loss = 404.313
Performance on test set:
  Test Lower Bound = -407.966, Test Loss = 407.966
[2018-06-04 18:52] Train Step 7625, Epoch 7.1, Batch Size = 256, Examples/Sec = 3863.62, Train LB = -412.045, Loss = 403.753
[2018-06-04 18:52] Train Step 7650, Epoch 7.1, Batch Size = 256, Examples/Sec = 3741.04, Train LB = -400.524, Loss = 404.761
[2018-06-04 18:52] Train Step 7675, Epoch 7.1, Batch Size = 256, Examples/Sec = 3859.08, Train LB = -401.150, Loss = 404.181
[2018-06-04 18:52] Train Step 7700, Epoch 7.1, Batch Size = 256, Examples/Sec = 3845.64, Train LB = -400.132, Loss = 403.129
[2018-06-04 18:52] Train Step 7725, Epoch 7.2, Batch Size = 256, Examples/Sec = 3818.39, Train LB = -396.677, Loss = 402.838
[2018-06-04 18:52] Train Step 7750, Epoch 7.2, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -403.216, Loss = 402.827
[2018-06-04 18:52] Train Step 7775, Epoch 7.2, Batch Size = 256, Examples/Sec = 3817.36, Train LB = -395.125, Loss = 403.067
[2018-06-04 18:52] Train Step 7800, Epoch 7.2, Batch Size = 256, Examples/Sec = 3859.04, Train LB = -390.162, Loss = 403.515
Performance on test set:
  Test Lower Bound = -406.619, Test Loss = 406.619
[2018-06-04 18:52] Train Step 7825, Epoch 7.2, Batch Size = 256, Examples/Sec = 3853.97, Train LB = -407.285, Loss = 403.507
[2018-06-04 18:52] Train Step 7850, Epoch 7.3, Batch Size = 256, Examples/Sec = 3870.16, Train LB = -393.107, Loss = 403.633
[2018-06-04 18:52] Train Step 7875, Epoch 7.3, Batch Size = 256, Examples/Sec = 3837.56, Train LB = -402.558, Loss = 402.686
[2018-06-04 18:52] Train Step 7900, Epoch 7.3, Batch Size = 256, Examples/Sec = 3853.98, Train LB = -396.785, Loss = 402.577
[2018-06-04 18:52] Train Step 7925, Epoch 7.3, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -398.808, Loss = 402.681
[2018-06-04 18:52] Train Step 7950, Epoch 7.4, Batch Size = 256, Examples/Sec = 3838.82, Train LB = -402.823, Loss = 402.093
[2018-06-04 18:52] Train Step 7975, Epoch 7.4, Batch Size = 256, Examples/Sec = 3786.14, Train LB = -404.456, Loss = 402.336
[2018-06-04 18:52] Train Step 8000, Epoch 7.4, Batch Size = 256, Examples/Sec = 3840.04, Train LB = -400.451, Loss = 402.959
Performance on test set:
  Test Lower Bound = -407.081, Test Loss = 407.081
[2018-06-04 18:52] Train Step 8025, Epoch 7.4, Batch Size = 256, Examples/Sec = 3873.40, Train LB = -395.166, Loss = 402.530
[2018-06-04 18:52] Train Step 8050, Epoch 7.5, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -404.916, Loss = 402.470
[2018-06-04 18:52] Train Step 8075, Epoch 7.5, Batch Size = 256, Examples/Sec = 3837.04, Train LB = -388.708, Loss = 402.514
[2018-06-04 18:52] Train Step 8100, Epoch 7.5, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -398.821, Loss = 402.029
[2018-06-04 18:52] Train Step 8125, Epoch 7.5, Batch Size = 256, Examples/Sec = 3854.44, Train LB = -415.780, Loss = 401.664
[2018-06-04 18:52] Train Step 8150, Epoch 7.5, Batch Size = 256, Examples/Sec = 3881.31, Train LB = -401.157, Loss = 402.207
[2018-06-04 18:52] Train Step 8175, Epoch 7.6, Batch Size = 256, Examples/Sec = 3809.07, Train LB = -392.928, Loss = 402.902
[2018-06-04 18:52] Train Step 8200, Epoch 7.6, Batch Size = 256, Examples/Sec = 3876.09, Train LB = -409.607, Loss = 403.035
Performance on test set:
  Test Lower Bound = -406.282, Test Loss = 406.282
[2018-06-04 18:53] Train Step 8225, Epoch 7.6, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -393.915, Loss = 403.079
[2018-06-04 18:53] Train Step 8250, Epoch 7.6, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -403.698, Loss = 402.889
[2018-06-04 18:53] Train Step 8275, Epoch 7.7, Batch Size = 256, Examples/Sec = 3878.55, Train LB = -407.760, Loss = 402.014
[2018-06-04 18:53] Train Step 8300, Epoch 7.7, Batch Size = 256, Examples/Sec = 3882.03, Train LB = -396.710, Loss = 402.182
[2018-06-04 18:53] Train Step 8325, Epoch 7.7, Batch Size = 256, Examples/Sec = 3869.23, Train LB = -409.577, Loss = 401.432
[2018-06-04 18:53] Train Step 8350, Epoch 7.7, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -396.977, Loss = 401.747
[2018-06-04 18:53] Train Step 8375, Epoch 7.8, Batch Size = 256, Examples/Sec = 3876.73, Train LB = -413.166, Loss = 401.445
[2018-06-04 18:53] Train Step 8400, Epoch 7.8, Batch Size = 256, Examples/Sec = 3854.31, Train LB = -397.500, Loss = 402.199
Performance on test set:
  Test Lower Bound = -405.392, Test Loss = 405.392
[2018-06-04 18:53] Train Step 8425, Epoch 7.8, Batch Size = 256, Examples/Sec = 3848.29, Train LB = -400.622, Loss = 401.406
[2018-06-04 18:53] Train Step 8450, Epoch 7.8, Batch Size = 256, Examples/Sec = 3799.35, Train LB = -385.833, Loss = 401.777
[2018-06-04 18:53] Train Step 8475, Epoch 7.8, Batch Size = 256, Examples/Sec = 3849.16, Train LB = -400.788, Loss = 401.564
[2018-06-04 18:53] Train Step 8500, Epoch 7.9, Batch Size = 256, Examples/Sec = 3818.78, Train LB = -413.320, Loss = 401.200
[2018-06-04 18:53] Train Step 8525, Epoch 7.9, Batch Size = 256, Examples/Sec = 3860.89, Train LB = -397.762, Loss = 400.673
[2018-06-04 18:53] Train Step 8550, Epoch 7.9, Batch Size = 256, Examples/Sec = 3854.96, Train LB = -393.397, Loss = 401.081
[2018-06-04 18:53] Train Step 8575, Epoch 7.9, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -407.973, Loss = 400.832
[2018-06-04 18:53] Train Step 8600, Epoch 8.0, Batch Size = 256, Examples/Sec = 3876.80, Train LB = -413.972, Loss = 402.086
Performance on test set:
  Test Lower Bound = -405.342, Test Loss = 405.342
[2018-06-04 18:53] Train Step 8625, Epoch 8.0, Batch Size = 256, Examples/Sec = 3826.16, Train LB = -398.521, Loss = 401.852
[2018-06-04 18:53] Train Step 8650, Epoch 8.0, Batch Size = 256, Examples/Sec = 3856.35, Train LB = -398.561, Loss = 401.897
[2018-06-04 18:53] Train Step 8675, Epoch 8.0, Batch Size = 256, Examples/Sec = 3885.32, Train LB = -408.912, Loss = 401.470
[2018-06-04 18:53] Train Step 8700, Epoch 8.1, Batch Size = 256, Examples/Sec = 3739.19, Train LB = -389.820, Loss = 401.935
[2018-06-04 18:53] Train Step 8725, Epoch 8.1, Batch Size = 256, Examples/Sec = 3835.44, Train LB = -409.031, Loss = 401.148
[2018-06-04 18:53] Train Step 8750, Epoch 8.1, Batch Size = 256, Examples/Sec = 3871.11, Train LB = -407.376, Loss = 400.663
[2018-06-04 18:53] Train Step 8775, Epoch 8.1, Batch Size = 256, Examples/Sec = 3751.02, Train LB = -393.057, Loss = 400.361
[2018-06-04 18:53] Train Step 8800, Epoch 8.1, Batch Size = 256, Examples/Sec = 3849.23, Train LB = -415.396, Loss = 401.310
Performance on test set:
  Test Lower Bound = -404.020, Test Loss = 404.020
[2018-06-04 18:53] Train Step 8825, Epoch 8.2, Batch Size = 256, Examples/Sec = 3862.94, Train LB = -400.223, Loss = 401.097
[2018-06-04 18:53] Train Step 8850, Epoch 8.2, Batch Size = 256, Examples/Sec = 3863.56, Train LB = -398.578, Loss = 401.168
[2018-06-04 18:53] Train Step 8875, Epoch 8.2, Batch Size = 256, Examples/Sec = 3841.94, Train LB = -419.949, Loss = 400.313
[2018-06-04 18:54] Train Step 8900, Epoch 8.2, Batch Size = 256, Examples/Sec = 3822.03, Train LB = -387.318, Loss = 400.775
[2018-06-04 18:54] Train Step 8925, Epoch 8.3, Batch Size = 256, Examples/Sec = 3870.93, Train LB = -393.604, Loss = 400.884
[2018-06-04 18:54] Train Step 8950, Epoch 8.3, Batch Size = 256, Examples/Sec = 3874.56, Train LB = -383.733, Loss = 400.078
[2018-06-04 18:54] Train Step 8975, Epoch 8.3, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -406.634, Loss = 400.241
[2018-06-04 18:54] Train Step 9000, Epoch 8.3, Batch Size = 256, Examples/Sec = 3863.33, Train LB = -405.125, Loss = 400.726
Performance on test set:
  Test Lower Bound = -404.440, Test Loss = 404.440
[2018-06-04 18:54] Train Step 9025, Epoch 8.4, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -396.374, Loss = 400.549
[2018-06-04 18:54] Train Step 9050, Epoch 8.4, Batch Size = 256, Examples/Sec = 3867.54, Train LB = -397.412, Loss = 401.105
[2018-06-04 18:54] Train Step 9075, Epoch 8.4, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -383.483, Loss = 400.464
[2018-06-04 18:54] Train Step 9100, Epoch 8.4, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -404.682, Loss = 400.300
[2018-06-04 18:54] Train Step 9125, Epoch 8.4, Batch Size = 256, Examples/Sec = 3847.96, Train LB = -399.535, Loss = 399.955
[2018-06-04 18:54] Train Step 9150, Epoch 8.5, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -390.618, Loss = 399.584
[2018-06-04 18:54] Train Step 9175, Epoch 8.5, Batch Size = 256, Examples/Sec = 3860.89, Train LB = -400.988, Loss = 399.742
[2018-06-04 18:54] Train Step 9200, Epoch 8.5, Batch Size = 256, Examples/Sec = 3871.98, Train LB = -401.601, Loss = 399.892
Performance on test set:
  Test Lower Bound = -403.205, Test Loss = 403.205
[2018-06-04 18:54] Train Step 9225, Epoch 8.5, Batch Size = 256, Examples/Sec = 3878.33, Train LB = -413.835, Loss = 399.140
[2018-06-04 18:54] Train Step 9250, Epoch 8.6, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -397.972, Loss = 399.371
[2018-06-04 18:54] Train Step 9275, Epoch 8.6, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -390.549, Loss = 399.148
[2018-06-04 18:54] Train Step 9300, Epoch 8.6, Batch Size = 256, Examples/Sec = 3873.86, Train LB = -397.528, Loss = 399.061
[2018-06-04 18:54] Train Step 9325, Epoch 8.6, Batch Size = 256, Examples/Sec = 3870.00, Train LB = -410.807, Loss = 399.006
[2018-06-04 18:54] Train Step 9350, Epoch 8.7, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -393.890, Loss = 399.379
[2018-06-04 18:54] Train Step 9375, Epoch 8.7, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -398.793, Loss = 398.971
[2018-06-04 18:54] Train Step 9400, Epoch 8.7, Batch Size = 256, Examples/Sec = 3840.39, Train LB = -406.370, Loss = 399.556
Performance on test set:
  Test Lower Bound = -404.659, Test Loss = 404.659
[2018-06-04 18:54] Train Step 9425, Epoch 8.7, Batch Size = 256, Examples/Sec = 3727.58, Train LB = -390.154, Loss = 399.356
[2018-06-04 18:54] Train Step 9450, Epoch 8.8, Batch Size = 256, Examples/Sec = 3843.44, Train LB = -405.287, Loss = 399.545
[2018-06-04 18:54] Train Step 9475, Epoch 8.8, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -404.074, Loss = 399.189
[2018-06-04 18:54] Train Step 9500, Epoch 8.8, Batch Size = 256, Examples/Sec = 3726.90, Train LB = -403.056, Loss = 399.141
[2018-06-04 18:54] Train Step 9525, Epoch 8.8, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -402.131, Loss = 399.015
[2018-06-04 18:54] Train Step 9550, Epoch 8.8, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -389.876, Loss = 398.422
[2018-06-04 18:54] Train Step 9575, Epoch 8.9, Batch Size = 256, Examples/Sec = 3846.32, Train LB = -409.909, Loss = 399.063
[2018-06-04 18:54] Train Step 9600, Epoch 8.9, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -403.716, Loss = 399.681
Performance on test set:
  Test Lower Bound = -403.417, Test Loss = 403.417
[2018-06-04 18:55] Train Step 9625, Epoch 8.9, Batch Size = 256, Examples/Sec = 3853.62, Train LB = -391.177, Loss = 399.059
[2018-06-04 18:55] Train Step 9650, Epoch 8.9, Batch Size = 256, Examples/Sec = 3881.26, Train LB = -402.444, Loss = 399.324
[2018-06-04 18:55] Train Step 9675, Epoch 9.0, Batch Size = 256, Examples/Sec = 3795.12, Train LB = -384.772, Loss = 398.637
[2018-06-04 18:55] Train Step 9700, Epoch 9.0, Batch Size = 256, Examples/Sec = 3875.32, Train LB = -407.870, Loss = 398.920
[2018-06-04 18:55] Train Step 9725, Epoch 9.0, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -397.516, Loss = 398.250
[2018-06-04 18:55] Train Step 9750, Epoch 9.0, Batch Size = 256, Examples/Sec = 3742.68, Train LB = -408.815, Loss = 397.980
[2018-06-04 18:55] Train Step 9775, Epoch 9.1, Batch Size = 256, Examples/Sec = 3848.69, Train LB = -398.975, Loss = 398.396
[2018-06-04 18:55] Train Step 9800, Epoch 9.1, Batch Size = 256, Examples/Sec = 3858.26, Train LB = -385.622, Loss = 399.089
Performance on test set:
  Test Lower Bound = -403.598, Test Loss = 403.598
[2018-06-04 18:55] Train Step 9825, Epoch 9.1, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -404.281, Loss = 398.999
[2018-06-04 18:55] Train Step 9850, Epoch 9.1, Batch Size = 256, Examples/Sec = 3872.91, Train LB = -405.124, Loss = 398.921
[2018-06-04 18:55] Train Step 9875, Epoch 9.1, Batch Size = 256, Examples/Sec = 3861.17, Train LB = -401.440, Loss = 398.433
[2018-06-04 18:55] Train Step 9900, Epoch 9.2, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -393.036, Loss = 398.181
[2018-06-04 18:55] Train Step 9925, Epoch 9.2, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -395.852, Loss = 397.946
[2018-06-04 18:55] Train Step 9950, Epoch 9.2, Batch Size = 256, Examples/Sec = 3877.21, Train LB = -397.867, Loss = 397.904
[2018-06-04 18:55] Train Step 9975, Epoch 9.2, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -406.284, Loss = 398.157
[2018-06-04 18:55] Train Step 10000, Epoch 9.3, Batch Size = 256, Examples/Sec = 3851.88, Train LB = -395.334, Loss = 399.242
Performance on test set:
  Test Lower Bound = -402.698, Test Loss = 402.698
[2018-06-04 18:55] Train Step 10025, Epoch 9.3, Batch Size = 256, Examples/Sec = 3837.51, Train LB = -401.286, Loss = 399.319
[2018-06-04 18:55] Train Step 10050, Epoch 9.3, Batch Size = 256, Examples/Sec = 3844.13, Train LB = -413.012, Loss = 398.816
[2018-06-04 18:55] Train Step 10075, Epoch 9.3, Batch Size = 256, Examples/Sec = 3798.49, Train LB = -404.602, Loss = 398.831
[2018-06-04 18:55] Train Step 10100, Epoch 9.4, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -404.002, Loss = 398.328
[2018-06-04 18:55] Train Step 10125, Epoch 9.4, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -395.505, Loss = 397.776
[2018-06-04 18:55] Train Step 10150, Epoch 9.4, Batch Size = 256, Examples/Sec = 3809.97, Train LB = -409.406, Loss = 397.764
[2018-06-04 18:55] Train Step 10175, Epoch 9.4, Batch Size = 256, Examples/Sec = 3875.51, Train LB = -390.637, Loss = 397.906
[2018-06-04 18:55] Train Step 10200, Epoch 9.4, Batch Size = 256, Examples/Sec = 3856.12, Train LB = -393.038, Loss = 398.553
Performance on test set:
  Test Lower Bound = -404.438, Test Loss = 404.438
[2018-06-04 18:55] Train Step 10225, Epoch 9.5, Batch Size = 256, Examples/Sec = 3850.37, Train LB = -398.584, Loss = 397.664
[2018-06-04 18:55] Train Step 10250, Epoch 9.5, Batch Size = 256, Examples/Sec = 3847.71, Train LB = -395.509, Loss = 398.044
[2018-06-04 18:55] Train Step 10275, Epoch 9.5, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -396.761, Loss = 397.906
[2018-06-04 18:55] Train Step 10300, Epoch 9.5, Batch Size = 256, Examples/Sec = 3836.07, Train LB = -387.724, Loss = 397.795
[2018-06-04 18:55] Train Step 10325, Epoch 9.6, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -387.155, Loss = 397.857
[2018-06-04 18:56] Train Step 10350, Epoch 9.6, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -395.837, Loss = 397.965
[2018-06-04 18:56] Train Step 10375, Epoch 9.6, Batch Size = 256, Examples/Sec = 3848.65, Train LB = -398.922, Loss = 398.041
[2018-06-04 18:56] Train Step 10400, Epoch 9.6, Batch Size = 256, Examples/Sec = 3859.78, Train LB = -396.317, Loss = 398.563
Performance on test set:
  Test Lower Bound = -401.302, Test Loss = 401.302
[2018-06-04 18:56] Train Step 10425, Epoch 9.7, Batch Size = 256, Examples/Sec = 3863.80, Train LB = -399.487, Loss = 398.228
[2018-06-04 18:56] Train Step 10450, Epoch 9.7, Batch Size = 256, Examples/Sec = 3847.25, Train LB = -395.058, Loss = 398.313
[2018-06-04 18:56] Train Step 10475, Epoch 9.7, Batch Size = 256, Examples/Sec = 3700.12, Train LB = -388.168, Loss = 397.714
[2018-06-04 18:56] Train Step 10500, Epoch 9.7, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -381.243, Loss = 397.714
[2018-06-04 18:56] Train Step 10525, Epoch 9.7, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -387.730, Loss = 397.170
[2018-06-04 18:56] Train Step 10550, Epoch 9.8, Batch Size = 256, Examples/Sec = 3742.37, Train LB = -396.689, Loss = 397.105
[2018-06-04 18:56] Train Step 10575, Epoch 9.8, Batch Size = 256, Examples/Sec = 3835.27, Train LB = -385.228, Loss = 397.531
[2018-06-04 18:56] Train Step 10600, Epoch 9.8, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -401.697, Loss = 398.085
Performance on test set:
  Test Lower Bound = -403.093, Test Loss = 403.093
[2018-06-04 18:56] Train Step 10625, Epoch 9.8, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -401.847, Loss = 397.346
[2018-06-04 18:56] Train Step 10650, Epoch 9.9, Batch Size = 256, Examples/Sec = 3875.33, Train LB = -385.392, Loss = 397.855
[2018-06-04 18:56] Train Step 10675, Epoch 9.9, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -405.688, Loss = 397.511
[2018-06-04 18:56] Train Step 10700, Epoch 9.9, Batch Size = 256, Examples/Sec = 3860.48, Train LB = -401.858, Loss = 396.925
[2018-06-04 18:56] Train Step 10725, Epoch 9.9, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -399.870, Loss = 396.581
[2018-06-04 18:56] Train Step 10750, Epoch 10.0, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -397.320, Loss = 396.281
[2018-06-04 18:56] Train Step 10775, Epoch 10.0, Batch Size = 256, Examples/Sec = 3847.78, Train LB = -407.185, Loss = 396.521
[2018-06-04 18:56] Train Step 10800, Epoch 10.0, Batch Size = 256, Examples/Sec = 3783.57, Train LB = -394.443, Loss = 397.184
Performance on test set:
  Test Lower Bound = -403.181, Test Loss = 403.181
[2018-06-04 18:56] Train Step 10825, Epoch 10.0, Batch Size = 256, Examples/Sec = 3868.66, Train LB = -397.669, Loss = 397.521
[2018-06-04 18:56] Train Step 10850, Epoch 10.0, Batch Size = 256, Examples/Sec = 3872.52, Train LB = -391.266, Loss = 396.680
[2018-06-04 18:56] Train Step 10875, Epoch 10.1, Batch Size = 256, Examples/Sec = 3869.98, Train LB = -399.732, Loss = 396.048
[2018-06-04 18:56] Train Step 10900, Epoch 10.1, Batch Size = 256, Examples/Sec = 3865.62, Train LB = -400.423, Loss = 395.799
[2018-06-04 18:56] Train Step 10925, Epoch 10.1, Batch Size = 256, Examples/Sec = 3845.63, Train LB = -398.325, Loss = 395.582
[2018-06-04 18:56] Train Step 10950, Epoch 10.1, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -388.570, Loss = 395.991
[2018-06-04 18:56] Train Step 10975, Epoch 10.2, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -398.460, Loss = 397.060
[2018-06-04 18:56] Train Step 11000, Epoch 10.2, Batch Size = 256, Examples/Sec = 3855.76, Train LB = -393.502, Loss = 396.821
Performance on test set:
  Test Lower Bound = -402.307, Test Loss = 402.307
[2018-06-04 18:57] Train Step 11025, Epoch 10.2, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -404.283, Loss = 396.586
[2018-06-04 18:57] Train Step 11050, Epoch 10.2, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -398.275, Loss = 396.086
[2018-06-04 18:57] Train Step 11075, Epoch 10.3, Batch Size = 256, Examples/Sec = 3871.06, Train LB = -397.663, Loss = 395.773
[2018-06-04 18:57] Train Step 11100, Epoch 10.3, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -401.273, Loss = 395.910
[2018-06-04 18:57] Train Step 11125, Epoch 10.3, Batch Size = 256, Examples/Sec = 3853.40, Train LB = -385.797, Loss = 396.195
[2018-06-04 18:57] Train Step 11150, Epoch 10.3, Batch Size = 256, Examples/Sec = 3851.60, Train LB = -398.331, Loss = 396.724
[2018-06-04 18:57] Train Step 11175, Epoch 10.3, Batch Size = 256, Examples/Sec = 3852.76, Train LB = -403.564, Loss = 396.603
[2018-06-04 18:57] Train Step 11200, Epoch 10.4, Batch Size = 256, Examples/Sec = 3838.43, Train LB = -398.678, Loss = 396.922
Performance on test set:
  Test Lower Bound = -401.629, Test Loss = 401.629
[2018-06-04 18:57] Train Step 11225, Epoch 10.4, Batch Size = 256, Examples/Sec = 3842.81, Train LB = -394.942, Loss = 396.749
[2018-06-04 18:57] Train Step 11250, Epoch 10.4, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -384.814, Loss = 396.690
[2018-06-04 18:57] Train Step 11275, Epoch 10.4, Batch Size = 256, Examples/Sec = 3867.71, Train LB = -412.021, Loss = 396.559
[2018-06-04 18:57] Train Step 11300, Epoch 10.5, Batch Size = 256, Examples/Sec = 3876.62, Train LB = -391.990, Loss = 396.044
[2018-06-04 18:57] Train Step 11325, Epoch 10.5, Batch Size = 256, Examples/Sec = 3858.38, Train LB = -394.039, Loss = 395.431
[2018-06-04 18:57] Train Step 11350, Epoch 10.5, Batch Size = 256, Examples/Sec = 3862.41, Train LB = -399.846, Loss = 395.883
[2018-06-04 18:57] Train Step 11375, Epoch 10.5, Batch Size = 256, Examples/Sec = 3869.34, Train LB = -403.762, Loss = 395.909
[2018-06-04 18:57] Train Step 11400, Epoch 10.6, Batch Size = 256, Examples/Sec = 3788.56, Train LB = -398.261, Loss = 396.612
Performance on test set:
  Test Lower Bound = -402.224, Test Loss = 402.224
[2018-06-04 18:57] Train Step 11425, Epoch 10.6, Batch Size = 256, Examples/Sec = 3871.22, Train LB = -408.662, Loss = 396.316
[2018-06-04 18:57] Train Step 11450, Epoch 10.6, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -389.932, Loss = 396.323
[2018-06-04 18:57] Train Step 11475, Epoch 10.6, Batch Size = 256, Examples/Sec = 3868.71, Train LB = -385.634, Loss = 395.667
[2018-06-04 18:57] Train Step 11500, Epoch 10.6, Batch Size = 256, Examples/Sec = 3814.86, Train LB = -388.414, Loss = 395.350
[2018-06-04 18:57] Train Step 11525, Epoch 10.7, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -390.892, Loss = 395.377
[2018-06-04 18:57] Train Step 11550, Epoch 10.7, Batch Size = 256, Examples/Sec = 3867.19, Train LB = -406.332, Loss = 395.475
[2018-06-04 18:57] Train Step 11575, Epoch 10.7, Batch Size = 256, Examples/Sec = 3850.50, Train LB = -401.502, Loss = 395.657
[2018-06-04 18:57] Train Step 11600, Epoch 10.7, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -398.913, Loss = 396.541
Performance on test set:
  Test Lower Bound = -400.126, Test Loss = 400.126
[2018-06-04 18:57] Train Step 11625, Epoch 10.8, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -397.558, Loss = 396.443
[2018-06-04 18:57] Train Step 11650, Epoch 10.8, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -383.970, Loss = 396.365
[2018-06-04 18:57] Train Step 11675, Epoch 10.8, Batch Size = 256, Examples/Sec = 3848.18, Train LB = -384.269, Loss = 396.110
[2018-06-04 18:57] Train Step 11700, Epoch 10.8, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -392.369, Loss = 395.301
[2018-06-04 18:57] Train Step 11725, Epoch 10.9, Batch Size = 256, Examples/Sec = 3828.15, Train LB = -392.672, Loss = 395.276
[2018-06-04 18:57] Train Step 11750, Epoch 10.9, Batch Size = 256, Examples/Sec = 3870.99, Train LB = -389.068, Loss = 394.651
[2018-06-04 18:58] Train Step 11775, Epoch 10.9, Batch Size = 256, Examples/Sec = 3863.56, Train LB = -390.771, Loss = 394.974
[2018-06-04 18:58] Train Step 11800, Epoch 10.9, Batch Size = 256, Examples/Sec = 3876.56, Train LB = -392.648, Loss = 395.431
Performance on test set:
  Test Lower Bound = -403.230, Test Loss = 403.230
[2018-06-04 18:58] Train Step 11825, Epoch 10.9, Batch Size = 256, Examples/Sec = 3749.66, Train LB = -398.250, Loss = 395.256
[2018-06-04 18:58] Train Step 11850, Epoch 11.0, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -403.260, Loss = 395.275
[2018-06-04 18:58] Train Step 11875, Epoch 11.0, Batch Size = 256, Examples/Sec = 3869.35, Train LB = -390.873, Loss = 395.060
[2018-06-04 18:58] Train Step 11900, Epoch 11.0, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -391.577, Loss = 394.555
[2018-06-04 18:58] Train Step 11925, Epoch 11.0, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -388.487, Loss = 394.211
[2018-06-04 18:58] Train Step 11950, Epoch 11.1, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -398.495, Loss = 394.304
[2018-06-04 18:58] Train Step 11975, Epoch 11.1, Batch Size = 256, Examples/Sec = 3871.81, Train LB = -400.146, Loss = 394.589
[2018-06-04 18:58] Train Step 12000, Epoch 11.1, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -391.031, Loss = 395.352
Performance on test set:
  Test Lower Bound = -402.122, Test Loss = 402.122
[2018-06-04 18:58] Train Step 12025, Epoch 11.1, Batch Size = 256, Examples/Sec = 3876.86, Train LB = -388.645, Loss = 395.674
[2018-06-04 18:58] Train Step 12050, Epoch 11.2, Batch Size = 256, Examples/Sec = 3858.33, Train LB = -389.075, Loss = 395.241
[2018-06-04 18:58] Train Step 12075, Epoch 11.2, Batch Size = 256, Examples/Sec = 3775.03, Train LB = -384.378, Loss = 394.937
[2018-06-04 18:58] Train Step 12100, Epoch 11.2, Batch Size = 256, Examples/Sec = 3863.80, Train LB = -394.994, Loss = 395.154
[2018-06-04 18:58] Train Step 12125, Epoch 11.2, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -408.391, Loss = 394.482
[2018-06-04 18:58] Train Step 12150, Epoch 11.2, Batch Size = 256, Examples/Sec = 3727.80, Train LB = -399.069, Loss = 394.703
[2018-06-04 18:58] Train Step 12175, Epoch 11.3, Batch Size = 256, Examples/Sec = 3849.92, Train LB = -399.552, Loss = 394.576
[2018-06-04 18:58] Train Step 12200, Epoch 11.3, Batch Size = 256, Examples/Sec = 3870.51, Train LB = -391.168, Loss = 395.288
Performance on test set:
  Test Lower Bound = -401.353, Test Loss = 401.353
[2018-06-04 18:58] Train Step 12225, Epoch 11.3, Batch Size = 256, Examples/Sec = 3814.86, Train LB = -393.531, Loss = 394.773
[2018-06-04 18:58] Train Step 12250, Epoch 11.3, Batch Size = 256, Examples/Sec = 3847.83, Train LB = -390.306, Loss = 394.772
[2018-06-04 18:58] Train Step 12275, Epoch 11.4, Batch Size = 256, Examples/Sec = 3875.90, Train LB = -377.607, Loss = 394.606
[2018-06-04 18:58] Train Step 12300, Epoch 11.4, Batch Size = 256, Examples/Sec = 3872.91, Train LB = -393.027, Loss = 394.656
[2018-06-04 18:58] Train Step 12325, Epoch 11.4, Batch Size = 256, Examples/Sec = 3855.20, Train LB = -395.541, Loss = 394.585
[2018-06-04 18:58] Train Step 12350, Epoch 11.4, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -394.560, Loss = 394.286
[2018-06-04 18:58] Train Step 12375, Epoch 11.5, Batch Size = 256, Examples/Sec = 3863.63, Train LB = -407.822, Loss = 394.234
[2018-06-04 18:58] Train Step 12400, Epoch 11.5, Batch Size = 256, Examples/Sec = 3876.21, Train LB = -394.258, Loss = 394.716
Performance on test set:
  Test Lower Bound = -399.697, Test Loss = 399.697
[2018-06-04 18:58] Train Step 12425, Epoch 11.5, Batch Size = 256, Examples/Sec = 3858.38, Train LB = -390.494, Loss = 393.750
[2018-06-04 18:58] Train Step 12450, Epoch 11.5, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -390.347, Loss = 394.534
[2018-06-04 18:59] Train Step 12475, Epoch 11.6, Batch Size = 256, Examples/Sec = 3877.61, Train LB = -388.484, Loss = 394.395
[2018-06-04 18:59] Train Step 12500, Epoch 11.6, Batch Size = 256, Examples/Sec = 3872.03, Train LB = -392.861, Loss = 393.806
[2018-06-04 18:59] Train Step 12525, Epoch 11.6, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -398.150, Loss = 393.895
[2018-06-04 18:59] Train Step 12550, Epoch 11.6, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -389.155, Loss = 393.669
[2018-06-04 18:59] Train Step 12575, Epoch 11.6, Batch Size = 256, Examples/Sec = 3870.41, Train LB = -413.974, Loss = 394.646
[2018-06-04 18:59] Train Step 12600, Epoch 11.7, Batch Size = 256, Examples/Sec = 3848.98, Train LB = -399.617, Loss = 395.138
Performance on test set:
  Test Lower Bound = -401.319, Test Loss = 401.319
[2018-06-04 18:59] Train Step 12625, Epoch 11.7, Batch Size = 256, Examples/Sec = 3865.37, Train LB = -383.235, Loss = 394.603
[2018-06-04 18:59] Train Step 12650, Epoch 11.7, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -403.341, Loss = 394.383
[2018-06-04 18:59] Train Step 12675, Epoch 11.7, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -394.666, Loss = 393.349
[2018-06-04 18:59] Train Step 12700, Epoch 11.8, Batch Size = 256, Examples/Sec = 3867.19, Train LB = -391.339, Loss = 392.995
[2018-06-04 18:59] Train Step 12725, Epoch 11.8, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -398.547, Loss = 393.344
[2018-06-04 18:59] Train Step 12750, Epoch 11.8, Batch Size = 256, Examples/Sec = 3852.69, Train LB = -396.799, Loss = 393.431
[2018-06-04 18:59] Train Step 12775, Epoch 11.8, Batch Size = 256, Examples/Sec = 3843.08, Train LB = -390.519, Loss = 393.812
[2018-06-04 18:59] Train Step 12800, Epoch 11.9, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -398.639, Loss = 394.467
Performance on test set:
  Test Lower Bound = -399.843, Test Loss = 399.843
[2018-06-04 18:59] Train Step 12825, Epoch 11.9, Batch Size = 256, Examples/Sec = 3866.25, Train LB = -391.094, Loss = 393.433
[2018-06-04 18:59] Train Step 12850, Epoch 11.9, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -386.698, Loss = 394.096
[2018-06-04 18:59] Train Step 12875, Epoch 11.9, Batch Size = 256, Examples/Sec = 3747.74, Train LB = -385.900, Loss = 394.001
[2018-06-04 18:59] Train Step 12900, Epoch 11.9, Batch Size = 256, Examples/Sec = 3863.80, Train LB = -385.007, Loss = 393.603
[2018-06-04 18:59] Train Step 12925, Epoch 12.0, Batch Size = 256, Examples/Sec = 3875.28, Train LB = -398.168, Loss = 393.363
[2018-06-04 18:59] Train Step 12950, Epoch 12.0, Batch Size = 256, Examples/Sec = 3827.47, Train LB = -402.649, Loss = 392.959
[2018-06-04 18:59] Train Step 12975, Epoch 12.0, Batch Size = 256, Examples/Sec = 3811.18, Train LB = -393.435, Loss = 393.039
[2018-06-04 18:59] Train Step 13000, Epoch 12.0, Batch Size = 256, Examples/Sec = 3845.45, Train LB = -403.449, Loss = 393.996
Performance on test set:
  Test Lower Bound = -402.827, Test Loss = 402.827
[2018-06-04 18:59] Train Step 13025, Epoch 12.1, Batch Size = 256, Examples/Sec = 3876.38, Train LB = -404.092, Loss = 394.328
[2018-06-04 18:59] Train Step 13050, Epoch 12.1, Batch Size = 256, Examples/Sec = 3872.44, Train LB = -400.636, Loss = 393.646
[2018-06-04 18:59] Train Step 13075, Epoch 12.1, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -397.470, Loss = 393.772
[2018-06-04 18:59] Train Step 13100, Epoch 12.1, Batch Size = 256, Examples/Sec = 3850.10, Train LB = -390.184, Loss = 392.779
[2018-06-04 18:59] Train Step 13125, Epoch 12.2, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -388.679, Loss = 392.960
[2018-06-04 18:59] Train Step 13150, Epoch 12.2, Batch Size = 256, Examples/Sec = 3852.58, Train LB = -391.666, Loss = 393.495
[2018-06-04 18:59] Train Step 13175, Epoch 12.2, Batch Size = 256, Examples/Sec = 3834.75, Train LB = -407.057, Loss = 393.769
[2018-06-04 19:00] Train Step 13200, Epoch 12.2, Batch Size = 256, Examples/Sec = 3815.89, Train LB = -402.980, Loss = 394.348
Performance on test set:
  Test Lower Bound = -399.753, Test Loss = 399.753
[2018-06-04 19:00] Train Step 13225, Epoch 12.2, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -386.429, Loss = 393.812
[2018-06-04 19:00] Train Step 13250, Epoch 12.3, Batch Size = 256, Examples/Sec = 3862.39, Train LB = -393.943, Loss = 393.509
[2018-06-04 19:00] Train Step 13275, Epoch 12.3, Batch Size = 256, Examples/Sec = 3844.36, Train LB = -396.817, Loss = 392.674
[2018-06-04 19:00] Train Step 13300, Epoch 12.3, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -386.643, Loss = 392.468
[2018-06-04 19:00] Train Step 13325, Epoch 12.3, Batch Size = 256, Examples/Sec = 3837.97, Train LB = -385.042, Loss = 392.138
[2018-06-04 19:00] Train Step 13350, Epoch 12.4, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -383.666, Loss = 391.647
[2018-06-04 19:00] Train Step 13375, Epoch 12.4, Batch Size = 256, Examples/Sec = 3816.39, Train LB = -394.969, Loss = 392.586
[2018-06-04 19:00] Train Step 13400, Epoch 12.4, Batch Size = 256, Examples/Sec = 3839.81, Train LB = -399.797, Loss = 394.022
Performance on test set:
  Test Lower Bound = -400.235, Test Loss = 400.235
[2018-06-04 19:00] Train Step 13425, Epoch 12.4, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -393.789, Loss = 393.763
[2018-06-04 19:00] Train Step 13450, Epoch 12.5, Batch Size = 256, Examples/Sec = 3837.09, Train LB = -403.457, Loss = 393.655
[2018-06-04 19:00] Train Step 13475, Epoch 12.5, Batch Size = 256, Examples/Sec = 3830.62, Train LB = -400.456, Loss = 392.957
[2018-06-04 19:00] Train Step 13500, Epoch 12.5, Batch Size = 256, Examples/Sec = 3855.58, Train LB = -397.517, Loss = 392.847
[2018-06-04 19:00] Train Step 13525, Epoch 12.5, Batch Size = 256, Examples/Sec = 3876.51, Train LB = -379.170, Loss = 393.078
[2018-06-04 19:00] Train Step 13550, Epoch 12.5, Batch Size = 256, Examples/Sec = 3848.29, Train LB = -401.028, Loss = 392.788
[2018-06-04 19:00] Train Step 13575, Epoch 12.6, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -382.554, Loss = 393.263
[2018-06-04 19:00] Train Step 13600, Epoch 12.6, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -395.898, Loss = 393.400
Performance on test set:
  Test Lower Bound = -400.666, Test Loss = 400.666
[2018-06-04 19:00] Train Step 13625, Epoch 12.6, Batch Size = 256, Examples/Sec = 3858.45, Train LB = -388.285, Loss = 393.178
[2018-06-04 19:00] Train Step 13650, Epoch 12.6, Batch Size = 256, Examples/Sec = 3858.11, Train LB = -393.738, Loss = 392.962
[2018-06-04 19:00] Train Step 13675, Epoch 12.7, Batch Size = 256, Examples/Sec = 3867.72, Train LB = -390.914, Loss = 391.984
[2018-06-04 19:00] Train Step 13700, Epoch 12.7, Batch Size = 256, Examples/Sec = 3859.67, Train LB = -394.203, Loss = 391.346
[2018-06-04 19:00] Train Step 13725, Epoch 12.7, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -402.012, Loss = 391.945
[2018-06-04 19:00] Train Step 13750, Epoch 12.7, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -397.191, Loss = 392.301
[2018-06-04 19:00] Train Step 13775, Epoch 12.8, Batch Size = 256, Examples/Sec = 3880.32, Train LB = -397.856, Loss = 392.309
[2018-06-04 19:00] Train Step 13800, Epoch 12.8, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -393.447, Loss = 393.304
Performance on test set:
  Test Lower Bound = -400.906, Test Loss = 400.906
[2018-06-04 19:00] Train Step 13825, Epoch 12.8, Batch Size = 256, Examples/Sec = 3860.60, Train LB = -387.543, Loss = 393.098
[2018-06-04 19:00] Train Step 13850, Epoch 12.8, Batch Size = 256, Examples/Sec = 3729.12, Train LB = -397.169, Loss = 392.634
[2018-06-04 19:00] Train Step 13875, Epoch 12.8, Batch Size = 256, Examples/Sec = 3853.62, Train LB = -402.717, Loss = 392.134
[2018-06-04 19:01] Train Step 13900, Epoch 12.9, Batch Size = 256, Examples/Sec = 3853.50, Train LB = -395.187, Loss = 391.832
[2018-06-04 19:01] Train Step 13925, Epoch 12.9, Batch Size = 256, Examples/Sec = 3725.85, Train LB = -377.659, Loss = 392.410
[2018-06-04 19:01] Train Step 13950, Epoch 12.9, Batch Size = 256, Examples/Sec = 3844.54, Train LB = -395.382, Loss = 392.254
[2018-06-04 19:01] Train Step 13975, Epoch 12.9, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -406.081, Loss = 392.231
[2018-06-04 19:01] Train Step 14000, Epoch 13.0, Batch Size = 256, Examples/Sec = 3853.98, Train LB = -409.957, Loss = 392.884
Performance on test set:
  Test Lower Bound = -400.429, Test Loss = 400.429
[2018-06-04 19:01] Train Step 14025, Epoch 13.0, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -384.538, Loss = 392.468
[2018-06-04 19:01] Train Step 14050, Epoch 13.0, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -383.897, Loss = 392.141
[2018-06-04 19:01] Train Step 14075, Epoch 13.0, Batch Size = 256, Examples/Sec = 3834.46, Train LB = -384.932, Loss = 392.295
[2018-06-04 19:01] Train Step 14100, Epoch 13.1, Batch Size = 256, Examples/Sec = 3850.83, Train LB = -384.832, Loss = 391.624
[2018-06-04 19:01] Train Step 14125, Epoch 13.1, Batch Size = 256, Examples/Sec = 3860.30, Train LB = -400.444, Loss = 391.248
[2018-06-04 19:01] Train Step 14150, Epoch 13.1, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -380.580, Loss = 391.765
[2018-06-04 19:01] Train Step 14175, Epoch 13.1, Batch Size = 256, Examples/Sec = 3742.03, Train LB = -390.975, Loss = 391.629
[2018-06-04 19:01] Train Step 14200, Epoch 13.1, Batch Size = 256, Examples/Sec = 3849.57, Train LB = -385.655, Loss = 392.436
Performance on test set:
  Test Lower Bound = -400.021, Test Loss = 400.021
[2018-06-04 19:01] Train Step 14225, Epoch 13.2, Batch Size = 256, Examples/Sec = 3848.87, Train LB = -390.919, Loss = 391.578
[2018-06-04 19:01] Train Step 14250, Epoch 13.2, Batch Size = 256, Examples/Sec = 3850.72, Train LB = -386.609, Loss = 391.896
[2018-06-04 19:01] Train Step 14275, Epoch 13.2, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -375.423, Loss = 390.759
[2018-06-04 19:01] Train Step 14300, Epoch 13.2, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -407.281, Loss = 390.896
[2018-06-04 19:01] Train Step 14325, Epoch 13.3, Batch Size = 256, Examples/Sec = 3795.96, Train LB = -393.703, Loss = 390.927
[2018-06-04 19:01] Train Step 14350, Epoch 13.3, Batch Size = 256, Examples/Sec = 3841.82, Train LB = -394.941, Loss = 391.224
[2018-06-04 19:01] Train Step 14375, Epoch 13.3, Batch Size = 256, Examples/Sec = 3788.49, Train LB = -381.700, Loss = 391.191
[2018-06-04 19:01] Train Step 14400, Epoch 13.3, Batch Size = 256, Examples/Sec = 3844.82, Train LB = -389.005, Loss = 392.471
Performance on test set:
  Test Lower Bound = -399.339, Test Loss = 399.339
[2018-06-04 19:01] Train Step 14425, Epoch 13.4, Batch Size = 256, Examples/Sec = 3832.10, Train LB = -406.193, Loss = 392.081
[2018-06-04 19:01] Train Step 14450, Epoch 13.4, Batch Size = 256, Examples/Sec = 3845.06, Train LB = -404.191, Loss = 391.585
[2018-06-04 19:01] Train Step 14475, Epoch 13.4, Batch Size = 256, Examples/Sec = 3872.38, Train LB = -400.962, Loss = 390.836
[2018-06-04 19:01] Train Step 14500, Epoch 13.4, Batch Size = 256, Examples/Sec = 3877.09, Train LB = -384.620, Loss = 390.431
[2018-06-04 19:01] Train Step 14525, Epoch 13.4, Batch Size = 256, Examples/Sec = 3819.12, Train LB = -382.297, Loss = 390.600
[2018-06-04 19:01] Train Step 14550, Epoch 13.5, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -390.528, Loss = 390.800
[2018-06-04 19:01] Train Step 14575, Epoch 13.5, Batch Size = 256, Examples/Sec = 3861.52, Train LB = -387.939, Loss = 391.020
[2018-06-04 19:01] Train Step 14600, Epoch 13.5, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -399.198, Loss = 391.737
Performance on test set:
  Test Lower Bound = -399.271, Test Loss = 399.271
[2018-06-04 19:02] Train Step 14625, Epoch 13.5, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -388.453, Loss = 391.453
[2018-06-04 19:02] Train Step 14650, Epoch 13.6, Batch Size = 256, Examples/Sec = 3763.38, Train LB = -373.738, Loss = 391.189
[2018-06-04 19:02] Train Step 14675, Epoch 13.6, Batch Size = 256, Examples/Sec = 3876.62, Train LB = -383.371, Loss = 390.860
[2018-06-04 19:02] Train Step 14700, Epoch 13.6, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -400.209, Loss = 390.632
[2018-06-04 19:02] Train Step 14725, Epoch 13.6, Batch Size = 256, Examples/Sec = 3798.15, Train LB = -393.295, Loss = 390.720
[2018-06-04 19:02] Train Step 14750, Epoch 13.7, Batch Size = 256, Examples/Sec = 3876.62, Train LB = -401.835, Loss = 390.228
[2018-06-04 19:02] Train Step 14775, Epoch 13.7, Batch Size = 256, Examples/Sec = 3845.57, Train LB = -394.061, Loss = 390.106
[2018-06-04 19:02] Train Step 14800, Epoch 13.7, Batch Size = 256, Examples/Sec = 3846.46, Train LB = -409.026, Loss = 390.645
Performance on test set:
  Test Lower Bound = -401.798, Test Loss = 401.798
[2018-06-04 19:02] Train Step 14825, Epoch 13.7, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -387.500, Loss = 390.603
[2018-06-04 19:02] Train Step 14850, Epoch 13.8, Batch Size = 256, Examples/Sec = 3869.70, Train LB = -382.684, Loss = 390.502
[2018-06-04 19:02] Train Step 14875, Epoch 13.8, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -390.549, Loss = 390.105
[2018-06-04 19:02] Train Step 14900, Epoch 13.8, Batch Size = 256, Examples/Sec = 3772.64, Train LB = -382.388, Loss = 389.459
[2018-06-04 19:02] Train Step 14925, Epoch 13.8, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -392.726, Loss = 389.281
[2018-06-04 19:02] Train Step 14950, Epoch 13.8, Batch Size = 256, Examples/Sec = 3874.32, Train LB = -376.714, Loss = 389.249
[2018-06-04 19:02] Train Step 14975, Epoch 13.9, Batch Size = 256, Examples/Sec = 3726.30, Train LB = -396.167, Loss = 389.647
[2018-06-04 19:02] Train Step 15000, Epoch 13.9, Batch Size = 256, Examples/Sec = 3863.56, Train LB = -397.985, Loss = 391.048
Performance on test set:
  Test Lower Bound = -402.848, Test Loss = 402.848
[2018-06-04 19:02] Train Step 15025, Epoch 13.9, Batch Size = 256, Examples/Sec = 3878.73, Train LB = -401.942, Loss = 390.994
[2018-06-04 19:02] Train Step 15050, Epoch 13.9, Batch Size = 256, Examples/Sec = 3856.69, Train LB = -386.247, Loss = 390.039
[2018-06-04 19:02] Train Step 15075, Epoch 14.0, Batch Size = 256, Examples/Sec = 3848.88, Train LB = -387.430, Loss = 389.439
[2018-06-04 19:02] Train Step 15100, Epoch 14.0, Batch Size = 256, Examples/Sec = 3871.98, Train LB = -382.734, Loss = 389.496
[2018-06-04 19:02] Train Step 15125, Epoch 14.0, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -385.470, Loss = 389.416
[2018-06-04 19:02] Train Step 15150, Epoch 14.0, Batch Size = 256, Examples/Sec = 3855.54, Train LB = -393.182, Loss = 389.643
[2018-06-04 19:02] Train Step 15175, Epoch 14.1, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -407.714, Loss = 390.587
[2018-06-04 19:02] Train Step 15200, Epoch 14.1, Batch Size = 256, Examples/Sec = 3888.28, Train LB = -388.088, Loss = 390.998
Performance on test set:
  Test Lower Bound = -398.157, Test Loss = 398.157
[2018-06-04 19:02] Train Step 15225, Epoch 14.1, Batch Size = 256, Examples/Sec = 3881.26, Train LB = -388.190, Loss = 390.489
[2018-06-04 19:02] Train Step 15250, Epoch 14.1, Batch Size = 256, Examples/Sec = 3871.40, Train LB = -381.231, Loss = 389.683
[2018-06-04 19:02] Train Step 15275, Epoch 14.1, Batch Size = 256, Examples/Sec = 3862.16, Train LB = -374.625, Loss = 390.576
[2018-06-04 19:02] Train Step 15300, Epoch 14.2, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -390.847, Loss = 390.048
[2018-06-04 19:03] Train Step 15325, Epoch 14.2, Batch Size = 256, Examples/Sec = 3836.42, Train LB = -393.508, Loss = 389.912
[2018-06-04 19:03] Train Step 15350, Epoch 14.2, Batch Size = 256, Examples/Sec = 3806.97, Train LB = -401.965, Loss = 390.105
[2018-06-04 19:03] Train Step 15375, Epoch 14.2, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -388.806, Loss = 390.116
[2018-06-04 19:03] Train Step 15400, Epoch 14.3, Batch Size = 256, Examples/Sec = 3847.42, Train LB = -400.086, Loss = 391.086
Performance on test set:
  Test Lower Bound = -399.495, Test Loss = 399.495
[2018-06-04 19:03] Train Step 15425, Epoch 14.3, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -382.570, Loss = 390.473
[2018-06-04 19:03] Train Step 15450, Epoch 14.3, Batch Size = 256, Examples/Sec = 3863.85, Train LB = -382.834, Loss = 390.840
[2018-06-04 19:03] Train Step 15475, Epoch 14.3, Batch Size = 256, Examples/Sec = 3854.91, Train LB = -387.958, Loss = 390.217
[2018-06-04 19:03] Train Step 15500, Epoch 14.4, Batch Size = 256, Examples/Sec = 3878.26, Train LB = -387.522, Loss = 390.090
[2018-06-04 19:03] Train Step 15525, Epoch 14.4, Batch Size = 256, Examples/Sec = 3860.31, Train LB = -382.238, Loss = 389.554
[2018-06-04 19:03] Train Step 15550, Epoch 14.4, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -386.430, Loss = 389.597
[2018-06-04 19:03] Train Step 15575, Epoch 14.4, Batch Size = 256, Examples/Sec = 3862.64, Train LB = -386.743, Loss = 390.112
[2018-06-04 19:03] Train Step 15600, Epoch 14.4, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -393.453, Loss = 390.821
Performance on test set:
  Test Lower Bound = -398.205, Test Loss = 398.205
[2018-06-04 19:03] Train Step 15625, Epoch 14.5, Batch Size = 256, Examples/Sec = 3750.53, Train LB = -374.511, Loss = 390.288
[2018-06-04 19:03] Train Step 15650, Epoch 14.5, Batch Size = 256, Examples/Sec = 3853.09, Train LB = -385.105, Loss = 389.942
[2018-06-04 19:03] Train Step 15675, Epoch 14.5, Batch Size = 256, Examples/Sec = 3817.55, Train LB = -393.038, Loss = 389.417
[2018-06-04 19:03] Train Step 15700, Epoch 14.5, Batch Size = 256, Examples/Sec = 3747.45, Train LB = -393.150, Loss = 389.477
[2018-06-04 19:03] Train Step 15725, Epoch 14.6, Batch Size = 256, Examples/Sec = 3833.20, Train LB = -396.723, Loss = 389.330
[2018-06-04 19:03] Train Step 15750, Epoch 14.6, Batch Size = 256, Examples/Sec = 3832.79, Train LB = -388.975, Loss = 388.984
[2018-06-04 19:03] Train Step 15775, Epoch 14.6, Batch Size = 256, Examples/Sec = 3848.30, Train LB = -377.570, Loss = 389.643
[2018-06-04 19:03] Train Step 15800, Epoch 14.6, Batch Size = 256, Examples/Sec = 3847.49, Train LB = -392.212, Loss = 389.999
Performance on test set:
  Test Lower Bound = -399.409, Test Loss = 399.409
[2018-06-04 19:03] Train Step 15825, Epoch 14.7, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -401.030, Loss = 389.576
[2018-06-04 19:03] Train Step 15850, Epoch 14.7, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -383.827, Loss = 389.787
[2018-06-04 19:03] Train Step 15875, Epoch 14.7, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -385.432, Loss = 389.340
[2018-06-04 19:03] Train Step 15900, Epoch 14.7, Batch Size = 256, Examples/Sec = 3863.17, Train LB = -379.566, Loss = 388.787
[2018-06-04 19:03] Train Step 15925, Epoch 14.7, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -401.343, Loss = 388.923
[2018-06-04 19:03] Train Step 15950, Epoch 14.8, Batch Size = 256, Examples/Sec = 3802.44, Train LB = -399.256, Loss = 388.900
[2018-06-04 19:03] Train Step 15975, Epoch 14.8, Batch Size = 256, Examples/Sec = 3856.40, Train LB = -399.067, Loss = 389.321
[2018-06-04 19:03] Train Step 16000, Epoch 14.8, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -390.059, Loss = 390.052
Performance on test set:
  Test Lower Bound = -399.186, Test Loss = 399.186
[2018-06-04 19:04] Train Step 16025, Epoch 14.8, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -401.947, Loss = 389.564
[2018-06-04 19:04] Train Step 16050, Epoch 14.9, Batch Size = 256, Examples/Sec = 3872.97, Train LB = -382.523, Loss = 389.909
[2018-06-04 19:04] Train Step 16075, Epoch 14.9, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -398.891, Loss = 388.979
[2018-06-04 19:04] Train Step 16100, Epoch 14.9, Batch Size = 256, Examples/Sec = 3876.62, Train LB = -391.468, Loss = 388.513
[2018-06-04 19:04] Train Step 16125, Epoch 14.9, Batch Size = 256, Examples/Sec = 3843.27, Train LB = -397.563, Loss = 388.410
[2018-06-04 19:04] Train Step 16150, Epoch 15.0, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -382.649, Loss = 388.684
[2018-06-04 19:04] Train Step 16175, Epoch 15.0, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -390.367, Loss = 389.148
[2018-06-04 19:04] Train Step 16200, Epoch 15.0, Batch Size = 256, Examples/Sec = 3859.78, Train LB = -402.820, Loss = 390.237
Performance on test set:
  Test Lower Bound = -399.204, Test Loss = 399.204
[2018-06-04 19:04] Train Step 16225, Epoch 15.0, Batch Size = 256, Examples/Sec = 3841.02, Train LB = -381.124, Loss = 389.345
[2018-06-04 19:04] Train Step 16250, Epoch 15.0, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -384.056, Loss = 389.346
[2018-06-04 19:04] Train Step 16275, Epoch 15.1, Batch Size = 256, Examples/Sec = 3852.82, Train LB = -396.815, Loss = 388.833
[2018-06-04 19:04] Train Step 16300, Epoch 15.1, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -386.245, Loss = 388.556
[2018-06-04 19:04] Train Step 16325, Epoch 15.1, Batch Size = 256, Examples/Sec = 3841.94, Train LB = -386.835, Loss = 388.189
[2018-06-04 19:04] Train Step 16350, Epoch 15.1, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -389.408, Loss = 388.210
[2018-06-04 19:04] Train Step 16375, Epoch 15.2, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -381.251, Loss = 388.479
[2018-06-04 19:04] Train Step 16400, Epoch 15.2, Batch Size = 256, Examples/Sec = 3868.06, Train LB = -416.964, Loss = 389.532
Performance on test set:
  Test Lower Bound = -402.813, Test Loss = 402.813
[2018-06-04 19:04] Train Step 16425, Epoch 15.2, Batch Size = 256, Examples/Sec = 3750.36, Train LB = -390.294, Loss = 389.434
[2018-06-04 19:04] Train Step 16450, Epoch 15.2, Batch Size = 256, Examples/Sec = 3844.71, Train LB = -385.487, Loss = 389.215
[2018-06-04 19:04] Train Step 16475, Epoch 15.3, Batch Size = 256, Examples/Sec = 3872.68, Train LB = -393.898, Loss = 388.920
[2018-06-04 19:04] Train Step 16500, Epoch 15.3, Batch Size = 256, Examples/Sec = 3846.44, Train LB = -376.719, Loss = 388.627
[2018-06-04 19:04] Train Step 16525, Epoch 15.3, Batch Size = 256, Examples/Sec = 3847.78, Train LB = -403.229, Loss = 388.290
[2018-06-04 19:04] Train Step 16550, Epoch 15.3, Batch Size = 256, Examples/Sec = 3860.55, Train LB = -386.375, Loss = 389.139
[2018-06-04 19:04] Train Step 16575, Epoch 15.3, Batch Size = 256, Examples/Sec = 3844.71, Train LB = -385.941, Loss = 388.988
[2018-06-04 19:04] Train Step 16600, Epoch 15.4, Batch Size = 256, Examples/Sec = 3811.50, Train LB = -391.298, Loss = 389.941
Performance on test set:
  Test Lower Bound = -400.474, Test Loss = 400.474
[2018-06-04 19:04] Train Step 16625, Epoch 15.4, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -384.219, Loss = 389.953
[2018-06-04 19:04] Train Step 16650, Epoch 15.4, Batch Size = 256, Examples/Sec = 3858.74, Train LB = -395.226, Loss = 389.505
[2018-06-04 19:04] Train Step 16675, Epoch 15.4, Batch Size = 256, Examples/Sec = 3785.19, Train LB = -375.676, Loss = 389.169
[2018-06-04 19:04] Train Step 16700, Epoch 15.5, Batch Size = 256, Examples/Sec = 3854.26, Train LB = -394.561, Loss = 388.066
[2018-06-04 19:04] Train Step 16725, Epoch 15.5, Batch Size = 256, Examples/Sec = 3874.97, Train LB = -395.889, Loss = 388.061
[2018-06-04 19:04] Train Step 16750, Epoch 15.5, Batch Size = 256, Examples/Sec = 3719.19, Train LB = -400.146, Loss = 388.354
[2018-06-04 19:05] Train Step 16775, Epoch 15.5, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -372.241, Loss = 388.393
[2018-06-04 19:05] Train Step 16800, Epoch 15.6, Batch Size = 256, Examples/Sec = 3883.73, Train LB = -389.140, Loss = 389.425
Performance on test set:
  Test Lower Bound = -399.297, Test Loss = 399.297
[2018-06-04 19:05] Train Step 16825, Epoch 15.6, Batch Size = 256, Examples/Sec = 3844.49, Train LB = -393.896, Loss = 388.962
[2018-06-04 19:05] Train Step 16850, Epoch 15.6, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -398.078, Loss = 388.443
[2018-06-04 19:05] Train Step 16875, Epoch 15.6, Batch Size = 256, Examples/Sec = 3863.87, Train LB = -377.992, Loss = 387.912
[2018-06-04 19:05] Train Step 16900, Epoch 15.6, Batch Size = 256, Examples/Sec = 3853.44, Train LB = -386.014, Loss = 387.430
[2018-06-04 19:05] Train Step 16925, Epoch 15.7, Batch Size = 256, Examples/Sec = 3802.90, Train LB = -401.967, Loss = 387.598
[2018-06-04 19:05] Train Step 16950, Epoch 15.7, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -397.084, Loss = 387.774
[2018-06-04 19:05] Train Step 16975, Epoch 15.7, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -393.251, Loss = 388.790
[2018-06-04 19:05] Train Step 17000, Epoch 15.7, Batch Size = 256, Examples/Sec = 3847.54, Train LB = -389.243, Loss = 389.349
Performance on test set:
  Test Lower Bound = -399.339, Test Loss = 399.339
[2018-06-04 19:05] Train Step 17025, Epoch 15.8, Batch Size = 256, Examples/Sec = 3865.61, Train LB = -397.798, Loss = 389.225
[2018-06-04 19:05] Train Step 17050, Epoch 15.8, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -387.617, Loss = 388.277
[2018-06-04 19:05] Train Step 17075, Epoch 15.8, Batch Size = 256, Examples/Sec = 3849.68, Train LB = -391.730, Loss = 388.060
[2018-06-04 19:05] Train Step 17100, Epoch 15.8, Batch Size = 256, Examples/Sec = 3856.06, Train LB = -382.233, Loss = 387.924
[2018-06-04 19:05] Train Step 17125, Epoch 15.9, Batch Size = 256, Examples/Sec = 3850.66, Train LB = -378.968, Loss = 387.352
[2018-06-04 19:05] Train Step 17150, Epoch 15.9, Batch Size = 256, Examples/Sec = 3870.00, Train LB = -401.207, Loss = 386.696
[2018-06-04 19:05] Train Step 17175, Epoch 15.9, Batch Size = 256, Examples/Sec = 3863.28, Train LB = -408.601, Loss = 387.280
[2018-06-04 19:05] Train Step 17200, Epoch 15.9, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -397.417, Loss = 388.488
Performance on test set:
  Test Lower Bound = -399.292, Test Loss = 399.292
[2018-06-04 19:05] Train Step 17225, Epoch 15.9, Batch Size = 256, Examples/Sec = 3820.10, Train LB = -381.820, Loss = 388.051
[2018-06-04 19:05] Train Step 17250, Epoch 16.0, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -381.132, Loss = 388.392
[2018-06-04 19:05] Train Step 17275, Epoch 16.0, Batch Size = 256, Examples/Sec = 3855.09, Train LB = -377.459, Loss = 387.814
[2018-06-04 19:05] Train Step 17300, Epoch 16.0, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -381.114, Loss = 386.850
[2018-06-04 19:05] Train Step 17325, Epoch 16.0, Batch Size = 256, Examples/Sec = 3804.26, Train LB = -386.913, Loss = 386.317
[2018-06-04 19:05] Train Step 17350, Epoch 16.1, Batch Size = 256, Examples/Sec = 3842.68, Train LB = -376.281, Loss = 386.621
[2018-06-04 19:05] Train Step 17375, Epoch 16.1, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -380.802, Loss = 387.264
[2018-06-04 19:05] Train Step 17400, Epoch 16.1, Batch Size = 256, Examples/Sec = 3852.91, Train LB = -390.504, Loss = 387.902
Performance on test set:
  Test Lower Bound = -399.210, Test Loss = 399.210
[2018-06-04 19:05] Train Step 17425, Epoch 16.1, Batch Size = 256, Examples/Sec = 3854.42, Train LB = -374.233, Loss = 387.577
[2018-06-04 19:05] Train Step 17450, Epoch 16.2, Batch Size = 256, Examples/Sec = 3845.92, Train LB = -387.052, Loss = 387.259
[2018-06-04 19:06] Train Step 17475, Epoch 16.2, Batch Size = 256, Examples/Sec = 3795.90, Train LB = -385.280, Loss = 386.913
[2018-06-04 19:06] Train Step 17500, Epoch 16.2, Batch Size = 256, Examples/Sec = 3853.69, Train LB = -389.091, Loss = 386.149
[2018-06-04 19:06] Train Step 17525, Epoch 16.2, Batch Size = 256, Examples/Sec = 3824.21, Train LB = -393.788, Loss = 386.325
[2018-06-04 19:06] Train Step 17550, Epoch 16.2, Batch Size = 256, Examples/Sec = 3844.77, Train LB = -378.189, Loss = 386.523
[2018-06-04 19:06] Train Step 17575, Epoch 16.3, Batch Size = 256, Examples/Sec = 3883.85, Train LB = -402.019, Loss = 387.102
[2018-06-04 19:06] Train Step 17600, Epoch 16.3, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -383.744, Loss = 388.263
Performance on test set:
  Test Lower Bound = -399.419, Test Loss = 399.419
[2018-06-04 19:06] Train Step 17625, Epoch 16.3, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -395.722, Loss = 387.468
[2018-06-04 19:06] Train Step 17650, Epoch 16.3, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -388.405, Loss = 387.300
[2018-06-04 19:06] Train Step 17675, Epoch 16.4, Batch Size = 256, Examples/Sec = 3867.71, Train LB = -390.948, Loss = 387.191
[2018-06-04 19:06] Train Step 17700, Epoch 16.4, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -373.965, Loss = 386.708
[2018-06-04 19:06] Train Step 17725, Epoch 16.4, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -383.658, Loss = 386.629
[2018-06-04 19:06] Train Step 17750, Epoch 16.4, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -399.908, Loss = 386.604
[2018-06-04 19:06] Train Step 17775, Epoch 16.5, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -383.606, Loss = 386.829
[2018-06-04 19:06] Train Step 17800, Epoch 16.5, Batch Size = 256, Examples/Sec = 3839.40, Train LB = -392.670, Loss = 388.288
Performance on test set:
  Test Lower Bound = -398.244, Test Loss = 398.244
[2018-06-04 19:06] Train Step 17825, Epoch 16.5, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -397.050, Loss = 388.320
[2018-06-04 19:06] Train Step 17850, Epoch 16.5, Batch Size = 256, Examples/Sec = 3768.98, Train LB = -386.163, Loss = 388.227
[2018-06-04 19:06] Train Step 17875, Epoch 16.6, Batch Size = 256, Examples/Sec = 3863.23, Train LB = -374.575, Loss = 387.111
[2018-06-04 19:06] Train Step 17900, Epoch 16.6, Batch Size = 256, Examples/Sec = 3807.37, Train LB = -396.137, Loss = 386.873
[2018-06-04 19:06] Train Step 17925, Epoch 16.6, Batch Size = 256, Examples/Sec = 3745.15, Train LB = -386.030, Loss = 387.420
[2018-06-04 19:06] Train Step 17950, Epoch 16.6, Batch Size = 256, Examples/Sec = 3882.03, Train LB = -387.385, Loss = 386.641
[2018-06-04 19:06] Train Step 17975, Epoch 16.6, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -392.769, Loss = 387.315
[2018-06-04 19:06] Train Step 18000, Epoch 16.7, Batch Size = 256, Examples/Sec = 3741.38, Train LB = -391.717, Loss = 388.197
Performance on test set:
  Test Lower Bound = -399.789, Test Loss = 399.789
[2018-06-04 19:06] Train Step 18025, Epoch 16.7, Batch Size = 256, Examples/Sec = 3852.51, Train LB = -384.365, Loss = 387.805
[2018-06-04 19:06] Train Step 18050, Epoch 16.7, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -380.868, Loss = 386.827
[2018-06-04 19:06] Train Step 18075, Epoch 16.7, Batch Size = 256, Examples/Sec = 3868.71, Train LB = -384.241, Loss = 386.433
[2018-06-04 19:06] Train Step 18100, Epoch 16.8, Batch Size = 256, Examples/Sec = 3869.69, Train LB = -389.329, Loss = 386.314
[2018-06-04 19:06] Train Step 18125, Epoch 16.8, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -387.709, Loss = 386.075
[2018-06-04 19:06] Train Step 18150, Epoch 16.8, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -382.728, Loss = 386.703
[2018-06-04 19:06] Train Step 18175, Epoch 16.8, Batch Size = 256, Examples/Sec = 3846.80, Train LB = -410.326, Loss = 386.623
[2018-06-04 19:07] Train Step 18200, Epoch 16.9, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -377.030, Loss = 387.798
Performance on test set:
  Test Lower Bound = -397.593, Test Loss = 397.593
[2018-06-04 19:07] Train Step 18225, Epoch 16.9, Batch Size = 256, Examples/Sec = 3803.93, Train LB = -385.575, Loss = 387.082
[2018-06-04 19:07] Train Step 18250, Epoch 16.9, Batch Size = 256, Examples/Sec = 3838.55, Train LB = -375.963, Loss = 386.633
[2018-06-04 19:07] Train Step 18275, Epoch 16.9, Batch Size = 256, Examples/Sec = 3865.97, Train LB = -386.411, Loss = 386.107
[2018-06-04 19:07] Train Step 18300, Epoch 16.9, Batch Size = 256, Examples/Sec = 3849.74, Train LB = -373.666, Loss = 386.034
[2018-06-04 19:07] Train Step 18325, Epoch 17.0, Batch Size = 256, Examples/Sec = 3875.61, Train LB = -386.965, Loss = 385.839
[2018-06-04 19:07] Train Step 18350, Epoch 17.0, Batch Size = 256, Examples/Sec = 3848.81, Train LB = -380.814, Loss = 386.342
[2018-06-04 19:07] Train Step 18375, Epoch 17.0, Batch Size = 256, Examples/Sec = 3870.75, Train LB = -374.593, Loss = 386.410
[2018-06-04 19:07] Train Step 18400, Epoch 17.0, Batch Size = 256, Examples/Sec = 3874.56, Train LB = -401.612, Loss = 387.708
Performance on test set:
  Test Lower Bound = -398.503, Test Loss = 398.503
[2018-06-04 19:07] Train Step 18425, Epoch 17.1, Batch Size = 256, Examples/Sec = 3859.13, Train LB = -385.488, Loss = 387.654
[2018-06-04 19:07] Train Step 18450, Epoch 17.1, Batch Size = 256, Examples/Sec = 3784.75, Train LB = -378.938, Loss = 386.768
[2018-06-04 19:07] Train Step 18475, Epoch 17.1, Batch Size = 256, Examples/Sec = 3855.49, Train LB = -385.109, Loss = 386.451
[2018-06-04 19:07] Train Step 18500, Epoch 17.1, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -386.804, Loss = 385.566
[2018-06-04 19:07] Train Step 18525, Epoch 17.2, Batch Size = 256, Examples/Sec = 3801.50, Train LB = -378.958, Loss = 385.769
[2018-06-04 19:07] Train Step 18550, Epoch 17.2, Batch Size = 256, Examples/Sec = 3870.62, Train LB = -380.983, Loss = 385.414
[2018-06-04 19:07] Train Step 18575, Epoch 17.2, Batch Size = 256, Examples/Sec = 3879.84, Train LB = -373.634, Loss = 385.401
[2018-06-04 19:07] Train Step 18600, Epoch 17.2, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -401.913, Loss = 386.328
Performance on test set:
  Test Lower Bound = -398.987, Test Loss = 398.987
[2018-06-04 19:07] Train Step 18625, Epoch 17.2, Batch Size = 256, Examples/Sec = 3867.78, Train LB = -395.229, Loss = 386.583
[2018-06-04 19:07] Train Step 18650, Epoch 17.3, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -385.147, Loss = 386.421
[2018-06-04 19:07] Train Step 18675, Epoch 17.3, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -386.487, Loss = 386.611
[2018-06-04 19:07] Train Step 18700, Epoch 17.3, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -375.899, Loss = 385.903
[2018-06-04 19:07] Train Step 18725, Epoch 17.3, Batch Size = 256, Examples/Sec = 3772.15, Train LB = -381.709, Loss = 385.864
[2018-06-04 19:07] Train Step 18750, Epoch 17.4, Batch Size = 256, Examples/Sec = 3886.79, Train LB = -392.002, Loss = 385.246
[2018-06-04 19:07] Train Step 18775, Epoch 17.4, Batch Size = 256, Examples/Sec = 3871.17, Train LB = -382.978, Loss = 385.380
[2018-06-04 19:07] Train Step 18800, Epoch 17.4, Batch Size = 256, Examples/Sec = 3753.23, Train LB = -385.831, Loss = 386.908
Performance on test set:
  Test Lower Bound = -399.382, Test Loss = 399.382
[2018-06-04 19:07] Train Step 18825, Epoch 17.4, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -396.819, Loss = 385.983
[2018-06-04 19:07] Train Step 18850, Epoch 17.5, Batch Size = 256, Examples/Sec = 3830.28, Train LB = -380.003, Loss = 385.718
[2018-06-04 19:07] Train Step 18875, Epoch 17.5, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -377.501, Loss = 385.437
[2018-06-04 19:08] Train Step 18900, Epoch 17.5, Batch Size = 256, Examples/Sec = 3845.75, Train LB = -376.035, Loss = 385.567
[2018-06-04 19:08] Train Step 18925, Epoch 17.5, Batch Size = 256, Examples/Sec = 3852.80, Train LB = -396.871, Loss = 385.620
[2018-06-04 19:08] Train Step 18950, Epoch 17.5, Batch Size = 256, Examples/Sec = 3845.05, Train LB = -385.476, Loss = 385.307
[2018-06-04 19:08] Train Step 18975, Epoch 17.6, Batch Size = 256, Examples/Sec = 3856.71, Train LB = -386.169, Loss = 385.691
[2018-06-04 19:08] Train Step 19000, Epoch 17.6, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -393.229, Loss = 386.907
Performance on test set:
  Test Lower Bound = -398.896, Test Loss = 398.896
[2018-06-04 19:08] Train Step 19025, Epoch 17.6, Batch Size = 256, Examples/Sec = 3863.63, Train LB = -374.523, Loss = 386.501
[2018-06-04 19:08] Train Step 19050, Epoch 17.6, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -378.004, Loss = 386.136
[2018-06-04 19:08] Train Step 19075, Epoch 17.7, Batch Size = 256, Examples/Sec = 3872.58, Train LB = -379.426, Loss = 385.585
[2018-06-04 19:08] Train Step 19100, Epoch 17.7, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -388.655, Loss = 385.177
[2018-06-04 19:08] Train Step 19125, Epoch 17.7, Batch Size = 256, Examples/Sec = 3878.02, Train LB = -388.832, Loss = 385.038
[2018-06-04 19:08] Train Step 19150, Epoch 17.7, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -393.424, Loss = 385.002
[2018-06-04 19:08] Train Step 19175, Epoch 17.8, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -388.243, Loss = 385.391
[2018-06-04 19:08] Train Step 19200, Epoch 17.8, Batch Size = 256, Examples/Sec = 3868.89, Train LB = -378.116, Loss = 386.958
Performance on test set:
  Test Lower Bound = -400.129, Test Loss = 400.129
[2018-06-04 19:08] Train Step 19225, Epoch 17.8, Batch Size = 256, Examples/Sec = 3824.15, Train LB = -385.165, Loss = 385.582
[2018-06-04 19:08] Train Step 19250, Epoch 17.8, Batch Size = 256, Examples/Sec = 3846.15, Train LB = -385.081, Loss = 384.961
[2018-06-04 19:08] Train Step 19275, Epoch 17.8, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -392.404, Loss = 385.075
[2018-06-04 19:08] Train Step 19300, Epoch 17.9, Batch Size = 256, Examples/Sec = 3848.76, Train LB = -398.299, Loss = 384.356
[2018-06-04 19:08] Train Step 19325, Epoch 17.9, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -392.423, Loss = 384.533
[2018-06-04 19:08] Train Step 19350, Epoch 17.9, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -395.740, Loss = 385.065
[2018-06-04 19:08] Train Step 19375, Epoch 17.9, Batch Size = 256, Examples/Sec = 3827.23, Train LB = -377.925, Loss = 385.423
[2018-06-04 19:08] Train Step 19400, Epoch 18.0, Batch Size = 256, Examples/Sec = 3848.41, Train LB = -396.446, Loss = 386.477
Performance on test set:
  Test Lower Bound = -399.702, Test Loss = 399.702
[2018-06-04 19:08] Train Step 19425, Epoch 18.0, Batch Size = 256, Examples/Sec = 3831.18, Train LB = -396.645, Loss = 385.996
[2018-06-04 19:08] Train Step 19450, Epoch 18.0, Batch Size = 256, Examples/Sec = 3754.88, Train LB = -378.521, Loss = 386.511
[2018-06-04 19:08] Train Step 19475, Epoch 18.0, Batch Size = 256, Examples/Sec = 3791.35, Train LB = -371.002, Loss = 385.903
[2018-06-04 19:08] Train Step 19500, Epoch 18.1, Batch Size = 256, Examples/Sec = 3837.51, Train LB = -370.985, Loss = 384.881
[2018-06-04 19:08] Train Step 19525, Epoch 18.1, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -397.422, Loss = 384.970
[2018-06-04 19:08] Train Step 19550, Epoch 18.1, Batch Size = 256, Examples/Sec = 3872.27, Train LB = -394.002, Loss = 384.927
[2018-06-04 19:08] Train Step 19575, Epoch 18.1, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -381.225, Loss = 385.360
[2018-06-04 19:08] Train Step 19600, Epoch 18.1, Batch Size = 256, Examples/Sec = 3862.81, Train LB = -390.797, Loss = 386.570
Performance on test set:
  Test Lower Bound = -399.379, Test Loss = 399.379
[2018-06-04 19:09] Train Step 19625, Epoch 18.2, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -373.792, Loss = 385.531
[2018-06-04 19:09] Train Step 19650, Epoch 18.2, Batch Size = 256, Examples/Sec = 3878.13, Train LB = -385.938, Loss = 384.965
[2018-06-04 19:09] Train Step 19675, Epoch 18.2, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -377.472, Loss = 384.701
[2018-06-04 19:09] Train Step 19700, Epoch 18.2, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -371.348, Loss = 383.986
[2018-06-04 19:09] Train Step 19725, Epoch 18.3, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -388.281, Loss = 383.810
[2018-06-04 19:09] Train Step 19750, Epoch 18.3, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -370.980, Loss = 384.111
[2018-06-04 19:09] Train Step 19775, Epoch 18.3, Batch Size = 256, Examples/Sec = 3726.14, Train LB = -386.571, Loss = 384.630
[2018-06-04 19:09] Train Step 19800, Epoch 18.3, Batch Size = 256, Examples/Sec = 3866.90, Train LB = -393.559, Loss = 385.812
Performance on test set:
  Test Lower Bound = -399.366, Test Loss = 399.366
[2018-06-04 19:09] Train Step 19825, Epoch 18.4, Batch Size = 256, Examples/Sec = 3860.02, Train LB = -376.872, Loss = 385.589
[2018-06-04 19:09] Train Step 19850, Epoch 18.4, Batch Size = 256, Examples/Sec = 3859.15, Train LB = -410.063, Loss = 385.376
[2018-06-04 19:09] Train Step 19875, Epoch 18.4, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -387.745, Loss = 384.577
[2018-06-04 19:09] Train Step 19900, Epoch 18.4, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -381.465, Loss = 384.323
[2018-06-04 19:09] Train Step 19925, Epoch 18.4, Batch Size = 256, Examples/Sec = 3842.00, Train LB = -379.811, Loss = 384.267
[2018-06-04 19:09] Train Step 19950, Epoch 18.5, Batch Size = 256, Examples/Sec = 3845.75, Train LB = -387.954, Loss = 384.885
[2018-06-04 19:09] Train Step 19975, Epoch 18.5, Batch Size = 256, Examples/Sec = 3868.07, Train LB = -397.251, Loss = 384.998
[2018-06-04 19:09] Train Step 20000, Epoch 18.5, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -384.967, Loss = 386.052
Performance on test set:
  Test Lower Bound = -398.385, Test Loss = 398.385
[2018-06-04 19:09] Train Step 20025, Epoch 18.5, Batch Size = 256, Examples/Sec = 3871.04, Train LB = -381.110, Loss = 386.120
[2018-06-04 19:09] Train Step 20050, Epoch 18.6, Batch Size = 256, Examples/Sec = 3862.76, Train LB = -375.597, Loss = 385.453
[2018-06-04 19:09] Train Step 20075, Epoch 18.6, Batch Size = 256, Examples/Sec = 3832.90, Train LB = -386.563, Loss = 384.968
[2018-06-04 19:09] Train Step 20100, Epoch 18.6, Batch Size = 256, Examples/Sec = 3852.80, Train LB = -362.622, Loss = 383.695
[2018-06-04 19:09] Train Step 20125, Epoch 18.6, Batch Size = 256, Examples/Sec = 3887.75, Train LB = -401.805, Loss = 383.514
[2018-06-04 19:09] Train Step 20150, Epoch 18.7, Batch Size = 256, Examples/Sec = 3854.02, Train LB = -390.230, Loss = 384.440
[2018-06-04 19:09] Train Step 20175, Epoch 18.7, Batch Size = 256, Examples/Sec = 3868.66, Train LB = -380.468, Loss = 384.583
[2018-06-04 19:09] Train Step 20200, Epoch 18.7, Batch Size = 256, Examples/Sec = 3859.62, Train LB = -392.627, Loss = 385.898
Performance on test set:
  Test Lower Bound = -399.360, Test Loss = 399.360
[2018-06-04 19:09] Train Step 20225, Epoch 18.7, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -378.114, Loss = 384.958
[2018-06-04 19:09] Train Step 20250, Epoch 18.8, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -367.450, Loss = 384.135
[2018-06-04 19:09] Train Step 20275, Epoch 18.8, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -392.189, Loss = 384.228
[2018-06-04 19:09] Train Step 20300, Epoch 18.8, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -387.057, Loss = 384.076
[2018-06-04 19:10] Train Step 20325, Epoch 18.8, Batch Size = 256, Examples/Sec = 3873.26, Train LB = -381.880, Loss = 383.556
[2018-06-04 19:10] Train Step 20350, Epoch 18.8, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -390.235, Loss = 383.320
[2018-06-04 19:10] Train Step 20375, Epoch 18.9, Batch Size = 256, Examples/Sec = 3852.69, Train LB = -369.679, Loss = 384.129
[2018-06-04 19:10] Train Step 20400, Epoch 18.9, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -396.039, Loss = 385.131
Performance on test set:
  Test Lower Bound = -399.872, Test Loss = 399.872
[2018-06-04 19:10] Train Step 20425, Epoch 18.9, Batch Size = 256, Examples/Sec = 3865.26, Train LB = -382.817, Loss = 384.050
[2018-06-04 19:10] Train Step 20450, Epoch 18.9, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -380.790, Loss = 384.765
[2018-06-04 19:10] Train Step 20475, Epoch 19.0, Batch Size = 256, Examples/Sec = 3867.08, Train LB = -388.693, Loss = 383.642
[2018-06-04 19:10] Train Step 20500, Epoch 19.0, Batch Size = 256, Examples/Sec = 3720.12, Train LB = -386.809, Loss = 383.174
[2018-06-04 19:10] Train Step 20525, Epoch 19.0, Batch Size = 256, Examples/Sec = 3881.68, Train LB = -395.962, Loss = 383.551
[2018-06-04 19:10] Train Step 20550, Epoch 19.0, Batch Size = 256, Examples/Sec = 3865.61, Train LB = -387.279, Loss = 384.163
[2018-06-04 19:10] Train Step 20575, Epoch 19.1, Batch Size = 256, Examples/Sec = 3741.59, Train LB = -379.588, Loss = 384.220
[2018-06-04 19:10] Train Step 20600, Epoch 19.1, Batch Size = 256, Examples/Sec = 3858.84, Train LB = -384.949, Loss = 385.641
Performance on test set:
  Test Lower Bound = -397.927, Test Loss = 397.927
[2018-06-04 19:10] Train Step 20625, Epoch 19.1, Batch Size = 256, Examples/Sec = 3850.14, Train LB = -379.969, Loss = 384.790
[2018-06-04 19:10] Train Step 20650, Epoch 19.1, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -388.218, Loss = 384.533
[2018-06-04 19:10] Train Step 20675, Epoch 19.1, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -378.933, Loss = 384.010
[2018-06-04 19:10] Train Step 20700, Epoch 19.2, Batch Size = 256, Examples/Sec = 3840.32, Train LB = -379.560, Loss = 383.111
[2018-06-04 19:10] Train Step 20725, Epoch 19.2, Batch Size = 256, Examples/Sec = 3837.04, Train LB = -383.708, Loss = 382.892
[2018-06-04 19:10] Train Step 20750, Epoch 19.2, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -379.276, Loss = 382.472
[2018-06-04 19:10] Train Step 20775, Epoch 19.2, Batch Size = 256, Examples/Sec = 3851.48, Train LB = -378.790, Loss = 383.690
[2018-06-04 19:10] Train Step 20800, Epoch 19.3, Batch Size = 256, Examples/Sec = 3803.98, Train LB = -388.776, Loss = 384.263
Performance on test set:
  Test Lower Bound = -398.333, Test Loss = 398.333
[2018-06-04 19:10] Train Step 20825, Epoch 19.3, Batch Size = 256, Examples/Sec = 3875.96, Train LB = -386.657, Loss = 384.073
[2018-06-04 19:10] Train Step 20850, Epoch 19.3, Batch Size = 256, Examples/Sec = 3856.40, Train LB = -399.133, Loss = 384.489
[2018-06-04 19:10] Train Step 20875, Epoch 19.3, Batch Size = 256, Examples/Sec = 3866.02, Train LB = -388.283, Loss = 383.594
[2018-06-04 19:10] Train Step 20900, Epoch 19.4, Batch Size = 256, Examples/Sec = 3864.15, Train LB = -368.654, Loss = 382.905
[2018-06-04 19:10] Train Step 20925, Epoch 19.4, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -397.632, Loss = 382.843
[2018-06-04 19:10] Train Step 20950, Epoch 19.4, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -365.392, Loss = 382.969
[2018-06-04 19:10] Train Step 20975, Epoch 19.4, Batch Size = 256, Examples/Sec = 3881.13, Train LB = -399.631, Loss = 383.166
[2018-06-04 19:10] Train Step 21000, Epoch 19.4, Batch Size = 256, Examples/Sec = 3865.95, Train LB = -390.536, Loss = 385.030
Performance on test set:
  Test Lower Bound = -398.563, Test Loss = 398.563
[2018-06-04 19:11] Train Step 21025, Epoch 19.5, Batch Size = 256, Examples/Sec = 3854.91, Train LB = -385.451, Loss = 385.199
[2018-06-04 19:11] Train Step 21050, Epoch 19.5, Batch Size = 256, Examples/Sec = 3825.53, Train LB = -408.718, Loss = 384.745
[2018-06-04 19:11] Train Step 21075, Epoch 19.5, Batch Size = 256, Examples/Sec = 3865.13, Train LB = -368.285, Loss = 383.885
[2018-06-04 19:11] Train Step 21100, Epoch 19.5, Batch Size = 256, Examples/Sec = 3877.32, Train LB = -376.289, Loss = 382.822
[2018-06-04 19:11] Train Step 21125, Epoch 19.6, Batch Size = 256, Examples/Sec = 3850.10, Train LB = -386.465, Loss = 382.389
[2018-06-04 19:11] Train Step 21150, Epoch 19.6, Batch Size = 256, Examples/Sec = 3871.99, Train LB = -387.901, Loss = 382.497
[2018-06-04 19:11] Train Step 21175, Epoch 19.6, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -386.260, Loss = 383.244
[2018-06-04 19:11] Train Step 21200, Epoch 19.6, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -397.024, Loss = 384.524
Performance on test set:
  Test Lower Bound = -398.402, Test Loss = 398.402
[2018-06-04 19:11] Train Step 21225, Epoch 19.7, Batch Size = 256, Examples/Sec = 3848.23, Train LB = -377.659, Loss = 383.738
[2018-06-04 19:11] Train Step 21250, Epoch 19.7, Batch Size = 256, Examples/Sec = 3871.11, Train LB = -379.494, Loss = 383.701
[2018-06-04 19:11] Train Step 21275, Epoch 19.7, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -367.169, Loss = 383.069
[2018-06-04 19:11] Train Step 21300, Epoch 19.7, Batch Size = 256, Examples/Sec = 3764.44, Train LB = -382.949, Loss = 382.270
[2018-06-04 19:11] Train Step 21325, Epoch 19.7, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -377.415, Loss = 382.118
[2018-06-04 19:11] Train Step 21350, Epoch 19.8, Batch Size = 256, Examples/Sec = 3844.54, Train LB = -379.778, Loss = 382.230
[2018-06-04 19:11] Train Step 21375, Epoch 19.8, Batch Size = 256, Examples/Sec = 3762.88, Train LB = -395.852, Loss = 382.841
[2018-06-04 19:11] Train Step 21400, Epoch 19.8, Batch Size = 256, Examples/Sec = 3847.83, Train LB = -374.378, Loss = 384.387
Performance on test set:
  Test Lower Bound = -399.833, Test Loss = 399.833
[2018-06-04 19:11] Train Step 21425, Epoch 19.8, Batch Size = 256, Examples/Sec = 3848.70, Train LB = -370.255, Loss = 382.904
[2018-06-04 19:11] Train Step 21450, Epoch 19.9, Batch Size = 256, Examples/Sec = 3852.86, Train LB = -391.015, Loss = 382.828
[2018-06-04 19:11] Train Step 21475, Epoch 19.9, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -372.113, Loss = 382.172
[2018-06-04 19:11] Train Step 21500, Epoch 19.9, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -385.902, Loss = 382.183
[2018-06-04 19:11] Train Step 21525, Epoch 19.9, Batch Size = 256, Examples/Sec = 3854.66, Train LB = -373.140, Loss = 382.348
[2018-06-04 19:11] Train Step 21550, Epoch 20.0, Batch Size = 256, Examples/Sec = 3859.20, Train LB = -390.649, Loss = 381.937
[2018-06-04 19:11] Train Step 21575, Epoch 20.0, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -395.579, Loss = 382.915
[2018-06-04 19:11] Train Step 21600, Epoch 20.0, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -369.533, Loss = 384.700
Performance on test set:
  Test Lower Bound = -400.412, Test Loss = 400.412
[2018-06-04 19:11] Train Step 21625, Epoch 20.0, Batch Size = 256, Examples/Sec = 3872.91, Train LB = -375.465, Loss = 384.546
[2018-06-04 19:11] Train Step 21650, Epoch 20.0, Batch Size = 256, Examples/Sec = 3865.73, Train LB = -379.316, Loss = 383.991
[2018-06-04 19:11] Train Step 21675, Epoch 20.1, Batch Size = 256, Examples/Sec = 3871.35, Train LB = -377.477, Loss = 383.689
[2018-06-04 19:11] Train Step 21700, Epoch 20.1, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -396.060, Loss = 382.867
[2018-06-04 19:11] Train Step 21725, Epoch 20.1, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -386.260, Loss = 382.629
[2018-06-04 19:11] Train Step 21750, Epoch 20.1, Batch Size = 256, Examples/Sec = 3833.37, Train LB = -380.600, Loss = 382.646
[2018-06-04 19:12] Train Step 21775, Epoch 20.2, Batch Size = 256, Examples/Sec = 3877.15, Train LB = -389.388, Loss = 383.017
[2018-06-04 19:12] Train Step 21800, Epoch 20.2, Batch Size = 256, Examples/Sec = 3845.52, Train LB = -390.355, Loss = 383.911
Performance on test set:
  Test Lower Bound = -399.954, Test Loss = 399.954
[2018-06-04 19:12] Train Step 21825, Epoch 20.2, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -394.225, Loss = 383.263
[2018-06-04 19:12] Train Step 21850, Epoch 20.2, Batch Size = 256, Examples/Sec = 3831.25, Train LB = -379.913, Loss = 383.038
[2018-06-04 19:12] Train Step 21875, Epoch 20.3, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -373.482, Loss = 382.028
[2018-06-04 19:12] Train Step 21900, Epoch 20.3, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -386.888, Loss = 381.296
[2018-06-04 19:12] Train Step 21925, Epoch 20.3, Batch Size = 256, Examples/Sec = 3833.19, Train LB = -380.041, Loss = 380.717
[2018-06-04 19:12] Train Step 21950, Epoch 20.3, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -382.619, Loss = 381.133
[2018-06-04 19:12] Train Step 21975, Epoch 20.3, Batch Size = 256, Examples/Sec = 3842.63, Train LB = -373.796, Loss = 382.196
[2018-06-04 19:12] Train Step 22000, Epoch 20.4, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -381.902, Loss = 384.063
Performance on test set:
  Test Lower Bound = -401.970, Test Loss = 401.970
[2018-06-04 19:12] Train Step 22025, Epoch 20.4, Batch Size = 256, Examples/Sec = 3739.74, Train LB = -376.985, Loss = 383.248
[2018-06-04 19:12] Train Step 22050, Epoch 20.4, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -385.682, Loss = 383.006
[2018-06-04 19:12] Train Step 22075, Epoch 20.4, Batch Size = 256, Examples/Sec = 3845.52, Train LB = -387.820, Loss = 382.605
[2018-06-04 19:12] Train Step 22100, Epoch 20.5, Batch Size = 256, Examples/Sec = 3736.69, Train LB = -386.428, Loss = 382.331
[2018-06-04 19:12] Train Step 22125, Epoch 20.5, Batch Size = 256, Examples/Sec = 3886.62, Train LB = -394.254, Loss = 381.356
[2018-06-04 19:12] Train Step 22150, Epoch 20.5, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -391.501, Loss = 380.877
[2018-06-04 19:12] Train Step 22175, Epoch 20.5, Batch Size = 256, Examples/Sec = 3782.34, Train LB = -383.651, Loss = 381.655
[2018-06-04 19:12] Train Step 22200, Epoch 20.6, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -380.359, Loss = 383.826
Performance on test set:
  Test Lower Bound = -399.387, Test Loss = 399.387
[2018-06-04 19:12] Train Step 22225, Epoch 20.6, Batch Size = 256, Examples/Sec = 3849.52, Train LB = -374.084, Loss = 383.776
[2018-06-04 19:12] Train Step 22250, Epoch 20.6, Batch Size = 256, Examples/Sec = 3851.93, Train LB = -376.822, Loss = 383.168
[2018-06-04 19:12] Train Step 22275, Epoch 20.6, Batch Size = 256, Examples/Sec = 3886.09, Train LB = -376.285, Loss = 382.026
[2018-06-04 19:12] Train Step 22300, Epoch 20.6, Batch Size = 256, Examples/Sec = 3861.41, Train LB = -369.669, Loss = 381.796
[2018-06-04 19:12] Train Step 22325, Epoch 20.7, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -373.042, Loss = 381.075
[2018-06-04 19:12] Train Step 22350, Epoch 20.7, Batch Size = 256, Examples/Sec = 3862.69, Train LB = -387.973, Loss = 381.294
[2018-06-04 19:12] Train Step 22375, Epoch 20.7, Batch Size = 256, Examples/Sec = 3886.14, Train LB = -378.966, Loss = 381.549
[2018-06-04 19:12] Train Step 22400, Epoch 20.7, Batch Size = 256, Examples/Sec = 3872.93, Train LB = -389.458, Loss = 382.858
Performance on test set:
  Test Lower Bound = -398.982, Test Loss = 398.982
[2018-06-04 19:12] Train Step 22425, Epoch 20.8, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -380.577, Loss = 382.679
[2018-06-04 19:13] Train Step 22450, Epoch 20.8, Batch Size = 256, Examples/Sec = 3871.99, Train LB = -376.638, Loss = 381.938
[2018-06-04 19:13] Train Step 22475, Epoch 20.8, Batch Size = 256, Examples/Sec = 3814.64, Train LB = -385.582, Loss = 381.124
[2018-06-04 19:13] Train Step 22500, Epoch 20.8, Batch Size = 256, Examples/Sec = 3855.38, Train LB = -388.480, Loss = 381.363
[2018-06-04 19:13] Train Step 22525, Epoch 20.9, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -383.090, Loss = 381.814
[2018-06-04 19:13] Train Step 22550, Epoch 20.9, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -380.763, Loss = 381.147
[2018-06-04 19:13] Train Step 22575, Epoch 20.9, Batch Size = 256, Examples/Sec = 3872.51, Train LB = -387.299, Loss = 381.858
[2018-06-04 19:13] Train Step 22600, Epoch 20.9, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -388.457, Loss = 383.528
Performance on test set:
  Test Lower Bound = -399.510, Test Loss = 399.510
[2018-06-04 19:13] Train Step 22625, Epoch 20.9, Batch Size = 256, Examples/Sec = 3857.93, Train LB = -391.615, Loss = 382.634
[2018-06-04 19:13] Train Step 22650, Epoch 21.0, Batch Size = 256, Examples/Sec = 3868.99, Train LB = -370.680, Loss = 382.134
[2018-06-04 19:13] Train Step 22675, Epoch 21.0, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -374.497, Loss = 381.828
[2018-06-04 19:13] Train Step 22700, Epoch 21.0, Batch Size = 256, Examples/Sec = 3860.48, Train LB = -382.203, Loss = 381.724
[2018-06-04 19:13] Train Step 22725, Epoch 21.0, Batch Size = 256, Examples/Sec = 3848.34, Train LB = -393.149, Loss = 381.120
[2018-06-04 19:13] Train Step 22750, Epoch 21.1, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -374.279, Loss = 381.334
[2018-06-04 19:13] Train Step 22775, Epoch 21.1, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -392.498, Loss = 381.905
[2018-06-04 19:13] Train Step 22800, Epoch 21.1, Batch Size = 256, Examples/Sec = 3871.29, Train LB = -385.118, Loss = 383.382
Performance on test set:
  Test Lower Bound = -400.611, Test Loss = 400.611
[2018-06-04 19:13] Train Step 22825, Epoch 21.1, Batch Size = 256, Examples/Sec = 3797.09, Train LB = -376.808, Loss = 382.410
[2018-06-04 19:13] Train Step 22850, Epoch 21.2, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -385.409, Loss = 382.097
[2018-06-04 19:13] Train Step 22875, Epoch 21.2, Batch Size = 256, Examples/Sec = 3840.68, Train LB = -389.491, Loss = 381.470
[2018-06-04 19:13] Train Step 22900, Epoch 21.2, Batch Size = 256, Examples/Sec = 3723.85, Train LB = -358.523, Loss = 380.143
[2018-06-04 19:13] Train Step 22925, Epoch 21.2, Batch Size = 256, Examples/Sec = 3854.33, Train LB = -369.917, Loss = 380.063
[2018-06-04 19:13] Train Step 22950, Epoch 21.2, Batch Size = 256, Examples/Sec = 3839.92, Train LB = -383.074, Loss = 380.617
[2018-06-04 19:13] Train Step 22975, Epoch 21.3, Batch Size = 256, Examples/Sec = 3749.16, Train LB = -382.710, Loss = 381.428
[2018-06-04 19:13] Train Step 23000, Epoch 21.3, Batch Size = 256, Examples/Sec = 3788.38, Train LB = -379.353, Loss = 382.623
Performance on test set:
  Test Lower Bound = -399.533, Test Loss = 399.533
[2018-06-04 19:13] Train Step 23025, Epoch 21.3, Batch Size = 256, Examples/Sec = 3836.77, Train LB = -386.793, Loss = 381.833
[2018-06-04 19:13] Train Step 23050, Epoch 21.3, Batch Size = 256, Examples/Sec = 3864.26, Train LB = -372.855, Loss = 381.674
[2018-06-04 19:13] Train Step 23075, Epoch 21.4, Batch Size = 256, Examples/Sec = 3847.82, Train LB = -377.856, Loss = 381.096
[2018-06-04 19:13] Train Step 23100, Epoch 21.4, Batch Size = 256, Examples/Sec = 3793.20, Train LB = -393.776, Loss = 380.748
[2018-06-04 19:13] Train Step 23125, Epoch 21.4, Batch Size = 256, Examples/Sec = 3863.63, Train LB = -385.046, Loss = 380.750
[2018-06-04 19:13] Train Step 23150, Epoch 21.4, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -381.258, Loss = 381.465
[2018-06-04 19:13] Train Step 23175, Epoch 21.5, Batch Size = 256, Examples/Sec = 3846.10, Train LB = -387.232, Loss = 381.779
[2018-06-04 19:14] Train Step 23200, Epoch 21.5, Batch Size = 256, Examples/Sec = 3873.16, Train LB = -393.750, Loss = 383.166
Performance on test set:
  Test Lower Bound = -398.986, Test Loss = 398.986
[2018-06-04 19:14] Train Step 23225, Epoch 21.5, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -396.189, Loss = 381.962
[2018-06-04 19:14] Train Step 23250, Epoch 21.5, Batch Size = 256, Examples/Sec = 3855.25, Train LB = -378.488, Loss = 381.775
[2018-06-04 19:14] Train Step 23275, Epoch 21.6, Batch Size = 256, Examples/Sec = 3852.22, Train LB = -393.162, Loss = 380.955
[2018-06-04 19:14] Train Step 23300, Epoch 21.6, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -376.233, Loss = 380.264
[2018-06-04 19:14] Train Step 23325, Epoch 21.6, Batch Size = 256, Examples/Sec = 3870.00, Train LB = -371.600, Loss = 380.356
[2018-06-04 19:14] Train Step 23350, Epoch 21.6, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -379.439, Loss = 380.199
[2018-06-04 19:14] Train Step 23375, Epoch 21.6, Batch Size = 256, Examples/Sec = 3848.16, Train LB = -392.464, Loss = 380.954
[2018-06-04 19:14] Train Step 23400, Epoch 21.7, Batch Size = 256, Examples/Sec = 3850.21, Train LB = -396.654, Loss = 382.501
Performance on test set:
  Test Lower Bound = -399.940, Test Loss = 399.940
[2018-06-04 19:14] Train Step 23425, Epoch 21.7, Batch Size = 256, Examples/Sec = 3787.70, Train LB = -375.341, Loss = 382.272
[2018-06-04 19:14] Train Step 23450, Epoch 21.7, Batch Size = 256, Examples/Sec = 3883.02, Train LB = -382.696, Loss = 381.481
[2018-06-04 19:14] Train Step 23475, Epoch 21.7, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -393.669, Loss = 381.256
[2018-06-04 19:14] Train Step 23500, Epoch 21.8, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -377.819, Loss = 380.328
[2018-06-04 19:14] Train Step 23525, Epoch 21.8, Batch Size = 256, Examples/Sec = 3872.75, Train LB = -371.886, Loss = 380.288
[2018-06-04 19:14] Train Step 23550, Epoch 21.8, Batch Size = 256, Examples/Sec = 3876.49, Train LB = -382.246, Loss = 380.050
[2018-06-04 19:14] Train Step 23575, Epoch 21.8, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -364.546, Loss = 380.991
[2018-06-04 19:14] Train Step 23600, Epoch 21.9, Batch Size = 256, Examples/Sec = 3853.97, Train LB = -378.779, Loss = 382.352
Performance on test set:
  Test Lower Bound = -398.554, Test Loss = 398.554
[2018-06-04 19:14] Train Step 23625, Epoch 21.9, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -374.403, Loss = 381.923
[2018-06-04 19:14] Train Step 23650, Epoch 21.9, Batch Size = 256, Examples/Sec = 3833.82, Train LB = -386.132, Loss = 381.489
[2018-06-04 19:14] Train Step 23675, Epoch 21.9, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -370.237, Loss = 380.768
[2018-06-04 19:14] Train Step 23700, Epoch 21.9, Batch Size = 256, Examples/Sec = 3876.38, Train LB = -384.187, Loss = 379.752
[2018-06-04 19:14] Train Step 23725, Epoch 22.0, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -387.098, Loss = 379.658
[2018-06-04 19:14] Train Step 23750, Epoch 22.0, Batch Size = 256, Examples/Sec = 3842.81, Train LB = -402.005, Loss = 379.560
[2018-06-04 19:14] Train Step 23775, Epoch 22.0, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -390.320, Loss = 380.385
[2018-06-04 19:14] Train Step 23800, Epoch 22.0, Batch Size = 256, Examples/Sec = 3880.91, Train LB = -385.226, Loss = 381.998
Performance on test set:
  Test Lower Bound = -401.031, Test Loss = 401.031
[2018-06-04 19:14] Train Step 23825, Epoch 22.1, Batch Size = 256, Examples/Sec = 3876.44, Train LB = -387.238, Loss = 381.469
[2018-06-04 19:14] Train Step 23850, Epoch 22.1, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -380.647, Loss = 380.954
[2018-06-04 19:14] Train Step 23875, Epoch 22.1, Batch Size = 256, Examples/Sec = 3755.98, Train LB = -374.878, Loss = 380.051
[2018-06-04 19:15] Train Step 23900, Epoch 22.1, Batch Size = 256, Examples/Sec = 3846.79, Train LB = -380.994, Loss = 379.034
[2018-06-04 19:15] Train Step 23925, Epoch 22.2, Batch Size = 256, Examples/Sec = 3857.23, Train LB = -379.829, Loss = 379.171
[2018-06-04 19:15] Train Step 23950, Epoch 22.2, Batch Size = 256, Examples/Sec = 3767.08, Train LB = -368.952, Loss = 379.384
[2018-06-04 19:15] Train Step 23975, Epoch 22.2, Batch Size = 256, Examples/Sec = 3869.17, Train LB = -395.715, Loss = 380.376
[2018-06-04 19:15] Train Step 24000, Epoch 22.2, Batch Size = 256, Examples/Sec = 3843.96, Train LB = -400.344, Loss = 381.637
Performance on test set:
  Test Lower Bound = -399.989, Test Loss = 399.989
[2018-06-04 19:15] Train Step 24025, Epoch 22.2, Batch Size = 256, Examples/Sec = 3838.66, Train LB = -371.231, Loss = 381.519
[2018-06-04 19:15] Train Step 24050, Epoch 22.3, Batch Size = 256, Examples/Sec = 3847.13, Train LB = -383.426, Loss = 380.924
[2018-06-04 19:15] Train Step 24075, Epoch 22.3, Batch Size = 256, Examples/Sec = 3854.15, Train LB = -380.491, Loss = 380.585
[2018-06-04 19:15] Train Step 24100, Epoch 22.3, Batch Size = 256, Examples/Sec = 3862.16, Train LB = -378.510, Loss = 379.840
[2018-06-04 19:15] Train Step 24125, Epoch 22.3, Batch Size = 256, Examples/Sec = 3847.08, Train LB = -380.329, Loss = 379.632
[2018-06-04 19:15] Train Step 24150, Epoch 22.4, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -387.722, Loss = 378.952
[2018-06-04 19:15] Train Step 24175, Epoch 22.4, Batch Size = 256, Examples/Sec = 3847.36, Train LB = -378.344, Loss = 380.161
[2018-06-04 19:15] Train Step 24200, Epoch 22.4, Batch Size = 256, Examples/Sec = 3741.05, Train LB = -388.221, Loss = 382.190
Performance on test set:
  Test Lower Bound = -399.836, Test Loss = 399.836
[2018-06-04 19:15] Train Step 24225, Epoch 22.4, Batch Size = 256, Examples/Sec = 3843.95, Train LB = -381.485, Loss = 381.411
[2018-06-04 19:15] Train Step 24250, Epoch 22.5, Batch Size = 256, Examples/Sec = 3849.86, Train LB = -380.227, Loss = 380.900
[2018-06-04 19:15] Train Step 24275, Epoch 22.5, Batch Size = 256, Examples/Sec = 3846.61, Train LB = -379.803, Loss = 380.366
[2018-06-04 19:15] Train Step 24300, Epoch 22.5, Batch Size = 256, Examples/Sec = 3886.86, Train LB = -382.125, Loss = 379.860
[2018-06-04 19:15] Train Step 24325, Epoch 22.5, Batch Size = 256, Examples/Sec = 3866.65, Train LB = -358.521, Loss = 379.713
[2018-06-04 19:15] Train Step 24350, Epoch 22.5, Batch Size = 256, Examples/Sec = 3804.48, Train LB = -372.904, Loss = 379.319
[2018-06-04 19:15] Train Step 24375, Epoch 22.6, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -383.486, Loss = 380.296
[2018-06-04 19:15] Train Step 24400, Epoch 22.6, Batch Size = 256, Examples/Sec = 3831.14, Train LB = -387.401, Loss = 381.296
Performance on test set:
  Test Lower Bound = -398.181, Test Loss = 398.181
[2018-06-04 19:15] Train Step 24425, Epoch 22.6, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -378.428, Loss = 380.937
[2018-06-04 19:15] Train Step 24450, Epoch 22.6, Batch Size = 256, Examples/Sec = 3873.85, Train LB = -383.615, Loss = 380.319
[2018-06-04 19:15] Train Step 24475, Epoch 22.7, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -377.239, Loss = 380.191
[2018-06-04 19:15] Train Step 24500, Epoch 22.7, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -370.968, Loss = 379.969
[2018-06-04 19:15] Train Step 24525, Epoch 22.7, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -379.958, Loss = 379.267
[2018-06-04 19:15] Train Step 24550, Epoch 22.7, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -372.405, Loss = 378.999
[2018-06-04 19:15] Train Step 24575, Epoch 22.8, Batch Size = 256, Examples/Sec = 3858.62, Train LB = -378.150, Loss = 380.253
[2018-06-04 19:15] Train Step 24600, Epoch 22.8, Batch Size = 256, Examples/Sec = 3891.40, Train LB = -389.430, Loss = 381.509
Performance on test set:
  Test Lower Bound = -400.289, Test Loss = 400.289
[2018-06-04 19:16] Train Step 24625, Epoch 22.8, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -381.514, Loss = 381.293
[2018-06-04 19:16] Train Step 24650, Epoch 22.8, Batch Size = 256, Examples/Sec = 3855.24, Train LB = -376.335, Loss = 380.323
[2018-06-04 19:16] Train Step 24675, Epoch 22.8, Batch Size = 256, Examples/Sec = 3797.03, Train LB = -354.871, Loss = 379.743
[2018-06-04 19:16] Train Step 24700, Epoch 22.9, Batch Size = 256, Examples/Sec = 3848.76, Train LB = -379.896, Loss = 379.947
[2018-06-04 19:16] Train Step 24725, Epoch 22.9, Batch Size = 256, Examples/Sec = 3867.78, Train LB = -392.121, Loss = 379.396
[2018-06-04 19:16] Train Step 24750, Epoch 22.9, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -384.306, Loss = 378.950
[2018-06-04 19:16] Train Step 24775, Epoch 22.9, Batch Size = 256, Examples/Sec = 3838.60, Train LB = -379.304, Loss = 379.629
[2018-06-04 19:16] Train Step 24800, Epoch 23.0, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -399.816, Loss = 381.049
Performance on test set:
  Test Lower Bound = -400.326, Test Loss = 400.326
[2018-06-04 19:16] Train Step 24825, Epoch 23.0, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -378.851, Loss = 380.518
[2018-06-04 19:16] Train Step 24850, Epoch 23.0, Batch Size = 256, Examples/Sec = 3751.47, Train LB = -376.784, Loss = 380.324
[2018-06-04 19:16] Train Step 24875, Epoch 23.0, Batch Size = 256, Examples/Sec = 3847.13, Train LB = -392.237, Loss = 379.940
[2018-06-04 19:16] Train Step 24900, Epoch 23.1, Batch Size = 256, Examples/Sec = 3861.48, Train LB = -368.744, Loss = 379.589
[2018-06-04 19:16] Train Step 24925, Epoch 23.1, Batch Size = 256, Examples/Sec = 3753.06, Train LB = -378.448, Loss = 379.114
[2018-06-04 19:16] Train Step 24950, Epoch 23.1, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -394.107, Loss = 379.195
[2018-06-04 19:16] Train Step 24975, Epoch 23.1, Batch Size = 256, Examples/Sec = 3823.12, Train LB = -383.725, Loss = 379.960
[2018-06-04 19:16] Train Step 25000, Epoch 23.1, Batch Size = 256, Examples/Sec = 3737.05, Train LB = -385.917, Loss = 381.548
Performance on test set:
  Test Lower Bound = -399.728, Test Loss = 399.728
[2018-06-04 19:16] Train Step 25025, Epoch 23.2, Batch Size = 256, Examples/Sec = 3867.25, Train LB = -376.781, Loss = 381.618
[2018-06-04 19:16] Train Step 25050, Epoch 23.2, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -371.079, Loss = 380.898
[2018-06-04 19:16] Train Step 25075, Epoch 23.2, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -364.149, Loss = 380.618
[2018-06-04 19:16] Train Step 25100, Epoch 23.2, Batch Size = 256, Examples/Sec = 3877.85, Train LB = -377.121, Loss = 379.630
[2018-06-04 19:16] Train Step 25125, Epoch 23.3, Batch Size = 256, Examples/Sec = 3856.07, Train LB = -371.472, Loss = 378.720
[2018-06-04 19:16] Train Step 25150, Epoch 23.3, Batch Size = 256, Examples/Sec = 3836.64, Train LB = -373.760, Loss = 378.299
[2018-06-04 19:16] Train Step 25175, Epoch 23.3, Batch Size = 256, Examples/Sec = 3874.27, Train LB = -380.451, Loss = 378.505
[2018-06-04 19:16] Train Step 25200, Epoch 23.3, Batch Size = 256, Examples/Sec = 3833.77, Train LB = -389.361, Loss = 380.259
Performance on test set:
  Test Lower Bound = -400.465, Test Loss = 400.465
[2018-06-04 19:16] Train Step 25225, Epoch 23.4, Batch Size = 256, Examples/Sec = 3855.13, Train LB = -372.474, Loss = 379.738
[2018-06-04 19:16] Train Step 25250, Epoch 23.4, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -383.673, Loss = 379.262
[2018-06-04 19:16] Train Step 25275, Epoch 23.4, Batch Size = 256, Examples/Sec = 3861.17, Train LB = -375.721, Loss = 378.730
[2018-06-04 19:16] Train Step 25300, Epoch 23.4, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -368.522, Loss = 378.604
[2018-06-04 19:17] Train Step 25325, Epoch 23.4, Batch Size = 256, Examples/Sec = 3856.93, Train LB = -370.239, Loss = 377.798
[2018-06-04 19:17] Train Step 25350, Epoch 23.5, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -371.673, Loss = 377.732
[2018-06-04 19:17] Train Step 25375, Epoch 23.5, Batch Size = 256, Examples/Sec = 3868.75, Train LB = -376.157, Loss = 378.879
[2018-06-04 19:17] Train Step 25400, Epoch 23.5, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -380.460, Loss = 380.869
Performance on test set:
  Test Lower Bound = -400.039, Test Loss = 400.039
[2018-06-04 19:17] Train Step 25425, Epoch 23.5, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -374.149, Loss = 380.177
[2018-06-04 19:17] Train Step 25450, Epoch 23.6, Batch Size = 256, Examples/Sec = 3874.91, Train LB = -366.653, Loss = 379.233
[2018-06-04 19:17] Train Step 25475, Epoch 23.6, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -376.910, Loss = 378.409
[2018-06-04 19:17] Train Step 25500, Epoch 23.6, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -386.340, Loss = 378.060
[2018-06-04 19:17] Train Step 25525, Epoch 23.6, Batch Size = 256, Examples/Sec = 3882.86, Train LB = -386.895, Loss = 377.763
[2018-06-04 19:17] Train Step 25550, Epoch 23.7, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -374.801, Loss = 378.385
[2018-06-04 19:17] Train Step 25575, Epoch 23.7, Batch Size = 256, Examples/Sec = 3863.23, Train LB = -379.398, Loss = 378.583
[2018-06-04 19:17] Train Step 25600, Epoch 23.7, Batch Size = 256, Examples/Sec = 3812.42, Train LB = -395.286, Loss = 380.242
Performance on test set:
  Test Lower Bound = -401.012, Test Loss = 401.012
[2018-06-04 19:17] Train Step 25625, Epoch 23.7, Batch Size = 256, Examples/Sec = 3827.82, Train LB = -373.960, Loss = 379.572
[2018-06-04 19:17] Train Step 25650, Epoch 23.8, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -389.207, Loss = 379.068
[2018-06-04 19:17] Train Step 25675, Epoch 23.8, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -388.254, Loss = 379.062
[2018-06-04 19:17] Train Step 25700, Epoch 23.8, Batch Size = 256, Examples/Sec = 3875.32, Train LB = -369.553, Loss = 378.618
[2018-06-04 19:17] Train Step 25725, Epoch 23.8, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -387.569, Loss = 377.665
[2018-06-04 19:17] Train Step 25750, Epoch 23.8, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -374.572, Loss = 378.382
[2018-06-04 19:17] Train Step 25775, Epoch 23.9, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -388.262, Loss = 378.646
[2018-06-04 19:17] Train Step 25800, Epoch 23.9, Batch Size = 256, Examples/Sec = 3854.08, Train LB = -389.564, Loss = 380.353
Performance on test set:
  Test Lower Bound = -400.142, Test Loss = 400.142
[2018-06-04 19:17] Train Step 25825, Epoch 23.9, Batch Size = 256, Examples/Sec = 3772.03, Train LB = -380.551, Loss = 379.681
[2018-06-04 19:17] Train Step 25850, Epoch 23.9, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -383.163, Loss = 379.495
[2018-06-04 19:17] Train Step 25875, Epoch 24.0, Batch Size = 256, Examples/Sec = 3865.97, Train LB = -378.679, Loss = 378.923
[2018-06-04 19:17] Train Step 25900, Epoch 24.0, Batch Size = 256, Examples/Sec = 3722.34, Train LB = -368.741, Loss = 378.628
[2018-06-04 19:17] Train Step 25925, Epoch 24.0, Batch Size = 256, Examples/Sec = 3813.55, Train LB = -383.370, Loss = 378.443
[2018-06-04 19:17] Train Step 25950, Epoch 24.0, Batch Size = 256, Examples/Sec = 3858.27, Train LB = -368.668, Loss = 378.375
[2018-06-04 19:17] Train Step 25975, Epoch 24.1, Batch Size = 256, Examples/Sec = 3730.15, Train LB = -378.957, Loss = 378.496
[2018-06-04 19:17] Train Step 26000, Epoch 24.1, Batch Size = 256, Examples/Sec = 3853.44, Train LB = -391.164, Loss = 380.015
Performance on test set:
  Test Lower Bound = -399.622, Test Loss = 399.622
[2018-06-04 19:18] Train Step 26025, Epoch 24.1, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -367.190, Loss = 379.259
[2018-06-04 19:18] Train Step 26050, Epoch 24.1, Batch Size = 256, Examples/Sec = 3874.74, Train LB = -371.203, Loss = 379.374
[2018-06-04 19:18] Train Step 26075, Epoch 24.1, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -374.060, Loss = 378.249
[2018-06-04 19:18] Train Step 26100, Epoch 24.2, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -376.471, Loss = 378.194
[2018-06-04 19:18] Train Step 26125, Epoch 24.2, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -379.481, Loss = 377.568
[2018-06-04 19:18] Train Step 26150, Epoch 24.2, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -374.519, Loss = 377.195
[2018-06-04 19:18] Train Step 26175, Epoch 24.2, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -395.635, Loss = 377.389
[2018-06-04 19:18] Train Step 26200, Epoch 24.3, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -372.181, Loss = 379.381
Performance on test set:
  Test Lower Bound = -401.003, Test Loss = 401.003
[2018-06-04 19:18] Train Step 26225, Epoch 24.3, Batch Size = 256, Examples/Sec = 3867.49, Train LB = -391.297, Loss = 379.027
[2018-06-04 19:18] Train Step 26250, Epoch 24.3, Batch Size = 256, Examples/Sec = 3843.62, Train LB = -386.530, Loss = 378.529
[2018-06-04 19:18] Train Step 26275, Epoch 24.3, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -383.713, Loss = 377.969
[2018-06-04 19:18] Train Step 26300, Epoch 24.4, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -379.487, Loss = 376.454
[2018-06-04 19:18] Train Step 26325, Epoch 24.4, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -378.162, Loss = 376.552
[2018-06-04 19:18] Train Step 26350, Epoch 24.4, Batch Size = 256, Examples/Sec = 3851.08, Train LB = -385.034, Loss = 376.893
[2018-06-04 19:18] Train Step 26375, Epoch 24.4, Batch Size = 256, Examples/Sec = 3853.15, Train LB = -393.697, Loss = 377.921
[2018-06-04 19:18] Train Step 26400, Epoch 24.4, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -388.162, Loss = 379.431
Performance on test set:
  Test Lower Bound = -400.084, Test Loss = 400.084
[2018-06-04 19:18] Train Step 26425, Epoch 24.5, Batch Size = 256, Examples/Sec = 3855.42, Train LB = -367.595, Loss = 378.683
[2018-06-04 19:18] Train Step 26450, Epoch 24.5, Batch Size = 256, Examples/Sec = 3868.06, Train LB = -369.213, Loss = 378.807
[2018-06-04 19:18] Train Step 26475, Epoch 24.5, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -380.997, Loss = 377.775
[2018-06-04 19:18] Train Step 26500, Epoch 24.5, Batch Size = 256, Examples/Sec = 3825.12, Train LB = -370.654, Loss = 377.772
[2018-06-04 19:18] Train Step 26525, Epoch 24.6, Batch Size = 256, Examples/Sec = 3872.98, Train LB = -360.923, Loss = 376.825
[2018-06-04 19:18] Train Step 26550, Epoch 24.6, Batch Size = 256, Examples/Sec = 3875.09, Train LB = -387.884, Loss = 376.401
[2018-06-04 19:18] Train Step 26575, Epoch 24.6, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -384.103, Loss = 377.528
[2018-06-04 19:18] Train Step 26600, Epoch 24.6, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -394.509, Loss = 379.005
Performance on test set:
  Test Lower Bound = -400.248, Test Loss = 400.248
[2018-06-04 19:18] Train Step 26625, Epoch 24.7, Batch Size = 256, Examples/Sec = 3795.17, Train LB = -378.717, Loss = 378.825
[2018-06-04 19:18] Train Step 26650, Epoch 24.7, Batch Size = 256, Examples/Sec = 3840.50, Train LB = -382.154, Loss = 378.337
[2018-06-04 19:18] Train Step 26675, Epoch 24.7, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -366.754, Loss = 377.775
[2018-06-04 19:18] Train Step 26700, Epoch 24.7, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -376.877, Loss = 376.343
[2018-06-04 19:18] Train Step 26725, Epoch 24.7, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -369.491, Loss = 376.571
[2018-06-04 19:18] Train Step 26750, Epoch 24.8, Batch Size = 256, Examples/Sec = 3860.30, Train LB = -360.808, Loss = 376.931
[2018-06-04 19:19] Train Step 26775, Epoch 24.8, Batch Size = 256, Examples/Sec = 3815.61, Train LB = -370.721, Loss = 378.090
[2018-06-04 19:19] Train Step 26800, Epoch 24.8, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -386.364, Loss = 379.179
Performance on test set:
  Test Lower Bound = -399.455, Test Loss = 399.455
[2018-06-04 19:19] Train Step 26825, Epoch 24.8, Batch Size = 256, Examples/Sec = 3841.19, Train LB = -374.820, Loss = 378.526
[2018-06-04 19:19] Train Step 26850, Epoch 24.9, Batch Size = 256, Examples/Sec = 3834.11, Train LB = -373.959, Loss = 378.181
[2018-06-04 19:19] Train Step 26875, Epoch 24.9, Batch Size = 256, Examples/Sec = 3772.41, Train LB = -377.302, Loss = 377.229
[2018-06-04 19:19] Train Step 26900, Epoch 24.9, Batch Size = 256, Examples/Sec = 3854.33, Train LB = -377.425, Loss = 376.315
[2018-06-04 19:19] Train Step 26925, Epoch 24.9, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -374.469, Loss = 376.774
[2018-06-04 19:19] Train Step 26950, Epoch 25.0, Batch Size = 256, Examples/Sec = 3756.42, Train LB = -381.407, Loss = 376.984
[2018-06-04 19:19] Train Step 26975, Epoch 25.0, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -386.792, Loss = 378.109
[2018-06-04 19:19] Train Step 27000, Epoch 25.0, Batch Size = 256, Examples/Sec = 3858.27, Train LB = -368.037, Loss = 379.590
Performance on test set:
  Test Lower Bound = -402.148, Test Loss = 402.147
[2018-06-04 19:19] Train Step 27025, Epoch 25.0, Batch Size = 256, Examples/Sec = 3849.52, Train LB = -368.946, Loss = 379.030
[2018-06-04 19:19] Train Step 27050, Epoch 25.0, Batch Size = 256, Examples/Sec = 3850.39, Train LB = -379.616, Loss = 378.348
[2018-06-04 19:19] Train Step 27075, Epoch 25.1, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -383.463, Loss = 376.918
[2018-06-04 19:19] Train Step 27100, Epoch 25.1, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -374.849, Loss = 376.418
[2018-06-04 19:19] Train Step 27125, Epoch 25.1, Batch Size = 256, Examples/Sec = 3838.49, Train LB = -401.080, Loss = 376.193
[2018-06-04 19:19] Train Step 27150, Epoch 25.1, Batch Size = 256, Examples/Sec = 3848.58, Train LB = -369.975, Loss = 376.467
[2018-06-04 19:19] Train Step 27175, Epoch 25.2, Batch Size = 256, Examples/Sec = 3816.23, Train LB = -367.081, Loss = 377.116
[2018-06-04 19:19] Train Step 27200, Epoch 25.2, Batch Size = 256, Examples/Sec = 3879.90, Train LB = -376.494, Loss = 379.252
Performance on test set:
  Test Lower Bound = -402.089, Test Loss = 402.089
[2018-06-04 19:19] Train Step 27225, Epoch 25.2, Batch Size = 256, Examples/Sec = 3841.25, Train LB = -375.424, Loss = 378.929
[2018-06-04 19:19] Train Step 27250, Epoch 25.2, Batch Size = 256, Examples/Sec = 3856.35, Train LB = -377.364, Loss = 378.040
[2018-06-04 19:19] Train Step 27275, Epoch 25.3, Batch Size = 256, Examples/Sec = 3844.13, Train LB = -381.111, Loss = 377.764
[2018-06-04 19:19] Train Step 27300, Epoch 25.3, Batch Size = 256, Examples/Sec = 3855.53, Train LB = -375.088, Loss = 377.441
[2018-06-04 19:19] Train Step 27325, Epoch 25.3, Batch Size = 256, Examples/Sec = 3841.82, Train LB = -377.209, Loss = 376.542
[2018-06-04 19:19] Train Step 27350, Epoch 25.3, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -378.792, Loss = 376.416
[2018-06-04 19:19] Train Step 27375, Epoch 25.3, Batch Size = 256, Examples/Sec = 3876.56, Train LB = -389.827, Loss = 377.383
[2018-06-04 19:19] Train Step 27400, Epoch 25.4, Batch Size = 256, Examples/Sec = 3852.47, Train LB = -383.152, Loss = 378.693
Performance on test set:
  Test Lower Bound = -401.055, Test Loss = 401.055
[2018-06-04 19:19] Train Step 27425, Epoch 25.4, Batch Size = 256, Examples/Sec = 3791.86, Train LB = -383.455, Loss = 378.027
[2018-06-04 19:20] Train Step 27450, Epoch 25.4, Batch Size = 256, Examples/Sec = 3876.80, Train LB = -373.429, Loss = 377.982
[2018-06-04 19:20] Train Step 27475, Epoch 25.4, Batch Size = 256, Examples/Sec = 3878.49, Train LB = -360.199, Loss = 377.479
[2018-06-04 19:20] Train Step 27500, Epoch 25.5, Batch Size = 256, Examples/Sec = 3873.04, Train LB = -363.606, Loss = 376.783
[2018-06-04 19:20] Train Step 27525, Epoch 25.5, Batch Size = 256, Examples/Sec = 3852.47, Train LB = -395.315, Loss = 376.448
[2018-06-04 19:20] Train Step 27550, Epoch 25.5, Batch Size = 256, Examples/Sec = 3846.22, Train LB = -363.595, Loss = 376.442
[2018-06-04 19:20] Train Step 27575, Epoch 25.5, Batch Size = 256, Examples/Sec = 3842.86, Train LB = -369.695, Loss = 376.467
[2018-06-04 19:20] Train Step 27600, Epoch 25.6, Batch Size = 256, Examples/Sec = 3880.85, Train LB = -389.233, Loss = 378.479
Performance on test set:
  Test Lower Bound = -400.523, Test Loss = 400.523
[2018-06-04 19:20] Train Step 27625, Epoch 25.6, Batch Size = 256, Examples/Sec = 3865.61, Train LB = -361.856, Loss = 378.460
[2018-06-04 19:20] Train Step 27650, Epoch 25.6, Batch Size = 256, Examples/Sec = 3880.85, Train LB = -383.624, Loss = 377.653
[2018-06-04 19:20] Train Step 27675, Epoch 25.6, Batch Size = 256, Examples/Sec = 3748.01, Train LB = -372.718, Loss = 376.613
[2018-06-04 19:20] Train Step 27700, Epoch 25.6, Batch Size = 256, Examples/Sec = 3834.57, Train LB = -363.967, Loss = 375.997
[2018-06-04 19:20] Train Step 27725, Epoch 25.7, Batch Size = 256, Examples/Sec = 3877.02, Train LB = -375.205, Loss = 375.782
[2018-06-04 19:20] Train Step 27750, Epoch 25.7, Batch Size = 256, Examples/Sec = 3760.73, Train LB = -365.149, Loss = 376.399
[2018-06-04 19:20] Train Step 27775, Epoch 25.7, Batch Size = 256, Examples/Sec = 3849.16, Train LB = -384.524, Loss = 377.069
[2018-06-04 19:20] Train Step 27800, Epoch 25.7, Batch Size = 256, Examples/Sec = 3803.13, Train LB = -387.832, Loss = 378.223
Performance on test set:
  Test Lower Bound = -401.789, Test Loss = 401.789
[2018-06-04 19:20] Train Step 27825, Epoch 25.8, Batch Size = 256, Examples/Sec = 3848.36, Train LB = -374.397, Loss = 377.900
[2018-06-04 19:20] Train Step 27850, Epoch 25.8, Batch Size = 256, Examples/Sec = 3861.41, Train LB = -383.750, Loss = 378.031
[2018-06-04 19:20] Train Step 27875, Epoch 25.8, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -374.361, Loss = 376.672
[2018-06-04 19:20] Train Step 27900, Epoch 25.8, Batch Size = 256, Examples/Sec = 3867.78, Train LB = -373.492, Loss = 375.390
[2018-06-04 19:20] Train Step 27925, Epoch 25.9, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -372.055, Loss = 374.927
[2018-06-04 19:20] Train Step 27950, Epoch 25.9, Batch Size = 256, Examples/Sec = 3871.70, Train LB = -363.735, Loss = 375.176
[2018-06-04 19:20] Train Step 27975, Epoch 25.9, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -389.661, Loss = 376.103
[2018-06-04 19:20] Train Step 28000, Epoch 25.9, Batch Size = 256, Examples/Sec = 3774.30, Train LB = -391.179, Loss = 378.746
Performance on test set:
  Test Lower Bound = -400.114, Test Loss = 400.114
[2018-06-04 19:20] Train Step 28025, Epoch 25.9, Batch Size = 256, Examples/Sec = 3880.50, Train LB = -364.252, Loss = 377.089
[2018-06-04 19:20] Train Step 28050, Epoch 26.0, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -377.140, Loss = 376.857
[2018-06-04 19:20] Train Step 28075, Epoch 26.0, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -381.992, Loss = 376.721
[2018-06-04 19:20] Train Step 28100, Epoch 26.0, Batch Size = 256, Examples/Sec = 3873.22, Train LB = -380.147, Loss = 375.986
[2018-06-04 19:20] Train Step 28125, Epoch 26.0, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -369.418, Loss = 375.239
[2018-06-04 19:20] Train Step 28150, Epoch 26.1, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -379.512, Loss = 375.409
[2018-06-04 19:20] Train Step 28175, Epoch 26.1, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -382.927, Loss = 376.622
[2018-06-04 19:21] Train Step 28200, Epoch 26.1, Batch Size = 256, Examples/Sec = 3851.53, Train LB = -375.086, Loss = 378.712
Performance on test set:
  Test Lower Bound = -401.152, Test Loss = 401.152
[2018-06-04 19:21] Train Step 28225, Epoch 26.1, Batch Size = 256, Examples/Sec = 3818.28, Train LB = -376.378, Loss = 377.723
[2018-06-04 19:21] Train Step 28250, Epoch 26.2, Batch Size = 256, Examples/Sec = 3853.69, Train LB = -369.629, Loss = 377.352
[2018-06-04 19:21] Train Step 28275, Epoch 26.2, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -375.649, Loss = 376.532
[2018-06-04 19:21] Train Step 28300, Epoch 26.2, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -384.542, Loss = 375.941
[2018-06-04 19:21] Train Step 28325, Epoch 26.2, Batch Size = 256, Examples/Sec = 3868.13, Train LB = -399.993, Loss = 375.770
[2018-06-04 19:21] Train Step 28350, Epoch 26.2, Batch Size = 256, Examples/Sec = 3859.19, Train LB = -356.624, Loss = 375.682
[2018-06-04 19:21] Train Step 28375, Epoch 26.3, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -385.051, Loss = 376.412
[2018-06-04 19:21] Train Step 28400, Epoch 26.3, Batch Size = 256, Examples/Sec = 3858.45, Train LB = -374.736, Loss = 378.145
Performance on test set:
  Test Lower Bound = -401.447, Test Loss = 401.447
[2018-06-04 19:21] Train Step 28425, Epoch 26.3, Batch Size = 256, Examples/Sec = 3856.12, Train LB = -372.222, Loss = 376.958
[2018-06-04 19:21] Train Step 28450, Epoch 26.3, Batch Size = 256, Examples/Sec = 3854.27, Train LB = -363.408, Loss = 376.523
[2018-06-04 19:21] Train Step 28475, Epoch 26.4, Batch Size = 256, Examples/Sec = 3728.24, Train LB = -371.977, Loss = 376.388
[2018-06-04 19:21] Train Step 28500, Epoch 26.4, Batch Size = 256, Examples/Sec = 3854.15, Train LB = -358.266, Loss = 375.950
[2018-06-04 19:21] Train Step 28525, Epoch 26.4, Batch Size = 256, Examples/Sec = 3818.79, Train LB = -368.105, Loss = 374.867
[2018-06-04 19:21] Train Step 28550, Epoch 26.4, Batch Size = 256, Examples/Sec = 3756.64, Train LB = -380.316, Loss = 375.176
[2018-06-04 19:21] Train Step 28575, Epoch 26.5, Batch Size = 256, Examples/Sec = 3846.57, Train LB = -366.625, Loss = 376.663
[2018-06-04 19:21] Train Step 28600, Epoch 26.5, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -371.515, Loss = 378.107
Performance on test set:
  Test Lower Bound = -400.987, Test Loss = 400.987
[2018-06-04 19:21] Train Step 28625, Epoch 26.5, Batch Size = 256, Examples/Sec = 3848.41, Train LB = -377.634, Loss = 377.211
[2018-06-04 19:21] Train Step 28650, Epoch 26.5, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -369.058, Loss = 376.802
[2018-06-04 19:21] Train Step 28675, Epoch 26.6, Batch Size = 256, Examples/Sec = 3872.93, Train LB = -363.496, Loss = 375.880
[2018-06-04 19:21] Train Step 28700, Epoch 26.6, Batch Size = 256, Examples/Sec = 3841.71, Train LB = -384.764, Loss = 374.901
[2018-06-04 19:21] Train Step 28725, Epoch 26.6, Batch Size = 256, Examples/Sec = 3866.32, Train LB = -359.259, Loss = 375.341
[2018-06-04 19:21] Train Step 28750, Epoch 26.6, Batch Size = 256, Examples/Sec = 3860.01, Train LB = -373.250, Loss = 375.889
[2018-06-04 19:21] Train Step 28775, Epoch 26.6, Batch Size = 256, Examples/Sec = 3858.40, Train LB = -385.848, Loss = 376.947
[2018-06-04 19:21] Train Step 28800, Epoch 26.7, Batch Size = 256, Examples/Sec = 3843.44, Train LB = -387.422, Loss = 378.327
Performance on test set:
  Test Lower Bound = -401.969, Test Loss = 401.969
[2018-06-04 19:21] Train Step 28825, Epoch 26.7, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -381.970, Loss = 377.273
[2018-06-04 19:21] Train Step 28850, Epoch 26.7, Batch Size = 256, Examples/Sec = 3873.21, Train LB = -376.179, Loss = 376.952
[2018-06-04 19:21] Train Step 28875, Epoch 26.7, Batch Size = 256, Examples/Sec = 3848.18, Train LB = -375.087, Loss = 375.985
[2018-06-04 19:22] Train Step 28900, Epoch 26.8, Batch Size = 256, Examples/Sec = 3866.90, Train LB = -373.945, Loss = 375.203
[2018-06-04 19:22] Train Step 28925, Epoch 26.8, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -376.997, Loss = 375.112
[2018-06-04 19:22] Train Step 28950, Epoch 26.8, Batch Size = 256, Examples/Sec = 3856.51, Train LB = -389.284, Loss = 375.187
[2018-06-04 19:22] Train Step 28975, Epoch 26.8, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -372.367, Loss = 376.346
[2018-06-04 19:22] Train Step 29000, Epoch 26.9, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -380.999, Loss = 377.546
Performance on test set:
  Test Lower Bound = -402.207, Test Loss = 402.207
[2018-06-04 19:22] Train Step 29025, Epoch 26.9, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -379.550, Loss = 376.908
[2018-06-04 19:22] Train Step 29050, Epoch 26.9, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -365.136, Loss = 376.488
[2018-06-04 19:22] Train Step 29075, Epoch 26.9, Batch Size = 256, Examples/Sec = 3839.63, Train LB = -371.895, Loss = 375.936
[2018-06-04 19:22] Train Step 29100, Epoch 26.9, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -382.025, Loss = 375.548
[2018-06-04 19:22] Train Step 29125, Epoch 27.0, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -366.495, Loss = 375.298
[2018-06-04 19:22] Train Step 29150, Epoch 27.0, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -379.062, Loss = 374.994
[2018-06-04 19:22] Train Step 29175, Epoch 27.0, Batch Size = 256, Examples/Sec = 3859.78, Train LB = -387.919, Loss = 375.947
[2018-06-04 19:22] Train Step 29200, Epoch 27.0, Batch Size = 256, Examples/Sec = 3882.14, Train LB = -384.739, Loss = 377.650
Performance on test set:
  Test Lower Bound = -401.286, Test Loss = 401.286
[2018-06-04 19:22] Train Step 29225, Epoch 27.1, Batch Size = 256, Examples/Sec = 3849.86, Train LB = -379.909, Loss = 376.507
[2018-06-04 19:22] Train Step 29250, Epoch 27.1, Batch Size = 256, Examples/Sec = 3809.01, Train LB = -357.093, Loss = 376.863
[2018-06-04 19:22] Train Step 29275, Epoch 27.1, Batch Size = 256, Examples/Sec = 3753.88, Train LB = -388.801, Loss = 375.913
[2018-06-04 19:22] Train Step 29300, Epoch 27.1, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -370.478, Loss = 375.615
[2018-06-04 19:22] Train Step 29325, Epoch 27.2, Batch Size = 256, Examples/Sec = 3875.44, Train LB = -378.431, Loss = 374.982
[2018-06-04 19:22] Train Step 29350, Epoch 27.2, Batch Size = 256, Examples/Sec = 3743.13, Train LB = -375.998, Loss = 374.569
[2018-06-04 19:22] Train Step 29375, Epoch 27.2, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -399.707, Loss = 375.299
[2018-06-04 19:22] Train Step 29400, Epoch 27.2, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -387.889, Loss = 377.195
Performance on test set:
  Test Lower Bound = -401.365, Test Loss = 401.365
[2018-06-04 19:22] Train Step 29425, Epoch 27.2, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -363.144, Loss = 376.929
[2018-06-04 19:22] Train Step 29450, Epoch 27.3, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -377.801, Loss = 376.085
[2018-06-04 19:22] Train Step 29475, Epoch 27.3, Batch Size = 256, Examples/Sec = 3846.33, Train LB = -363.109, Loss = 375.584
[2018-06-04 19:22] Train Step 29500, Epoch 27.3, Batch Size = 256, Examples/Sec = 3865.97, Train LB = -364.443, Loss = 374.841
[2018-06-04 19:22] Train Step 29525, Epoch 27.3, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -380.644, Loss = 374.395
[2018-06-04 19:22] Train Step 29550, Epoch 27.4, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -381.316, Loss = 374.317
[2018-06-04 19:22] Train Step 29575, Epoch 27.4, Batch Size = 256, Examples/Sec = 3831.93, Train LB = -374.101, Loss = 375.392
[2018-06-04 19:22] Train Step 29600, Epoch 27.4, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -386.149, Loss = 378.154
Performance on test set:
  Test Lower Bound = -401.578, Test Loss = 401.578
[2018-06-04 19:23] Train Step 29625, Epoch 27.4, Batch Size = 256, Examples/Sec = 3881.09, Train LB = -363.924, Loss = 377.573
[2018-06-04 19:23] Train Step 29650, Epoch 27.5, Batch Size = 256, Examples/Sec = 3852.58, Train LB = -363.169, Loss = 376.491
[2018-06-04 19:23] Train Step 29675, Epoch 27.5, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -373.857, Loss = 375.598
[2018-06-04 19:23] Train Step 29700, Epoch 27.5, Batch Size = 256, Examples/Sec = 3840.28, Train LB = -373.776, Loss = 374.848
[2018-06-04 19:23] Train Step 29725, Epoch 27.5, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -367.874, Loss = 373.968
[2018-06-04 19:23] Train Step 29750, Epoch 27.5, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -376.549, Loss = 374.350
[2018-06-04 19:23] Train Step 29775, Epoch 27.6, Batch Size = 256, Examples/Sec = 3809.24, Train LB = -383.761, Loss = 374.823
[2018-06-04 19:23] Train Step 29800, Epoch 27.6, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -377.655, Loss = 377.409
Performance on test set:
  Test Lower Bound = -401.671, Test Loss = 401.671
[2018-06-04 19:23] Train Step 29825, Epoch 27.6, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -378.504, Loss = 376.852
[2018-06-04 19:23] Train Step 29850, Epoch 27.6, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -366.822, Loss = 375.914
[2018-06-04 19:23] Train Step 29875, Epoch 27.7, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -368.626, Loss = 375.030
[2018-06-04 19:23] Train Step 29900, Epoch 27.7, Batch Size = 256, Examples/Sec = 3847.89, Train LB = -361.108, Loss = 374.433
[2018-06-04 19:23] Train Step 29925, Epoch 27.7, Batch Size = 256, Examples/Sec = 3858.73, Train LB = -381.553, Loss = 373.488
[2018-06-04 19:23] Train Step 29950, Epoch 27.7, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -374.834, Loss = 374.293
[2018-06-04 19:23] Train Step 29975, Epoch 27.8, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -378.680, Loss = 375.310
[2018-06-04 19:23] Train Step 30000, Epoch 27.8, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -388.066, Loss = 377.238
Performance on test set:
  Test Lower Bound = -404.081, Test Loss = 404.081
[2018-06-04 19:23] Train Step 30025, Epoch 27.8, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -361.972, Loss = 377.075
[2018-06-04 19:23] Train Step 30050, Epoch 27.8, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -379.867, Loss = 376.750
[2018-06-04 19:23] Train Step 30075, Epoch 27.8, Batch Size = 256, Examples/Sec = 3737.45, Train LB = -383.884, Loss = 375.635
[2018-06-04 19:23] Train Step 30100, Epoch 27.9, Batch Size = 256, Examples/Sec = 3871.17, Train LB = -380.934, Loss = 375.151
[2018-06-04 19:23] Train Step 30125, Epoch 27.9, Batch Size = 256, Examples/Sec = 3862.16, Train LB = -369.281, Loss = 374.589
[2018-06-04 19:23] Train Step 30150, Epoch 27.9, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -383.782, Loss = 374.386
[2018-06-04 19:23] Train Step 30175, Epoch 27.9, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -389.599, Loss = 375.156
[2018-06-04 19:23] Train Step 30200, Epoch 28.0, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -386.039, Loss = 377.251
Performance on test set:
  Test Lower Bound = -403.267, Test Loss = 403.267
[2018-06-04 19:23] Train Step 30225, Epoch 28.0, Batch Size = 256, Examples/Sec = 3841.19, Train LB = -373.858, Loss = 376.752
[2018-06-04 19:23] Train Step 30250, Epoch 28.0, Batch Size = 256, Examples/Sec = 3853.68, Train LB = -379.578, Loss = 376.156
[2018-06-04 19:23] Train Step 30275, Epoch 28.0, Batch Size = 256, Examples/Sec = 3858.44, Train LB = -375.244, Loss = 375.735
[2018-06-04 19:23] Train Step 30300, Epoch 28.1, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -362.863, Loss = 374.494
[2018-06-04 19:24] Train Step 30325, Epoch 28.1, Batch Size = 256, Examples/Sec = 3716.18, Train LB = -382.405, Loss = 374.082
[2018-06-04 19:24] Train Step 30350, Epoch 28.1, Batch Size = 256, Examples/Sec = 3866.50, Train LB = -369.005, Loss = 374.534
[2018-06-04 19:24] Train Step 30375, Epoch 28.1, Batch Size = 256, Examples/Sec = 3856.69, Train LB = -374.692, Loss = 375.228
[2018-06-04 19:24] Train Step 30400, Epoch 28.1, Batch Size = 256, Examples/Sec = 3737.17, Train LB = -383.509, Loss = 376.699
Performance on test set:
  Test Lower Bound = -402.592, Test Loss = 402.592
[2018-06-04 19:24] Train Step 30425, Epoch 28.2, Batch Size = 256, Examples/Sec = 3887.81, Train LB = -385.053, Loss = 375.801
[2018-06-04 19:24] Train Step 30450, Epoch 28.2, Batch Size = 256, Examples/Sec = 3855.49, Train LB = -367.765, Loss = 375.028
[2018-06-04 19:24] Train Step 30475, Epoch 28.2, Batch Size = 256, Examples/Sec = 3830.73, Train LB = -374.292, Loss = 374.652
[2018-06-04 19:24] Train Step 30500, Epoch 28.2, Batch Size = 256, Examples/Sec = 3782.06, Train LB = -358.600, Loss = 373.702
[2018-06-04 19:24] Train Step 30525, Epoch 28.3, Batch Size = 256, Examples/Sec = 3873.75, Train LB = -370.785, Loss = 373.653
[2018-06-04 19:24] Train Step 30550, Epoch 28.3, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -367.895, Loss = 373.660
[2018-06-04 19:24] Train Step 30575, Epoch 28.3, Batch Size = 256, Examples/Sec = 3836.77, Train LB = -387.927, Loss = 374.723
[2018-06-04 19:24] Train Step 30600, Epoch 28.3, Batch Size = 256, Examples/Sec = 3850.97, Train LB = -382.393, Loss = 376.647
Performance on test set:
  Test Lower Bound = -399.880, Test Loss = 399.880
[2018-06-04 19:24] Train Step 30625, Epoch 28.4, Batch Size = 256, Examples/Sec = 3832.34, Train LB = -383.408, Loss = 375.418
[2018-06-04 19:24] Train Step 30650, Epoch 28.4, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -362.888, Loss = 375.394
[2018-06-04 19:24] Train Step 30675, Epoch 28.4, Batch Size = 256, Examples/Sec = 3855.72, Train LB = -381.841, Loss = 374.122
[2018-06-04 19:24] Train Step 30700, Epoch 28.4, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -372.307, Loss = 373.301
[2018-06-04 19:24] Train Step 30725, Epoch 28.4, Batch Size = 256, Examples/Sec = 3874.67, Train LB = -359.801, Loss = 373.714
[2018-06-04 19:24] Train Step 30750, Epoch 28.5, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -364.218, Loss = 373.536
[2018-06-04 19:24] Train Step 30775, Epoch 28.5, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -379.107, Loss = 375.100
[2018-06-04 19:24] Train Step 30800, Epoch 28.5, Batch Size = 256, Examples/Sec = 3802.00, Train LB = -391.105, Loss = 376.835
Performance on test set:
  Test Lower Bound = -401.415, Test Loss = 401.415
[2018-06-04 19:24] Train Step 30825, Epoch 28.5, Batch Size = 256, Examples/Sec = 3817.82, Train LB = -394.170, Loss = 375.530
[2018-06-04 19:24] Train Step 30850, Epoch 28.6, Batch Size = 256, Examples/Sec = 3841.54, Train LB = -369.625, Loss = 375.365
[2018-06-04 19:24] Train Step 30875, Epoch 28.6, Batch Size = 256, Examples/Sec = 3875.67, Train LB = -356.717, Loss = 374.407
[2018-06-04 19:24] Train Step 30900, Epoch 28.6, Batch Size = 256, Examples/Sec = 3880.48, Train LB = -362.592, Loss = 374.015
[2018-06-04 19:24] Train Step 30925, Epoch 28.6, Batch Size = 256, Examples/Sec = 3876.14, Train LB = -373.384, Loss = 373.353
[2018-06-04 19:24] Train Step 30950, Epoch 28.7, Batch Size = 256, Examples/Sec = 3840.84, Train LB = -365.195, Loss = 373.067
[2018-06-04 19:24] Train Step 30975, Epoch 28.7, Batch Size = 256, Examples/Sec = 3878.84, Train LB = -369.278, Loss = 373.661
[2018-06-04 19:24] Train Step 31000, Epoch 28.7, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -390.969, Loss = 375.905
Performance on test set:
  Test Lower Bound = -401.552, Test Loss = 401.552
[2018-06-04 19:25] Train Step 31025, Epoch 28.7, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -379.814, Loss = 375.721
[2018-06-04 19:25] Train Step 31050, Epoch 28.8, Batch Size = 256, Examples/Sec = 3846.91, Train LB = -374.009, Loss = 374.975
[2018-06-04 19:25] Train Step 31075, Epoch 28.8, Batch Size = 256, Examples/Sec = 3837.22, Train LB = -377.665, Loss = 373.934
[2018-06-04 19:25] Train Step 31100, Epoch 28.8, Batch Size = 256, Examples/Sec = 3847.36, Train LB = -367.874, Loss = 373.187
[2018-06-04 19:25] Train Step 31125, Epoch 28.8, Batch Size = 256, Examples/Sec = 3738.92, Train LB = -383.509, Loss = 372.520
[2018-06-04 19:25] Train Step 31150, Epoch 28.8, Batch Size = 256, Examples/Sec = 3871.10, Train LB = -368.029, Loss = 373.179
[2018-06-04 19:25] Train Step 31175, Epoch 28.9, Batch Size = 256, Examples/Sec = 3846.91, Train LB = -382.956, Loss = 374.028
[2018-06-04 19:25] Train Step 31200, Epoch 28.9, Batch Size = 256, Examples/Sec = 3745.97, Train LB = -384.512, Loss = 375.899
Performance on test set:
  Test Lower Bound = -401.573, Test Loss = 401.573
[2018-06-04 19:25] Train Step 31225, Epoch 28.9, Batch Size = 256, Examples/Sec = 3873.09, Train LB = -373.469, Loss = 375.262
[2018-06-04 19:25] Train Step 31250, Epoch 28.9, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -374.872, Loss = 374.504
[2018-06-04 19:25] Train Step 31275, Epoch 29.0, Batch Size = 256, Examples/Sec = 3858.79, Train LB = -378.469, Loss = 373.738
[2018-06-04 19:25] Train Step 31300, Epoch 29.0, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -362.196, Loss = 373.261
[2018-06-04 19:25] Train Step 31325, Epoch 29.0, Batch Size = 256, Examples/Sec = 3858.20, Train LB = -375.270, Loss = 373.202
[2018-06-04 19:25] Train Step 31350, Epoch 29.0, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -385.500, Loss = 373.571
[2018-06-04 19:25] Train Step 31375, Epoch 29.1, Batch Size = 256, Examples/Sec = 3854.95, Train LB = -405.061, Loss = 374.339
[2018-06-04 19:25] Train Step 31400, Epoch 29.1, Batch Size = 256, Examples/Sec = 3873.61, Train LB = -385.410, Loss = 376.626
Performance on test set:
  Test Lower Bound = -401.209, Test Loss = 401.209
[2018-06-04 19:25] Train Step 31425, Epoch 29.1, Batch Size = 256, Examples/Sec = 3862.35, Train LB = -379.300, Loss = 376.263
[2018-06-04 19:25] Train Step 31450, Epoch 29.1, Batch Size = 256, Examples/Sec = 3874.97, Train LB = -348.599, Loss = 374.966
[2018-06-04 19:25] Train Step 31475, Epoch 29.1, Batch Size = 256, Examples/Sec = 3876.14, Train LB = -364.942, Loss = 373.258
[2018-06-04 19:25] Train Step 31500, Epoch 29.2, Batch Size = 256, Examples/Sec = 3852.69, Train LB = -373.179, Loss = 373.149
[2018-06-04 19:25] Train Step 31525, Epoch 29.2, Batch Size = 256, Examples/Sec = 3873.57, Train LB = -367.651, Loss = 372.657
[2018-06-04 19:25] Train Step 31550, Epoch 29.2, Batch Size = 256, Examples/Sec = 3866.01, Train LB = -384.304, Loss = 373.140
[2018-06-04 19:25] Train Step 31575, Epoch 29.2, Batch Size = 256, Examples/Sec = 3877.74, Train LB = -388.938, Loss = 374.354
[2018-06-04 19:25] Train Step 31600, Epoch 29.3, Batch Size = 256, Examples/Sec = 3847.60, Train LB = -395.252, Loss = 376.352
Performance on test set:
  Test Lower Bound = -401.677, Test Loss = 401.677
[2018-06-04 19:25] Train Step 31625, Epoch 29.3, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -389.572, Loss = 375.220
[2018-06-04 19:25] Train Step 31650, Epoch 29.3, Batch Size = 256, Examples/Sec = 3827.87, Train LB = -370.069, Loss = 374.760
[2018-06-04 19:25] Train Step 31675, Epoch 29.3, Batch Size = 256, Examples/Sec = 3852.46, Train LB = -376.347, Loss = 373.605
[2018-06-04 19:25] Train Step 31700, Epoch 29.4, Batch Size = 256, Examples/Sec = 3845.16, Train LB = -369.023, Loss = 373.029
[2018-06-04 19:25] Train Step 31725, Epoch 29.4, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -371.394, Loss = 372.723
[2018-06-04 19:26] Train Step 31750, Epoch 29.4, Batch Size = 256, Examples/Sec = 3822.04, Train LB = -373.943, Loss = 373.146
[2018-06-04 19:26] Train Step 31775, Epoch 29.4, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -383.819, Loss = 374.016
[2018-06-04 19:26] Train Step 31800, Epoch 29.4, Batch Size = 256, Examples/Sec = 3880.72, Train LB = -381.061, Loss = 376.010
Performance on test set:
  Test Lower Bound = -401.435, Test Loss = 401.435
[2018-06-04 19:26] Train Step 31825, Epoch 29.5, Batch Size = 256, Examples/Sec = 3856.93, Train LB = -374.324, Loss = 375.453
[2018-06-04 19:26] Train Step 31850, Epoch 29.5, Batch Size = 256, Examples/Sec = 3699.37, Train LB = -365.166, Loss = 374.708
[2018-06-04 19:26] Train Step 31875, Epoch 29.5, Batch Size = 256, Examples/Sec = 3853.98, Train LB = -379.031, Loss = 374.296
[2018-06-04 19:26] Train Step 31900, Epoch 29.5, Batch Size = 256, Examples/Sec = 3860.83, Train LB = -370.067, Loss = 372.897
[2018-06-04 19:26] Train Step 31925, Epoch 29.6, Batch Size = 256, Examples/Sec = 3748.88, Train LB = -370.789, Loss = 372.667
[2018-06-04 19:26] Train Step 31950, Epoch 29.6, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -384.037, Loss = 372.736
[2018-06-04 19:26] Train Step 31975, Epoch 29.6, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -383.222, Loss = 373.741
[2018-06-04 19:26] Train Step 32000, Epoch 29.6, Batch Size = 256, Examples/Sec = 3827.92, Train LB = -391.073, Loss = 375.162
Performance on test set:
  Test Lower Bound = -401.810, Test Loss = 401.810
[2018-06-04 19:26] Train Step 32025, Epoch 29.7, Batch Size = 256, Examples/Sec = 3887.73, Train LB = -357.242, Loss = 374.564
[2018-06-04 19:26] Train Step 32050, Epoch 29.7, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -361.658, Loss = 373.930
[2018-06-04 19:26] Train Step 32075, Epoch 29.7, Batch Size = 256, Examples/Sec = 3820.10, Train LB = -370.144, Loss = 372.915
[2018-06-04 19:26] Train Step 32100, Epoch 29.7, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -365.342, Loss = 373.156
[2018-06-04 19:26] Train Step 32125, Epoch 29.7, Batch Size = 256, Examples/Sec = 3851.64, Train LB = -370.313, Loss = 372.292
[2018-06-04 19:26] Train Step 32150, Epoch 29.8, Batch Size = 256, Examples/Sec = 3881.20, Train LB = -372.276, Loss = 372.675
[2018-06-04 19:26] Train Step 32175, Epoch 29.8, Batch Size = 256, Examples/Sec = 3856.76, Train LB = -381.730, Loss = 373.760
[2018-06-04 19:26] Train Step 32200, Epoch 29.8, Batch Size = 256, Examples/Sec = 3852.53, Train LB = -398.254, Loss = 375.382
Performance on test set:
  Test Lower Bound = -401.438, Test Loss = 401.438
[2018-06-04 19:26] Train Step 32225, Epoch 29.8, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -377.642, Loss = 374.368
[2018-06-04 19:26] Train Step 32250, Epoch 29.9, Batch Size = 256, Examples/Sec = 3858.98, Train LB = -375.766, Loss = 374.558
[2018-06-04 19:26] Train Step 32275, Epoch 29.9, Batch Size = 256, Examples/Sec = 3844.82, Train LB = -384.894, Loss = 373.777
[2018-06-04 19:26] Train Step 32300, Epoch 29.9, Batch Size = 256, Examples/Sec = 3841.02, Train LB = -371.498, Loss = 373.427
[2018-06-04 19:26] Train Step 32325, Epoch 29.9, Batch Size = 256, Examples/Sec = 3848.94, Train LB = -377.603, Loss = 372.270
[2018-06-04 19:26] Train Step 32350, Epoch 30.0, Batch Size = 256, Examples/Sec = 3879.20, Train LB = -370.738, Loss = 372.610
[2018-06-04 19:26] Train Step 32375, Epoch 30.0, Batch Size = 256, Examples/Sec = 3835.31, Train LB = -393.166, Loss = 373.490
[2018-06-04 19:26] Train Step 32400, Epoch 30.0, Batch Size = 256, Examples/Sec = 3868.06, Train LB = -392.099, Loss = 375.161
Performance on test set:
  Test Lower Bound = -404.114, Test Loss = 404.114
[2018-06-04 19:26] Train Step 32425, Epoch 30.0, Batch Size = 256, Examples/Sec = 3865.72, Train LB = -367.804, Loss = 374.339
[2018-06-04 19:27] Train Step 32450, Epoch 30.0, Batch Size = 256, Examples/Sec = 3864.16, Train LB = -372.450, Loss = 373.792
[2018-06-04 19:27] Train Step 32475, Epoch 30.1, Batch Size = 256, Examples/Sec = 3803.47, Train LB = -358.109, Loss = 373.086
[2018-06-04 19:27] Train Step 32500, Epoch 30.1, Batch Size = 256, Examples/Sec = 3865.48, Train LB = -364.215, Loss = 372.558
[2018-06-04 19:27] Train Step 32525, Epoch 30.1, Batch Size = 256, Examples/Sec = 3865.44, Train LB = -372.602, Loss = 372.522
[2018-06-04 19:27] Train Step 32550, Epoch 30.1, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -367.438, Loss = 372.749
[2018-06-04 19:27] Train Step 32575, Epoch 30.2, Batch Size = 256, Examples/Sec = 3855.78, Train LB = -382.523, Loss = 372.910
[2018-06-04 19:27] Train Step 32600, Epoch 30.2, Batch Size = 256, Examples/Sec = 3860.64, Train LB = -403.244, Loss = 374.874
Performance on test set:
  Test Lower Bound = -402.788, Test Loss = 402.788
[2018-06-04 19:27] Train Step 32625, Epoch 30.2, Batch Size = 256, Examples/Sec = 3851.24, Train LB = -397.708, Loss = 373.998
[2018-06-04 19:27] Train Step 32650, Epoch 30.2, Batch Size = 256, Examples/Sec = 3755.14, Train LB = -380.895, Loss = 373.536
[2018-06-04 19:27] Train Step 32675, Epoch 30.3, Batch Size = 256, Examples/Sec = 3840.04, Train LB = -389.303, Loss = 373.072
[2018-06-04 19:27] Train Step 32700, Epoch 30.3, Batch Size = 256, Examples/Sec = 3806.46, Train LB = -353.665, Loss = 372.898
[2018-06-04 19:27] Train Step 32725, Epoch 30.3, Batch Size = 256, Examples/Sec = 3736.30, Train LB = -373.310, Loss = 372.257
[2018-06-04 19:27] Train Step 32750, Epoch 30.3, Batch Size = 256, Examples/Sec = 3852.28, Train LB = -369.211, Loss = 372.194
[2018-06-04 19:27] Train Step 32775, Epoch 30.3, Batch Size = 256, Examples/Sec = 3877.21, Train LB = -377.852, Loss = 373.020
[2018-06-04 19:27] Train Step 32800, Epoch 30.4, Batch Size = 256, Examples/Sec = 3813.26, Train LB = -388.459, Loss = 375.157
Performance on test set:
  Test Lower Bound = -403.002, Test Loss = 403.002
[2018-06-04 19:27] Train Step 32825, Epoch 30.4, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -377.309, Loss = 374.498
[2018-06-04 19:27] Train Step 32850, Epoch 30.4, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -376.899, Loss = 373.516
[2018-06-04 19:27] Train Step 32875, Epoch 30.4, Batch Size = 256, Examples/Sec = 3805.22, Train LB = -373.245, Loss = 372.640
[2018-06-04 19:27] Train Step 32900, Epoch 30.5, Batch Size = 256, Examples/Sec = 3856.69, Train LB = -363.179, Loss = 371.848
[2018-06-04 19:27] Train Step 32925, Epoch 30.5, Batch Size = 256, Examples/Sec = 3871.33, Train LB = -381.797, Loss = 371.123
[2018-06-04 19:27] Train Step 32950, Epoch 30.5, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -376.817, Loss = 371.605
[2018-06-04 19:27] Train Step 32975, Epoch 30.5, Batch Size = 256, Examples/Sec = 3871.22, Train LB = -384.438, Loss = 373.512
[2018-06-04 19:27] Train Step 33000, Epoch 30.6, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -396.006, Loss = 375.126
Performance on test set:
  Test Lower Bound = -403.801, Test Loss = 403.801
[2018-06-04 19:27] Train Step 33025, Epoch 30.6, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -389.440, Loss = 374.237
[2018-06-04 19:27] Train Step 33050, Epoch 30.6, Batch Size = 256, Examples/Sec = 3871.45, Train LB = -367.594, Loss = 373.462
[2018-06-04 19:27] Train Step 33075, Epoch 30.6, Batch Size = 256, Examples/Sec = 3873.26, Train LB = -363.426, Loss = 372.888
[2018-06-04 19:27] Train Step 33100, Epoch 30.6, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -367.890, Loss = 372.281
[2018-06-04 19:27] Train Step 33125, Epoch 30.7, Batch Size = 256, Examples/Sec = 3828.38, Train LB = -385.073, Loss = 371.908
[2018-06-04 19:27] Train Step 33150, Epoch 30.7, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -374.777, Loss = 372.687
[2018-06-04 19:27] Train Step 33175, Epoch 30.7, Batch Size = 256, Examples/Sec = 3809.47, Train LB = -392.466, Loss = 373.221
[2018-06-04 19:28] Train Step 33200, Epoch 30.7, Batch Size = 256, Examples/Sec = 3850.79, Train LB = -394.081, Loss = 375.266
Performance on test set:
  Test Lower Bound = -403.120, Test Loss = 403.120
[2018-06-04 19:28] Train Step 33225, Epoch 30.8, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -378.018, Loss = 375.115
[2018-06-04 19:28] Train Step 33250, Epoch 30.8, Batch Size = 256, Examples/Sec = 3871.21, Train LB = -371.532, Loss = 373.882
[2018-06-04 19:28] Train Step 33275, Epoch 30.8, Batch Size = 256, Examples/Sec = 3857.63, Train LB = -368.983, Loss = 372.875
[2018-06-04 19:28] Train Step 33300, Epoch 30.8, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -382.025, Loss = 372.054
[2018-06-04 19:28] Train Step 33325, Epoch 30.9, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -379.881, Loss = 372.592
[2018-06-04 19:28] Train Step 33350, Epoch 30.9, Batch Size = 256, Examples/Sec = 3871.39, Train LB = -376.935, Loss = 373.178
[2018-06-04 19:28] Train Step 33375, Epoch 30.9, Batch Size = 256, Examples/Sec = 3876.25, Train LB = -380.066, Loss = 373.912
[2018-06-04 19:28] Train Step 33400, Epoch 30.9, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -398.614, Loss = 376.015
Performance on test set:
  Test Lower Bound = -403.890, Test Loss = 403.890
[2018-06-04 19:28] Train Step 33425, Epoch 30.9, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -377.069, Loss = 375.466
[2018-06-04 19:28] Train Step 33450, Epoch 31.0, Batch Size = 256, Examples/Sec = 3741.16, Train LB = -363.662, Loss = 374.106
[2018-06-04 19:28] Train Step 33475, Epoch 31.0, Batch Size = 256, Examples/Sec = 3868.41, Train LB = -361.897, Loss = 373.080
[2018-06-04 19:28] Train Step 33500, Epoch 31.0, Batch Size = 256, Examples/Sec = 3819.87, Train LB = -390.010, Loss = 372.606
[2018-06-04 19:28] Train Step 33525, Epoch 31.0, Batch Size = 256, Examples/Sec = 3744.44, Train LB = -353.489, Loss = 372.474
[2018-06-04 19:28] Train Step 33550, Epoch 31.1, Batch Size = 256, Examples/Sec = 3840.55, Train LB = -365.417, Loss = 371.474
[2018-06-04 19:28] Train Step 33575, Epoch 31.1, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -382.338, Loss = 372.178
[2018-06-04 19:28] Train Step 33600, Epoch 31.1, Batch Size = 256, Examples/Sec = 3784.69, Train LB = -384.048, Loss = 374.335
Performance on test set:
  Test Lower Bound = -402.257, Test Loss = 402.257
[2018-06-04 19:28] Train Step 33625, Epoch 31.1, Batch Size = 256, Examples/Sec = 3860.48, Train LB = -379.106, Loss = 373.891
[2018-06-04 19:28] Train Step 33650, Epoch 31.2, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -369.015, Loss = 373.099
[2018-06-04 19:28] Train Step 33675, Epoch 31.2, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -365.171, Loss = 372.024
[2018-06-04 19:28] Train Step 33700, Epoch 31.2, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -371.211, Loss = 370.698
[2018-06-04 19:28] Train Step 33725, Epoch 31.2, Batch Size = 256, Examples/Sec = 3845.11, Train LB = -382.732, Loss = 370.666
[2018-06-04 19:28] Train Step 33750, Epoch 31.2, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -362.087, Loss = 371.745
[2018-06-04 19:28] Train Step 33775, Epoch 31.3, Batch Size = 256, Examples/Sec = 3855.88, Train LB = -374.737, Loss = 372.447
[2018-06-04 19:28] Train Step 33800, Epoch 31.3, Batch Size = 256, Examples/Sec = 3860.35, Train LB = -398.445, Loss = 373.882
Performance on test set:
  Test Lower Bound = -403.004, Test Loss = 403.004
[2018-06-04 19:28] Train Step 33825, Epoch 31.3, Batch Size = 256, Examples/Sec = 3788.22, Train LB = -376.674, Loss = 372.981
[2018-06-04 19:28] Train Step 33850, Epoch 31.3, Batch Size = 256, Examples/Sec = 3850.61, Train LB = -363.389, Loss = 372.582
[2018-06-04 19:29] Train Step 33875, Epoch 31.4, Batch Size = 256, Examples/Sec = 3839.69, Train LB = -386.010, Loss = 371.981
[2018-06-04 19:29] Train Step 33900, Epoch 31.4, Batch Size = 256, Examples/Sec = 3807.31, Train LB = -369.030, Loss = 370.980
[2018-06-04 19:29] Train Step 33925, Epoch 31.4, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -376.901, Loss = 370.200
[2018-06-04 19:29] Train Step 33950, Epoch 31.4, Batch Size = 256, Examples/Sec = 3834.86, Train LB = -382.771, Loss = 370.329
[2018-06-04 19:29] Train Step 33975, Epoch 31.5, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -387.431, Loss = 371.675
[2018-06-04 19:29] Train Step 34000, Epoch 31.5, Batch Size = 256, Examples/Sec = 3846.51, Train LB = -388.791, Loss = 374.165
Performance on test set:
  Test Lower Bound = -402.532, Test Loss = 402.532
[2018-06-04 19:29] Train Step 34025, Epoch 31.5, Batch Size = 256, Examples/Sec = 3856.30, Train LB = -366.133, Loss = 372.984
[2018-06-04 19:29] Train Step 34050, Epoch 31.5, Batch Size = 256, Examples/Sec = 3852.76, Train LB = -377.097, Loss = 372.930
[2018-06-04 19:29] Train Step 34075, Epoch 31.6, Batch Size = 256, Examples/Sec = 3835.72, Train LB = -352.735, Loss = 371.457
[2018-06-04 19:29] Train Step 34100, Epoch 31.6, Batch Size = 256, Examples/Sec = 3848.92, Train LB = -373.513, Loss = 371.135
[2018-06-04 19:29] Train Step 34125, Epoch 31.6, Batch Size = 256, Examples/Sec = 3862.81, Train LB = -371.739, Loss = 370.981
[2018-06-04 19:29] Train Step 34150, Epoch 31.6, Batch Size = 256, Examples/Sec = 3873.75, Train LB = -374.268, Loss = 371.034
[2018-06-04 19:29] Train Step 34175, Epoch 31.6, Batch Size = 256, Examples/Sec = 3888.28, Train LB = -379.729, Loss = 371.845
[2018-06-04 19:29] Train Step 34200, Epoch 31.7, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -392.646, Loss = 374.250
Performance on test set:
  Test Lower Bound = -403.004, Test Loss = 403.004
[2018-06-04 19:29] Train Step 34225, Epoch 31.7, Batch Size = 256, Examples/Sec = 3818.39, Train LB = -365.791, Loss = 373.473
[2018-06-04 19:29] Train Step 34250, Epoch 31.7, Batch Size = 256, Examples/Sec = 3763.11, Train LB = -358.547, Loss = 372.411
[2018-06-04 19:29] Train Step 34275, Epoch 31.7, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -386.471, Loss = 371.282
[2018-06-04 19:29] Train Step 34300, Epoch 31.8, Batch Size = 256, Examples/Sec = 3874.91, Train LB = -387.446, Loss = 371.022
[2018-06-04 19:29] Train Step 34325, Epoch 31.8, Batch Size = 256, Examples/Sec = 3746.09, Train LB = -377.192, Loss = 370.577
[2018-06-04 19:29] Train Step 34350, Epoch 31.8, Batch Size = 256, Examples/Sec = 3832.86, Train LB = -366.194, Loss = 370.744
[2018-06-04 19:29] Train Step 34375, Epoch 31.8, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -363.600, Loss = 372.060
[2018-06-04 19:29] Train Step 34400, Epoch 31.9, Batch Size = 256, Examples/Sec = 3762.55, Train LB = -385.907, Loss = 373.986
Performance on test set:
  Test Lower Bound = -403.181, Test Loss = 403.181
[2018-06-04 19:29] Train Step 34425, Epoch 31.9, Batch Size = 256, Examples/Sec = 3859.66, Train LB = -358.999, Loss = 373.074
[2018-06-04 19:29] Train Step 34450, Epoch 31.9, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -364.234, Loss = 372.238
[2018-06-04 19:29] Train Step 34475, Epoch 31.9, Batch Size = 256, Examples/Sec = 3855.53, Train LB = -372.778, Loss = 371.420
[2018-06-04 19:29] Train Step 34500, Epoch 31.9, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -353.826, Loss = 370.267
[2018-06-04 19:29] Train Step 34525, Epoch 32.0, Batch Size = 256, Examples/Sec = 3863.87, Train LB = -369.829, Loss = 370.337
[2018-06-04 19:29] Train Step 34550, Epoch 32.0, Batch Size = 256, Examples/Sec = 3850.32, Train LB = -370.446, Loss = 370.859
[2018-06-04 19:29] Train Step 34575, Epoch 32.0, Batch Size = 256, Examples/Sec = 3850.66, Train LB = -372.063, Loss = 371.399
[2018-06-04 19:29] Train Step 34600, Epoch 32.0, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -377.896, Loss = 373.872
Performance on test set:
  Test Lower Bound = -403.481, Test Loss = 403.481
[2018-06-04 19:30] Train Step 34625, Epoch 32.1, Batch Size = 256, Examples/Sec = 3858.56, Train LB = -360.376, Loss = 373.156
[2018-06-04 19:30] Train Step 34650, Epoch 32.1, Batch Size = 256, Examples/Sec = 3869.47, Train LB = -381.947, Loss = 371.661
[2018-06-04 19:30] Train Step 34675, Epoch 32.1, Batch Size = 256, Examples/Sec = 3870.99, Train LB = -381.038, Loss = 371.279
[2018-06-04 19:30] Train Step 34700, Epoch 32.1, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -374.394, Loss = 370.778
[2018-06-04 19:30] Train Step 34725, Epoch 32.2, Batch Size = 256, Examples/Sec = 3875.33, Train LB = -368.461, Loss = 370.769
[2018-06-04 19:30] Train Step 34750, Epoch 32.2, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -362.998, Loss = 370.191
[2018-06-04 19:30] Train Step 34775, Epoch 32.2, Batch Size = 256, Examples/Sec = 3867.29, Train LB = -358.954, Loss = 371.102
[2018-06-04 19:30] Train Step 34800, Epoch 32.2, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -379.248, Loss = 373.341
Performance on test set:
  Test Lower Bound = -404.086, Test Loss = 404.087
[2018-06-04 19:30] Train Step 34825, Epoch 32.2, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -374.798, Loss = 372.593
[2018-06-04 19:30] Train Step 34850, Epoch 32.3, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -367.285, Loss = 372.390
[2018-06-04 19:30] Train Step 34875, Epoch 32.3, Batch Size = 256, Examples/Sec = 3837.16, Train LB = -381.853, Loss = 370.969
[2018-06-04 19:30] Train Step 34900, Epoch 32.3, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -363.819, Loss = 369.769
[2018-06-04 19:30] Train Step 34925, Epoch 32.3, Batch Size = 256, Examples/Sec = 3842.86, Train LB = -367.552, Loss = 369.877
[2018-06-04 19:30] Train Step 34950, Epoch 32.4, Batch Size = 256, Examples/Sec = 3848.18, Train LB = -368.887, Loss = 370.004
[2018-06-04 19:30] Train Step 34975, Epoch 32.4, Batch Size = 256, Examples/Sec = 3833.44, Train LB = -370.370, Loss = 370.713
[2018-06-04 19:30] Train Step 35000, Epoch 32.4, Batch Size = 256, Examples/Sec = 3869.19, Train LB = -396.695, Loss = 373.099
Performance on test set:
  Test Lower Bound = -403.086, Test Loss = 403.086
[2018-06-04 19:30] Train Step 35025, Epoch 32.4, Batch Size = 256, Examples/Sec = 3843.27, Train LB = -357.610, Loss = 372.577
[2018-06-04 19:30] Train Step 35050, Epoch 32.5, Batch Size = 256, Examples/Sec = 3752.12, Train LB = -363.552, Loss = 371.520
[2018-06-04 19:30] Train Step 35075, Epoch 32.5, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -373.040, Loss = 370.447
[2018-06-04 19:30] Train Step 35100, Epoch 32.5, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -362.482, Loss = 369.832
[2018-06-04 19:30] Train Step 35125, Epoch 32.5, Batch Size = 256, Examples/Sec = 3734.46, Train LB = -376.244, Loss = 369.558
[2018-06-04 19:30] Train Step 35150, Epoch 32.5, Batch Size = 256, Examples/Sec = 3831.59, Train LB = -385.339, Loss = 369.790
[2018-06-04 19:30] Train Step 35175, Epoch 32.6, Batch Size = 256, Examples/Sec = 3870.16, Train LB = -378.314, Loss = 371.114
[2018-06-04 19:30] Train Step 35200, Epoch 32.6, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -382.631, Loss = 373.257
Performance on test set:
  Test Lower Bound = -403.919, Test Loss = 403.919
[2018-06-04 19:30] Train Step 35225, Epoch 32.6, Batch Size = 256, Examples/Sec = 3848.01, Train LB = -368.476, Loss = 372.386
[2018-06-04 19:30] Train Step 35250, Epoch 32.6, Batch Size = 256, Examples/Sec = 3884.61, Train LB = -366.624, Loss = 372.425
[2018-06-04 19:30] Train Step 35275, Epoch 32.7, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -368.505, Loss = 371.235
[2018-06-04 19:30] Train Step 35300, Epoch 32.7, Batch Size = 256, Examples/Sec = 3836.41, Train LB = -375.018, Loss = 370.099
[2018-06-04 19:31] Train Step 35325, Epoch 32.7, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -371.109, Loss = 370.021
[2018-06-04 19:31] Train Step 35350, Epoch 32.7, Batch Size = 256, Examples/Sec = 3869.70, Train LB = -375.198, Loss = 370.189
[2018-06-04 19:31] Train Step 35375, Epoch 32.8, Batch Size = 256, Examples/Sec = 3720.54, Train LB = -367.465, Loss = 371.401
[2018-06-04 19:31] Train Step 35400, Epoch 32.8, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -393.763, Loss = 373.061
Performance on test set:
  Test Lower Bound = -404.728, Test Loss = 404.728
[2018-06-04 19:31] Train Step 35425, Epoch 32.8, Batch Size = 256, Examples/Sec = 3874.39, Train LB = -362.952, Loss = 373.368
[2018-06-04 19:31] Train Step 35450, Epoch 32.8, Batch Size = 256, Examples/Sec = 3868.06, Train LB = -361.781, Loss = 372.096
[2018-06-04 19:31] Train Step 35475, Epoch 32.8, Batch Size = 256, Examples/Sec = 3815.48, Train LB = -365.858, Loss = 370.642
[2018-06-04 19:31] Train Step 35500, Epoch 32.9, Batch Size = 256, Examples/Sec = 3866.66, Train LB = -369.535, Loss = 369.416
[2018-06-04 19:31] Train Step 35525, Epoch 32.9, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -361.433, Loss = 369.401
[2018-06-04 19:31] Train Step 35550, Epoch 32.9, Batch Size = 256, Examples/Sec = 3842.70, Train LB = -356.978, Loss = 369.329
[2018-06-04 19:31] Train Step 35575, Epoch 32.9, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -378.350, Loss = 370.198
[2018-06-04 19:31] Train Step 35600, Epoch 33.0, Batch Size = 256, Examples/Sec = 3874.03, Train LB = -385.983, Loss = 372.461
Performance on test set:
  Test Lower Bound = -404.002, Test Loss = 404.002
[2018-06-04 19:31] Train Step 35625, Epoch 33.0, Batch Size = 256, Examples/Sec = 3844.76, Train LB = -388.257, Loss = 372.234
[2018-06-04 19:31] Train Step 35650, Epoch 33.0, Batch Size = 256, Examples/Sec = 3869.23, Train LB = -363.872, Loss = 371.521
[2018-06-04 19:31] Train Step 35675, Epoch 33.0, Batch Size = 256, Examples/Sec = 3875.15, Train LB = -370.442, Loss = 369.931
[2018-06-04 19:31] Train Step 35700, Epoch 33.1, Batch Size = 256, Examples/Sec = 3852.28, Train LB = -373.513, Loss = 368.866
[2018-06-04 19:31] Train Step 35725, Epoch 33.1, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -377.117, Loss = 368.164
[2018-06-04 19:31] Train Step 35750, Epoch 33.1, Batch Size = 256, Examples/Sec = 3838.88, Train LB = -359.918, Loss = 368.183
[2018-06-04 19:31] Train Step 35775, Epoch 33.1, Batch Size = 256, Examples/Sec = 3843.96, Train LB = -368.241, Loss = 370.512
[2018-06-04 19:31] Train Step 35800, Epoch 33.1, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -386.490, Loss = 373.043
Performance on test set:
  Test Lower Bound = -403.626, Test Loss = 403.626
[2018-06-04 19:31] Train Step 35825, Epoch 33.2, Batch Size = 256, Examples/Sec = 3874.51, Train LB = -362.268, Loss = 372.054
[2018-06-04 19:31] Train Step 35850, Epoch 33.2, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -368.340, Loss = 372.122
[2018-06-04 19:31] Train Step 35875, Epoch 33.2, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -363.934, Loss = 370.651
[2018-06-04 19:31] Train Step 35900, Epoch 33.2, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -375.048, Loss = 370.371
[2018-06-04 19:31] Train Step 35925, Epoch 33.3, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -364.388, Loss = 370.740
[2018-06-04 19:31] Train Step 35950, Epoch 33.3, Batch Size = 256, Examples/Sec = 3862.46, Train LB = -361.773, Loss = 370.080
[2018-06-04 19:31] Train Step 35975, Epoch 33.3, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -368.769, Loss = 369.915
[2018-06-04 19:31] Train Step 36000, Epoch 33.3, Batch Size = 256, Examples/Sec = 3859.42, Train LB = -384.467, Loss = 372.532
Performance on test set:
  Test Lower Bound = -403.477, Test Loss = 403.477
[2018-06-04 19:32] Train Step 36025, Epoch 33.4, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -380.840, Loss = 371.423
[2018-06-04 19:32] Train Step 36050, Epoch 33.4, Batch Size = 256, Examples/Sec = 3852.17, Train LB = -367.967, Loss = 370.528
[2018-06-04 19:32] Train Step 36075, Epoch 33.4, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -366.216, Loss = 369.214
[2018-06-04 19:32] Train Step 36100, Epoch 33.4, Batch Size = 256, Examples/Sec = 3773.80, Train LB = -362.013, Loss = 368.945
[2018-06-04 19:32] Train Step 36125, Epoch 33.4, Batch Size = 256, Examples/Sec = 3847.88, Train LB = -382.836, Loss = 368.894
[2018-06-04 19:32] Train Step 36150, Epoch 33.5, Batch Size = 256, Examples/Sec = 3866.90, Train LB = -377.537, Loss = 369.442
[2018-06-04 19:32] Train Step 36175, Epoch 33.5, Batch Size = 256, Examples/Sec = 3729.98, Train LB = -365.376, Loss = 370.033
[2018-06-04 19:32] Train Step 36200, Epoch 33.5, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -391.451, Loss = 372.053
Performance on test set:
  Test Lower Bound = -405.321, Test Loss = 405.321
[2018-06-04 19:32] Train Step 36225, Epoch 33.5, Batch Size = 256, Examples/Sec = 3866.94, Train LB = -385.265, Loss = 371.803
[2018-06-04 19:32] Train Step 36250, Epoch 33.6, Batch Size = 256, Examples/Sec = 3873.63, Train LB = -354.775, Loss = 371.498
[2018-06-04 19:32] Train Step 36275, Epoch 33.6, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -356.068, Loss = 370.431
[2018-06-04 19:32] Train Step 36300, Epoch 33.6, Batch Size = 256, Examples/Sec = 3878.27, Train LB = -362.199, Loss = 369.903
[2018-06-04 19:32] Train Step 36325, Epoch 33.6, Batch Size = 256, Examples/Sec = 3858.73, Train LB = -374.382, Loss = 369.315
[2018-06-04 19:32] Train Step 36350, Epoch 33.7, Batch Size = 256, Examples/Sec = 3851.06, Train LB = -383.957, Loss = 369.185
[2018-06-04 19:32] Train Step 36375, Epoch 33.7, Batch Size = 256, Examples/Sec = 3868.82, Train LB = -360.535, Loss = 370.626
[2018-06-04 19:32] Train Step 36400, Epoch 33.7, Batch Size = 256, Examples/Sec = 3851.26, Train LB = -394.925, Loss = 371.799
Performance on test set:
  Test Lower Bound = -403.335, Test Loss = 403.335
[2018-06-04 19:32] Train Step 36425, Epoch 33.7, Batch Size = 256, Examples/Sec = 3846.33, Train LB = -362.898, Loss = 371.367
[2018-06-04 19:32] Train Step 36450, Epoch 33.8, Batch Size = 256, Examples/Sec = 3837.79, Train LB = -362.666, Loss = 370.333
[2018-06-04 19:32] Train Step 36475, Epoch 33.8, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -362.685, Loss = 369.928
[2018-06-04 19:32] Train Step 36500, Epoch 33.8, Batch Size = 256, Examples/Sec = 3869.30, Train LB = -356.593, Loss = 369.199
[2018-06-04 19:32] Train Step 36525, Epoch 33.8, Batch Size = 256, Examples/Sec = 3834.52, Train LB = -364.594, Loss = 368.791
[2018-06-04 19:32] Train Step 36550, Epoch 33.8, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -369.753, Loss = 368.745
[2018-06-04 19:32] Train Step 36575, Epoch 33.9, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -387.380, Loss = 369.590
[2018-06-04 19:32] Train Step 36600, Epoch 33.9, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -386.595, Loss = 372.363
Performance on test set:
  Test Lower Bound = -404.249, Test Loss = 404.249
[2018-06-04 19:32] Train Step 36625, Epoch 33.9, Batch Size = 256, Examples/Sec = 3874.27, Train LB = -374.917, Loss = 371.285
[2018-06-04 19:32] Train Step 36650, Epoch 33.9, Batch Size = 256, Examples/Sec = 3751.46, Train LB = -372.016, Loss = 369.993
[2018-06-04 19:32] Train Step 36675, Epoch 34.0, Batch Size = 256, Examples/Sec = 3874.67, Train LB = -382.057, Loss = 368.911
[2018-06-04 19:32] Train Step 36700, Epoch 34.0, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -364.049, Loss = 368.435
[2018-06-04 19:32] Train Step 36725, Epoch 34.0, Batch Size = 256, Examples/Sec = 3754.05, Train LB = -365.145, Loss = 367.843
[2018-06-04 19:33] Train Step 36750, Epoch 34.0, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -376.559, Loss = 368.429
[2018-06-04 19:33] Train Step 36775, Epoch 34.1, Batch Size = 256, Examples/Sec = 3848.07, Train LB = -373.989, Loss = 370.033
[2018-06-04 19:33] Train Step 36800, Epoch 34.1, Batch Size = 256, Examples/Sec = 3718.02, Train LB = -375.506, Loss = 371.779
Performance on test set:
  Test Lower Bound = -406.020, Test Loss = 406.020
[2018-06-04 19:33] Train Step 36825, Epoch 34.1, Batch Size = 256, Examples/Sec = 3875.14, Train LB = -358.599, Loss = 371.457
[2018-06-04 19:33] Train Step 36850, Epoch 34.1, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -369.698, Loss = 370.323
[2018-06-04 19:33] Train Step 36875, Epoch 34.1, Batch Size = 256, Examples/Sec = 3874.21, Train LB = -389.541, Loss = 368.670
[2018-06-04 19:33] Train Step 36900, Epoch 34.2, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -365.177, Loss = 367.964
[2018-06-04 19:33] Train Step 36925, Epoch 34.2, Batch Size = 256, Examples/Sec = 3873.46, Train LB = -367.832, Loss = 368.126
[2018-06-04 19:33] Train Step 36950, Epoch 34.2, Batch Size = 256, Examples/Sec = 3878.91, Train LB = -373.838, Loss = 369.037
[2018-06-04 19:33] Train Step 36975, Epoch 34.2, Batch Size = 256, Examples/Sec = 3787.26, Train LB = -393.943, Loss = 369.655
[2018-06-04 19:33] Train Step 37000, Epoch 34.3, Batch Size = 256, Examples/Sec = 3860.83, Train LB = -388.877, Loss = 372.285
Performance on test set:
  Test Lower Bound = -404.636, Test Loss = 404.636
[2018-06-04 19:33] Train Step 37025, Epoch 34.3, Batch Size = 256, Examples/Sec = 3840.97, Train LB = -373.146, Loss = 371.094
[2018-06-04 19:33] Train Step 37050, Epoch 34.3, Batch Size = 256, Examples/Sec = 3883.56, Train LB = -361.134, Loss = 370.651
[2018-06-04 19:33] Train Step 37075, Epoch 34.3, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -357.576, Loss = 369.173
[2018-06-04 19:33] Train Step 37100, Epoch 34.4, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -377.593, Loss = 368.623
[2018-06-04 19:33] Train Step 37125, Epoch 34.4, Batch Size = 256, Examples/Sec = 3869.30, Train LB = -369.464, Loss = 368.717
[2018-06-04 19:33] Train Step 37150, Epoch 34.4, Batch Size = 256, Examples/Sec = 3854.96, Train LB = -376.591, Loss = 369.307
[2018-06-04 19:33] Train Step 37175, Epoch 34.4, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -375.870, Loss = 370.646
[2018-06-04 19:33] Train Step 37200, Epoch 34.4, Batch Size = 256, Examples/Sec = 3873.68, Train LB = -387.411, Loss = 372.235
Performance on test set:
  Test Lower Bound = -406.166, Test Loss = 406.166
[2018-06-04 19:33] Train Step 37225, Epoch 34.5, Batch Size = 256, Examples/Sec = 3813.60, Train LB = -362.302, Loss = 371.945
[2018-06-04 19:33] Train Step 37250, Epoch 34.5, Batch Size = 256, Examples/Sec = 3875.09, Train LB = -352.116, Loss = 370.368
[2018-06-04 19:33] Train Step 37275, Epoch 34.5, Batch Size = 256, Examples/Sec = 3845.75, Train LB = -377.919, Loss = 369.905
[2018-06-04 19:33] Train Step 37300, Epoch 34.5, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -357.306, Loss = 369.823
[2018-06-04 19:33] Train Step 37325, Epoch 34.6, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -361.897, Loss = 368.490
[2018-06-04 19:33] Train Step 37350, Epoch 34.6, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -357.010, Loss = 368.149
[2018-06-04 19:33] Train Step 37375, Epoch 34.6, Batch Size = 256, Examples/Sec = 3872.62, Train LB = -384.563, Loss = 369.333
[2018-06-04 19:33] Train Step 37400, Epoch 34.6, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -393.048, Loss = 371.918
Performance on test set:
  Test Lower Bound = -403.618, Test Loss = 403.618
[2018-06-04 19:33] Train Step 37425, Epoch 34.7, Batch Size = 256, Examples/Sec = 3847.53, Train LB = -365.654, Loss = 370.516
[2018-06-04 19:34] Train Step 37450, Epoch 34.7, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -363.996, Loss = 369.998
[2018-06-04 19:34] Train Step 37475, Epoch 34.7, Batch Size = 256, Examples/Sec = 3872.58, Train LB = -361.079, Loss = 368.344
[2018-06-04 19:34] Train Step 37500, Epoch 34.7, Batch Size = 256, Examples/Sec = 3849.16, Train LB = -377.946, Loss = 367.606
[2018-06-04 19:34] Train Step 37525, Epoch 34.7, Batch Size = 256, Examples/Sec = 3865.44, Train LB = -359.027, Loss = 367.263
[2018-06-04 19:34] Train Step 37550, Epoch 34.8, Batch Size = 256, Examples/Sec = 3863.62, Train LB = -365.170, Loss = 367.282
[2018-06-04 19:34] Train Step 37575, Epoch 34.8, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -360.744, Loss = 369.391
[2018-06-04 19:34] Train Step 37600, Epoch 34.8, Batch Size = 256, Examples/Sec = 3838.43, Train LB = -384.175, Loss = 371.597
Performance on test set:
  Test Lower Bound = -405.170, Test Loss = 405.170
[2018-06-04 19:34] Train Step 37625, Epoch 34.8, Batch Size = 256, Examples/Sec = 3727.97, Train LB = -365.842, Loss = 370.869
[2018-06-04 19:34] Train Step 37650, Epoch 34.9, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -389.449, Loss = 369.701
[2018-06-04 19:34] Train Step 37675, Epoch 34.9, Batch Size = 256, Examples/Sec = 3853.38, Train LB = -364.369, Loss = 368.829
[2018-06-04 19:34] Train Step 37700, Epoch 34.9, Batch Size = 256, Examples/Sec = 3733.90, Train LB = -368.627, Loss = 367.707
[2018-06-04 19:34] Train Step 37725, Epoch 34.9, Batch Size = 256, Examples/Sec = 3840.62, Train LB = -359.156, Loss = 367.534
[2018-06-04 19:34] Train Step 37750, Epoch 35.0, Batch Size = 256, Examples/Sec = 3853.38, Train LB = -370.963, Loss = 368.391
[2018-06-04 19:34] Train Step 37775, Epoch 35.0, Batch Size = 256, Examples/Sec = 3740.93, Train LB = -365.880, Loss = 369.885
[2018-06-04 19:34] Train Step 37800, Epoch 35.0, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -375.821, Loss = 371.350
Performance on test set:
  Test Lower Bound = -406.672, Test Loss = 406.672
[2018-06-04 19:34] Train Step 37825, Epoch 35.0, Batch Size = 256, Examples/Sec = 3864.44, Train LB = -360.587, Loss = 370.398
[2018-06-04 19:34] Train Step 37850, Epoch 35.0, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -369.854, Loss = 369.449
[2018-06-04 19:34] Train Step 37875, Epoch 35.1, Batch Size = 256, Examples/Sec = 3842.00, Train LB = -376.737, Loss = 369.414
[2018-06-04 19:34] Train Step 37900, Epoch 35.1, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -360.290, Loss = 368.396
[2018-06-04 19:34] Train Step 37925, Epoch 35.1, Batch Size = 256, Examples/Sec = 3832.85, Train LB = -378.010, Loss = 367.357
[2018-06-04 19:34] Train Step 37950, Epoch 35.1, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -370.158, Loss = 368.339
[2018-06-04 19:34] Train Step 37975, Epoch 35.2, Batch Size = 256, Examples/Sec = 3884.61, Train LB = -361.867, Loss = 369.642
[2018-06-04 19:34] Train Step 38000, Epoch 35.2, Batch Size = 256, Examples/Sec = 3865.38, Train LB = -384.126, Loss = 372.135
Performance on test set:
  Test Lower Bound = -405.406, Test Loss = 405.406
[2018-06-04 19:34] Train Step 38025, Epoch 35.2, Batch Size = 256, Examples/Sec = 3854.89, Train LB = -362.020, Loss = 371.556
[2018-06-04 19:34] Train Step 38050, Epoch 35.2, Batch Size = 256, Examples/Sec = 3850.14, Train LB = -371.335, Loss = 370.276
[2018-06-04 19:34] Train Step 38075, Epoch 35.3, Batch Size = 256, Examples/Sec = 3824.49, Train LB = -355.190, Loss = 369.487
[2018-06-04 19:34] Train Step 38100, Epoch 35.3, Batch Size = 256, Examples/Sec = 3868.94, Train LB = -370.354, Loss = 369.285
[2018-06-04 19:34] Train Step 38125, Epoch 35.3, Batch Size = 256, Examples/Sec = 3885.33, Train LB = -358.042, Loss = 368.182
[2018-06-04 19:34] Train Step 38150, Epoch 35.3, Batch Size = 256, Examples/Sec = 3863.85, Train LB = -368.530, Loss = 368.373
[2018-06-04 19:34] Train Step 38175, Epoch 35.3, Batch Size = 256, Examples/Sec = 3844.65, Train LB = -370.960, Loss = 369.142
[2018-06-04 19:35] Train Step 38200, Epoch 35.4, Batch Size = 256, Examples/Sec = 3858.61, Train LB = -390.194, Loss = 371.326
Performance on test set:
  Test Lower Bound = -405.535, Test Loss = 405.535
[2018-06-04 19:35] Train Step 38225, Epoch 35.4, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -361.439, Loss = 370.582
[2018-06-04 19:35] Train Step 38250, Epoch 35.4, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -376.463, Loss = 369.223
[2018-06-04 19:35] Train Step 38275, Epoch 35.4, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -364.812, Loss = 368.472
[2018-06-04 19:35] Train Step 38300, Epoch 35.5, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -360.715, Loss = 368.064
[2018-06-04 19:35] Train Step 38325, Epoch 35.5, Batch Size = 256, Examples/Sec = 3879.43, Train LB = -354.421, Loss = 367.846
[2018-06-04 19:35] Train Step 38350, Epoch 35.5, Batch Size = 256, Examples/Sec = 3866.01, Train LB = -364.707, Loss = 367.863
[2018-06-04 19:35] Train Step 38375, Epoch 35.5, Batch Size = 256, Examples/Sec = 3796.19, Train LB = -370.315, Loss = 368.952
[2018-06-04 19:35] Train Step 38400, Epoch 35.6, Batch Size = 256, Examples/Sec = 3878.66, Train LB = -372.748, Loss = 370.768
Performance on test set:
  Test Lower Bound = -405.074, Test Loss = 405.074
[2018-06-04 19:35] Train Step 38425, Epoch 35.6, Batch Size = 256, Examples/Sec = 3741.60, Train LB = -369.625, Loss = 369.931
[2018-06-04 19:35] Train Step 38450, Epoch 35.6, Batch Size = 256, Examples/Sec = 3873.33, Train LB = -343.310, Loss = 369.299
[2018-06-04 19:35] Train Step 38475, Epoch 35.6, Batch Size = 256, Examples/Sec = 3814.29, Train LB = -373.406, Loss = 367.886
[2018-06-04 19:35] Train Step 38500, Epoch 35.6, Batch Size = 256, Examples/Sec = 3822.26, Train LB = -363.081, Loss = 367.229
[2018-06-04 19:35] Train Step 38525, Epoch 35.7, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -381.658, Loss = 367.688
[2018-06-04 19:35] Train Step 38550, Epoch 35.7, Batch Size = 256, Examples/Sec = 3873.75, Train LB = -374.488, Loss = 368.081
[2018-06-04 19:35] Train Step 38575, Epoch 35.7, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -375.222, Loss = 369.188
[2018-06-04 19:35] Train Step 38600, Epoch 35.7, Batch Size = 256, Examples/Sec = 3843.26, Train LB = -376.240, Loss = 371.457
Performance on test set:
  Test Lower Bound = -404.773, Test Loss = 404.773
[2018-06-04 19:35] Train Step 38625, Epoch 35.8, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -359.433, Loss = 370.244
[2018-06-04 19:35] Train Step 38650, Epoch 35.8, Batch Size = 256, Examples/Sec = 3856.75, Train LB = -362.172, Loss = 369.767
[2018-06-04 19:35] Train Step 38675, Epoch 35.8, Batch Size = 256, Examples/Sec = 3849.46, Train LB = -365.915, Loss = 368.430
[2018-06-04 19:35] Train Step 38700, Epoch 35.8, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -344.710, Loss = 366.837
[2018-06-04 19:35] Train Step 38725, Epoch 35.9, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -377.060, Loss = 366.336
[2018-06-04 19:35] Train Step 38750, Epoch 35.9, Batch Size = 256, Examples/Sec = 3750.15, Train LB = -346.733, Loss = 366.879
[2018-06-04 19:35] Train Step 38775, Epoch 35.9, Batch Size = 256, Examples/Sec = 3796.93, Train LB = -378.188, Loss = 368.130
[2018-06-04 19:35] Train Step 38800, Epoch 35.9, Batch Size = 256, Examples/Sec = 3845.28, Train LB = -368.719, Loss = 371.169
Performance on test set:
  Test Lower Bound = -404.837, Test Loss = 404.837
[2018-06-04 19:35] Train Step 38825, Epoch 35.9, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -372.283, Loss = 370.341
[2018-06-04 19:35] Train Step 38850, Epoch 36.0, Batch Size = 256, Examples/Sec = 3815.48, Train LB = -349.408, Loss = 369.446
[2018-06-04 19:36] Train Step 38875, Epoch 36.0, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -356.847, Loss = 368.091
[2018-06-04 19:36] Train Step 38900, Epoch 36.0, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -380.934, Loss = 367.678
[2018-06-04 19:36] Train Step 38925, Epoch 36.0, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -343.704, Loss = 366.846
[2018-06-04 19:36] Train Step 38950, Epoch 36.1, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -374.416, Loss = 367.180
[2018-06-04 19:36] Train Step 38975, Epoch 36.1, Batch Size = 256, Examples/Sec = 3864.02, Train LB = -366.171, Loss = 368.702
[2018-06-04 19:36] Train Step 39000, Epoch 36.1, Batch Size = 256, Examples/Sec = 3874.21, Train LB = -394.935, Loss = 371.363
Performance on test set:
  Test Lower Bound = -404.914, Test Loss = 404.914
[2018-06-04 19:36] Train Step 39025, Epoch 36.1, Batch Size = 256, Examples/Sec = 3879.38, Train LB = -365.226, Loss = 370.223
[2018-06-04 19:36] Train Step 39050, Epoch 36.2, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -368.058, Loss = 369.493
[2018-06-04 19:36] Train Step 39075, Epoch 36.2, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -363.840, Loss = 368.207
[2018-06-04 19:36] Train Step 39100, Epoch 36.2, Batch Size = 256, Examples/Sec = 3820.10, Train LB = -362.343, Loss = 367.117
[2018-06-04 19:36] Train Step 39125, Epoch 36.2, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -375.678, Loss = 366.391
[2018-06-04 19:36] Train Step 39150, Epoch 36.2, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -365.430, Loss = 366.460
[2018-06-04 19:36] Train Step 39175, Epoch 36.3, Batch Size = 256, Examples/Sec = 3870.76, Train LB = -379.115, Loss = 367.931
[2018-06-04 19:36] Train Step 39200, Epoch 36.3, Batch Size = 256, Examples/Sec = 3847.60, Train LB = -384.604, Loss = 370.197
Performance on test set:
  Test Lower Bound = -404.897, Test Loss = 404.897
[2018-06-04 19:36] Train Step 39225, Epoch 36.3, Batch Size = 256, Examples/Sec = 3824.44, Train LB = -369.758, Loss = 369.414
[2018-06-04 19:36] Train Step 39250, Epoch 36.3, Batch Size = 256, Examples/Sec = 3857.58, Train LB = -367.388, Loss = 368.385
[2018-06-04 19:36] Train Step 39275, Epoch 36.4, Batch Size = 256, Examples/Sec = 3844.25, Train LB = -366.082, Loss = 367.764
[2018-06-04 19:36] Train Step 39300, Epoch 36.4, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -367.492, Loss = 367.492
[2018-06-04 19:36] Train Step 39325, Epoch 36.4, Batch Size = 256, Examples/Sec = 3818.96, Train LB = -369.672, Loss = 366.867
[2018-06-04 19:36] Train Step 39350, Epoch 36.4, Batch Size = 256, Examples/Sec = 3871.63, Train LB = -364.695, Loss = 367.020
[2018-06-04 19:36] Train Step 39375, Epoch 36.5, Batch Size = 256, Examples/Sec = 3853.44, Train LB = -374.932, Loss = 368.342
[2018-06-04 19:36] Train Step 39400, Epoch 36.5, Batch Size = 256, Examples/Sec = 3862.81, Train LB = -378.382, Loss = 370.552
Performance on test set:
  Test Lower Bound = -406.039, Test Loss = 406.039
[2018-06-04 19:36] Train Step 39425, Epoch 36.5, Batch Size = 256, Examples/Sec = 3805.38, Train LB = -376.807, Loss = 369.592
[2018-06-04 19:36] Train Step 39450, Epoch 36.5, Batch Size = 256, Examples/Sec = 3872.62, Train LB = -366.020, Loss = 369.224
[2018-06-04 19:36] Train Step 39475, Epoch 36.6, Batch Size = 256, Examples/Sec = 3797.71, Train LB = -353.095, Loss = 368.094
[2018-06-04 19:36] Train Step 39500, Epoch 36.6, Batch Size = 256, Examples/Sec = 3824.26, Train LB = -366.843, Loss = 367.068
[2018-06-04 19:36] Train Step 39525, Epoch 36.6, Batch Size = 256, Examples/Sec = 3858.26, Train LB = -360.637, Loss = 366.612
[2018-06-04 19:36] Train Step 39550, Epoch 36.6, Batch Size = 256, Examples/Sec = 3758.90, Train LB = -378.966, Loss = 366.893
[2018-06-04 19:36] Train Step 39575, Epoch 36.6, Batch Size = 256, Examples/Sec = 3850.68, Train LB = -364.524, Loss = 367.958
[2018-06-04 19:36] Train Step 39600, Epoch 36.7, Batch Size = 256, Examples/Sec = 3885.92, Train LB = -385.232, Loss = 370.711
Performance on test set:
  Test Lower Bound = -406.624, Test Loss = 406.624
[2018-06-04 19:37] Train Step 39625, Epoch 36.7, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -347.902, Loss = 370.237
[2018-06-04 19:37] Train Step 39650, Epoch 36.7, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -359.716, Loss = 369.144
[2018-06-04 19:37] Train Step 39675, Epoch 36.7, Batch Size = 256, Examples/Sec = 3880.13, Train LB = -356.147, Loss = 367.819
[2018-06-04 19:37] Train Step 39700, Epoch 36.8, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -358.375, Loss = 366.404
[2018-06-04 19:37] Train Step 39725, Epoch 36.8, Batch Size = 256, Examples/Sec = 3816.98, Train LB = -369.452, Loss = 366.276
[2018-06-04 19:37] Train Step 39750, Epoch 36.8, Batch Size = 256, Examples/Sec = 3858.80, Train LB = -368.974, Loss = 366.786
[2018-06-04 19:37] Train Step 39775, Epoch 36.8, Batch Size = 256, Examples/Sec = 3870.27, Train LB = -378.715, Loss = 367.572
[2018-06-04 19:37] Train Step 39800, Epoch 36.9, Batch Size = 256, Examples/Sec = 3887.86, Train LB = -368.747, Loss = 370.262
Performance on test set:
  Test Lower Bound = -405.304, Test Loss = 405.304
[2018-06-04 19:37] Train Step 39825, Epoch 36.9, Batch Size = 256, Examples/Sec = 3863.67, Train LB = -358.296, Loss = 369.715
[2018-06-04 19:37] Train Step 39850, Epoch 36.9, Batch Size = 256, Examples/Sec = 3865.38, Train LB = -370.230, Loss = 368.664
[2018-06-04 19:37] Train Step 39875, Epoch 36.9, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -361.557, Loss = 368.231
[2018-06-04 19:37] Train Step 39900, Epoch 36.9, Batch Size = 256, Examples/Sec = 3850.97, Train LB = -370.888, Loss = 366.975
[2018-06-04 19:37] Train Step 39925, Epoch 37.0, Batch Size = 256, Examples/Sec = 3849.50, Train LB = -375.214, Loss = 366.594
[2018-06-04 19:37] Train Step 39950, Epoch 37.0, Batch Size = 256, Examples/Sec = 3855.71, Train LB = -368.304, Loss = 365.815
[2018-06-04 19:37] Train Step 39975, Epoch 37.0, Batch Size = 256, Examples/Sec = 3871.92, Train LB = -369.356, Loss = 367.268
[2018-06-04 19:37] Train Step 40000, Epoch 37.0, Batch Size = 256, Examples/Sec = 3871.40, Train LB = -383.711, Loss = 370.094
Performance on test set:
  Test Lower Bound = -405.651, Test Loss = 405.651
[2018-06-04 19:37] Train Step 40025, Epoch 37.1, Batch Size = 256, Examples/Sec = 3855.58, Train LB = -359.388, Loss = 369.676
[2018-06-04 19:37] Train Step 40050, Epoch 37.1, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -365.812, Loss = 368.561
[2018-06-04 19:37] Train Step 40075, Epoch 37.1, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -366.827, Loss = 367.541
[2018-06-04 19:37] Train Step 40100, Epoch 37.1, Batch Size = 256, Examples/Sec = 3863.21, Train LB = -361.140, Loss = 366.773
[2018-06-04 19:37] Train Step 40125, Epoch 37.2, Batch Size = 256, Examples/Sec = 3850.15, Train LB = -368.042, Loss = 366.119
[2018-06-04 19:37] Train Step 40150, Epoch 37.2, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -374.257, Loss = 365.850
[2018-06-04 19:37] Train Step 40175, Epoch 37.2, Batch Size = 256, Examples/Sec = 3861.99, Train LB = -368.100, Loss = 367.215
[2018-06-04 19:37] Train Step 40200, Epoch 37.2, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -389.088, Loss = 369.954
Performance on test set:
  Test Lower Bound = -405.891, Test Loss = 405.891
[2018-06-04 19:37] Train Step 40225, Epoch 37.2, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -360.902, Loss = 369.239
[2018-06-04 19:37] Train Step 40250, Epoch 37.3, Batch Size = 256, Examples/Sec = 3843.33, Train LB = -373.918, Loss = 368.181
[2018-06-04 19:37] Train Step 40275, Epoch 37.3, Batch Size = 256, Examples/Sec = 3735.00, Train LB = -360.900, Loss = 367.618
[2018-06-04 19:37] Train Step 40300, Epoch 37.3, Batch Size = 256, Examples/Sec = 3850.73, Train LB = -406.953, Loss = 365.837
[2018-06-04 19:38] Train Step 40325, Epoch 37.3, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -364.059, Loss = 365.930
[2018-06-04 19:38] Train Step 40350, Epoch 37.4, Batch Size = 256, Examples/Sec = 3802.05, Train LB = -367.192, Loss = 366.803
[2018-06-04 19:38] Train Step 40375, Epoch 37.4, Batch Size = 256, Examples/Sec = 3839.76, Train LB = -384.394, Loss = 368.139
[2018-06-04 19:38] Train Step 40400, Epoch 37.4, Batch Size = 256, Examples/Sec = 3852.64, Train LB = -388.579, Loss = 370.408
Performance on test set:
  Test Lower Bound = -407.340, Test Loss = 407.340
[2018-06-04 19:38] Train Step 40425, Epoch 37.4, Batch Size = 256, Examples/Sec = 3853.50, Train LB = -355.157, Loss = 370.331
[2018-06-04 19:38] Train Step 40450, Epoch 37.5, Batch Size = 256, Examples/Sec = 3852.64, Train LB = -354.765, Loss = 368.975
[2018-06-04 19:38] Train Step 40475, Epoch 37.5, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -358.088, Loss = 367.393
[2018-06-04 19:38] Train Step 40500, Epoch 37.5, Batch Size = 256, Examples/Sec = 3836.18, Train LB = -353.640, Loss = 365.969
[2018-06-04 19:38] Train Step 40525, Epoch 37.5, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -357.166, Loss = 365.323
[2018-06-04 19:38] Train Step 40550, Epoch 37.5, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -372.530, Loss = 364.918
[2018-06-04 19:38] Train Step 40575, Epoch 37.6, Batch Size = 256, Examples/Sec = 3853.69, Train LB = -376.458, Loss = 366.788
[2018-06-04 19:38] Train Step 40600, Epoch 37.6, Batch Size = 256, Examples/Sec = 3782.74, Train LB = -378.069, Loss = 369.221
Performance on test set:
  Test Lower Bound = -407.523, Test Loss = 407.523
[2018-06-04 19:38] Train Step 40625, Epoch 37.6, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -356.697, Loss = 368.838
[2018-06-04 19:38] Train Step 40650, Epoch 37.6, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -358.141, Loss = 367.998
[2018-06-04 19:38] Train Step 40675, Epoch 37.7, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -347.024, Loss = 366.693
[2018-06-04 19:38] Train Step 40700, Epoch 37.7, Batch Size = 256, Examples/Sec = 3873.04, Train LB = -374.473, Loss = 365.324
[2018-06-04 19:38] Train Step 40725, Epoch 37.7, Batch Size = 256, Examples/Sec = 3835.31, Train LB = -352.248, Loss = 364.386
[2018-06-04 19:38] Train Step 40750, Epoch 37.7, Batch Size = 256, Examples/Sec = 3873.32, Train LB = -355.952, Loss = 365.728
[2018-06-04 19:38] Train Step 40775, Epoch 37.8, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -393.525, Loss = 367.001
[2018-06-04 19:38] Train Step 40800, Epoch 37.8, Batch Size = 256, Examples/Sec = 3858.85, Train LB = -390.112, Loss = 369.737
Performance on test set:
  Test Lower Bound = -407.595, Test Loss = 407.595
[2018-06-04 19:38] Train Step 40825, Epoch 37.8, Batch Size = 256, Examples/Sec = 3866.25, Train LB = -378.967, Loss = 369.058
[2018-06-04 19:38] Train Step 40850, Epoch 37.8, Batch Size = 256, Examples/Sec = 3854.56, Train LB = -348.518, Loss = 367.875
[2018-06-04 19:38] Train Step 40875, Epoch 37.8, Batch Size = 256, Examples/Sec = 3859.67, Train LB = -371.781, Loss = 366.830
[2018-06-04 19:38] Train Step 40900, Epoch 37.9, Batch Size = 256, Examples/Sec = 3844.42, Train LB = -354.278, Loss = 366.212
[2018-06-04 19:38] Train Step 40925, Epoch 37.9, Batch Size = 256, Examples/Sec = 3836.59, Train LB = -369.925, Loss = 365.562
[2018-06-04 19:38] Train Step 40950, Epoch 37.9, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -355.359, Loss = 366.243
[2018-06-04 19:38] Train Step 40975, Epoch 37.9, Batch Size = 256, Examples/Sec = 3836.81, Train LB = -367.439, Loss = 367.065
[2018-06-04 19:38] Train Step 41000, Epoch 38.0, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -376.106, Loss = 369.678
Performance on test set:
  Test Lower Bound = -406.754, Test Loss = 406.754
[2018-06-04 19:39] Train Step 41025, Epoch 38.0, Batch Size = 256, Examples/Sec = 3857.63, Train LB = -358.384, Loss = 368.502
[2018-06-04 19:39] Train Step 41050, Epoch 38.0, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -357.740, Loss = 367.770
[2018-06-04 19:39] Train Step 41075, Epoch 38.0, Batch Size = 256, Examples/Sec = 3818.73, Train LB = -361.793, Loss = 366.411
[2018-06-04 19:39] Train Step 41100, Epoch 38.1, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -349.550, Loss = 366.084
[2018-06-04 19:39] Train Step 41125, Epoch 38.1, Batch Size = 256, Examples/Sec = 3849.57, Train LB = -354.706, Loss = 365.152
[2018-06-04 19:39] Train Step 41150, Epoch 38.1, Batch Size = 256, Examples/Sec = 3845.17, Train LB = -374.616, Loss = 365.225
[2018-06-04 19:39] Train Step 41175, Epoch 38.1, Batch Size = 256, Examples/Sec = 3860.66, Train LB = -374.840, Loss = 366.589
[2018-06-04 19:39] Train Step 41200, Epoch 38.1, Batch Size = 256, Examples/Sec = 3850.21, Train LB = -381.267, Loss = 368.807
Performance on test set:
  Test Lower Bound = -407.751, Test Loss = 407.751
[2018-06-04 19:39] Train Step 41225, Epoch 38.2, Batch Size = 256, Examples/Sec = 3868.60, Train LB = -359.873, Loss = 368.174
[2018-06-04 19:39] Train Step 41250, Epoch 38.2, Batch Size = 256, Examples/Sec = 3760.34, Train LB = -357.689, Loss = 367.526
[2018-06-04 19:39] Train Step 41275, Epoch 38.2, Batch Size = 256, Examples/Sec = 3845.35, Train LB = -365.260, Loss = 365.941
[2018-06-04 19:39] Train Step 41300, Epoch 38.2, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -350.926, Loss = 365.854
[2018-06-04 19:39] Train Step 41325, Epoch 38.3, Batch Size = 256, Examples/Sec = 3737.99, Train LB = -359.394, Loss = 365.552
[2018-06-04 19:39] Train Step 41350, Epoch 38.3, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -366.110, Loss = 364.652
[2018-06-04 19:39] Train Step 41375, Epoch 38.3, Batch Size = 256, Examples/Sec = 3810.27, Train LB = -376.142, Loss = 366.729
[2018-06-04 19:39] Train Step 41400, Epoch 38.3, Batch Size = 256, Examples/Sec = 3742.90, Train LB = -394.177, Loss = 369.689
Performance on test set:
  Test Lower Bound = -407.642, Test Loss = 407.642
[2018-06-04 19:39] Train Step 41425, Epoch 38.4, Batch Size = 256, Examples/Sec = 3847.82, Train LB = -380.609, Loss = 368.659
[2018-06-04 19:39] Train Step 41450, Epoch 38.4, Batch Size = 256, Examples/Sec = 3834.97, Train LB = -364.314, Loss = 367.961
[2018-06-04 19:39] Train Step 41475, Epoch 38.4, Batch Size = 256, Examples/Sec = 3849.86, Train LB = -353.061, Loss = 366.800
[2018-06-04 19:39] Train Step 41500, Epoch 38.4, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -363.332, Loss = 366.017
[2018-06-04 19:39] Train Step 41525, Epoch 38.4, Batch Size = 256, Examples/Sec = 3865.43, Train LB = -369.658, Loss = 365.844
[2018-06-04 19:39] Train Step 41550, Epoch 38.5, Batch Size = 256, Examples/Sec = 3850.21, Train LB = -373.489, Loss = 366.351
[2018-06-04 19:39] Train Step 41575, Epoch 38.5, Batch Size = 256, Examples/Sec = 3807.31, Train LB = -382.471, Loss = 366.690
[2018-06-04 19:39] Train Step 41600, Epoch 38.5, Batch Size = 256, Examples/Sec = 3885.32, Train LB = -383.131, Loss = 369.669
Performance on test set:
  Test Lower Bound = -407.356, Test Loss = 407.356
[2018-06-04 19:39] Train Step 41625, Epoch 38.5, Batch Size = 256, Examples/Sec = 3799.90, Train LB = -356.545, Loss = 368.838
[2018-06-04 19:39] Train Step 41650, Epoch 38.6, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -363.109, Loss = 367.779
[2018-06-04 19:39] Train Step 41675, Epoch 38.6, Batch Size = 256, Examples/Sec = 3863.28, Train LB = -347.573, Loss = 366.227
[2018-06-04 19:39] Train Step 41700, Epoch 38.6, Batch Size = 256, Examples/Sec = 3878.90, Train LB = -386.664, Loss = 364.892
[2018-06-04 19:39] Train Step 41725, Epoch 38.6, Batch Size = 256, Examples/Sec = 3862.64, Train LB = -377.685, Loss = 364.594
[2018-06-04 19:40] Train Step 41750, Epoch 38.7, Batch Size = 256, Examples/Sec = 3895.20, Train LB = -361.041, Loss = 365.061
[2018-06-04 19:40] Train Step 41775, Epoch 38.7, Batch Size = 256, Examples/Sec = 3863.87, Train LB = -379.048, Loss = 366.628
[2018-06-04 19:40] Train Step 41800, Epoch 38.7, Batch Size = 256, Examples/Sec = 3841.76, Train LB = -371.538, Loss = 368.596
Performance on test set:
  Test Lower Bound = -406.153, Test Loss = 406.153
[2018-06-04 19:40] Train Step 41825, Epoch 38.7, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -363.524, Loss = 367.469
[2018-06-04 19:40] Train Step 41850, Epoch 38.8, Batch Size = 256, Examples/Sec = 3872.40, Train LB = -373.054, Loss = 367.195
[2018-06-04 19:40] Train Step 41875, Epoch 38.8, Batch Size = 256, Examples/Sec = 3843.96, Train LB = -358.670, Loss = 365.492
[2018-06-04 19:40] Train Step 41900, Epoch 38.8, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -350.615, Loss = 364.294
[2018-06-04 19:40] Train Step 41925, Epoch 38.8, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -355.395, Loss = 364.876
[2018-06-04 19:40] Train Step 41950, Epoch 38.8, Batch Size = 256, Examples/Sec = 3884.72, Train LB = -364.424, Loss = 365.133
[2018-06-04 19:40] Train Step 41975, Epoch 38.9, Batch Size = 256, Examples/Sec = 3855.71, Train LB = -356.082, Loss = 366.196
[2018-06-04 19:40] Train Step 42000, Epoch 38.9, Batch Size = 256, Examples/Sec = 3871.10, Train LB = -386.440, Loss = 369.411
Performance on test set:
  Test Lower Bound = -407.340, Test Loss = 407.340
[2018-06-04 19:40] Train Step 42025, Epoch 38.9, Batch Size = 256, Examples/Sec = 3802.22, Train LB = -372.790, Loss = 369.731
[2018-06-04 19:40] Train Step 42050, Epoch 38.9, Batch Size = 256, Examples/Sec = 3745.85, Train LB = -357.627, Loss = 368.196
[2018-06-04 19:40] Train Step 42075, Epoch 39.0, Batch Size = 256, Examples/Sec = 3863.33, Train LB = -350.692, Loss = 366.278
[2018-06-04 19:40] Train Step 42100, Epoch 39.0, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -364.992, Loss = 365.822
[2018-06-04 19:40] Train Step 42125, Epoch 39.0, Batch Size = 256, Examples/Sec = 3763.37, Train LB = -369.098, Loss = 365.432
[2018-06-04 19:40] Train Step 42150, Epoch 39.0, Batch Size = 256, Examples/Sec = 3878.55, Train LB = -369.279, Loss = 365.512
[2018-06-04 19:40] Train Step 42175, Epoch 39.1, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -370.336, Loss = 367.372
[2018-06-04 19:40] Train Step 42200, Epoch 39.1, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -396.913, Loss = 369.545
Performance on test set:
  Test Lower Bound = -406.155, Test Loss = 406.155
[2018-06-04 19:40] Train Step 42225, Epoch 39.1, Batch Size = 256, Examples/Sec = 3849.57, Train LB = -361.633, Loss = 369.305
[2018-06-04 19:40] Train Step 42250, Epoch 39.1, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -354.289, Loss = 368.015
[2018-06-04 19:40] Train Step 42275, Epoch 39.1, Batch Size = 256, Examples/Sec = 3865.43, Train LB = -361.505, Loss = 366.385
[2018-06-04 19:40] Train Step 42300, Epoch 39.2, Batch Size = 256, Examples/Sec = 3843.15, Train LB = -374.406, Loss = 365.561
[2018-06-04 19:40] Train Step 42325, Epoch 39.2, Batch Size = 256, Examples/Sec = 3822.55, Train LB = -374.726, Loss = 365.142
[2018-06-04 19:40] Train Step 42350, Epoch 39.2, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -355.545, Loss = 365.208
[2018-06-04 19:40] Train Step 42375, Epoch 39.2, Batch Size = 256, Examples/Sec = 3739.85, Train LB = -380.850, Loss = 365.905
[2018-06-04 19:40] Train Step 42400, Epoch 39.3, Batch Size = 256, Examples/Sec = 3849.16, Train LB = -387.207, Loss = 368.465
Performance on test set:
  Test Lower Bound = -406.916, Test Loss = 406.916
[2018-06-04 19:40] Train Step 42425, Epoch 39.3, Batch Size = 256, Examples/Sec = 3847.72, Train LB = -359.377, Loss = 367.587
[2018-06-04 19:41] Train Step 42450, Epoch 39.3, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -360.305, Loss = 366.949
[2018-06-04 19:41] Train Step 42475, Epoch 39.3, Batch Size = 256, Examples/Sec = 3877.14, Train LB = -358.421, Loss = 365.886
[2018-06-04 19:41] Train Step 42500, Epoch 39.4, Batch Size = 256, Examples/Sec = 3869.10, Train LB = -356.489, Loss = 365.226
[2018-06-04 19:41] Train Step 42525, Epoch 39.4, Batch Size = 256, Examples/Sec = 3868.70, Train LB = -366.254, Loss = 364.505
[2018-06-04 19:41] Train Step 42550, Epoch 39.4, Batch Size = 256, Examples/Sec = 3861.13, Train LB = -371.618, Loss = 364.325
[2018-06-04 19:41] Train Step 42575, Epoch 39.4, Batch Size = 256, Examples/Sec = 3854.26, Train LB = -389.833, Loss = 365.524
[2018-06-04 19:41] Train Step 42600, Epoch 39.4, Batch Size = 256, Examples/Sec = 3854.85, Train LB = -388.906, Loss = 368.336
Performance on test set:
  Test Lower Bound = -408.187, Test Loss = 408.187
[2018-06-04 19:41] Train Step 42625, Epoch 39.5, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -355.220, Loss = 367.635
[2018-06-04 19:41] Train Step 42650, Epoch 39.5, Batch Size = 256, Examples/Sec = 3850.43, Train LB = -373.942, Loss = 367.326
[2018-06-04 19:41] Train Step 42675, Epoch 39.5, Batch Size = 256, Examples/Sec = 3863.67, Train LB = -345.037, Loss = 366.177
[2018-06-04 19:41] Train Step 42700, Epoch 39.5, Batch Size = 256, Examples/Sec = 3865.02, Train LB = -376.391, Loss = 365.052
[2018-06-04 19:41] Train Step 42725, Epoch 39.6, Batch Size = 256, Examples/Sec = 3881.66, Train LB = -365.561, Loss = 364.152
[2018-06-04 19:41] Train Step 42750, Epoch 39.6, Batch Size = 256, Examples/Sec = 3851.02, Train LB = -366.217, Loss = 364.741
[2018-06-04 19:41] Train Step 42775, Epoch 39.6, Batch Size = 256, Examples/Sec = 3838.37, Train LB = -375.514, Loss = 366.108
[2018-06-04 19:41] Train Step 42800, Epoch 39.6, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -384.265, Loss = 368.504
Performance on test set:
  Test Lower Bound = -406.438, Test Loss = 406.438
[2018-06-04 19:41] Train Step 42825, Epoch 39.7, Batch Size = 256, Examples/Sec = 3851.53, Train LB = -368.389, Loss = 367.428
[2018-06-04 19:41] Train Step 42850, Epoch 39.7, Batch Size = 256, Examples/Sec = 3862.39, Train LB = -346.990, Loss = 366.396
[2018-06-04 19:41] Train Step 42875, Epoch 39.7, Batch Size = 256, Examples/Sec = 3827.70, Train LB = -358.188, Loss = 365.307
[2018-06-04 19:41] Train Step 42900, Epoch 39.7, Batch Size = 256, Examples/Sec = 3861.28, Train LB = -358.121, Loss = 364.117
[2018-06-04 19:41] Train Step 42925, Epoch 39.7, Batch Size = 256, Examples/Sec = 3854.37, Train LB = -370.945, Loss = 363.794
[2018-06-04 19:41] Train Step 42950, Epoch 39.8, Batch Size = 256, Examples/Sec = 3807.88, Train LB = -386.964, Loss = 363.369
[2018-06-04 19:41] Train Step 42975, Epoch 39.8, Batch Size = 256, Examples/Sec = 3841.29, Train LB = -374.034, Loss = 366.030
[2018-06-04 19:41] Train Step 43000, Epoch 39.8, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -383.264, Loss = 368.461
Performance on test set:
  Test Lower Bound = -406.259, Test Loss = 406.259
[2018-06-04 19:41] Train Step 43025, Epoch 39.8, Batch Size = 256, Examples/Sec = 3828.61, Train LB = -353.594, Loss = 367.403
[2018-06-04 19:41] Train Step 43050, Epoch 39.9, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -354.313, Loss = 366.382
[2018-06-04 19:41] Train Step 43075, Epoch 39.9, Batch Size = 256, Examples/Sec = 3882.27, Train LB = -338.126, Loss = 365.163
[2018-06-04 19:41] Train Step 43100, Epoch 39.9, Batch Size = 256, Examples/Sec = 3765.04, Train LB = -370.814, Loss = 363.979
[2018-06-04 19:41] Train Step 43125, Epoch 39.9, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -364.472, Loss = 363.325
[2018-06-04 19:41] Train Step 43150, Epoch 40.0, Batch Size = 256, Examples/Sec = 3871.99, Train LB = -368.097, Loss = 364.462
[2018-06-04 19:41] Train Step 43175, Epoch 40.0, Batch Size = 256, Examples/Sec = 3760.44, Train LB = -374.281, Loss = 365.821
[2018-06-04 19:42] Train Step 43200, Epoch 40.0, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -375.267, Loss = 368.798
Performance on test set:
  Test Lower Bound = -405.806, Test Loss = 405.806
[2018-06-04 19:42] Train Step 43225, Epoch 40.0, Batch Size = 256, Examples/Sec = 3845.52, Train LB = -366.820, Loss = 367.806
[2018-06-04 19:42] Train Step 43250, Epoch 40.0, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -354.114, Loss = 366.190
[2018-06-04 19:42] Train Step 43275, Epoch 40.1, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -355.540, Loss = 365.216
[2018-06-04 19:42] Train Step 43300, Epoch 40.1, Batch Size = 256, Examples/Sec = 3847.36, Train LB = -364.759, Loss = 365.039
[2018-06-04 19:42] Train Step 43325, Epoch 40.1, Batch Size = 256, Examples/Sec = 3871.46, Train LB = -372.411, Loss = 364.381
[2018-06-04 19:42] Train Step 43350, Epoch 40.1, Batch Size = 256, Examples/Sec = 3819.30, Train LB = -369.048, Loss = 364.523
[2018-06-04 19:42] Train Step 43375, Epoch 40.2, Batch Size = 256, Examples/Sec = 3874.27, Train LB = -383.184, Loss = 365.940
[2018-06-04 19:42] Train Step 43400, Epoch 40.2, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -378.414, Loss = 367.981
Performance on test set:
  Test Lower Bound = -406.175, Test Loss = 406.175
[2018-06-04 19:42] Train Step 43425, Epoch 40.2, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -354.642, Loss = 366.947
[2018-06-04 19:42] Train Step 43450, Epoch 40.2, Batch Size = 256, Examples/Sec = 3873.68, Train LB = -351.392, Loss = 366.257
[2018-06-04 19:42] Train Step 43475, Epoch 40.3, Batch Size = 256, Examples/Sec = 3872.28, Train LB = -362.176, Loss = 363.926
[2018-06-04 19:42] Train Step 43500, Epoch 40.3, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -364.615, Loss = 364.000
[2018-06-04 19:42] Train Step 43525, Epoch 40.3, Batch Size = 256, Examples/Sec = 3866.32, Train LB = -360.352, Loss = 363.685
[2018-06-04 19:42] Train Step 43550, Epoch 40.3, Batch Size = 256, Examples/Sec = 3855.83, Train LB = -380.346, Loss = 364.394
[2018-06-04 19:42] Train Step 43575, Epoch 40.3, Batch Size = 256, Examples/Sec = 3822.61, Train LB = -367.553, Loss = 365.379
[2018-06-04 19:42] Train Step 43600, Epoch 40.4, Batch Size = 256, Examples/Sec = 3874.80, Train LB = -393.193, Loss = 368.257
Performance on test set:
  Test Lower Bound = -406.652, Test Loss = 406.652
[2018-06-04 19:42] Train Step 43625, Epoch 40.4, Batch Size = 256, Examples/Sec = 3861.76, Train LB = -365.009, Loss = 367.282
[2018-06-04 19:42] Train Step 43650, Epoch 40.4, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -356.441, Loss = 366.814
[2018-06-04 19:42] Train Step 43675, Epoch 40.4, Batch Size = 256, Examples/Sec = 3796.64, Train LB = -349.715, Loss = 365.453
[2018-06-04 19:42] Train Step 43700, Epoch 40.5, Batch Size = 256, Examples/Sec = 3866.50, Train LB = -354.118, Loss = 363.764
[2018-06-04 19:42] Train Step 43725, Epoch 40.5, Batch Size = 256, Examples/Sec = 3838.71, Train LB = -366.294, Loss = 363.931
[2018-06-04 19:42] Train Step 43750, Epoch 40.5, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -372.559, Loss = 364.245
[2018-06-04 19:42] Train Step 43775, Epoch 40.5, Batch Size = 256, Examples/Sec = 3881.14, Train LB = -384.669, Loss = 365.206
[2018-06-04 19:42] Train Step 43800, Epoch 40.6, Batch Size = 256, Examples/Sec = 3865.13, Train LB = -391.771, Loss = 367.823
Performance on test set:
  Test Lower Bound = -405.855, Test Loss = 405.855
[2018-06-04 19:42] Train Step 43825, Epoch 40.6, Batch Size = 256, Examples/Sec = 3737.99, Train LB = -354.108, Loss = 366.841
[2018-06-04 19:42] Train Step 43850, Epoch 40.6, Batch Size = 256, Examples/Sec = 3876.79, Train LB = -359.809, Loss = 365.299
[2018-06-04 19:43] Train Step 43875, Epoch 40.6, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -385.011, Loss = 364.699
[2018-06-04 19:43] Train Step 43900, Epoch 40.6, Batch Size = 256, Examples/Sec = 3737.55, Train LB = -369.999, Loss = 364.473
[2018-06-04 19:43] Train Step 43925, Epoch 40.7, Batch Size = 256, Examples/Sec = 3868.42, Train LB = -364.510, Loss = 364.146
[2018-06-04 19:43] Train Step 43950, Epoch 40.7, Batch Size = 256, Examples/Sec = 3875.44, Train LB = -373.848, Loss = 364.059
[2018-06-04 19:43] Train Step 43975, Epoch 40.7, Batch Size = 256, Examples/Sec = 3759.73, Train LB = -371.815, Loss = 365.197
[2018-06-04 19:43] Train Step 44000, Epoch 40.7, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -377.375, Loss = 368.309
Performance on test set:
  Test Lower Bound = -407.320, Test Loss = 407.320
[2018-06-04 19:43] Train Step 44025, Epoch 40.8, Batch Size = 256, Examples/Sec = 3863.16, Train LB = -359.798, Loss = 366.798
[2018-06-04 19:43] Train Step 44050, Epoch 40.8, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -351.875, Loss = 366.192
[2018-06-04 19:43] Train Step 44075, Epoch 40.8, Batch Size = 256, Examples/Sec = 3848.40, Train LB = -353.108, Loss = 364.162
[2018-06-04 19:43] Train Step 44100, Epoch 40.8, Batch Size = 256, Examples/Sec = 3876.03, Train LB = -356.834, Loss = 363.875
[2018-06-04 19:43] Train Step 44125, Epoch 40.9, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -364.853, Loss = 363.032
[2018-06-04 19:43] Train Step 44150, Epoch 40.9, Batch Size = 256, Examples/Sec = 3776.87, Train LB = -367.042, Loss = 364.003
[2018-06-04 19:43] Train Step 44175, Epoch 40.9, Batch Size = 256, Examples/Sec = 3867.19, Train LB = -374.502, Loss = 365.134
[2018-06-04 19:43] Train Step 44200, Epoch 40.9, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -382.403, Loss = 368.335
Performance on test set:
  Test Lower Bound = -406.594, Test Loss = 406.594
[2018-06-04 19:43] Train Step 44225, Epoch 40.9, Batch Size = 256, Examples/Sec = 3866.72, Train LB = -372.074, Loss = 367.468
[2018-06-04 19:43] Train Step 44250, Epoch 41.0, Batch Size = 256, Examples/Sec = 3881.42, Train LB = -353.562, Loss = 365.946
[2018-06-04 19:43] Train Step 44275, Epoch 41.0, Batch Size = 256, Examples/Sec = 3858.27, Train LB = -373.203, Loss = 364.681
[2018-06-04 19:43] Train Step 44300, Epoch 41.0, Batch Size = 256, Examples/Sec = 3822.27, Train LB = -366.613, Loss = 364.328
[2018-06-04 19:43] Train Step 44325, Epoch 41.0, Batch Size = 256, Examples/Sec = 3859.08, Train LB = -352.723, Loss = 363.410
[2018-06-04 19:43] Train Step 44350, Epoch 41.1, Batch Size = 256, Examples/Sec = 3873.39, Train LB = -361.719, Loss = 363.842
[2018-06-04 19:43] Train Step 44375, Epoch 41.1, Batch Size = 256, Examples/Sec = 3851.89, Train LB = -361.919, Loss = 365.272
[2018-06-04 19:43] Train Step 44400, Epoch 41.1, Batch Size = 256, Examples/Sec = 3880.96, Train LB = -391.185, Loss = 367.305
Performance on test set:
  Test Lower Bound = -409.348, Test Loss = 409.348
[2018-06-04 19:43] Train Step 44425, Epoch 41.1, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -342.267, Loss = 366.187
[2018-06-04 19:43] Train Step 44450, Epoch 41.2, Batch Size = 256, Examples/Sec = 3841.24, Train LB = -351.530, Loss = 365.648
[2018-06-04 19:43] Train Step 44475, Epoch 41.2, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -342.614, Loss = 364.288
[2018-06-04 19:43] Train Step 44500, Epoch 41.2, Batch Size = 256, Examples/Sec = 3873.63, Train LB = -373.609, Loss = 363.708
[2018-06-04 19:43] Train Step 44525, Epoch 41.2, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -363.382, Loss = 364.078
[2018-06-04 19:43] Train Step 44550, Epoch 41.2, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -355.180, Loss = 363.265
[2018-06-04 19:43] Train Step 44575, Epoch 41.3, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -371.238, Loss = 363.999
[2018-06-04 19:43] Train Step 44600, Epoch 41.3, Batch Size = 256, Examples/Sec = 3821.17, Train LB = -366.342, Loss = 366.706
Performance on test set:
  Test Lower Bound = -407.525, Test Loss = 407.525
[2018-06-04 19:44] Train Step 44625, Epoch 41.3, Batch Size = 256, Examples/Sec = 3714.98, Train LB = -348.723, Loss = 366.278
[2018-06-04 19:44] Train Step 44650, Epoch 41.3, Batch Size = 256, Examples/Sec = 3842.46, Train LB = -368.931, Loss = 365.173
[2018-06-04 19:44] Train Step 44675, Epoch 41.4, Batch Size = 256, Examples/Sec = 3874.93, Train LB = -350.608, Loss = 364.291
[2018-06-04 19:44] Train Step 44700, Epoch 41.4, Batch Size = 256, Examples/Sec = 3819.03, Train LB = -358.355, Loss = 363.212
[2018-06-04 19:44] Train Step 44725, Epoch 41.4, Batch Size = 256, Examples/Sec = 3849.28, Train LB = -357.565, Loss = 363.640
[2018-06-04 19:44] Train Step 44750, Epoch 41.4, Batch Size = 256, Examples/Sec = 3856.76, Train LB = -370.720, Loss = 363.460
[2018-06-04 19:44] Train Step 44775, Epoch 41.5, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -380.561, Loss = 365.221
[2018-06-04 19:44] Train Step 44800, Epoch 41.5, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -384.491, Loss = 368.015
Performance on test set:
  Test Lower Bound = -407.425, Test Loss = 407.425
[2018-06-04 19:44] Train Step 44825, Epoch 41.5, Batch Size = 256, Examples/Sec = 3846.84, Train LB = -359.391, Loss = 367.336
[2018-06-04 19:44] Train Step 44850, Epoch 41.5, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -344.682, Loss = 365.581
[2018-06-04 19:44] Train Step 44875, Epoch 41.6, Batch Size = 256, Examples/Sec = 3766.31, Train LB = -348.483, Loss = 363.444
[2018-06-04 19:44] Train Step 44900, Epoch 41.6, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -359.884, Loss = 362.513
[2018-06-04 19:44] Train Step 44925, Epoch 41.6, Batch Size = 256, Examples/Sec = 3852.04, Train LB = -374.805, Loss = 362.730
[2018-06-04 19:44] Train Step 44950, Epoch 41.6, Batch Size = 256, Examples/Sec = 3761.93, Train LB = -353.888, Loss = 362.906
[2018-06-04 19:44] Train Step 44975, Epoch 41.6, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -368.177, Loss = 364.029
[2018-06-04 19:44] Train Step 45000, Epoch 41.7, Batch Size = 256, Examples/Sec = 3847.83, Train LB = -392.882, Loss = 367.161
Performance on test set:
  Test Lower Bound = -408.305, Test Loss = 408.305
[2018-06-04 19:44] Train Step 45025, Epoch 41.7, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -350.906, Loss = 366.945
[2018-06-04 19:44] Train Step 45050, Epoch 41.7, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -375.651, Loss = 366.428
[2018-06-04 19:44] Train Step 45075, Epoch 41.7, Batch Size = 256, Examples/Sec = 3856.42, Train LB = -343.760, Loss = 364.540
[2018-06-04 19:44] Train Step 45100, Epoch 41.8, Batch Size = 256, Examples/Sec = 3842.68, Train LB = -369.400, Loss = 362.896
[2018-06-04 19:44] Train Step 45125, Epoch 41.8, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -364.578, Loss = 362.605
[2018-06-04 19:44] Train Step 45150, Epoch 41.8, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -367.342, Loss = 362.903
[2018-06-04 19:44] Train Step 45175, Epoch 41.8, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -372.137, Loss = 364.460
[2018-06-04 19:44] Train Step 45200, Epoch 41.9, Batch Size = 256, Examples/Sec = 3879.38, Train LB = -380.386, Loss = 367.105
Performance on test set:
  Test Lower Bound = -407.937, Test Loss = 407.937
[2018-06-04 19:44] Train Step 45225, Epoch 41.9, Batch Size = 256, Examples/Sec = 3856.69, Train LB = -348.466, Loss = 366.133
[2018-06-04 19:44] Train Step 45250, Epoch 41.9, Batch Size = 256, Examples/Sec = 3834.16, Train LB = -365.935, Loss = 365.266
[2018-06-04 19:44] Train Step 45275, Epoch 41.9, Batch Size = 256, Examples/Sec = 3841.31, Train LB = -374.152, Loss = 364.252
[2018-06-04 19:44] Train Step 45300, Epoch 41.9, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -361.709, Loss = 363.571
[2018-06-04 19:45] Train Step 45325, Epoch 42.0, Batch Size = 256, Examples/Sec = 3857.57, Train LB = -371.233, Loss = 362.699
[2018-06-04 19:45] Train Step 45350, Epoch 42.0, Batch Size = 256, Examples/Sec = 3854.85, Train LB = -355.447, Loss = 362.633
[2018-06-04 19:45] Train Step 45375, Epoch 42.0, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -358.649, Loss = 363.638
[2018-06-04 19:45] Train Step 45400, Epoch 42.0, Batch Size = 256, Examples/Sec = 3874.73, Train LB = -381.848, Loss = 366.639
Performance on test set:
  Test Lower Bound = -409.414, Test Loss = 409.414
[2018-06-04 19:45] Train Step 45425, Epoch 42.1, Batch Size = 256, Examples/Sec = 3835.26, Train LB = -349.897, Loss = 365.921
[2018-06-04 19:45] Train Step 45450, Epoch 42.1, Batch Size = 256, Examples/Sec = 3877.85, Train LB = -343.002, Loss = 364.220
[2018-06-04 19:45] Train Step 45475, Epoch 42.1, Batch Size = 256, Examples/Sec = 3850.43, Train LB = -360.065, Loss = 363.703
[2018-06-04 19:45] Train Step 45500, Epoch 42.1, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -358.320, Loss = 362.375
[2018-06-04 19:45] Train Step 45525, Epoch 42.2, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -362.783, Loss = 362.103
[2018-06-04 19:45] Train Step 45550, Epoch 42.2, Batch Size = 256, Examples/Sec = 3818.73, Train LB = -361.172, Loss = 362.887
[2018-06-04 19:45] Train Step 45575, Epoch 42.2, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -372.025, Loss = 364.249
[2018-06-04 19:45] Train Step 45600, Epoch 42.2, Batch Size = 256, Examples/Sec = 3846.55, Train LB = -398.446, Loss = 366.909
Performance on test set:
  Test Lower Bound = -409.099, Test Loss = 409.099
[2018-06-04 19:45] Train Step 45625, Epoch 42.2, Batch Size = 256, Examples/Sec = 3878.44, Train LB = -360.567, Loss = 365.924
[2018-06-04 19:45] Train Step 45650, Epoch 42.3, Batch Size = 256, Examples/Sec = 3802.28, Train LB = -357.961, Loss = 365.047
[2018-06-04 19:45] Train Step 45675, Epoch 42.3, Batch Size = 256, Examples/Sec = 3742.75, Train LB = -355.015, Loss = 364.096
[2018-06-04 19:45] Train Step 45700, Epoch 42.3, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -371.016, Loss = 363.386
[2018-06-04 19:45] Train Step 45725, Epoch 42.3, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -361.435, Loss = 362.946
[2018-06-04 19:45] Train Step 45750, Epoch 42.4, Batch Size = 256, Examples/Sec = 3799.85, Train LB = -359.593, Loss = 363.099
[2018-06-04 19:45] Train Step 45775, Epoch 42.4, Batch Size = 256, Examples/Sec = 3795.35, Train LB = -370.452, Loss = 364.423
[2018-06-04 19:45] Train Step 45800, Epoch 42.4, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -388.238, Loss = 367.464
Performance on test set:
  Test Lower Bound = -409.061, Test Loss = 409.061
[2018-06-04 19:45] Train Step 45825, Epoch 42.4, Batch Size = 256, Examples/Sec = 3853.15, Train LB = -352.888, Loss = 366.571
[2018-06-04 19:45] Train Step 45850, Epoch 42.5, Batch Size = 256, Examples/Sec = 3867.53, Train LB = -359.821, Loss = 365.149
[2018-06-04 19:45] Train Step 45875, Epoch 42.5, Batch Size = 256, Examples/Sec = 3812.42, Train LB = -350.268, Loss = 363.779
[2018-06-04 19:45] Train Step 45900, Epoch 42.5, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -387.474, Loss = 362.934
[2018-06-04 19:45] Train Step 45925, Epoch 42.5, Batch Size = 256, Examples/Sec = 3841.42, Train LB = -368.612, Loss = 362.332
[2018-06-04 19:45] Train Step 45950, Epoch 42.5, Batch Size = 256, Examples/Sec = 3819.80, Train LB = -370.211, Loss = 362.411
[2018-06-04 19:45] Train Step 45975, Epoch 42.6, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -371.435, Loss = 363.849
[2018-06-04 19:45] Train Step 46000, Epoch 42.6, Batch Size = 256, Examples/Sec = 3769.02, Train LB = -367.088, Loss = 366.815
Performance on test set:
  Test Lower Bound = -408.331, Test Loss = 408.331
[2018-06-04 19:46] Train Step 46025, Epoch 42.6, Batch Size = 256, Examples/Sec = 3852.47, Train LB = -354.466, Loss = 365.953
[2018-06-04 19:46] Train Step 46050, Epoch 42.6, Batch Size = 256, Examples/Sec = 3836.88, Train LB = -367.120, Loss = 364.904
[2018-06-04 19:46] Train Step 46075, Epoch 42.7, Batch Size = 256, Examples/Sec = 3865.77, Train LB = -367.033, Loss = 363.931
[2018-06-04 19:46] Train Step 46100, Epoch 42.7, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -351.198, Loss = 363.211
[2018-06-04 19:46] Train Step 46125, Epoch 42.7, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -368.009, Loss = 362.730
[2018-06-04 19:46] Train Step 46150, Epoch 42.7, Batch Size = 256, Examples/Sec = 3858.62, Train LB = -364.640, Loss = 362.246
[2018-06-04 19:46] Train Step 46175, Epoch 42.8, Batch Size = 256, Examples/Sec = 3813.79, Train LB = -377.891, Loss = 363.325
[2018-06-04 19:46] Train Step 46200, Epoch 42.8, Batch Size = 256, Examples/Sec = 3861.30, Train LB = -372.199, Loss = 366.218
Performance on test set:
  Test Lower Bound = -408.770, Test Loss = 408.770
[2018-06-04 19:46] Train Step 46225, Epoch 42.8, Batch Size = 256, Examples/Sec = 3848.11, Train LB = -354.078, Loss = 365.273
[2018-06-04 19:46] Train Step 46250, Epoch 42.8, Batch Size = 256, Examples/Sec = 3831.71, Train LB = -371.516, Loss = 363.456
[2018-06-04 19:46] Train Step 46275, Epoch 42.8, Batch Size = 256, Examples/Sec = 3856.12, Train LB = -352.822, Loss = 362.764
[2018-06-04 19:46] Train Step 46300, Epoch 42.9, Batch Size = 256, Examples/Sec = 3859.96, Train LB = -360.127, Loss = 361.370
[2018-06-04 19:46] Train Step 46325, Epoch 42.9, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -347.270, Loss = 361.819
[2018-06-04 19:46] Train Step 46350, Epoch 42.9, Batch Size = 256, Examples/Sec = 3840.55, Train LB = -356.890, Loss = 362.428
[2018-06-04 19:46] Train Step 46375, Epoch 42.9, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -371.371, Loss = 363.567
[2018-06-04 19:46] Train Step 46400, Epoch 43.0, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -374.303, Loss = 366.567
Performance on test set:
  Test Lower Bound = -408.956, Test Loss = 408.956
[2018-06-04 19:46] Train Step 46425, Epoch 43.0, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -363.913, Loss = 365.830
[2018-06-04 19:46] Train Step 46450, Epoch 43.0, Batch Size = 256, Examples/Sec = 3842.28, Train LB = -367.499, Loss = 364.086
[2018-06-04 19:46] Train Step 46475, Epoch 43.0, Batch Size = 256, Examples/Sec = 3747.74, Train LB = -355.830, Loss = 362.652
[2018-06-04 19:46] Train Step 46500, Epoch 43.1, Batch Size = 256, Examples/Sec = 3837.38, Train LB = -369.910, Loss = 361.972
[2018-06-04 19:46] Train Step 46525, Epoch 43.1, Batch Size = 256, Examples/Sec = 3873.04, Train LB = -367.113, Loss = 361.520
[2018-06-04 19:46] Train Step 46550, Epoch 43.1, Batch Size = 256, Examples/Sec = 3828.43, Train LB = -377.104, Loss = 362.076
[2018-06-04 19:46] Train Step 46575, Epoch 43.1, Batch Size = 256, Examples/Sec = 3782.67, Train LB = -362.335, Loss = 363.530
[2018-06-04 19:46] Train Step 46600, Epoch 43.1, Batch Size = 256, Examples/Sec = 3855.14, Train LB = -390.949, Loss = 366.139
Performance on test set:
  Test Lower Bound = -409.152, Test Loss = 409.152
[2018-06-04 19:46] Train Step 46625, Epoch 43.2, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -343.498, Loss = 365.423
[2018-06-04 19:46] Train Step 46650, Epoch 43.2, Batch Size = 256, Examples/Sec = 3852.24, Train LB = -351.344, Loss = 364.068
[2018-06-04 19:46] Train Step 46675, Epoch 43.2, Batch Size = 256, Examples/Sec = 3841.60, Train LB = -357.876, Loss = 363.189
[2018-06-04 19:46] Train Step 46700, Epoch 43.2, Batch Size = 256, Examples/Sec = 3845.41, Train LB = -348.588, Loss = 362.069
[2018-06-04 19:46] Train Step 46725, Epoch 43.3, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -353.059, Loss = 362.142
[2018-06-04 19:47] Train Step 46750, Epoch 43.3, Batch Size = 256, Examples/Sec = 3866.61, Train LB = -365.876, Loss = 362.274
[2018-06-04 19:47] Train Step 46775, Epoch 43.3, Batch Size = 256, Examples/Sec = 3845.46, Train LB = -366.262, Loss = 363.680
[2018-06-04 19:47] Train Step 46800, Epoch 43.3, Batch Size = 256, Examples/Sec = 3775.58, Train LB = -392.959, Loss = 365.893
Performance on test set:
  Test Lower Bound = -409.836, Test Loss = 409.836
[2018-06-04 19:47] Train Step 46825, Epoch 43.4, Batch Size = 256, Examples/Sec = 3838.32, Train LB = -366.134, Loss = 364.868
[2018-06-04 19:47] Train Step 46850, Epoch 43.4, Batch Size = 256, Examples/Sec = 3873.32, Train LB = -369.585, Loss = 363.833
[2018-06-04 19:47] Train Step 46875, Epoch 43.4, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -335.664, Loss = 362.385
[2018-06-04 19:47] Train Step 46900, Epoch 43.4, Batch Size = 256, Examples/Sec = 3865.31, Train LB = -361.326, Loss = 362.018
[2018-06-04 19:47] Train Step 46925, Epoch 43.4, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -377.637, Loss = 361.916
[2018-06-04 19:47] Train Step 46950, Epoch 43.5, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -355.042, Loss = 362.604
[2018-06-04 19:47] Train Step 46975, Epoch 43.5, Batch Size = 256, Examples/Sec = 3836.70, Train LB = -353.745, Loss = 363.914
[2018-06-04 19:47] Train Step 47000, Epoch 43.5, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -384.305, Loss = 367.225
Performance on test set:
  Test Lower Bound = -409.313, Test Loss = 409.313
[2018-06-04 19:47] Train Step 47025, Epoch 43.5, Batch Size = 256, Examples/Sec = 3874.34, Train LB = -367.573, Loss = 366.207
[2018-06-04 19:47] Train Step 47050, Epoch 43.6, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -355.318, Loss = 364.284
[2018-06-04 19:47] Train Step 47075, Epoch 43.6, Batch Size = 256, Examples/Sec = 3843.78, Train LB = -378.242, Loss = 362.426
[2018-06-04 19:47] Train Step 47100, Epoch 43.6, Batch Size = 256, Examples/Sec = 3859.66, Train LB = -364.174, Loss = 362.350
[2018-06-04 19:47] Train Step 47125, Epoch 43.6, Batch Size = 256, Examples/Sec = 3866.89, Train LB = -358.145, Loss = 361.955
[2018-06-04 19:47] Train Step 47150, Epoch 43.7, Batch Size = 256, Examples/Sec = 3868.99, Train LB = -356.041, Loss = 362.531
[2018-06-04 19:47] Train Step 47175, Epoch 43.7, Batch Size = 256, Examples/Sec = 3850.32, Train LB = -375.538, Loss = 363.540
[2018-06-04 19:47] Train Step 47200, Epoch 43.7, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -382.035, Loss = 366.499
Performance on test set:
  Test Lower Bound = -409.632, Test Loss = 409.632
[2018-06-04 19:47] Train Step 47225, Epoch 43.7, Batch Size = 256, Examples/Sec = 3869.88, Train LB = -366.360, Loss = 365.430
[2018-06-04 19:47] Train Step 47250, Epoch 43.8, Batch Size = 256, Examples/Sec = 3867.14, Train LB = -363.063, Loss = 363.962
[2018-06-04 19:47] Train Step 47275, Epoch 43.8, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -357.334, Loss = 363.030
[2018-06-04 19:47] Train Step 47300, Epoch 43.8, Batch Size = 256, Examples/Sec = 3837.40, Train LB = -351.374, Loss = 362.267
[2018-06-04 19:47] Train Step 47325, Epoch 43.8, Batch Size = 256, Examples/Sec = 3877.32, Train LB = -377.003, Loss = 361.800
[2018-06-04 19:47] Train Step 47350, Epoch 43.8, Batch Size = 256, Examples/Sec = 3867.43, Train LB = -362.858, Loss = 361.731
[2018-06-04 19:47] Train Step 47375, Epoch 43.9, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -351.098, Loss = 362.452
[2018-06-04 19:47] Train Step 47400, Epoch 43.9, Batch Size = 256, Examples/Sec = 3886.86, Train LB = -372.283, Loss = 365.846
Performance on test set:
  Test Lower Bound = -409.183, Test Loss = 409.183
[2018-06-04 19:47] Train Step 47425, Epoch 43.9, Batch Size = 256, Examples/Sec = 3870.47, Train LB = -361.797, Loss = 365.207
[2018-06-04 19:48] Train Step 47450, Epoch 43.9, Batch Size = 256, Examples/Sec = 3842.00, Train LB = -346.431, Loss = 363.727
[2018-06-04 19:48] Train Step 47475, Epoch 44.0, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -370.874, Loss = 362.434
[2018-06-04 19:48] Train Step 47500, Epoch 44.0, Batch Size = 256, Examples/Sec = 3881.72, Train LB = -350.606, Loss = 361.493
[2018-06-04 19:48] Train Step 47525, Epoch 44.0, Batch Size = 256, Examples/Sec = 3791.58, Train LB = -359.904, Loss = 361.305
[2018-06-04 19:48] Train Step 47550, Epoch 44.0, Batch Size = 256, Examples/Sec = 3856.40, Train LB = -371.830, Loss = 361.786
[2018-06-04 19:48] Train Step 47575, Epoch 44.1, Batch Size = 256, Examples/Sec = 3838.84, Train LB = -349.167, Loss = 363.110
[2018-06-04 19:48] Train Step 47600, Epoch 44.1, Batch Size = 256, Examples/Sec = 3745.59, Train LB = -382.984, Loss = 365.937
Performance on test set:
  Test Lower Bound = -407.808, Test Loss = 407.808
[2018-06-04 19:48] Train Step 47625, Epoch 44.1, Batch Size = 256, Examples/Sec = 3876.97, Train LB = -348.772, Loss = 364.804
[2018-06-04 19:48] Train Step 47650, Epoch 44.1, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -357.840, Loss = 363.908
[2018-06-04 19:48] Train Step 47675, Epoch 44.1, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -365.802, Loss = 363.187
[2018-06-04 19:48] Train Step 47700, Epoch 44.2, Batch Size = 256, Examples/Sec = 3854.44, Train LB = -367.462, Loss = 362.669
[2018-06-04 19:48] Train Step 47725, Epoch 44.2, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -355.058, Loss = 362.193
[2018-06-04 19:48] Train Step 47750, Epoch 44.2, Batch Size = 256, Examples/Sec = 3856.46, Train LB = -368.179, Loss = 361.260
[2018-06-04 19:48] Train Step 47775, Epoch 44.2, Batch Size = 256, Examples/Sec = 3777.64, Train LB = -376.576, Loss = 362.877
[2018-06-04 19:48] Train Step 47800, Epoch 44.3, Batch Size = 256, Examples/Sec = 3845.93, Train LB = -368.675, Loss = 365.436
Performance on test set:
  Test Lower Bound = -410.462, Test Loss = 410.462
[2018-06-04 19:48] Train Step 47825, Epoch 44.3, Batch Size = 256, Examples/Sec = 3846.15, Train LB = -370.819, Loss = 364.589
[2018-06-04 19:48] Train Step 47850, Epoch 44.3, Batch Size = 256, Examples/Sec = 3784.58, Train LB = -358.166, Loss = 363.266
[2018-06-04 19:48] Train Step 47875, Epoch 44.3, Batch Size = 256, Examples/Sec = 3841.08, Train LB = -368.815, Loss = 361.823
[2018-06-04 19:48] Train Step 47900, Epoch 44.4, Batch Size = 256, Examples/Sec = 3865.02, Train LB = -343.602, Loss = 361.038
[2018-06-04 19:48] Train Step 47925, Epoch 44.4, Batch Size = 256, Examples/Sec = 3867.83, Train LB = -356.834, Loss = 360.642
[2018-06-04 19:48] Train Step 47950, Epoch 44.4, Batch Size = 256, Examples/Sec = 3850.68, Train LB = -371.881, Loss = 360.832
[2018-06-04 19:48] Train Step 47975, Epoch 44.4, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -378.356, Loss = 362.585
[2018-06-04 19:48] Train Step 48000, Epoch 44.4, Batch Size = 256, Examples/Sec = 3877.68, Train LB = -390.985, Loss = 365.226
Performance on test set:
  Test Lower Bound = -409.502, Test Loss = 409.502
[2018-06-04 19:48] Train Step 48025, Epoch 44.5, Batch Size = 256, Examples/Sec = 3875.32, Train LB = -351.103, Loss = 364.727
[2018-06-04 19:48] Train Step 48050, Epoch 44.5, Batch Size = 256, Examples/Sec = 3844.42, Train LB = -358.023, Loss = 363.340
[2018-06-04 19:48] Train Step 48075, Epoch 44.5, Batch Size = 256, Examples/Sec = 3848.63, Train LB = -352.457, Loss = 362.519
[2018-06-04 19:48] Train Step 48100, Epoch 44.5, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -346.804, Loss = 360.832
[2018-06-04 19:48] Train Step 48125, Epoch 44.6, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -348.061, Loss = 360.319
[2018-06-04 19:48] Train Step 48150, Epoch 44.6, Batch Size = 256, Examples/Sec = 3813.17, Train LB = -374.428, Loss = 360.648
[2018-06-04 19:49] Train Step 48175, Epoch 44.6, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -361.421, Loss = 362.310
[2018-06-04 19:49] Train Step 48200, Epoch 44.6, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -379.460, Loss = 365.105
Performance on test set:
  Test Lower Bound = -409.357, Test Loss = 409.357
[2018-06-04 19:49] Train Step 48225, Epoch 44.7, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -337.593, Loss = 363.677
[2018-06-04 19:49] Train Step 48250, Epoch 44.7, Batch Size = 256, Examples/Sec = 3684.35, Train LB = -344.819, Loss = 363.008
[2018-06-04 19:49] Train Step 48275, Epoch 44.7, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -372.060, Loss = 362.365
[2018-06-04 19:49] Train Step 48300, Epoch 44.7, Batch Size = 256, Examples/Sec = 3861.23, Train LB = -349.247, Loss = 361.845
[2018-06-04 19:49] Train Step 48325, Epoch 44.7, Batch Size = 256, Examples/Sec = 3840.72, Train LB = -370.434, Loss = 361.268
[2018-06-04 19:49] Train Step 48350, Epoch 44.8, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -361.466, Loss = 360.782
[2018-06-04 19:49] Train Step 48375, Epoch 44.8, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -381.152, Loss = 362.013
[2018-06-04 19:49] Train Step 48400, Epoch 44.8, Batch Size = 256, Examples/Sec = 3869.59, Train LB = -388.998, Loss = 365.555
Performance on test set:
  Test Lower Bound = -410.501, Test Loss = 410.501
[2018-06-04 19:49] Train Step 48425, Epoch 44.8, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -358.178, Loss = 365.007
[2018-06-04 19:49] Train Step 48450, Epoch 44.9, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -352.461, Loss = 363.369
[2018-06-04 19:49] Train Step 48475, Epoch 44.9, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -363.465, Loss = 361.577
[2018-06-04 19:49] Train Step 48500, Epoch 44.9, Batch Size = 256, Examples/Sec = 3843.10, Train LB = -383.536, Loss = 361.171
[2018-06-04 19:49] Train Step 48525, Epoch 44.9, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -340.239, Loss = 360.855
[2018-06-04 19:49] Train Step 48550, Epoch 45.0, Batch Size = 256, Examples/Sec = 3804.21, Train LB = -369.796, Loss = 360.674
[2018-06-04 19:49] Train Step 48575, Epoch 45.0, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -357.894, Loss = 362.533
[2018-06-04 19:49] Train Step 48600, Epoch 45.0, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -362.569, Loss = 365.643
Performance on test set:
  Test Lower Bound = -409.864, Test Loss = 409.864
[2018-06-04 19:49] Train Step 48625, Epoch 45.0, Batch Size = 256, Examples/Sec = 3867.54, Train LB = -368.152, Loss = 365.030
[2018-06-04 19:49] Train Step 48650, Epoch 45.0, Batch Size = 256, Examples/Sec = 3858.02, Train LB = -354.763, Loss = 363.678
[2018-06-04 19:49] Train Step 48675, Epoch 45.1, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -347.687, Loss = 361.818
[2018-06-04 19:49] Train Step 48700, Epoch 45.1, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -364.813, Loss = 361.348
[2018-06-04 19:49] Train Step 48725, Epoch 45.1, Batch Size = 256, Examples/Sec = 3841.08, Train LB = -359.032, Loss = 360.612
[2018-06-04 19:49] Train Step 48750, Epoch 45.1, Batch Size = 256, Examples/Sec = 3865.73, Train LB = -376.621, Loss = 361.233
[2018-06-04 19:49] Train Step 48775, Epoch 45.2, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -358.714, Loss = 362.056
[2018-06-04 19:49] Train Step 48800, Epoch 45.2, Batch Size = 256, Examples/Sec = 3870.51, Train LB = -384.665, Loss = 365.460
Performance on test set:
  Test Lower Bound = -408.621, Test Loss = 408.621
[2018-06-04 19:49] Train Step 48825, Epoch 45.2, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -359.793, Loss = 364.584
[2018-06-04 19:49] Train Step 48850, Epoch 45.2, Batch Size = 256, Examples/Sec = 3867.76, Train LB = -363.865, Loss = 363.086
[2018-06-04 19:50] Train Step 48875, Epoch 45.3, Batch Size = 256, Examples/Sec = 3838.14, Train LB = -340.135, Loss = 362.041
[2018-06-04 19:50] Train Step 48900, Epoch 45.3, Batch Size = 256, Examples/Sec = 3856.35, Train LB = -345.655, Loss = 360.680
[2018-06-04 19:50] Train Step 48925, Epoch 45.3, Batch Size = 256, Examples/Sec = 3846.95, Train LB = -371.517, Loss = 360.190
[2018-06-04 19:50] Train Step 48950, Epoch 45.3, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -360.057, Loss = 360.534
[2018-06-04 19:50] Train Step 48975, Epoch 45.3, Batch Size = 256, Examples/Sec = 3860.06, Train LB = -362.568, Loss = 362.107
[2018-06-04 19:50] Train Step 49000, Epoch 45.4, Batch Size = 256, Examples/Sec = 3829.01, Train LB = -386.838, Loss = 365.149
Performance on test set:
  Test Lower Bound = -409.692, Test Loss = 409.692
[2018-06-04 19:50] Train Step 49025, Epoch 45.4, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -361.448, Loss = 364.389
[2018-06-04 19:50] Train Step 49050, Epoch 45.4, Batch Size = 256, Examples/Sec = 3776.75, Train LB = -347.896, Loss = 363.480
[2018-06-04 19:50] Train Step 49075, Epoch 45.4, Batch Size = 256, Examples/Sec = 3876.20, Train LB = -364.142, Loss = 361.608
[2018-06-04 19:50] Train Step 49100, Epoch 45.5, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -356.883, Loss = 360.373
[2018-06-04 19:50] Train Step 49125, Epoch 45.5, Batch Size = 256, Examples/Sec = 3730.58, Train LB = -375.467, Loss = 359.914
[2018-06-04 19:50] Train Step 49150, Epoch 45.5, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -359.836, Loss = 360.659
[2018-06-04 19:50] Train Step 49175, Epoch 45.5, Batch Size = 256, Examples/Sec = 3855.71, Train LB = -369.107, Loss = 361.960
[2018-06-04 19:50] Train Step 49200, Epoch 45.6, Batch Size = 256, Examples/Sec = 3732.92, Train LB = -394.112, Loss = 364.465
Performance on test set:
  Test Lower Bound = -410.318, Test Loss = 410.318
[2018-06-04 19:50] Train Step 49225, Epoch 45.6, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -348.786, Loss = 363.910
[2018-06-04 19:50] Train Step 49250, Epoch 45.6, Batch Size = 256, Examples/Sec = 3850.04, Train LB = -358.405, Loss = 362.113
[2018-06-04 19:50] Train Step 49275, Epoch 45.6, Batch Size = 256, Examples/Sec = 3864.44, Train LB = -355.665, Loss = 361.328
[2018-06-04 19:50] Train Step 49300, Epoch 45.6, Batch Size = 256, Examples/Sec = 3858.33, Train LB = -355.873, Loss = 360.506
[2018-06-04 19:50] Train Step 49325, Epoch 45.7, Batch Size = 256, Examples/Sec = 3870.40, Train LB = -370.483, Loss = 359.889
[2018-06-04 19:50] Train Step 49350, Epoch 45.7, Batch Size = 256, Examples/Sec = 3863.38, Train LB = -369.287, Loss = 360.077
[2018-06-04 19:50] Train Step 49375, Epoch 45.7, Batch Size = 256, Examples/Sec = 3851.08, Train LB = -372.204, Loss = 361.667
[2018-06-04 19:50] Train Step 49400, Epoch 45.7, Batch Size = 256, Examples/Sec = 3886.44, Train LB = -378.756, Loss = 364.628
Performance on test set:
  Test Lower Bound = -410.556, Test Loss = 410.556
[2018-06-04 19:50] Train Step 49425, Epoch 45.8, Batch Size = 256, Examples/Sec = 3842.52, Train LB = -367.179, Loss = 363.828
[2018-06-04 19:50] Train Step 49450, Epoch 45.8, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -349.371, Loss = 362.818
[2018-06-04 19:50] Train Step 49475, Epoch 45.8, Batch Size = 256, Examples/Sec = 3843.84, Train LB = -363.111, Loss = 361.194
[2018-06-04 19:50] Train Step 49500, Epoch 45.8, Batch Size = 256, Examples/Sec = 3851.30, Train LB = -360.331, Loss = 360.352
[2018-06-04 19:50] Train Step 49525, Epoch 45.9, Batch Size = 256, Examples/Sec = 3845.00, Train LB = -350.236, Loss = 359.309
[2018-06-04 19:50] Train Step 49550, Epoch 45.9, Batch Size = 256, Examples/Sec = 3839.81, Train LB = -348.590, Loss = 359.886
[2018-06-04 19:50] Train Step 49575, Epoch 45.9, Batch Size = 256, Examples/Sec = 3819.99, Train LB = -373.269, Loss = 362.000
[2018-06-04 19:50] Train Step 49600, Epoch 45.9, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -377.069, Loss = 365.039
Performance on test set:
  Test Lower Bound = -409.360, Test Loss = 409.360
[2018-06-04 19:51] Train Step 49625, Epoch 45.9, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -355.188, Loss = 364.092
[2018-06-04 19:51] Train Step 49650, Epoch 46.0, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -347.310, Loss = 363.112
[2018-06-04 19:51] Train Step 49675, Epoch 46.0, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -361.243, Loss = 361.234
[2018-06-04 19:51] Train Step 49700, Epoch 46.0, Batch Size = 256, Examples/Sec = 3844.07, Train LB = -351.230, Loss = 360.526
[2018-06-04 19:51] Train Step 49725, Epoch 46.0, Batch Size = 256, Examples/Sec = 3867.25, Train LB = -358.454, Loss = 360.683
[2018-06-04 19:51] Train Step 49750, Epoch 46.1, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -364.639, Loss = 360.807
[2018-06-04 19:51] Train Step 49775, Epoch 46.1, Batch Size = 256, Examples/Sec = 3847.48, Train LB = -364.825, Loss = 361.585
[2018-06-04 19:51] Train Step 49800, Epoch 46.1, Batch Size = 256, Examples/Sec = 3837.56, Train LB = -374.594, Loss = 364.638
Performance on test set:
  Test Lower Bound = -409.399, Test Loss = 409.399
[2018-06-04 19:51] Train Step 49825, Epoch 46.1, Batch Size = 256, Examples/Sec = 3871.10, Train LB = -346.492, Loss = 363.765
[2018-06-04 19:51] Train Step 49850, Epoch 46.2, Batch Size = 256, Examples/Sec = 3821.80, Train LB = -354.380, Loss = 362.565
[2018-06-04 19:51] Train Step 49875, Epoch 46.2, Batch Size = 256, Examples/Sec = 3849.67, Train LB = -351.886, Loss = 361.007
[2018-06-04 19:51] Train Step 49900, Epoch 46.2, Batch Size = 256, Examples/Sec = 3814.98, Train LB = -377.201, Loss = 360.610
[2018-06-04 19:51] Train Step 49925, Epoch 46.2, Batch Size = 256, Examples/Sec = 3866.61, Train LB = -362.095, Loss = 360.196
[2018-06-04 19:51] Train Step 49950, Epoch 46.2, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -360.926, Loss = 360.499
[2018-06-04 19:51] Train Step 49975, Epoch 46.3, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -356.412, Loss = 361.477
[2018-06-04 19:51] Train Step 50000, Epoch 46.3, Batch Size = 256, Examples/Sec = 3842.06, Train LB = -380.892, Loss = 363.826
Performance on test set:
  Test Lower Bound = -411.539, Test Loss = 411.539
[2018-06-04 19:51] Train Step 50025, Epoch 46.3, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -379.787, Loss = 362.767
[2018-06-04 19:51] Train Step 50050, Epoch 46.3, Batch Size = 256, Examples/Sec = 3865.26, Train LB = -360.862, Loss = 361.663
[2018-06-04 19:51] Train Step 50075, Epoch 46.4, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -342.183, Loss = 360.778
[2018-06-04 19:51] Train Step 50100, Epoch 46.4, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -355.437, Loss = 359.737
[2018-06-04 19:51] Train Step 50125, Epoch 46.4, Batch Size = 256, Examples/Sec = 3848.11, Train LB = -374.020, Loss = 359.207
[2018-06-04 19:51] Train Step 50150, Epoch 46.4, Batch Size = 256, Examples/Sec = 3856.69, Train LB = -365.067, Loss = 359.269
[2018-06-04 19:51] Train Step 50175, Epoch 46.5, Batch Size = 256, Examples/Sec = 3749.54, Train LB = -368.391, Loss = 361.442
[2018-06-04 19:51] Train Step 50200, Epoch 46.5, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -379.061, Loss = 365.030
Performance on test set:
  Test Lower Bound = -410.885, Test Loss = 410.885
[2018-06-04 19:51] Train Step 50225, Epoch 46.5, Batch Size = 256, Examples/Sec = 3812.65, Train LB = -362.837, Loss = 363.608
[2018-06-04 19:51] Train Step 50250, Epoch 46.5, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -369.952, Loss = 363.150
[2018-06-04 19:51] Train Step 50275, Epoch 46.6, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -360.672, Loss = 362.131
[2018-06-04 19:52] Train Step 50300, Epoch 46.6, Batch Size = 256, Examples/Sec = 3870.47, Train LB = -370.915, Loss = 360.889
[2018-06-04 19:52] Train Step 50325, Epoch 46.6, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -358.587, Loss = 359.962
[2018-06-04 19:52] Train Step 50350, Epoch 46.6, Batch Size = 256, Examples/Sec = 3840.21, Train LB = -377.535, Loss = 359.773
[2018-06-04 19:52] Train Step 50375, Epoch 46.6, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -377.033, Loss = 360.969
[2018-06-04 19:52] Train Step 50400, Epoch 46.7, Batch Size = 256, Examples/Sec = 3870.46, Train LB = -382.119, Loss = 364.030
Performance on test set:
  Test Lower Bound = -410.512, Test Loss = 410.512
[2018-06-04 19:52] Train Step 50425, Epoch 46.7, Batch Size = 256, Examples/Sec = 3847.65, Train LB = -360.617, Loss = 363.133
[2018-06-04 19:52] Train Step 50450, Epoch 46.7, Batch Size = 256, Examples/Sec = 3844.07, Train LB = -356.738, Loss = 361.859
[2018-06-04 19:52] Train Step 50475, Epoch 46.7, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -350.079, Loss = 361.524
[2018-06-04 19:52] Train Step 50500, Epoch 46.8, Batch Size = 256, Examples/Sec = 3878.07, Train LB = -355.253, Loss = 360.716
[2018-06-04 19:52] Train Step 50525, Epoch 46.8, Batch Size = 256, Examples/Sec = 3823.51, Train LB = -366.130, Loss = 359.812
[2018-06-04 19:52] Train Step 50550, Epoch 46.8, Batch Size = 256, Examples/Sec = 3836.24, Train LB = -373.274, Loss = 360.038
[2018-06-04 19:52] Train Step 50575, Epoch 46.8, Batch Size = 256, Examples/Sec = 3861.81, Train LB = -365.446, Loss = 360.736
[2018-06-04 19:52] Train Step 50600, Epoch 46.9, Batch Size = 256, Examples/Sec = 3875.57, Train LB = -379.459, Loss = 363.826
Performance on test set:
  Test Lower Bound = -410.058, Test Loss = 410.058
[2018-06-04 19:52] Train Step 50625, Epoch 46.9, Batch Size = 256, Examples/Sec = 3837.40, Train LB = -366.473, Loss = 363.514
[2018-06-04 19:52] Train Step 50650, Epoch 46.9, Batch Size = 256, Examples/Sec = 3818.33, Train LB = -373.525, Loss = 362.115
[2018-06-04 19:52] Train Step 50675, Epoch 46.9, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -362.222, Loss = 361.443
[2018-06-04 19:52] Train Step 50700, Epoch 46.9, Batch Size = 256, Examples/Sec = 3849.86, Train LB = -356.351, Loss = 360.451
[2018-06-04 19:52] Train Step 50725, Epoch 47.0, Batch Size = 256, Examples/Sec = 3875.50, Train LB = -367.654, Loss = 360.076
[2018-06-04 19:52] Train Step 50750, Epoch 47.0, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -368.176, Loss = 360.381
[2018-06-04 19:52] Train Step 50775, Epoch 47.0, Batch Size = 256, Examples/Sec = 3866.61, Train LB = -388.702, Loss = 361.308
[2018-06-04 19:52] Train Step 50800, Epoch 47.0, Batch Size = 256, Examples/Sec = 3863.09, Train LB = -384.187, Loss = 364.490
Performance on test set:
  Test Lower Bound = -409.993, Test Loss = 409.993
[2018-06-04 19:52] Train Step 50825, Epoch 47.1, Batch Size = 256, Examples/Sec = 3876.02, Train LB = -359.909, Loss = 364.003
[2018-06-04 19:52] Train Step 50850, Epoch 47.1, Batch Size = 256, Examples/Sec = 3846.57, Train LB = -355.954, Loss = 362.911
[2018-06-04 19:52] Train Step 50875, Epoch 47.1, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -341.185, Loss = 362.424
[2018-06-04 19:52] Train Step 50900, Epoch 47.1, Batch Size = 256, Examples/Sec = 3781.78, Train LB = -355.977, Loss = 360.608
[2018-06-04 19:52] Train Step 50925, Epoch 47.2, Batch Size = 256, Examples/Sec = 3800.65, Train LB = -381.745, Loss = 359.708
[2018-06-04 19:52] Train Step 50950, Epoch 47.2, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -360.831, Loss = 359.980
[2018-06-04 19:52] Train Step 50975, Epoch 47.2, Batch Size = 256, Examples/Sec = 3729.66, Train LB = -385.834, Loss = 361.305
[2018-06-04 19:52] Train Step 51000, Epoch 47.2, Batch Size = 256, Examples/Sec = 3858.22, Train LB = -368.455, Loss = 364.314
Performance on test set:
  Test Lower Bound = -410.783, Test Loss = 410.783
[2018-06-04 19:53] Train Step 51025, Epoch 47.2, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -360.115, Loss = 362.405
[2018-06-04 19:53] Train Step 51050, Epoch 47.3, Batch Size = 256, Examples/Sec = 3886.79, Train LB = -356.843, Loss = 361.139
[2018-06-04 19:53] Train Step 51075, Epoch 47.3, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -363.626, Loss = 360.288
[2018-06-04 19:53] Train Step 51100, Epoch 47.3, Batch Size = 256, Examples/Sec = 3838.03, Train LB = -353.210, Loss = 359.683
[2018-06-04 19:53] Train Step 51125, Epoch 47.3, Batch Size = 256, Examples/Sec = 3843.78, Train LB = -359.759, Loss = 358.931
[2018-06-04 19:53] Train Step 51150, Epoch 47.4, Batch Size = 256, Examples/Sec = 3848.76, Train LB = -355.915, Loss = 359.850
[2018-06-04 19:53] Train Step 51175, Epoch 47.4, Batch Size = 256, Examples/Sec = 3845.06, Train LB = -383.088, Loss = 361.160
[2018-06-04 19:53] Train Step 51200, Epoch 47.4, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -388.732, Loss = 363.865
Performance on test set:
  Test Lower Bound = -411.209, Test Loss = 411.209
[2018-06-04 19:53] Train Step 51225, Epoch 47.4, Batch Size = 256, Examples/Sec = 3873.68, Train LB = -354.475, Loss = 363.405
[2018-06-04 19:53] Train Step 51250, Epoch 47.5, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -350.002, Loss = 362.007
[2018-06-04 19:53] Train Step 51275, Epoch 47.5, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -368.338, Loss = 360.175
[2018-06-04 19:53] Train Step 51300, Epoch 47.5, Batch Size = 256, Examples/Sec = 3865.37, Train LB = -364.618, Loss = 358.923
[2018-06-04 19:53] Train Step 51325, Epoch 47.5, Batch Size = 256, Examples/Sec = 3860.64, Train LB = -362.801, Loss = 358.859
[2018-06-04 19:53] Train Step 51350, Epoch 47.5, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -360.363, Loss = 359.253
[2018-06-04 19:53] Train Step 51375, Epoch 47.6, Batch Size = 256, Examples/Sec = 3881.49, Train LB = -380.288, Loss = 360.922
[2018-06-04 19:53] Train Step 51400, Epoch 47.6, Batch Size = 256, Examples/Sec = 3868.31, Train LB = -384.284, Loss = 364.023
Performance on test set:
  Test Lower Bound = -410.723, Test Loss = 410.723
[2018-06-04 19:53] Train Step 51425, Epoch 47.6, Batch Size = 256, Examples/Sec = 3875.09, Train LB = -355.923, Loss = 363.694
[2018-06-04 19:53] Train Step 51450, Epoch 47.6, Batch Size = 256, Examples/Sec = 3812.87, Train LB = -350.239, Loss = 362.352
[2018-06-04 19:53] Train Step 51475, Epoch 47.7, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -347.280, Loss = 361.433
[2018-06-04 19:53] Train Step 51500, Epoch 47.7, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -355.459, Loss = 359.194
[2018-06-04 19:53] Train Step 51525, Epoch 47.7, Batch Size = 256, Examples/Sec = 3874.16, Train LB = -346.109, Loss = 359.487
[2018-06-04 19:53] Train Step 51550, Epoch 47.7, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -372.197, Loss = 359.788
[2018-06-04 19:53] Train Step 51575, Epoch 47.8, Batch Size = 256, Examples/Sec = 3847.71, Train LB = -365.404, Loss = 361.227
[2018-06-04 19:53] Train Step 51600, Epoch 47.8, Batch Size = 256, Examples/Sec = 3874.97, Train LB = -379.362, Loss = 364.009
Performance on test set:
  Test Lower Bound = -412.734, Test Loss = 412.734
[2018-06-04 19:53] Train Step 51625, Epoch 47.8, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -355.299, Loss = 363.112
[2018-06-04 19:53] Train Step 51650, Epoch 47.8, Batch Size = 256, Examples/Sec = 3812.94, Train LB = -361.271, Loss = 361.351
[2018-06-04 19:53] Train Step 51675, Epoch 47.8, Batch Size = 256, Examples/Sec = 3861.30, Train LB = -343.165, Loss = 360.233
[2018-06-04 19:53] Train Step 51700, Epoch 47.9, Batch Size = 256, Examples/Sec = 3734.51, Train LB = -349.794, Loss = 358.911
[2018-06-04 19:53] Train Step 51725, Epoch 47.9, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -365.026, Loss = 358.110
[2018-06-04 19:54] Train Step 51750, Epoch 47.9, Batch Size = 256, Examples/Sec = 3855.13, Train LB = -362.386, Loss = 359.168
[2018-06-04 19:54] Train Step 51775, Epoch 47.9, Batch Size = 256, Examples/Sec = 3716.82, Train LB = -352.917, Loss = 361.128
[2018-06-04 19:54] Train Step 51800, Epoch 48.0, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -383.844, Loss = 363.859
Performance on test set:
  Test Lower Bound = -411.520, Test Loss = 411.520
[2018-06-04 19:54] Train Step 51825, Epoch 48.0, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -349.877, Loss = 362.677
[2018-06-04 19:54] Train Step 51850, Epoch 48.0, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -347.361, Loss = 361.565
[2018-06-04 19:54] Train Step 51875, Epoch 48.0, Batch Size = 256, Examples/Sec = 3850.79, Train LB = -364.586, Loss = 360.606
[2018-06-04 19:54] Train Step 51900, Epoch 48.1, Batch Size = 256, Examples/Sec = 3868.88, Train LB = -353.300, Loss = 359.244
[2018-06-04 19:54] Train Step 51925, Epoch 48.1, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -344.753, Loss = 358.952
[2018-06-04 19:54] Train Step 51950, Epoch 48.1, Batch Size = 256, Examples/Sec = 3855.20, Train LB = -365.055, Loss = 358.828
[2018-06-04 19:54] Train Step 51975, Epoch 48.1, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -384.502, Loss = 360.001
[2018-06-04 19:54] Train Step 52000, Epoch 48.1, Batch Size = 256, Examples/Sec = 3840.44, Train LB = -384.012, Loss = 364.072
Performance on test set:
  Test Lower Bound = -408.952, Test Loss = 408.952
[2018-06-04 19:54] Train Step 52025, Epoch 48.2, Batch Size = 256, Examples/Sec = 3872.45, Train LB = -356.998, Loss = 362.927
[2018-06-04 19:54] Train Step 52050, Epoch 48.2, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -376.256, Loss = 362.083
[2018-06-04 19:54] Train Step 52075, Epoch 48.2, Batch Size = 256, Examples/Sec = 3837.96, Train LB = -338.913, Loss = 361.062
[2018-06-04 19:54] Train Step 52100, Epoch 48.2, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -360.222, Loss = 359.385
[2018-06-04 19:54] Train Step 52125, Epoch 48.3, Batch Size = 256, Examples/Sec = 3868.35, Train LB = -362.644, Loss = 359.291
[2018-06-04 19:54] Train Step 52150, Epoch 48.3, Batch Size = 256, Examples/Sec = 3857.51, Train LB = -339.297, Loss = 359.038
[2018-06-04 19:54] Train Step 52175, Epoch 48.3, Batch Size = 256, Examples/Sec = 3845.70, Train LB = -371.347, Loss = 360.378
[2018-06-04 19:54] Train Step 52200, Epoch 48.3, Batch Size = 256, Examples/Sec = 3872.93, Train LB = -385.693, Loss = 364.236
Performance on test set:
  Test Lower Bound = -410.870, Test Loss = 410.870
[2018-06-04 19:54] Train Step 52225, Epoch 48.4, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -373.750, Loss = 363.568
[2018-06-04 19:54] Train Step 52250, Epoch 48.4, Batch Size = 256, Examples/Sec = 3845.28, Train LB = -369.732, Loss = 361.529
[2018-06-04 19:54] Train Step 52275, Epoch 48.4, Batch Size = 256, Examples/Sec = 3869.17, Train LB = -355.057, Loss = 359.702
[2018-06-04 19:54] Train Step 52300, Epoch 48.4, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -350.663, Loss = 358.711
[2018-06-04 19:54] Train Step 52325, Epoch 48.4, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -376.237, Loss = 358.777
[2018-06-04 19:54] Train Step 52350, Epoch 48.5, Batch Size = 256, Examples/Sec = 3858.26, Train LB = -361.718, Loss = 359.746
[2018-06-04 19:54] Train Step 52375, Epoch 48.5, Batch Size = 256, Examples/Sec = 3861.71, Train LB = -371.604, Loss = 361.278
[2018-06-04 19:54] Train Step 52400, Epoch 48.5, Batch Size = 256, Examples/Sec = 3854.66, Train LB = -375.889, Loss = 364.136
Performance on test set:
  Test Lower Bound = -411.365, Test Loss = 411.365
[2018-06-04 19:55] Train Step 52425, Epoch 48.5, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -360.413, Loss = 362.986
[2018-06-04 19:55] Train Step 52450, Epoch 48.6, Batch Size = 256, Examples/Sec = 3882.73, Train LB = -353.371, Loss = 362.507
[2018-06-04 19:55] Train Step 52475, Epoch 48.6, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -359.125, Loss = 360.969
[2018-06-04 19:55] Train Step 52500, Epoch 48.6, Batch Size = 256, Examples/Sec = 3861.77, Train LB = -364.179, Loss = 360.071
[2018-06-04 19:55] Train Step 52525, Epoch 48.6, Batch Size = 256, Examples/Sec = 3840.97, Train LB = -353.794, Loss = 358.659
[2018-06-04 19:55] Train Step 52550, Epoch 48.7, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -364.016, Loss = 359.611
[2018-06-04 19:55] Train Step 52575, Epoch 48.7, Batch Size = 256, Examples/Sec = 3730.96, Train LB = -378.762, Loss = 360.716
[2018-06-04 19:55] Train Step 52600, Epoch 48.7, Batch Size = 256, Examples/Sec = 3843.15, Train LB = -379.593, Loss = 364.119
Performance on test set:
  Test Lower Bound = -409.861, Test Loss = 409.861
[2018-06-04 19:55] Train Step 52625, Epoch 48.7, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -359.464, Loss = 362.749
[2018-06-04 19:55] Train Step 52650, Epoch 48.8, Batch Size = 256, Examples/Sec = 3853.16, Train LB = -366.421, Loss = 361.790
[2018-06-04 19:55] Train Step 52675, Epoch 48.8, Batch Size = 256, Examples/Sec = 3865.09, Train LB = -352.344, Loss = 360.730
[2018-06-04 19:55] Train Step 52700, Epoch 48.8, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -354.872, Loss = 359.638
[2018-06-04 19:55] Train Step 52725, Epoch 48.8, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -362.218, Loss = 358.857
[2018-06-04 19:55] Train Step 52750, Epoch 48.8, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -361.104, Loss = 358.912
[2018-06-04 19:55] Train Step 52775, Epoch 48.9, Batch Size = 256, Examples/Sec = 3868.00, Train LB = -363.826, Loss = 360.140
[2018-06-04 19:55] Train Step 52800, Epoch 48.9, Batch Size = 256, Examples/Sec = 3854.15, Train LB = -374.201, Loss = 362.715
Performance on test set:
  Test Lower Bound = -410.755, Test Loss = 410.755
[2018-06-04 19:55] Train Step 52825, Epoch 48.9, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -370.883, Loss = 361.961
[2018-06-04 19:55] Train Step 52850, Epoch 48.9, Batch Size = 256, Examples/Sec = 3860.35, Train LB = -363.392, Loss = 361.310
[2018-06-04 19:55] Train Step 52875, Epoch 49.0, Batch Size = 256, Examples/Sec = 3862.94, Train LB = -367.879, Loss = 360.004
[2018-06-04 19:55] Train Step 52900, Epoch 49.0, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -338.077, Loss = 358.637
[2018-06-04 19:55] Train Step 52925, Epoch 49.0, Batch Size = 256, Examples/Sec = 3847.83, Train LB = -357.088, Loss = 358.102
[2018-06-04 19:55] Train Step 52950, Epoch 49.0, Batch Size = 256, Examples/Sec = 3861.53, Train LB = -356.943, Loss = 358.130
[2018-06-04 19:55] Train Step 52975, Epoch 49.1, Batch Size = 256, Examples/Sec = 3798.56, Train LB = -374.479, Loss = 359.635
[2018-06-04 19:55] Train Step 53000, Epoch 49.1, Batch Size = 256, Examples/Sec = 3872.97, Train LB = -375.761, Loss = 362.606
Performance on test set:
  Test Lower Bound = -411.332, Test Loss = 411.332
[2018-06-04 19:55] Train Step 53025, Epoch 49.1, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -360.045, Loss = 361.923
[2018-06-04 19:55] Train Step 53050, Epoch 49.1, Batch Size = 256, Examples/Sec = 3739.02, Train LB = -358.983, Loss = 360.695
[2018-06-04 19:55] Train Step 53075, Epoch 49.1, Batch Size = 256, Examples/Sec = 3878.26, Train LB = -371.448, Loss = 359.477
[2018-06-04 19:55] Train Step 53100, Epoch 49.2, Batch Size = 256, Examples/Sec = 3852.17, Train LB = -361.908, Loss = 358.020
[2018-06-04 19:55] Train Step 53125, Epoch 49.2, Batch Size = 256, Examples/Sec = 3736.08, Train LB = -349.464, Loss = 357.977
[2018-06-04 19:55] Train Step 53150, Epoch 49.2, Batch Size = 256, Examples/Sec = 3822.15, Train LB = -376.541, Loss = 359.127
[2018-06-04 19:56] Train Step 53175, Epoch 49.2, Batch Size = 256, Examples/Sec = 3880.61, Train LB = -371.584, Loss = 360.341
[2018-06-04 19:56] Train Step 53200, Epoch 49.3, Batch Size = 256, Examples/Sec = 3824.49, Train LB = -376.208, Loss = 362.667
Performance on test set:
  Test Lower Bound = -411.844, Test Loss = 411.844
[2018-06-04 19:56] Train Step 53225, Epoch 49.3, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -354.781, Loss = 361.987
[2018-06-04 19:56] Train Step 53250, Epoch 49.3, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -337.584, Loss = 361.096
[2018-06-04 19:56] Train Step 53275, Epoch 49.3, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -361.108, Loss = 358.613
[2018-06-04 19:56] Train Step 53300, Epoch 49.4, Batch Size = 256, Examples/Sec = 3814.45, Train LB = -374.468, Loss = 357.728
[2018-06-04 19:56] Train Step 53325, Epoch 49.4, Batch Size = 256, Examples/Sec = 3876.03, Train LB = -349.281, Loss = 357.934
[2018-06-04 19:56] Train Step 53350, Epoch 49.4, Batch Size = 256, Examples/Sec = 3863.21, Train LB = -358.182, Loss = 358.946
[2018-06-04 19:56] Train Step 53375, Epoch 49.4, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -377.034, Loss = 360.270
[2018-06-04 19:56] Train Step 53400, Epoch 49.4, Batch Size = 256, Examples/Sec = 3882.49, Train LB = -378.259, Loss = 363.659
Performance on test set:
  Test Lower Bound = -412.565, Test Loss = 412.565
[2018-06-04 19:56] Train Step 53425, Epoch 49.5, Batch Size = 256, Examples/Sec = 3877.79, Train LB = -358.653, Loss = 362.340
[2018-06-04 19:56] Train Step 53450, Epoch 49.5, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -378.042, Loss = 360.722
[2018-06-04 19:56] Train Step 53475, Epoch 49.5, Batch Size = 256, Examples/Sec = 3831.54, Train LB = -366.314, Loss = 359.803
[2018-06-04 19:56] Train Step 53500, Epoch 49.5, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -364.474, Loss = 358.558
[2018-06-04 19:56] Train Step 53525, Epoch 49.6, Batch Size = 256, Examples/Sec = 3804.37, Train LB = -369.590, Loss = 357.929
[2018-06-04 19:56] Train Step 53550, Epoch 49.6, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -354.834, Loss = 358.532
[2018-06-04 19:56] Train Step 53575, Epoch 49.6, Batch Size = 256, Examples/Sec = 3863.45, Train LB = -377.699, Loss = 359.301
[2018-06-04 19:56] Train Step 53600, Epoch 49.6, Batch Size = 256, Examples/Sec = 3788.10, Train LB = -376.314, Loss = 363.104
Performance on test set:
  Test Lower Bound = -416.154, Test Loss = 416.154
[2018-06-04 19:56] Train Step 53625, Epoch 49.7, Batch Size = 256, Examples/Sec = 3855.25, Train LB = -356.755, Loss = 362.215
[2018-06-04 19:56] Train Step 53650, Epoch 49.7, Batch Size = 256, Examples/Sec = 3862.98, Train LB = -347.520, Loss = 360.785
[2018-06-04 19:56] Train Step 53675, Epoch 49.7, Batch Size = 256, Examples/Sec = 3876.25, Train LB = -351.668, Loss = 359.154
[2018-06-04 19:56] Train Step 53700, Epoch 49.7, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -356.528, Loss = 358.536
[2018-06-04 19:56] Train Step 53725, Epoch 49.7, Batch Size = 256, Examples/Sec = 3834.98, Train LB = -366.567, Loss = 358.844
[2018-06-04 19:56] Train Step 53750, Epoch 49.8, Batch Size = 256, Examples/Sec = 3860.89, Train LB = -363.626, Loss = 359.087
[2018-06-04 19:56] Train Step 53775, Epoch 49.8, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -380.466, Loss = 360.305
[2018-06-04 19:56] Train Step 53800, Epoch 49.8, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -384.076, Loss = 363.325
Performance on test set:
  Test Lower Bound = -411.064, Test Loss = 411.064
[2018-06-04 19:56] Train Step 53825, Epoch 49.8, Batch Size = 256, Examples/Sec = 3875.50, Train LB = -345.991, Loss = 361.952
[2018-06-04 19:56] Train Step 53850, Epoch 49.9, Batch Size = 256, Examples/Sec = 3733.08, Train LB = -363.042, Loss = 360.301
[2018-06-04 19:57] Train Step 53875, Epoch 49.9, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -355.520, Loss = 359.395
[2018-06-04 19:57] Train Step 53900, Epoch 49.9, Batch Size = 256, Examples/Sec = 3860.59, Train LB = -359.777, Loss = 358.140
[2018-06-04 19:57] Train Step 53925, Epoch 49.9, Batch Size = 256, Examples/Sec = 3781.78, Train LB = -370.423, Loss = 357.321
[2018-06-04 19:57] Train Step 53950, Epoch 50.0, Batch Size = 256, Examples/Sec = 3836.93, Train LB = -376.815, Loss = 357.367
[2018-06-04 19:57] Train Step 53975, Epoch 50.0, Batch Size = 256, Examples/Sec = 3839.18, Train LB = -362.251, Loss = 359.708
[2018-06-04 19:57] Train Step 54000, Epoch 50.0, Batch Size = 256, Examples/Sec = 3853.34, Train LB = -386.376, Loss = 362.596
Performance on test set:
  Test Lower Bound = -413.082, Test Loss = 413.082
[2018-06-04 19:57] Train Step 54025, Epoch 50.0, Batch Size = 256, Examples/Sec = 3817.69, Train LB = -359.626, Loss = 361.803
[2018-06-04 19:57] Train Step 54050, Epoch 50.0, Batch Size = 256, Examples/Sec = 3832.40, Train LB = -340.974, Loss = 359.796
[2018-06-04 19:57] Train Step 54075, Epoch 50.1, Batch Size = 256, Examples/Sec = 3855.54, Train LB = -351.169, Loss = 358.756
[2018-06-04 19:57] Train Step 54100, Epoch 50.1, Batch Size = 256, Examples/Sec = 3869.28, Train LB = -354.190, Loss = 358.124
[2018-06-04 19:57] Train Step 54125, Epoch 50.1, Batch Size = 256, Examples/Sec = 3874.98, Train LB = -361.516, Loss = 358.673
[2018-06-04 19:57] Train Step 54150, Epoch 50.1, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -369.884, Loss = 358.350
[2018-06-04 19:57] Train Step 54175, Epoch 50.2, Batch Size = 256, Examples/Sec = 3853.40, Train LB = -363.278, Loss = 360.272
[2018-06-04 19:57] Train Step 54200, Epoch 50.2, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -375.079, Loss = 363.053
Performance on test set:
  Test Lower Bound = -412.374, Test Loss = 412.374
[2018-06-04 19:57] Train Step 54225, Epoch 50.2, Batch Size = 256, Examples/Sec = 3860.02, Train LB = -362.111, Loss = 361.483
[2018-06-04 19:57] Train Step 54250, Epoch 50.2, Batch Size = 256, Examples/Sec = 3810.93, Train LB = -341.916, Loss = 360.079
[2018-06-04 19:57] Train Step 54275, Epoch 50.3, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -337.649, Loss = 358.335
[2018-06-04 19:57] Train Step 54300, Epoch 50.3, Batch Size = 256, Examples/Sec = 3801.82, Train LB = -373.562, Loss = 357.593
[2018-06-04 19:57] Train Step 54325, Epoch 50.3, Batch Size = 256, Examples/Sec = 3812.76, Train LB = -359.046, Loss = 357.463
[2018-06-04 19:57] Train Step 54350, Epoch 50.3, Batch Size = 256, Examples/Sec = 3859.73, Train LB = -356.952, Loss = 357.664
[2018-06-04 19:57] Train Step 54375, Epoch 50.3, Batch Size = 256, Examples/Sec = 3849.68, Train LB = -365.914, Loss = 359.096
[2018-06-04 19:57] Train Step 54400, Epoch 50.4, Batch Size = 256, Examples/Sec = 3854.51, Train LB = -391.949, Loss = 362.681
Performance on test set:
  Test Lower Bound = -414.167, Test Loss = 414.167
[2018-06-04 19:57] Train Step 54425, Epoch 50.4, Batch Size = 256, Examples/Sec = 3851.48, Train LB = -354.859, Loss = 361.686
[2018-06-04 19:57] Train Step 54450, Epoch 50.4, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -360.646, Loss = 359.937
[2018-06-04 19:57] Train Step 54475, Epoch 50.4, Batch Size = 256, Examples/Sec = 3868.66, Train LB = -351.861, Loss = 358.418
[2018-06-04 19:57] Train Step 54500, Epoch 50.5, Batch Size = 256, Examples/Sec = 3861.30, Train LB = -375.483, Loss = 358.271
[2018-06-04 19:57] Train Step 54525, Epoch 50.5, Batch Size = 256, Examples/Sec = 3865.08, Train LB = -362.233, Loss = 357.890
[2018-06-04 19:57] Train Step 54550, Epoch 50.5, Batch Size = 256, Examples/Sec = 3869.17, Train LB = -356.682, Loss = 357.859
[2018-06-04 19:57] Train Step 54575, Epoch 50.5, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -357.799, Loss = 359.234
[2018-06-04 19:57] Train Step 54600, Epoch 50.6, Batch Size = 256, Examples/Sec = 3846.44, Train LB = -383.777, Loss = 361.902
Performance on test set:
  Test Lower Bound = -412.888, Test Loss = 412.888
[2018-06-04 19:58] Train Step 54625, Epoch 50.6, Batch Size = 256, Examples/Sec = 3842.00, Train LB = -345.312, Loss = 361.352
[2018-06-04 19:58] Train Step 54650, Epoch 50.6, Batch Size = 256, Examples/Sec = 3745.82, Train LB = -359.657, Loss = 359.563
[2018-06-04 19:58] Train Step 54675, Epoch 50.6, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -345.033, Loss = 358.202
[2018-06-04 19:58] Train Step 54700, Epoch 50.6, Batch Size = 256, Examples/Sec = 3846.22, Train LB = -360.334, Loss = 358.130
[2018-06-04 19:58] Train Step 54725, Epoch 50.7, Batch Size = 256, Examples/Sec = 3727.44, Train LB = -346.751, Loss = 357.349
[2018-06-04 19:58] Train Step 54750, Epoch 50.7, Batch Size = 256, Examples/Sec = 3871.04, Train LB = -370.265, Loss = 357.781
[2018-06-04 19:58] Train Step 54775, Epoch 50.7, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -386.142, Loss = 359.084
[2018-06-04 19:58] Train Step 54800, Epoch 50.7, Batch Size = 256, Examples/Sec = 3813.04, Train LB = -381.365, Loss = 362.834
Performance on test set:
  Test Lower Bound = -413.165, Test Loss = 413.165
[2018-06-04 19:58] Train Step 54825, Epoch 50.8, Batch Size = 256, Examples/Sec = 3865.68, Train LB = -358.507, Loss = 361.799
[2018-06-04 19:58] Train Step 54850, Epoch 50.8, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -349.722, Loss = 360.901
[2018-06-04 19:58] Train Step 54875, Epoch 50.8, Batch Size = 256, Examples/Sec = 3841.36, Train LB = -361.727, Loss = 359.734
[2018-06-04 19:58] Train Step 54900, Epoch 50.8, Batch Size = 256, Examples/Sec = 3862.41, Train LB = -338.635, Loss = 358.189
[2018-06-04 19:58] Train Step 54925, Epoch 50.9, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -366.487, Loss = 357.765
[2018-06-04 19:58] Train Step 54950, Epoch 50.9, Batch Size = 256, Examples/Sec = 3793.16, Train LB = -350.647, Loss = 358.205
[2018-06-04 19:58] Train Step 54975, Epoch 50.9, Batch Size = 256, Examples/Sec = 3834.57, Train LB = -359.308, Loss = 360.192
[2018-06-04 19:58] Train Step 55000, Epoch 50.9, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -373.808, Loss = 362.717
Performance on test set:
  Test Lower Bound = -411.640, Test Loss = 411.640
[2018-06-04 19:58] Train Step 55025, Epoch 50.9, Batch Size = 256, Examples/Sec = 3836.01, Train LB = -357.647, Loss = 361.937
[2018-06-04 19:58] Train Step 55050, Epoch 51.0, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -349.670, Loss = 361.096
[2018-06-04 19:58] Train Step 55075, Epoch 51.0, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -362.410, Loss = 359.657
[2018-06-04 19:58] Train Step 55100, Epoch 51.0, Batch Size = 256, Examples/Sec = 3869.24, Train LB = -357.391, Loss = 358.263
[2018-06-04 19:58] Train Step 55125, Epoch 51.0, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -346.644, Loss = 356.723
[2018-06-04 19:58] Train Step 55150, Epoch 51.1, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -362.295, Loss = 357.496
[2018-06-04 19:58] Train Step 55175, Epoch 51.1, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -370.793, Loss = 358.386
[2018-06-04 19:58] Train Step 55200, Epoch 51.1, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -385.615, Loss = 361.724
Performance on test set:
  Test Lower Bound = -412.320, Test Loss = 412.320
[2018-06-04 19:58] Train Step 55225, Epoch 51.1, Batch Size = 256, Examples/Sec = 3842.74, Train LB = -364.611, Loss = 361.254
[2018-06-04 19:58] Train Step 55250, Epoch 51.2, Batch Size = 256, Examples/Sec = 3881.02, Train LB = -350.683, Loss = 358.976
[2018-06-04 19:58] Train Step 55275, Epoch 51.2, Batch Size = 256, Examples/Sec = 3818.10, Train LB = -350.268, Loss = 358.145
[2018-06-04 19:59] Train Step 55300, Epoch 51.2, Batch Size = 256, Examples/Sec = 3858.62, Train LB = -352.815, Loss = 357.106
[2018-06-04 19:59] Train Step 55325, Epoch 51.2, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -358.123, Loss = 356.840
[2018-06-04 19:59] Train Step 55350, Epoch 51.2, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -362.049, Loss = 356.700
[2018-06-04 19:59] Train Step 55375, Epoch 51.3, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -357.712, Loss = 358.577
[2018-06-04 19:59] Train Step 55400, Epoch 51.3, Batch Size = 256, Examples/Sec = 3840.21, Train LB = -386.524, Loss = 362.370
Performance on test set:
  Test Lower Bound = -412.652, Test Loss = 412.652
[2018-06-04 19:59] Train Step 55425, Epoch 51.3, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -355.494, Loss = 361.480
[2018-06-04 19:59] Train Step 55450, Epoch 51.3, Batch Size = 256, Examples/Sec = 3784.18, Train LB = -348.179, Loss = 360.873
[2018-06-04 19:59] Train Step 55475, Epoch 51.4, Batch Size = 256, Examples/Sec = 3860.89, Train LB = -351.878, Loss = 358.727
[2018-06-04 19:59] Train Step 55500, Epoch 51.4, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -361.664, Loss = 357.222
[2018-06-04 19:59] Train Step 55525, Epoch 51.4, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -343.923, Loss = 357.144
[2018-06-04 19:59] Train Step 55550, Epoch 51.4, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -369.194, Loss = 357.447
[2018-06-04 19:59] Train Step 55575, Epoch 51.5, Batch Size = 256, Examples/Sec = 3845.16, Train LB = -369.200, Loss = 358.486
[2018-06-04 19:59] Train Step 55600, Epoch 51.5, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -386.397, Loss = 361.720
Performance on test set:
  Test Lower Bound = -410.796, Test Loss = 410.796
[2018-06-04 19:59] Train Step 55625, Epoch 51.5, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -357.371, Loss = 361.218
[2018-06-04 19:59] Train Step 55650, Epoch 51.5, Batch Size = 256, Examples/Sec = 3857.58, Train LB = -358.857, Loss = 360.088
[2018-06-04 19:59] Train Step 55675, Epoch 51.6, Batch Size = 256, Examples/Sec = 3827.41, Train LB = -358.094, Loss = 358.422
[2018-06-04 19:59] Train Step 55700, Epoch 51.6, Batch Size = 256, Examples/Sec = 3845.75, Train LB = -350.865, Loss = 357.605
[2018-06-04 19:59] Train Step 55725, Epoch 51.6, Batch Size = 256, Examples/Sec = 3839.63, Train LB = -358.719, Loss = 356.650
[2018-06-04 19:59] Train Step 55750, Epoch 51.6, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -369.699, Loss = 357.545
[2018-06-04 19:59] Train Step 55775, Epoch 51.6, Batch Size = 256, Examples/Sec = 3865.37, Train LB = -379.969, Loss = 358.502
[2018-06-04 19:59] Train Step 55800, Epoch 51.7, Batch Size = 256, Examples/Sec = 3843.62, Train LB = -387.889, Loss = 362.303
Performance on test set:
  Test Lower Bound = -412.838, Test Loss = 412.838
[2018-06-04 19:59] Train Step 55825, Epoch 51.7, Batch Size = 256, Examples/Sec = 3854.37, Train LB = -344.007, Loss = 361.491
[2018-06-04 19:59] Train Step 55850, Epoch 51.7, Batch Size = 256, Examples/Sec = 3848.05, Train LB = -358.722, Loss = 360.045
[2018-06-04 19:59] Train Step 55875, Epoch 51.7, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -363.828, Loss = 358.253
[2018-06-04 19:59] Train Step 55900, Epoch 51.8, Batch Size = 256, Examples/Sec = 3860.37, Train LB = -360.948, Loss = 357.820
[2018-06-04 19:59] Train Step 55925, Epoch 51.8, Batch Size = 256, Examples/Sec = 3881.20, Train LB = -375.516, Loss = 357.195
[2018-06-04 19:59] Train Step 55950, Epoch 51.8, Batch Size = 256, Examples/Sec = 3841.24, Train LB = -367.600, Loss = 357.645
[2018-06-04 19:59] Train Step 55975, Epoch 51.8, Batch Size = 256, Examples/Sec = 3850.21, Train LB = -376.117, Loss = 358.900
[2018-06-04 19:59] Train Step 56000, Epoch 51.9, Batch Size = 256, Examples/Sec = 3849.10, Train LB = -364.251, Loss = 361.881
Performance on test set:
  Test Lower Bound = -413.167, Test Loss = 413.167
[2018-06-04 20:00] Train Step 56025, Epoch 51.9, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -344.466, Loss = 361.023
[2018-06-04 20:00] Train Step 56050, Epoch 51.9, Batch Size = 256, Examples/Sec = 3855.14, Train LB = -349.005, Loss = 359.721
[2018-06-04 20:00] Train Step 56075, Epoch 51.9, Batch Size = 256, Examples/Sec = 3851.42, Train LB = -360.738, Loss = 358.669
[2018-06-04 20:00] Train Step 56100, Epoch 51.9, Batch Size = 256, Examples/Sec = 3850.32, Train LB = -347.893, Loss = 357.322
[2018-06-04 20:00] Train Step 56125, Epoch 52.0, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -351.930, Loss = 356.236
[2018-06-04 20:00] Train Step 56150, Epoch 52.0, Batch Size = 256, Examples/Sec = 3878.91, Train LB = -365.885, Loss = 356.699
[2018-06-04 20:00] Train Step 56175, Epoch 52.0, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -361.486, Loss = 358.595
[2018-06-04 20:00] Train Step 56200, Epoch 52.0, Batch Size = 256, Examples/Sec = 3866.36, Train LB = -363.853, Loss = 361.270
Performance on test set:
  Test Lower Bound = -413.225, Test Loss = 413.225
[2018-06-04 20:00] Train Step 56225, Epoch 52.1, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -358.751, Loss = 360.491
[2018-06-04 20:00] Train Step 56250, Epoch 52.1, Batch Size = 256, Examples/Sec = 3731.24, Train LB = -348.225, Loss = 359.458
[2018-06-04 20:00] Train Step 56275, Epoch 52.1, Batch Size = 256, Examples/Sec = 3858.80, Train LB = -351.936, Loss = 358.220
[2018-06-04 20:00] Train Step 56300, Epoch 52.1, Batch Size = 256, Examples/Sec = 3794.45, Train LB = -341.743, Loss = 356.918
[2018-06-04 20:00] Train Step 56325, Epoch 52.2, Batch Size = 256, Examples/Sec = 3740.23, Train LB = -359.459, Loss = 356.152
[2018-06-04 20:00] Train Step 56350, Epoch 52.2, Batch Size = 256, Examples/Sec = 3876.02, Train LB = -360.059, Loss = 356.643
[2018-06-04 20:00] Train Step 56375, Epoch 52.2, Batch Size = 256, Examples/Sec = 3845.64, Train LB = -349.904, Loss = 358.404
[2018-06-04 20:00] Train Step 56400, Epoch 52.2, Batch Size = 256, Examples/Sec = 3732.43, Train LB = -380.003, Loss = 361.340
Performance on test set:
  Test Lower Bound = -413.139, Test Loss = 413.139
[2018-06-04 20:00] Train Step 56425, Epoch 52.2, Batch Size = 256, Examples/Sec = 3850.79, Train LB = -353.013, Loss = 360.060
[2018-06-04 20:00] Train Step 56450, Epoch 52.3, Batch Size = 256, Examples/Sec = 3829.88, Train LB = -343.457, Loss = 359.430
[2018-06-04 20:00] Train Step 56475, Epoch 52.3, Batch Size = 256, Examples/Sec = 3853.74, Train LB = -358.438, Loss = 358.280
[2018-06-04 20:00] Train Step 56500, Epoch 52.3, Batch Size = 256, Examples/Sec = 3847.83, Train LB = -354.954, Loss = 357.780
[2018-06-04 20:00] Train Step 56525, Epoch 52.3, Batch Size = 256, Examples/Sec = 3848.05, Train LB = -369.365, Loss = 357.125
[2018-06-04 20:00] Train Step 56550, Epoch 52.4, Batch Size = 256, Examples/Sec = 3861.71, Train LB = -355.580, Loss = 357.125
[2018-06-04 20:00] Train Step 56575, Epoch 52.4, Batch Size = 256, Examples/Sec = 3834.29, Train LB = -344.260, Loss = 358.592
[2018-06-04 20:00] Train Step 56600, Epoch 52.4, Batch Size = 256, Examples/Sec = 3827.81, Train LB = -391.931, Loss = 361.251
Performance on test set:
  Test Lower Bound = -412.459, Test Loss = 412.459
[2018-06-04 20:00] Train Step 56625, Epoch 52.4, Batch Size = 256, Examples/Sec = 3818.83, Train LB = -367.112, Loss = 360.928
[2018-06-04 20:00] Train Step 56650, Epoch 52.5, Batch Size = 256, Examples/Sec = 3859.91, Train LB = -354.156, Loss = 358.958
[2018-06-04 20:00] Train Step 56675, Epoch 52.5, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -353.749, Loss = 357.521
[2018-06-04 20:00] Train Step 56700, Epoch 52.5, Batch Size = 256, Examples/Sec = 3791.41, Train LB = -351.071, Loss = 356.765
[2018-06-04 20:00] Train Step 56725, Epoch 52.5, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -356.074, Loss = 357.060
[2018-06-04 20:01] Train Step 56750, Epoch 52.5, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -354.990, Loss = 356.042
[2018-06-04 20:01] Train Step 56775, Epoch 52.6, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -359.514, Loss = 356.966
[2018-06-04 20:01] Train Step 56800, Epoch 52.6, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -382.683, Loss = 360.401
Performance on test set:
  Test Lower Bound = -412.800, Test Loss = 412.800
[2018-06-04 20:01] Train Step 56825, Epoch 52.6, Batch Size = 256, Examples/Sec = 3856.17, Train LB = -366.395, Loss = 359.174
[2018-06-04 20:01] Train Step 56850, Epoch 52.6, Batch Size = 256, Examples/Sec = 3864.40, Train LB = -345.346, Loss = 358.776
[2018-06-04 20:01] Train Step 56875, Epoch 52.7, Batch Size = 256, Examples/Sec = 3804.26, Train LB = -348.563, Loss = 357.791
[2018-06-04 20:01] Train Step 56900, Epoch 52.7, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -360.427, Loss = 356.521
[2018-06-04 20:01] Train Step 56925, Epoch 52.7, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -346.799, Loss = 356.187
[2018-06-04 20:01] Train Step 56950, Epoch 52.7, Batch Size = 256, Examples/Sec = 3852.04, Train LB = -352.787, Loss = 356.076
[2018-06-04 20:01] Train Step 56975, Epoch 52.8, Batch Size = 256, Examples/Sec = 3856.65, Train LB = -366.220, Loss = 358.058
[2018-06-04 20:01] Train Step 57000, Epoch 52.8, Batch Size = 256, Examples/Sec = 3820.22, Train LB = -396.906, Loss = 361.294
Performance on test set:
  Test Lower Bound = -413.631, Test Loss = 413.631
[2018-06-04 20:01] Train Step 57025, Epoch 52.8, Batch Size = 256, Examples/Sec = 3842.63, Train LB = -356.591, Loss = 360.418
[2018-06-04 20:01] Train Step 57050, Epoch 52.8, Batch Size = 256, Examples/Sec = 3845.06, Train LB = -373.512, Loss = 359.174
[2018-06-04 20:01] Train Step 57075, Epoch 52.8, Batch Size = 256, Examples/Sec = 3845.17, Train LB = -339.677, Loss = 357.858
[2018-06-04 20:01] Train Step 57100, Epoch 52.9, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -355.843, Loss = 356.983
[2018-06-04 20:01] Train Step 57125, Epoch 52.9, Batch Size = 256, Examples/Sec = 3875.04, Train LB = -350.406, Loss = 357.173
[2018-06-04 20:01] Train Step 57150, Epoch 52.9, Batch Size = 256, Examples/Sec = 3844.65, Train LB = -359.711, Loss = 356.674
[2018-06-04 20:01] Train Step 57175, Epoch 52.9, Batch Size = 256, Examples/Sec = 3847.65, Train LB = -360.954, Loss = 358.058
[2018-06-04 20:01] Train Step 57200, Epoch 53.0, Batch Size = 256, Examples/Sec = 3878.79, Train LB = -381.776, Loss = 360.721
Performance on test set:
  Test Lower Bound = -412.115, Test Loss = 412.115
[2018-06-04 20:01] Train Step 57225, Epoch 53.0, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -347.138, Loss = 360.444
[2018-06-04 20:01] Train Step 57250, Epoch 53.0, Batch Size = 256, Examples/Sec = 3834.11, Train LB = -358.822, Loss = 359.078
[2018-06-04 20:01] Train Step 57275, Epoch 53.0, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -347.464, Loss = 357.589
[2018-06-04 20:01] Train Step 57300, Epoch 53.1, Batch Size = 256, Examples/Sec = 3831.59, Train LB = -373.558, Loss = 356.843
[2018-06-04 20:01] Train Step 57325, Epoch 53.1, Batch Size = 256, Examples/Sec = 3832.10, Train LB = -347.507, Loss = 356.218
[2018-06-04 20:01] Train Step 57350, Epoch 53.1, Batch Size = 256, Examples/Sec = 3849.50, Train LB = -371.897, Loss = 356.162
[2018-06-04 20:01] Train Step 57375, Epoch 53.1, Batch Size = 256, Examples/Sec = 3845.23, Train LB = -359.613, Loss = 357.935
[2018-06-04 20:01] Train Step 57400, Epoch 53.1, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -385.709, Loss = 361.202
Performance on test set:
  Test Lower Bound = -414.372, Test Loss = 414.372
[2018-06-04 20:02] Train Step 57425, Epoch 53.2, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -342.631, Loss = 360.375
[2018-06-04 20:02] Train Step 57450, Epoch 53.2, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -359.217, Loss = 358.641
[2018-06-04 20:02] Train Step 57475, Epoch 53.2, Batch Size = 256, Examples/Sec = 3865.73, Train LB = -333.165, Loss = 357.631
[2018-06-04 20:02] Train Step 57500, Epoch 53.2, Batch Size = 256, Examples/Sec = 3841.82, Train LB = -364.457, Loss = 357.037
[2018-06-04 20:02] Train Step 57525, Epoch 53.3, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -364.387, Loss = 356.728
[2018-06-04 20:02] Train Step 57550, Epoch 53.3, Batch Size = 256, Examples/Sec = 3871.98, Train LB = -351.012, Loss = 356.622
[2018-06-04 20:02] Train Step 57575, Epoch 53.3, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -367.077, Loss = 357.496
[2018-06-04 20:02] Train Step 57600, Epoch 53.3, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -364.223, Loss = 360.890
Performance on test set:
  Test Lower Bound = -412.607, Test Loss = 412.607
[2018-06-04 20:02] Train Step 57625, Epoch 53.4, Batch Size = 256, Examples/Sec = 3854.67, Train LB = -350.671, Loss = 359.740
[2018-06-04 20:02] Train Step 57650, Epoch 53.4, Batch Size = 256, Examples/Sec = 3851.88, Train LB = -345.291, Loss = 358.406
[2018-06-04 20:02] Train Step 57675, Epoch 53.4, Batch Size = 256, Examples/Sec = 3776.21, Train LB = -368.444, Loss = 356.824
[2018-06-04 20:02] Train Step 57700, Epoch 53.4, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -364.914, Loss = 355.881
[2018-06-04 20:02] Train Step 57725, Epoch 53.4, Batch Size = 256, Examples/Sec = 3795.96, Train LB = -357.054, Loss = 355.412
[2018-06-04 20:02] Train Step 57750, Epoch 53.5, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -360.416, Loss = 355.569
[2018-06-04 20:02] Train Step 57775, Epoch 53.5, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -383.146, Loss = 356.841
[2018-06-04 20:02] Train Step 57800, Epoch 53.5, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -372.629, Loss = 360.814
Performance on test set:
  Test Lower Bound = -416.055, Test Loss = 416.055
[2018-06-04 20:02] Train Step 57825, Epoch 53.5, Batch Size = 256, Examples/Sec = 3874.49, Train LB = -348.477, Loss = 360.013
[2018-06-04 20:02] Train Step 57850, Epoch 53.6, Batch Size = 256, Examples/Sec = 3839.18, Train LB = -353.169, Loss = 358.190
[2018-06-04 20:02] Train Step 57875, Epoch 53.6, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -364.539, Loss = 356.568
[2018-06-04 20:02] Train Step 57900, Epoch 53.6, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -341.785, Loss = 356.493
[2018-06-04 20:02] Train Step 57925, Epoch 53.6, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -351.408, Loss = 356.441
[2018-06-04 20:02] Train Step 57950, Epoch 53.7, Batch Size = 256, Examples/Sec = 3876.91, Train LB = -365.130, Loss = 355.315
[2018-06-04 20:02] Train Step 57975, Epoch 53.7, Batch Size = 256, Examples/Sec = 3832.74, Train LB = -376.357, Loss = 356.574
[2018-06-04 20:02] Train Step 58000, Epoch 53.7, Batch Size = 256, Examples/Sec = 3750.75, Train LB = -365.315, Loss = 360.378
Performance on test set:
  Test Lower Bound = -415.338, Test Loss = 415.338
[2018-06-04 20:02] Train Step 58025, Epoch 53.7, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -349.699, Loss = 359.190
[2018-06-04 20:02] Train Step 58050, Epoch 53.8, Batch Size = 256, Examples/Sec = 3842.86, Train LB = -353.276, Loss = 357.471
[2018-06-04 20:02] Train Step 58075, Epoch 53.8, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -344.320, Loss = 357.180
[2018-06-04 20:02] Train Step 58100, Epoch 53.8, Batch Size = 256, Examples/Sec = 3853.38, Train LB = -342.679, Loss = 357.299
[2018-06-04 20:02] Train Step 58125, Epoch 53.8, Batch Size = 256, Examples/Sec = 3855.25, Train LB = -354.208, Loss = 356.194
[2018-06-04 20:02] Train Step 58150, Epoch 53.8, Batch Size = 256, Examples/Sec = 3878.91, Train LB = -359.636, Loss = 356.415
[2018-06-04 20:03] Train Step 58175, Epoch 53.9, Batch Size = 256, Examples/Sec = 3851.35, Train LB = -364.256, Loss = 356.773
[2018-06-04 20:03] Train Step 58200, Epoch 53.9, Batch Size = 256, Examples/Sec = 3851.99, Train LB = -364.931, Loss = 360.462
Performance on test set:
  Test Lower Bound = -415.059, Test Loss = 415.059
[2018-06-04 20:03] Train Step 58225, Epoch 53.9, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -346.543, Loss = 359.658
[2018-06-04 20:03] Train Step 58250, Epoch 53.9, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -356.555, Loss = 358.584
[2018-06-04 20:03] Train Step 58275, Epoch 54.0, Batch Size = 256, Examples/Sec = 3858.84, Train LB = -353.189, Loss = 357.365
[2018-06-04 20:03] Train Step 58300, Epoch 54.0, Batch Size = 256, Examples/Sec = 3850.50, Train LB = -346.727, Loss = 356.075
[2018-06-04 20:03] Train Step 58325, Epoch 54.0, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -354.968, Loss = 355.223
[2018-06-04 20:03] Train Step 58350, Epoch 54.0, Batch Size = 256, Examples/Sec = 3795.01, Train LB = -362.241, Loss = 355.610
[2018-06-04 20:03] Train Step 58375, Epoch 54.1, Batch Size = 256, Examples/Sec = 3858.85, Train LB = -357.381, Loss = 357.081
[2018-06-04 20:03] Train Step 58400, Epoch 54.1, Batch Size = 256, Examples/Sec = 3842.28, Train LB = -376.653, Loss = 360.947
Performance on test set:
  Test Lower Bound = -413.866, Test Loss = 413.866
[2018-06-04 20:03] Train Step 58425, Epoch 54.1, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -330.869, Loss = 360.266
[2018-06-04 20:03] Train Step 58450, Epoch 54.1, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -369.843, Loss = 359.195
[2018-06-04 20:03] Train Step 58475, Epoch 54.1, Batch Size = 256, Examples/Sec = 3735.31, Train LB = -348.936, Loss = 357.642
[2018-06-04 20:03] Train Step 58500, Epoch 54.2, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -354.464, Loss = 356.625
[2018-06-04 20:03] Train Step 58525, Epoch 54.2, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -366.129, Loss = 356.547
[2018-06-04 20:03] Train Step 58550, Epoch 54.2, Batch Size = 256, Examples/Sec = 3810.72, Train LB = -364.029, Loss = 356.461
[2018-06-04 20:03] Train Step 58575, Epoch 54.2, Batch Size = 256, Examples/Sec = 3865.13, Train LB = -362.389, Loss = 357.577
[2018-06-04 20:03] Train Step 58600, Epoch 54.3, Batch Size = 256, Examples/Sec = 3858.09, Train LB = -367.187, Loss = 360.992
Performance on test set:
  Test Lower Bound = -414.624, Test Loss = 414.624
[2018-06-04 20:03] Train Step 58625, Epoch 54.3, Batch Size = 256, Examples/Sec = 3876.73, Train LB = -356.235, Loss = 360.219
[2018-06-04 20:03] Train Step 58650, Epoch 54.3, Batch Size = 256, Examples/Sec = 3859.19, Train LB = -351.872, Loss = 358.755
[2018-06-04 20:03] Train Step 58675, Epoch 54.3, Batch Size = 256, Examples/Sec = 3850.50, Train LB = -349.770, Loss = 356.666
[2018-06-04 20:03] Train Step 58700, Epoch 54.4, Batch Size = 256, Examples/Sec = 3872.33, Train LB = -362.797, Loss = 354.937
[2018-06-04 20:03] Train Step 58725, Epoch 54.4, Batch Size = 256, Examples/Sec = 3840.55, Train LB = -359.931, Loss = 355.228
[2018-06-04 20:03] Train Step 58750, Epoch 54.4, Batch Size = 256, Examples/Sec = 3859.15, Train LB = -363.074, Loss = 355.678
[2018-06-04 20:03] Train Step 58775, Epoch 54.4, Batch Size = 256, Examples/Sec = 3860.35, Train LB = -392.988, Loss = 357.761
[2018-06-04 20:03] Train Step 58800, Epoch 54.4, Batch Size = 256, Examples/Sec = 3857.87, Train LB = -367.929, Loss = 361.551
Performance on test set:
  Test Lower Bound = -413.776, Test Loss = 413.776
[2018-06-04 20:03] Train Step 58825, Epoch 54.5, Batch Size = 256, Examples/Sec = 3840.26, Train LB = -351.069, Loss = 360.474
[2018-06-04 20:03] Train Step 58850, Epoch 54.5, Batch Size = 256, Examples/Sec = 3874.38, Train LB = -335.306, Loss = 358.501
[2018-06-04 20:04] Train Step 58875, Epoch 54.5, Batch Size = 256, Examples/Sec = 3869.35, Train LB = -343.199, Loss = 357.229
[2018-06-04 20:04] Train Step 58900, Epoch 54.5, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -345.612, Loss = 356.150
[2018-06-04 20:04] Train Step 58925, Epoch 54.6, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -346.341, Loss = 355.519
[2018-06-04 20:04] Train Step 58950, Epoch 54.6, Batch Size = 256, Examples/Sec = 3836.64, Train LB = -356.290, Loss = 355.391
[2018-06-04 20:04] Train Step 58975, Epoch 54.6, Batch Size = 256, Examples/Sec = 3841.71, Train LB = -359.520, Loss = 356.947
[2018-06-04 20:04] Train Step 59000, Epoch 54.6, Batch Size = 256, Examples/Sec = 3851.37, Train LB = -398.300, Loss = 359.716
Performance on test set:
  Test Lower Bound = -415.917, Test Loss = 415.917
[2018-06-04 20:04] Train Step 59025, Epoch 54.7, Batch Size = 256, Examples/Sec = 3821.24, Train LB = -351.329, Loss = 358.963
[2018-06-04 20:04] Train Step 59050, Epoch 54.7, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -356.501, Loss = 358.357
[2018-06-04 20:04] Train Step 59075, Epoch 54.7, Batch Size = 256, Examples/Sec = 3861.35, Train LB = -353.706, Loss = 357.718
[2018-06-04 20:04] Train Step 59100, Epoch 54.7, Batch Size = 256, Examples/Sec = 3827.92, Train LB = -356.527, Loss = 357.016
[2018-06-04 20:04] Train Step 59125, Epoch 54.7, Batch Size = 256, Examples/Sec = 3852.17, Train LB = -367.676, Loss = 355.622
[2018-06-04 20:04] Train Step 59150, Epoch 54.8, Batch Size = 256, Examples/Sec = 3853.11, Train LB = -345.287, Loss = 356.201
[2018-06-04 20:04] Train Step 59175, Epoch 54.8, Batch Size = 256, Examples/Sec = 3864.90, Train LB = -376.138, Loss = 357.292
[2018-06-04 20:04] Train Step 59200, Epoch 54.8, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -369.989, Loss = 360.248
Performance on test set:
  Test Lower Bound = -414.102, Test Loss = 414.102
[2018-06-04 20:04] Train Step 59225, Epoch 54.8, Batch Size = 256, Examples/Sec = 3886.50, Train LB = -353.490, Loss = 358.693
[2018-06-04 20:04] Train Step 59250, Epoch 54.9, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -348.757, Loss = 357.970
[2018-06-04 20:04] Train Step 59275, Epoch 54.9, Batch Size = 256, Examples/Sec = 3730.25, Train LB = -341.355, Loss = 355.965
[2018-06-04 20:04] Train Step 59300, Epoch 54.9, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -343.873, Loss = 355.121
[2018-06-04 20:04] Train Step 59325, Epoch 54.9, Batch Size = 256, Examples/Sec = 3868.48, Train LB = -364.151, Loss = 354.953
[2018-06-04 20:04] Train Step 59350, Epoch 55.0, Batch Size = 256, Examples/Sec = 3788.26, Train LB = -368.613, Loss = 355.358
[2018-06-04 20:04] Train Step 59375, Epoch 55.0, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -369.483, Loss = 357.496
[2018-06-04 20:04] Train Step 59400, Epoch 55.0, Batch Size = 256, Examples/Sec = 3846.21, Train LB = -388.711, Loss = 360.871
Performance on test set:
  Test Lower Bound = -414.815, Test Loss = 414.815
[2018-06-04 20:04] Train Step 59425, Epoch 55.0, Batch Size = 256, Examples/Sec = 3843.44, Train LB = -353.990, Loss = 359.810
[2018-06-04 20:04] Train Step 59450, Epoch 55.0, Batch Size = 256, Examples/Sec = 3873.21, Train LB = -352.036, Loss = 358.311
[2018-06-04 20:04] Train Step 59475, Epoch 55.1, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -338.848, Loss = 356.582
[2018-06-04 20:04] Train Step 59500, Epoch 55.1, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -337.985, Loss = 355.333
[2018-06-04 20:04] Train Step 59525, Epoch 55.1, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -363.617, Loss = 354.525
[2018-06-04 20:04] Train Step 59550, Epoch 55.1, Batch Size = 256, Examples/Sec = 3870.58, Train LB = -384.174, Loss = 355.195
[2018-06-04 20:04] Train Step 59575, Epoch 55.2, Batch Size = 256, Examples/Sec = 3858.44, Train LB = -351.573, Loss = 357.194
[2018-06-04 20:05] Train Step 59600, Epoch 55.2, Batch Size = 256, Examples/Sec = 3835.04, Train LB = -383.544, Loss = 360.244
Performance on test set:
  Test Lower Bound = -413.706, Test Loss = 413.706
[2018-06-04 20:05] Train Step 59625, Epoch 55.2, Batch Size = 256, Examples/Sec = 3832.33, Train LB = -364.915, Loss = 358.785
[2018-06-04 20:05] Train Step 59650, Epoch 55.2, Batch Size = 256, Examples/Sec = 3851.64, Train LB = -366.449, Loss = 357.626
[2018-06-04 20:05] Train Step 59675, Epoch 55.3, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -363.118, Loss = 356.493
[2018-06-04 20:05] Train Step 59700, Epoch 55.3, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -356.886, Loss = 356.461
[2018-06-04 20:05] Train Step 59725, Epoch 55.3, Batch Size = 256, Examples/Sec = 3845.35, Train LB = -361.158, Loss = 356.471
[2018-06-04 20:05] Train Step 59750, Epoch 55.3, Batch Size = 256, Examples/Sec = 3828.79, Train LB = -351.374, Loss = 356.992
[2018-06-04 20:05] Train Step 59775, Epoch 55.3, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -356.562, Loss = 357.463
[2018-06-04 20:05] Train Step 59800, Epoch 55.4, Batch Size = 256, Examples/Sec = 3827.07, Train LB = -372.353, Loss = 360.673
Performance on test set:
  Test Lower Bound = -415.439, Test Loss = 415.439
[2018-06-04 20:05] Train Step 59825, Epoch 55.4, Batch Size = 256, Examples/Sec = 3849.56, Train LB = -352.037, Loss = 359.273
[2018-06-04 20:05] Train Step 59850, Epoch 55.4, Batch Size = 256, Examples/Sec = 3846.21, Train LB = -333.801, Loss = 357.859
[2018-06-04 20:05] Train Step 59875, Epoch 55.4, Batch Size = 256, Examples/Sec = 3858.44, Train LB = -344.364, Loss = 355.947
[2018-06-04 20:05] Train Step 59900, Epoch 55.5, Batch Size = 256, Examples/Sec = 3843.96, Train LB = -369.443, Loss = 355.001
[2018-06-04 20:05] Train Step 59925, Epoch 55.5, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -363.501, Loss = 355.744
[2018-06-04 20:05] Train Step 59950, Epoch 55.5, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -366.514, Loss = 355.337
[2018-06-04 20:05] Train Step 59975, Epoch 55.5, Batch Size = 256, Examples/Sec = 3844.18, Train LB = -363.031, Loss = 357.340
[2018-06-04 20:05] Train Step 60000, Epoch 55.6, Batch Size = 256, Examples/Sec = 3870.53, Train LB = -391.434, Loss = 360.483
Performance on test set:
  Test Lower Bound = -413.573, Test Loss = 413.573
[2018-06-04 20:05] Train Step 60025, Epoch 55.6, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -361.955, Loss = 359.674
[2018-06-04 20:05] Train Step 60050, Epoch 55.6, Batch Size = 256, Examples/Sec = 3851.30, Train LB = -353.681, Loss = 358.345
[2018-06-04 20:05] Train Step 60075, Epoch 55.6, Batch Size = 256, Examples/Sec = 3855.24, Train LB = -343.899, Loss = 357.046
[2018-06-04 20:05] Train Step 60100, Epoch 55.6, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -343.832, Loss = 356.041
[2018-06-04 20:05] Train Step 60125, Epoch 55.7, Batch Size = 256, Examples/Sec = 3865.44, Train LB = -354.905, Loss = 355.160
[2018-06-04 20:05] Train Step 60150, Epoch 55.7, Batch Size = 256, Examples/Sec = 3721.96, Train LB = -359.020, Loss = 355.806
[2018-06-04 20:05] Train Step 60175, Epoch 55.7, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -376.944, Loss = 356.726
[2018-06-04 20:05] Train Step 60200, Epoch 55.7, Batch Size = 256, Examples/Sec = 3848.41, Train LB = -399.830, Loss = 360.275
Performance on test set:
  Test Lower Bound = -415.231, Test Loss = 415.231
[2018-06-04 20:05] Train Step 60225, Epoch 55.8, Batch Size = 256, Examples/Sec = 3830.62, Train LB = -339.474, Loss = 359.870
[2018-06-04 20:05] Train Step 60250, Epoch 55.8, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -356.335, Loss = 358.619
[2018-06-04 20:05] Train Step 60275, Epoch 55.8, Batch Size = 256, Examples/Sec = 3839.47, Train LB = -354.620, Loss = 356.834
[2018-06-04 20:06] Train Step 60300, Epoch 55.8, Batch Size = 256, Examples/Sec = 3865.20, Train LB = -364.381, Loss = 355.496
[2018-06-04 20:06] Train Step 60325, Epoch 55.9, Batch Size = 256, Examples/Sec = 3851.24, Train LB = -350.795, Loss = 354.898
[2018-06-04 20:06] Train Step 60350, Epoch 55.9, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -372.431, Loss = 355.638
[2018-06-04 20:06] Train Step 60375, Epoch 55.9, Batch Size = 256, Examples/Sec = 3840.90, Train LB = -346.754, Loss = 356.157
[2018-06-04 20:06] Train Step 60400, Epoch 55.9, Batch Size = 256, Examples/Sec = 3870.41, Train LB = -372.602, Loss = 359.331
Performance on test set:
  Test Lower Bound = -416.492, Test Loss = 416.492
[2018-06-04 20:06] Train Step 60425, Epoch 55.9, Batch Size = 256, Examples/Sec = 3845.92, Train LB = -370.087, Loss = 357.841
[2018-06-04 20:06] Train Step 60450, Epoch 56.0, Batch Size = 256, Examples/Sec = 3858.20, Train LB = -367.739, Loss = 357.307
[2018-06-04 20:06] Train Step 60475, Epoch 56.0, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -367.246, Loss = 356.384
[2018-06-04 20:06] Train Step 60500, Epoch 56.0, Batch Size = 256, Examples/Sec = 3867.95, Train LB = -354.838, Loss = 355.297
[2018-06-04 20:06] Train Step 60525, Epoch 56.0, Batch Size = 256, Examples/Sec = 3851.02, Train LB = -346.540, Loss = 354.200
[2018-06-04 20:06] Train Step 60550, Epoch 56.1, Batch Size = 256, Examples/Sec = 3855.36, Train LB = -355.453, Loss = 354.680
[2018-06-04 20:06] Train Step 60575, Epoch 56.1, Batch Size = 256, Examples/Sec = 3849.92, Train LB = -374.783, Loss = 355.759
[2018-06-04 20:06] Train Step 60600, Epoch 56.1, Batch Size = 256, Examples/Sec = 3880.96, Train LB = -386.262, Loss = 359.166
Performance on test set:
  Test Lower Bound = -413.743, Test Loss = 413.743
[2018-06-04 20:06] Train Step 60625, Epoch 56.1, Batch Size = 256, Examples/Sec = 3852.57, Train LB = -345.595, Loss = 358.401
[2018-06-04 20:06] Train Step 60650, Epoch 56.2, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -345.460, Loss = 356.999
[2018-06-04 20:06] Train Step 60675, Epoch 56.2, Batch Size = 256, Examples/Sec = 3887.92, Train LB = -348.002, Loss = 355.589
[2018-06-04 20:06] Train Step 60700, Epoch 56.2, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -360.638, Loss = 354.599
[2018-06-04 20:06] Train Step 60725, Epoch 56.2, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -366.901, Loss = 354.647
[2018-06-04 20:06] Train Step 60750, Epoch 56.2, Batch Size = 256, Examples/Sec = 3858.38, Train LB = -355.674, Loss = 355.584
[2018-06-04 20:06] Train Step 60775, Epoch 56.3, Batch Size = 256, Examples/Sec = 3861.58, Train LB = -367.779, Loss = 356.923
[2018-06-04 20:06] Train Step 60800, Epoch 56.3, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -375.536, Loss = 359.832
Performance on test set:
  Test Lower Bound = -414.247, Test Loss = 414.247
[2018-06-04 20:06] Train Step 60825, Epoch 56.3, Batch Size = 256, Examples/Sec = 3784.41, Train LB = -356.485, Loss = 358.697
[2018-06-04 20:06] Train Step 60850, Epoch 56.3, Batch Size = 256, Examples/Sec = 3821.53, Train LB = -344.878, Loss = 357.778
[2018-06-04 20:06] Train Step 60875, Epoch 56.4, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -347.191, Loss = 356.410
[2018-06-04 20:06] Train Step 60900, Epoch 56.4, Batch Size = 256, Examples/Sec = 3739.19, Train LB = -358.211, Loss = 355.399
[2018-06-04 20:06] Train Step 60925, Epoch 56.4, Batch Size = 256, Examples/Sec = 3829.24, Train LB = -356.741, Loss = 355.215
[2018-06-04 20:06] Train Step 60950, Epoch 56.4, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -357.341, Loss = 354.717
[2018-06-04 20:06] Train Step 60975, Epoch 56.5, Batch Size = 256, Examples/Sec = 3716.77, Train LB = -361.448, Loss = 357.126
[2018-06-04 20:06] Train Step 61000, Epoch 56.5, Batch Size = 256, Examples/Sec = 3850.79, Train LB = -371.132, Loss = 359.644
Performance on test set:
  Test Lower Bound = -415.374, Test Loss = 415.374
[2018-06-04 20:07] Train Step 61025, Epoch 56.5, Batch Size = 256, Examples/Sec = 3837.16, Train LB = -349.281, Loss = 358.953
[2018-06-04 20:07] Train Step 61050, Epoch 56.5, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -351.453, Loss = 357.515
[2018-06-04 20:07] Train Step 61075, Epoch 56.6, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -356.502, Loss = 355.982
[2018-06-04 20:07] Train Step 61100, Epoch 56.6, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -345.265, Loss = 354.028
[2018-06-04 20:07] Train Step 61125, Epoch 56.6, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -368.868, Loss = 353.904
[2018-06-04 20:07] Train Step 61150, Epoch 56.6, Batch Size = 256, Examples/Sec = 3837.16, Train LB = -364.495, Loss = 355.323
[2018-06-04 20:07] Train Step 61175, Epoch 56.6, Batch Size = 256, Examples/Sec = 3878.79, Train LB = -352.120, Loss = 356.532
[2018-06-04 20:07] Train Step 61200, Epoch 56.7, Batch Size = 256, Examples/Sec = 3851.19, Train LB = -384.312, Loss = 359.610
Performance on test set:
  Test Lower Bound = -415.393, Test Loss = 415.393
[2018-06-04 20:07] Train Step 61225, Epoch 56.7, Batch Size = 256, Examples/Sec = 3857.93, Train LB = -370.125, Loss = 358.549
[2018-06-04 20:07] Train Step 61250, Epoch 56.7, Batch Size = 256, Examples/Sec = 3829.98, Train LB = -353.141, Loss = 356.956
[2018-06-04 20:07] Train Step 61275, Epoch 56.7, Batch Size = 256, Examples/Sec = 3837.33, Train LB = -349.080, Loss = 355.859
[2018-06-04 20:07] Train Step 61300, Epoch 56.8, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -353.386, Loss = 354.325
[2018-06-04 20:07] Train Step 61325, Epoch 56.8, Batch Size = 256, Examples/Sec = 3847.08, Train LB = -366.605, Loss = 352.778
[2018-06-04 20:07] Train Step 61350, Epoch 56.8, Batch Size = 256, Examples/Sec = 3843.78, Train LB = -353.676, Loss = 354.508
[2018-06-04 20:07] Train Step 61375, Epoch 56.8, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -366.559, Loss = 356.045
[2018-06-04 20:07] Train Step 61400, Epoch 56.9, Batch Size = 256, Examples/Sec = 3875.85, Train LB = -380.196, Loss = 359.471
Performance on test set:
  Test Lower Bound = -415.405, Test Loss = 415.405
[2018-06-04 20:07] Train Step 61425, Epoch 56.9, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -357.665, Loss = 358.640
[2018-06-04 20:07] Train Step 61450, Epoch 56.9, Batch Size = 256, Examples/Sec = 3721.10, Train LB = -344.084, Loss = 357.161
[2018-06-04 20:07] Train Step 61475, Epoch 56.9, Batch Size = 256, Examples/Sec = 3822.32, Train LB = -346.963, Loss = 355.334
[2018-06-04 20:07] Train Step 61500, Epoch 56.9, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -364.751, Loss = 354.407
[2018-06-04 20:07] Train Step 61525, Epoch 57.0, Batch Size = 256, Examples/Sec = 3807.03, Train LB = -358.095, Loss = 354.648
[2018-06-04 20:07] Train Step 61550, Epoch 57.0, Batch Size = 256, Examples/Sec = 3849.81, Train LB = -367.792, Loss = 355.289
[2018-06-04 20:07] Train Step 61575, Epoch 57.0, Batch Size = 256, Examples/Sec = 3841.89, Train LB = -378.671, Loss = 356.352
[2018-06-04 20:07] Train Step 61600, Epoch 57.0, Batch Size = 256, Examples/Sec = 3850.66, Train LB = -371.221, Loss = 359.702
Performance on test set:
  Test Lower Bound = -416.747, Test Loss = 416.747
[2018-06-04 20:07] Train Step 61625, Epoch 57.1, Batch Size = 256, Examples/Sec = 3849.86, Train LB = -344.233, Loss = 358.836
[2018-06-04 20:07] Train Step 61650, Epoch 57.1, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -352.224, Loss = 356.865
[2018-06-04 20:07] Train Step 61675, Epoch 57.1, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -353.917, Loss = 355.996
[2018-06-04 20:07] Train Step 61700, Epoch 57.1, Batch Size = 256, Examples/Sec = 3841.58, Train LB = -360.754, Loss = 354.238
[2018-06-04 20:08] Train Step 61725, Epoch 57.2, Batch Size = 256, Examples/Sec = 3858.22, Train LB = -336.968, Loss = 353.381
[2018-06-04 20:08] Train Step 61750, Epoch 57.2, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -354.235, Loss = 354.013
[2018-06-04 20:08] Train Step 61775, Epoch 57.2, Batch Size = 256, Examples/Sec = 3675.31, Train LB = -359.585, Loss = 355.610
[2018-06-04 20:08] Train Step 61800, Epoch 57.2, Batch Size = 256, Examples/Sec = 3854.67, Train LB = -364.956, Loss = 358.629
Performance on test set:
  Test Lower Bound = -415.169, Test Loss = 415.169
[2018-06-04 20:08] Train Step 61825, Epoch 57.2, Batch Size = 256, Examples/Sec = 3845.59, Train LB = -345.328, Loss = 358.204
[2018-06-04 20:08] Train Step 61850, Epoch 57.3, Batch Size = 256, Examples/Sec = 3841.89, Train LB = -357.373, Loss = 356.664
[2018-06-04 20:08] Train Step 61875, Epoch 57.3, Batch Size = 256, Examples/Sec = 3792.65, Train LB = -362.455, Loss = 355.591
[2018-06-04 20:08] Train Step 61900, Epoch 57.3, Batch Size = 256, Examples/Sec = 3839.93, Train LB = -350.022, Loss = 354.351
[2018-06-04 20:08] Train Step 61925, Epoch 57.3, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -366.240, Loss = 353.747
[2018-06-04 20:08] Train Step 61950, Epoch 57.4, Batch Size = 256, Examples/Sec = 3865.38, Train LB = -366.578, Loss = 354.370
[2018-06-04 20:08] Train Step 61975, Epoch 57.4, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -360.109, Loss = 355.582
[2018-06-04 20:08] Train Step 62000, Epoch 57.4, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -368.336, Loss = 360.034
Performance on test set:
  Test Lower Bound = -414.359, Test Loss = 414.359
[2018-06-04 20:08] Train Step 62025, Epoch 57.4, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -345.459, Loss = 359.159
[2018-06-04 20:08] Train Step 62050, Epoch 57.5, Batch Size = 256, Examples/Sec = 3852.58, Train LB = -356.491, Loss = 357.078
[2018-06-04 20:08] Train Step 62075, Epoch 57.5, Batch Size = 256, Examples/Sec = 3858.74, Train LB = -357.211, Loss = 356.075
[2018-06-04 20:08] Train Step 62100, Epoch 57.5, Batch Size = 256, Examples/Sec = 3814.01, Train LB = -360.509, Loss = 354.974
[2018-06-04 20:08] Train Step 62125, Epoch 57.5, Batch Size = 256, Examples/Sec = 3838.82, Train LB = -334.948, Loss = 354.755
[2018-06-04 20:08] Train Step 62150, Epoch 57.5, Batch Size = 256, Examples/Sec = 3853.38, Train LB = -359.088, Loss = 354.279
[2018-06-04 20:08] Train Step 62175, Epoch 57.6, Batch Size = 256, Examples/Sec = 3806.07, Train LB = -366.834, Loss = 356.010
[2018-06-04 20:08] Train Step 62200, Epoch 57.6, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -375.479, Loss = 359.746
Performance on test set:
  Test Lower Bound = -415.608, Test Loss = 415.609
[2018-06-04 20:08] Train Step 62225, Epoch 57.6, Batch Size = 256, Examples/Sec = 3858.98, Train LB = -344.981, Loss = 359.000
[2018-06-04 20:08] Train Step 62250, Epoch 57.6, Batch Size = 256, Examples/Sec = 3747.57, Train LB = -337.600, Loss = 356.839
[2018-06-04 20:08] Train Step 62275, Epoch 57.7, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -360.218, Loss = 355.463
[2018-06-04 20:08] Train Step 62300, Epoch 57.7, Batch Size = 256, Examples/Sec = 3844.77, Train LB = -335.030, Loss = 354.134
[2018-06-04 20:08] Train Step 62325, Epoch 57.7, Batch Size = 256, Examples/Sec = 3823.81, Train LB = -357.137, Loss = 353.668
[2018-06-04 20:08] Train Step 62350, Epoch 57.7, Batch Size = 256, Examples/Sec = 3861.77, Train LB = -362.541, Loss = 353.757
[2018-06-04 20:08] Train Step 62375, Epoch 57.8, Batch Size = 256, Examples/Sec = 3834.70, Train LB = -366.436, Loss = 355.431
[2018-06-04 20:08] Train Step 62400, Epoch 57.8, Batch Size = 256, Examples/Sec = 3881.20, Train LB = -376.785, Loss = 359.166
Performance on test set:
  Test Lower Bound = -415.084, Test Loss = 415.084
[2018-06-04 20:09] Train Step 62425, Epoch 57.8, Batch Size = 256, Examples/Sec = 3845.57, Train LB = -362.895, Loss = 357.915
[2018-06-04 20:09] Train Step 62450, Epoch 57.8, Batch Size = 256, Examples/Sec = 3867.71, Train LB = -361.269, Loss = 357.172
[2018-06-04 20:09] Train Step 62475, Epoch 57.8, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -349.005, Loss = 355.688
[2018-06-04 20:09] Train Step 62500, Epoch 57.9, Batch Size = 256, Examples/Sec = 3787.60, Train LB = -337.663, Loss = 354.387
[2018-06-04 20:09] Train Step 62525, Epoch 57.9, Batch Size = 256, Examples/Sec = 3869.30, Train LB = -351.947, Loss = 353.633
[2018-06-04 20:09] Train Step 62550, Epoch 57.9, Batch Size = 256, Examples/Sec = 3853.97, Train LB = -373.161, Loss = 353.947
[2018-06-04 20:09] Train Step 62575, Epoch 57.9, Batch Size = 256, Examples/Sec = 3803.86, Train LB = -377.364, Loss = 355.812
[2018-06-04 20:09] Train Step 62600, Epoch 58.0, Batch Size = 256, Examples/Sec = 3869.88, Train LB = -388.564, Loss = 358.988
Performance on test set:
  Test Lower Bound = -416.344, Test Loss = 416.344
[2018-06-04 20:09] Train Step 62625, Epoch 58.0, Batch Size = 256, Examples/Sec = 3843.89, Train LB = -347.868, Loss = 357.789
[2018-06-04 20:09] Train Step 62650, Epoch 58.0, Batch Size = 256, Examples/Sec = 3865.15, Train LB = -342.543, Loss = 356.516
[2018-06-04 20:09] Train Step 62675, Epoch 58.0, Batch Size = 256, Examples/Sec = 3851.31, Train LB = -356.648, Loss = 355.773
[2018-06-04 20:09] Train Step 62700, Epoch 58.1, Batch Size = 256, Examples/Sec = 3847.25, Train LB = -373.633, Loss = 354.686
[2018-06-04 20:09] Train Step 62725, Epoch 58.1, Batch Size = 256, Examples/Sec = 3835.15, Train LB = -360.974, Loss = 354.708
[2018-06-04 20:09] Train Step 62750, Epoch 58.1, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -361.546, Loss = 354.225
[2018-06-04 20:09] Train Step 62775, Epoch 58.1, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -359.430, Loss = 356.193
[2018-06-04 20:09] Train Step 62800, Epoch 58.1, Batch Size = 256, Examples/Sec = 3801.50, Train LB = -373.111, Loss = 359.228
Performance on test set:
  Test Lower Bound = -415.611, Test Loss = 415.611
[2018-06-04 20:09] Train Step 62825, Epoch 58.2, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -354.518, Loss = 357.963
[2018-06-04 20:09] Train Step 62850, Epoch 58.2, Batch Size = 256, Examples/Sec = 3841.19, Train LB = -356.183, Loss = 356.753
[2018-06-04 20:09] Train Step 62875, Epoch 58.2, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -359.145, Loss = 354.896
[2018-06-04 20:09] Train Step 62900, Epoch 58.2, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -352.346, Loss = 354.215
[2018-06-04 20:09] Train Step 62925, Epoch 58.3, Batch Size = 256, Examples/Sec = 3853.44, Train LB = -361.573, Loss = 354.708
[2018-06-04 20:09] Train Step 62950, Epoch 58.3, Batch Size = 256, Examples/Sec = 3862.06, Train LB = -358.750, Loss = 355.085
[2018-06-04 20:09] Train Step 62975, Epoch 58.3, Batch Size = 256, Examples/Sec = 3853.74, Train LB = -365.673, Loss = 356.579
[2018-06-04 20:09] Train Step 63000, Epoch 58.3, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -376.461, Loss = 359.973
Performance on test set:
  Test Lower Bound = -415.193, Test Loss = 415.193
[2018-06-04 20:09] Train Step 63025, Epoch 58.4, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -361.274, Loss = 359.432
[2018-06-04 20:09] Train Step 63050, Epoch 58.4, Batch Size = 256, Examples/Sec = 3736.14, Train LB = -341.014, Loss = 358.264
[2018-06-04 20:09] Train Step 63075, Epoch 58.4, Batch Size = 256, Examples/Sec = 3850.50, Train LB = -343.456, Loss = 355.538
[2018-06-04 20:09] Train Step 63100, Epoch 58.4, Batch Size = 256, Examples/Sec = 3876.27, Train LB = -356.746, Loss = 354.006
[2018-06-04 20:09] Train Step 63125, Epoch 58.4, Batch Size = 256, Examples/Sec = 3728.79, Train LB = -359.288, Loss = 353.981
[2018-06-04 20:10] Train Step 63150, Epoch 58.5, Batch Size = 256, Examples/Sec = 3855.18, Train LB = -367.334, Loss = 354.184
[2018-06-04 20:10] Train Step 63175, Epoch 58.5, Batch Size = 256, Examples/Sec = 3855.20, Train LB = -347.564, Loss = 355.560
[2018-06-04 20:10] Train Step 63200, Epoch 58.5, Batch Size = 256, Examples/Sec = 3778.15, Train LB = -378.345, Loss = 358.794
Performance on test set:
  Test Lower Bound = -417.753, Test Loss = 417.753
[2018-06-04 20:10] Train Step 63225, Epoch 58.5, Batch Size = 256, Examples/Sec = 3784.46, Train LB = -355.948, Loss = 357.483
[2018-06-04 20:10] Train Step 63250, Epoch 58.6, Batch Size = 256, Examples/Sec = 3870.16, Train LB = -349.857, Loss = 356.112
[2018-06-04 20:10] Train Step 63275, Epoch 58.6, Batch Size = 256, Examples/Sec = 3858.22, Train LB = -345.652, Loss = 355.506
[2018-06-04 20:10] Train Step 63300, Epoch 58.6, Batch Size = 256, Examples/Sec = 3857.93, Train LB = -342.253, Loss = 354.612
[2018-06-04 20:10] Train Step 63325, Epoch 58.6, Batch Size = 256, Examples/Sec = 3850.32, Train LB = -371.094, Loss = 353.729
[2018-06-04 20:10] Train Step 63350, Epoch 58.7, Batch Size = 256, Examples/Sec = 3853.73, Train LB = -358.751, Loss = 353.741
[2018-06-04 20:10] Train Step 63375, Epoch 58.7, Batch Size = 256, Examples/Sec = 3853.68, Train LB = -355.757, Loss = 355.531
[2018-06-04 20:10] Train Step 63400, Epoch 58.7, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -379.950, Loss = 358.573
Performance on test set:
  Test Lower Bound = -415.962, Test Loss = 415.962
[2018-06-04 20:10] Train Step 63425, Epoch 58.7, Batch Size = 256, Examples/Sec = 3870.12, Train LB = -348.042, Loss = 358.581
[2018-06-04 20:10] Train Step 63450, Epoch 58.8, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -361.681, Loss = 356.569
[2018-06-04 20:10] Train Step 63475, Epoch 58.8, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -367.697, Loss = 355.382
[2018-06-04 20:10] Train Step 63500, Epoch 58.8, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -336.969, Loss = 354.150
[2018-06-04 20:10] Train Step 63525, Epoch 58.8, Batch Size = 256, Examples/Sec = 3821.92, Train LB = -343.470, Loss = 353.496
[2018-06-04 20:10] Train Step 63550, Epoch 58.8, Batch Size = 256, Examples/Sec = 3844.71, Train LB = -369.923, Loss = 353.791
[2018-06-04 20:10] Train Step 63575, Epoch 58.9, Batch Size = 256, Examples/Sec = 3871.70, Train LB = -366.129, Loss = 355.112
[2018-06-04 20:10] Train Step 63600, Epoch 58.9, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -374.340, Loss = 358.729
Performance on test set:
  Test Lower Bound = -416.494, Test Loss = 416.494
[2018-06-04 20:10] Train Step 63625, Epoch 58.9, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -342.605, Loss = 357.616
[2018-06-04 20:10] Train Step 63650, Epoch 58.9, Batch Size = 256, Examples/Sec = 3831.75, Train LB = -344.797, Loss = 356.363
[2018-06-04 20:10] Train Step 63675, Epoch 59.0, Batch Size = 256, Examples/Sec = 3869.28, Train LB = -357.193, Loss = 355.093
[2018-06-04 20:10] Train Step 63700, Epoch 59.0, Batch Size = 256, Examples/Sec = 3876.73, Train LB = -346.143, Loss = 354.460
[2018-06-04 20:10] Train Step 63725, Epoch 59.0, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -358.523, Loss = 354.020
[2018-06-04 20:10] Train Step 63750, Epoch 59.0, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -351.874, Loss = 354.151
[2018-06-04 20:10] Train Step 63775, Epoch 59.1, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -380.460, Loss = 355.929
[2018-06-04 20:10] Train Step 63800, Epoch 59.1, Batch Size = 256, Examples/Sec = 3843.91, Train LB = -370.558, Loss = 360.207
Performance on test set:
  Test Lower Bound = -415.291, Test Loss = 415.291
[2018-06-04 20:10] Train Step 63825, Epoch 59.1, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -343.542, Loss = 359.317
[2018-06-04 20:11] Train Step 63850, Epoch 59.1, Batch Size = 256, Examples/Sec = 3756.47, Train LB = -354.017, Loss = 356.618
[2018-06-04 20:11] Train Step 63875, Epoch 59.1, Batch Size = 256, Examples/Sec = 3841.89, Train LB = -345.126, Loss = 354.831
[2018-06-04 20:11] Train Step 63900, Epoch 59.2, Batch Size = 256, Examples/Sec = 3869.70, Train LB = -366.595, Loss = 353.349
[2018-06-04 20:11] Train Step 63925, Epoch 59.2, Batch Size = 256, Examples/Sec = 3746.14, Train LB = -354.019, Loss = 353.134
[2018-06-04 20:11] Train Step 63950, Epoch 59.2, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -361.402, Loss = 353.908
[2018-06-04 20:11] Train Step 63975, Epoch 59.2, Batch Size = 256, Examples/Sec = 3838.93, Train LB = -364.643, Loss = 355.946
[2018-06-04 20:11] Train Step 64000, Epoch 59.3, Batch Size = 256, Examples/Sec = 3740.78, Train LB = -369.788, Loss = 358.274
Performance on test set:
  Test Lower Bound = -417.333, Test Loss = 417.333
[2018-06-04 20:11] Train Step 64025, Epoch 59.3, Batch Size = 256, Examples/Sec = 3856.11, Train LB = -349.394, Loss = 357.252
[2018-06-04 20:11] Train Step 64050, Epoch 59.3, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -342.932, Loss = 356.055
[2018-06-04 20:11] Train Step 64075, Epoch 59.3, Batch Size = 256, Examples/Sec = 3839.52, Train LB = -340.309, Loss = 354.820
[2018-06-04 20:11] Train Step 64100, Epoch 59.4, Batch Size = 256, Examples/Sec = 3852.17, Train LB = -348.114, Loss = 353.586
[2018-06-04 20:11] Train Step 64125, Epoch 59.4, Batch Size = 256, Examples/Sec = 3846.95, Train LB = -358.243, Loss = 352.418
[2018-06-04 20:11] Train Step 64150, Epoch 59.4, Batch Size = 256, Examples/Sec = 3851.02, Train LB = -352.400, Loss = 352.512
[2018-06-04 20:11] Train Step 64175, Epoch 59.4, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -351.813, Loss = 354.596
[2018-06-04 20:11] Train Step 64200, Epoch 59.4, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -368.484, Loss = 358.646
Performance on test set:
  Test Lower Bound = -416.256, Test Loss = 416.256
[2018-06-04 20:11] Train Step 64225, Epoch 59.5, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -355.525, Loss = 357.344
[2018-06-04 20:11] Train Step 64250, Epoch 59.5, Batch Size = 256, Examples/Sec = 3806.97, Train LB = -348.714, Loss = 355.806
[2018-06-04 20:11] Train Step 64275, Epoch 59.5, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -336.593, Loss = 354.253
[2018-06-04 20:11] Train Step 64300, Epoch 59.5, Batch Size = 256, Examples/Sec = 3855.78, Train LB = -353.809, Loss = 353.472
[2018-06-04 20:11] Train Step 64325, Epoch 59.6, Batch Size = 256, Examples/Sec = 3842.17, Train LB = -359.004, Loss = 352.969
[2018-06-04 20:11] Train Step 64350, Epoch 59.6, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -351.957, Loss = 353.475
[2018-06-04 20:11] Train Step 64375, Epoch 59.6, Batch Size = 256, Examples/Sec = 3872.03, Train LB = -383.255, Loss = 354.737
[2018-06-04 20:11] Train Step 64400, Epoch 59.6, Batch Size = 256, Examples/Sec = 3842.17, Train LB = -384.668, Loss = 358.059
Performance on test set:
  Test Lower Bound = -419.359, Test Loss = 419.359
[2018-06-04 20:11] Train Step 64425, Epoch 59.7, Batch Size = 256, Examples/Sec = 3851.88, Train LB = -355.931, Loss = 357.516
[2018-06-04 20:11] Train Step 64450, Epoch 59.7, Batch Size = 256, Examples/Sec = 3850.84, Train LB = -345.985, Loss = 356.489
[2018-06-04 20:11] Train Step 64475, Epoch 59.7, Batch Size = 256, Examples/Sec = 3835.78, Train LB = -341.998, Loss = 355.005
[2018-06-04 20:11] Train Step 64500, Epoch 59.7, Batch Size = 256, Examples/Sec = 3878.66, Train LB = -345.127, Loss = 354.220
[2018-06-04 20:11] Train Step 64525, Epoch 59.7, Batch Size = 256, Examples/Sec = 3866.32, Train LB = -355.855, Loss = 353.502
[2018-06-04 20:11] Train Step 64550, Epoch 59.8, Batch Size = 256, Examples/Sec = 3795.91, Train LB = -352.841, Loss = 353.882
[2018-06-04 20:11] Train Step 64575, Epoch 59.8, Batch Size = 256, Examples/Sec = 3831.25, Train LB = -370.371, Loss = 354.495
[2018-06-04 20:12] Train Step 64600, Epoch 59.8, Batch Size = 256, Examples/Sec = 3872.33, Train LB = -361.362, Loss = 358.582
Performance on test set:
  Test Lower Bound = -417.105, Test Loss = 417.105
[2018-06-04 20:12] Train Step 64625, Epoch 59.8, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -349.311, Loss = 356.802
[2018-06-04 20:12] Train Step 64650, Epoch 59.9, Batch Size = 256, Examples/Sec = 3837.51, Train LB = -342.063, Loss = 355.878
[2018-06-04 20:12] Train Step 64675, Epoch 59.9, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -356.235, Loss = 354.379
[2018-06-04 20:12] Train Step 64700, Epoch 59.9, Batch Size = 256, Examples/Sec = 3867.82, Train LB = -350.787, Loss = 353.831
[2018-06-04 20:12] Train Step 64725, Epoch 59.9, Batch Size = 256, Examples/Sec = 3730.64, Train LB = -349.805, Loss = 353.462
[2018-06-04 20:12] Train Step 64750, Epoch 60.0, Batch Size = 256, Examples/Sec = 3861.58, Train LB = -357.714, Loss = 353.292
[2018-06-04 20:12] Train Step 64775, Epoch 60.0, Batch Size = 256, Examples/Sec = 3807.15, Train LB = -361.213, Loss = 355.509
[2018-06-04 20:12] Train Step 64800, Epoch 60.0, Batch Size = 256, Examples/Sec = 3715.10, Train LB = -380.052, Loss = 358.514
Performance on test set:
  Test Lower Bound = -417.143, Test Loss = 417.143
[2018-06-04 20:12] Train Step 64825, Epoch 60.0, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -351.791, Loss = 357.660
[2018-06-04 20:12] Train Step 64850, Epoch 60.0, Batch Size = 256, Examples/Sec = 3855.53, Train LB = -355.700, Loss = 355.664
[2018-06-04 20:12] Train Step 64875, Epoch 60.1, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -344.566, Loss = 354.426
[2018-06-04 20:12] Train Step 64900, Epoch 60.1, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -366.964, Loss = 353.646
[2018-06-04 20:12] Train Step 64925, Epoch 60.1, Batch Size = 256, Examples/Sec = 3871.98, Train LB = -341.978, Loss = 352.723
[2018-06-04 20:12] Train Step 64950, Epoch 60.1, Batch Size = 256, Examples/Sec = 3811.23, Train LB = -349.985, Loss = 353.485
[2018-06-04 20:12] Train Step 64975, Epoch 60.2, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -356.301, Loss = 355.242
[2018-06-04 20:12] Train Step 65000, Epoch 60.2, Batch Size = 256, Examples/Sec = 3846.03, Train LB = -385.727, Loss = 358.224
Performance on test set:
  Test Lower Bound = -415.708, Test Loss = 415.708
[2018-06-04 20:12] Train Step 65025, Epoch 60.2, Batch Size = 256, Examples/Sec = 3854.26, Train LB = -344.944, Loss = 356.299
[2018-06-04 20:12] Train Step 65050, Epoch 60.2, Batch Size = 256, Examples/Sec = 3851.30, Train LB = -356.099, Loss = 355.626
[2018-06-04 20:12] Train Step 65075, Epoch 60.3, Batch Size = 256, Examples/Sec = 3835.37, Train LB = -352.606, Loss = 354.740
[2018-06-04 20:12] Train Step 65100, Epoch 60.3, Batch Size = 256, Examples/Sec = 3844.49, Train LB = -336.690, Loss = 353.354
[2018-06-04 20:12] Train Step 65125, Epoch 60.3, Batch Size = 256, Examples/Sec = 3845.01, Train LB = -351.325, Loss = 352.849
[2018-06-04 20:12] Train Step 65150, Epoch 60.3, Batch Size = 256, Examples/Sec = 3868.11, Train LB = -368.480, Loss = 352.762
[2018-06-04 20:12] Train Step 65175, Epoch 60.3, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -355.889, Loss = 354.354
[2018-06-04 20:12] Train Step 65200, Epoch 60.4, Batch Size = 256, Examples/Sec = 3862.58, Train LB = -388.990, Loss = 358.363
Performance on test set:
  Test Lower Bound = -418.055, Test Loss = 418.055
[2018-06-04 20:12] Train Step 65225, Epoch 60.4, Batch Size = 256, Examples/Sec = 3851.35, Train LB = -339.774, Loss = 357.450
[2018-06-04 20:12] Train Step 65250, Epoch 60.4, Batch Size = 256, Examples/Sec = 3860.30, Train LB = -358.257, Loss = 355.876
[2018-06-04 20:13] Train Step 65275, Epoch 60.4, Batch Size = 256, Examples/Sec = 3810.93, Train LB = -339.553, Loss = 354.202
[2018-06-04 20:13] Train Step 65300, Epoch 60.5, Batch Size = 256, Examples/Sec = 3837.22, Train LB = -339.723, Loss = 353.127
[2018-06-04 20:13] Train Step 65325, Epoch 60.5, Batch Size = 256, Examples/Sec = 3859.44, Train LB = -350.881, Loss = 353.660
[2018-06-04 20:13] Train Step 65350, Epoch 60.5, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -352.288, Loss = 353.681
[2018-06-04 20:13] Train Step 65375, Epoch 60.5, Batch Size = 256, Examples/Sec = 3854.15, Train LB = -363.040, Loss = 354.625
[2018-06-04 20:13] Train Step 65400, Epoch 60.6, Batch Size = 256, Examples/Sec = 3834.18, Train LB = -386.253, Loss = 358.184
Performance on test set:
  Test Lower Bound = -417.858, Test Loss = 417.858
[2018-06-04 20:13] Train Step 65425, Epoch 60.6, Batch Size = 256, Examples/Sec = 3853.69, Train LB = -357.782, Loss = 357.395
[2018-06-04 20:13] Train Step 65450, Epoch 60.6, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -349.007, Loss = 356.683
[2018-06-04 20:13] Train Step 65475, Epoch 60.6, Batch Size = 256, Examples/Sec = 3871.40, Train LB = -354.010, Loss = 354.802
[2018-06-04 20:13] Train Step 65500, Epoch 60.6, Batch Size = 256, Examples/Sec = 3837.62, Train LB = -358.521, Loss = 353.729
[2018-06-04 20:13] Train Step 65525, Epoch 60.7, Batch Size = 256, Examples/Sec = 3786.91, Train LB = -360.823, Loss = 352.968
[2018-06-04 20:13] Train Step 65550, Epoch 60.7, Batch Size = 256, Examples/Sec = 3861.06, Train LB = -364.481, Loss = 353.294
[2018-06-04 20:13] Train Step 65575, Epoch 60.7, Batch Size = 256, Examples/Sec = 3785.75, Train LB = -379.090, Loss = 355.125
[2018-06-04 20:13] Train Step 65600, Epoch 60.7, Batch Size = 256, Examples/Sec = 3751.68, Train LB = -361.910, Loss = 358.530
Performance on test set:
  Test Lower Bound = -418.464, Test Loss = 418.464
[2018-06-04 20:13] Train Step 65625, Epoch 60.8, Batch Size = 256, Examples/Sec = 3856.06, Train LB = -370.080, Loss = 357.182
[2018-06-04 20:13] Train Step 65650, Epoch 60.8, Batch Size = 256, Examples/Sec = 3840.86, Train LB = -349.071, Loss = 355.548
[2018-06-04 20:13] Train Step 65675, Epoch 60.8, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -344.042, Loss = 354.201
[2018-06-04 20:13] Train Step 65700, Epoch 60.8, Batch Size = 256, Examples/Sec = 3831.36, Train LB = -354.378, Loss = 352.731
[2018-06-04 20:13] Train Step 65725, Epoch 60.9, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -366.912, Loss = 352.336
[2018-06-04 20:13] Train Step 65750, Epoch 60.9, Batch Size = 256, Examples/Sec = 3852.82, Train LB = -351.637, Loss = 352.859
[2018-06-04 20:13] Train Step 65775, Epoch 60.9, Batch Size = 256, Examples/Sec = 3838.77, Train LB = -354.975, Loss = 354.651
[2018-06-04 20:13] Train Step 65800, Epoch 60.9, Batch Size = 256, Examples/Sec = 3842.41, Train LB = -372.734, Loss = 357.502
Performance on test set:
  Test Lower Bound = -414.736, Test Loss = 414.736
[2018-06-04 20:13] Train Step 65825, Epoch 60.9, Batch Size = 256, Examples/Sec = 3808.05, Train LB = -352.139, Loss = 356.849
[2018-06-04 20:13] Train Step 65850, Epoch 61.0, Batch Size = 256, Examples/Sec = 3861.99, Train LB = -348.207, Loss = 355.726
[2018-06-04 20:13] Train Step 65875, Epoch 61.0, Batch Size = 256, Examples/Sec = 3863.92, Train LB = -344.397, Loss = 353.434
[2018-06-04 20:13] Train Step 65900, Epoch 61.0, Batch Size = 256, Examples/Sec = 3804.59, Train LB = -355.115, Loss = 351.889
[2018-06-04 20:13] Train Step 65925, Epoch 61.0, Batch Size = 256, Examples/Sec = 3832.27, Train LB = -348.945, Loss = 351.932
[2018-06-04 20:13] Train Step 65950, Epoch 61.1, Batch Size = 256, Examples/Sec = 3858.73, Train LB = -351.603, Loss = 352.516
[2018-06-04 20:13] Train Step 65975, Epoch 61.1, Batch Size = 256, Examples/Sec = 3857.62, Train LB = -370.248, Loss = 354.322
[2018-06-04 20:13] Train Step 66000, Epoch 61.1, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -380.385, Loss = 358.030
Performance on test set:
  Test Lower Bound = -416.695, Test Loss = 416.695
[2018-06-04 20:14] Train Step 66025, Epoch 61.1, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -356.798, Loss = 356.548
[2018-06-04 20:14] Train Step 66050, Epoch 61.2, Batch Size = 256, Examples/Sec = 3842.63, Train LB = -326.786, Loss = 355.083
[2018-06-04 20:14] Train Step 66075, Epoch 61.2, Batch Size = 256, Examples/Sec = 3882.79, Train LB = -361.094, Loss = 354.370
[2018-06-04 20:14] Train Step 66100, Epoch 61.2, Batch Size = 256, Examples/Sec = 3866.66, Train LB = -354.964, Loss = 353.822
[2018-06-04 20:14] Train Step 66125, Epoch 61.2, Batch Size = 256, Examples/Sec = 3837.74, Train LB = -355.429, Loss = 353.059
[2018-06-04 20:14] Train Step 66150, Epoch 61.2, Batch Size = 256, Examples/Sec = 3880.98, Train LB = -355.925, Loss = 352.947
[2018-06-04 20:14] Train Step 66175, Epoch 61.3, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -363.858, Loss = 354.942
[2018-06-04 20:14] Train Step 66200, Epoch 61.3, Batch Size = 256, Examples/Sec = 3806.30, Train LB = -383.205, Loss = 358.333
Performance on test set:
  Test Lower Bound = -418.269, Test Loss = 418.269
[2018-06-04 20:14] Train Step 66225, Epoch 61.3, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -345.129, Loss = 357.284
[2018-06-04 20:14] Train Step 66250, Epoch 61.3, Batch Size = 256, Examples/Sec = 3758.14, Train LB = -356.299, Loss = 356.118
[2018-06-04 20:14] Train Step 66275, Epoch 61.4, Batch Size = 256, Examples/Sec = 3854.44, Train LB = -350.579, Loss = 355.278
[2018-06-04 20:14] Train Step 66300, Epoch 61.4, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -363.698, Loss = 354.186
[2018-06-04 20:14] Train Step 66325, Epoch 61.4, Batch Size = 256, Examples/Sec = 3775.93, Train LB = -365.126, Loss = 353.322
[2018-06-04 20:14] Train Step 66350, Epoch 61.4, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -358.147, Loss = 353.650
[2018-06-04 20:14] Train Step 66375, Epoch 61.5, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -371.465, Loss = 354.667
[2018-06-04 20:14] Train Step 66400, Epoch 61.5, Batch Size = 256, Examples/Sec = 3731.51, Train LB = -370.909, Loss = 358.447
Performance on test set:
  Test Lower Bound = -418.100, Test Loss = 418.100
[2018-06-04 20:14] Train Step 66425, Epoch 61.5, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -364.343, Loss = 357.311
[2018-06-04 20:14] Train Step 66450, Epoch 61.5, Batch Size = 256, Examples/Sec = 3841.89, Train LB = -352.569, Loss = 355.815
[2018-06-04 20:14] Train Step 66475, Epoch 61.6, Batch Size = 256, Examples/Sec = 3843.04, Train LB = -343.016, Loss = 354.135
[2018-06-04 20:14] Train Step 66500, Epoch 61.6, Batch Size = 256, Examples/Sec = 3843.03, Train LB = -344.884, Loss = 353.578
[2018-06-04 20:14] Train Step 66525, Epoch 61.6, Batch Size = 256, Examples/Sec = 3805.06, Train LB = -363.891, Loss = 353.727
[2018-06-04 20:14] Train Step 66550, Epoch 61.6, Batch Size = 256, Examples/Sec = 3850.44, Train LB = -346.051, Loss = 353.604
[2018-06-04 20:14] Train Step 66575, Epoch 61.6, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -362.137, Loss = 354.347
[2018-06-04 20:14] Train Step 66600, Epoch 61.7, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -360.076, Loss = 358.040
Performance on test set:
  Test Lower Bound = -418.701, Test Loss = 418.701
[2018-06-04 20:14] Train Step 66625, Epoch 61.7, Batch Size = 256, Examples/Sec = 3873.68, Train LB = -333.320, Loss = 357.620
[2018-06-04 20:14] Train Step 66650, Epoch 61.7, Batch Size = 256, Examples/Sec = 3853.51, Train LB = -344.337, Loss = 355.674
[2018-06-04 20:14] Train Step 66675, Epoch 61.7, Batch Size = 256, Examples/Sec = 3832.45, Train LB = -351.093, Loss = 353.706
[2018-06-04 20:14] Train Step 66700, Epoch 61.8, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -347.997, Loss = 353.114
[2018-06-04 20:15] Train Step 66725, Epoch 61.8, Batch Size = 256, Examples/Sec = 3873.32, Train LB = -347.212, Loss = 352.262
[2018-06-04 20:15] Train Step 66750, Epoch 61.8, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -352.266, Loss = 352.198
[2018-06-04 20:15] Train Step 66775, Epoch 61.8, Batch Size = 256, Examples/Sec = 3846.91, Train LB = -350.347, Loss = 353.880
[2018-06-04 20:15] Train Step 66800, Epoch 61.9, Batch Size = 256, Examples/Sec = 3853.16, Train LB = -393.394, Loss = 358.029
Performance on test set:
  Test Lower Bound = -415.887, Test Loss = 415.887
[2018-06-04 20:15] Train Step 66825, Epoch 61.9, Batch Size = 256, Examples/Sec = 3853.97, Train LB = -339.743, Loss = 356.901
[2018-06-04 20:15] Train Step 66850, Epoch 61.9, Batch Size = 256, Examples/Sec = 3865.09, Train LB = -343.065, Loss = 355.402
[2018-06-04 20:15] Train Step 66875, Epoch 61.9, Batch Size = 256, Examples/Sec = 3802.74, Train LB = -343.967, Loss = 354.521
[2018-06-04 20:15] Train Step 66900, Epoch 61.9, Batch Size = 256, Examples/Sec = 3837.27, Train LB = -340.264, Loss = 353.686
[2018-06-04 20:15] Train Step 66925, Epoch 62.0, Batch Size = 256, Examples/Sec = 3805.22, Train LB = -357.682, Loss = 352.663
[2018-06-04 20:15] Train Step 66950, Epoch 62.0, Batch Size = 256, Examples/Sec = 3878.68, Train LB = -362.285, Loss = 352.813
[2018-06-04 20:15] Train Step 66975, Epoch 62.0, Batch Size = 256, Examples/Sec = 3844.94, Train LB = -367.788, Loss = 354.167
[2018-06-04 20:15] Train Step 67000, Epoch 62.0, Batch Size = 256, Examples/Sec = 3850.10, Train LB = -383.739, Loss = 357.692
Performance on test set:
  Test Lower Bound = -417.872, Test Loss = 417.872
[2018-06-04 20:15] Train Step 67025, Epoch 62.1, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -343.042, Loss = 356.537
[2018-06-04 20:15] Train Step 67050, Epoch 62.1, Batch Size = 256, Examples/Sec = 3845.34, Train LB = -335.941, Loss = 355.316
[2018-06-04 20:15] Train Step 67075, Epoch 62.1, Batch Size = 256, Examples/Sec = 3857.52, Train LB = -342.685, Loss = 354.131
[2018-06-04 20:15] Train Step 67100, Epoch 62.1, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -350.372, Loss = 352.947
[2018-06-04 20:15] Train Step 67125, Epoch 62.2, Batch Size = 256, Examples/Sec = 3871.10, Train LB = -352.991, Loss = 351.976
[2018-06-04 20:15] Train Step 67150, Epoch 62.2, Batch Size = 256, Examples/Sec = 3848.94, Train LB = -361.692, Loss = 351.882
[2018-06-04 20:15] Train Step 67175, Epoch 62.2, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -365.861, Loss = 353.480
[2018-06-04 20:15] Train Step 67200, Epoch 62.2, Batch Size = 256, Examples/Sec = 3774.36, Train LB = -381.565, Loss = 356.940
Performance on test set:
  Test Lower Bound = -418.480, Test Loss = 418.480
[2018-06-04 20:15] Train Step 67225, Epoch 62.2, Batch Size = 256, Examples/Sec = 3852.18, Train LB = -363.316, Loss = 355.932
[2018-06-04 20:15] Train Step 67250, Epoch 62.3, Batch Size = 256, Examples/Sec = 3844.07, Train LB = -364.651, Loss = 354.327
[2018-06-04 20:15] Train Step 67275, Epoch 62.3, Batch Size = 256, Examples/Sec = 3861.53, Train LB = -335.867, Loss = 353.230
[2018-06-04 20:15] Train Step 67300, Epoch 62.3, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -359.975, Loss = 352.705
[2018-06-04 20:15] Train Step 67325, Epoch 62.3, Batch Size = 256, Examples/Sec = 3853.09, Train LB = -348.566, Loss = 352.799
[2018-06-04 20:15] Train Step 67350, Epoch 62.4, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -359.433, Loss = 352.836
[2018-06-04 20:15] Train Step 67375, Epoch 62.4, Batch Size = 256, Examples/Sec = 3844.02, Train LB = -353.786, Loss = 354.678
[2018-06-04 20:15] Train Step 67400, Epoch 62.4, Batch Size = 256, Examples/Sec = 3838.82, Train LB = -370.367, Loss = 356.787
Performance on test set:
  Test Lower Bound = -417.935, Test Loss = 417.935
[2018-06-04 20:16] Train Step 67425, Epoch 62.4, Batch Size = 256, Examples/Sec = 3822.67, Train LB = -347.834, Loss = 355.779
[2018-06-04 20:16] Train Step 67450, Epoch 62.5, Batch Size = 256, Examples/Sec = 3844.18, Train LB = -358.775, Loss = 355.334
[2018-06-04 20:16] Train Step 67475, Epoch 62.5, Batch Size = 256, Examples/Sec = 3884.09, Train LB = -336.753, Loss = 353.689
[2018-06-04 20:16] Train Step 67500, Epoch 62.5, Batch Size = 256, Examples/Sec = 3852.93, Train LB = -349.324, Loss = 352.234
[2018-06-04 20:16] Train Step 67525, Epoch 62.5, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -349.193, Loss = 351.765
[2018-06-04 20:16] Train Step 67550, Epoch 62.5, Batch Size = 256, Examples/Sec = 3863.56, Train LB = -370.544, Loss = 351.274
[2018-06-04 20:16] Train Step 67575, Epoch 62.6, Batch Size = 256, Examples/Sec = 3870.00, Train LB = -371.800, Loss = 353.211
[2018-06-04 20:16] Train Step 67600, Epoch 62.6, Batch Size = 256, Examples/Sec = 3856.17, Train LB = -384.376, Loss = 356.660
Performance on test set:
  Test Lower Bound = -418.394, Test Loss = 418.394
[2018-06-04 20:16] Train Step 67625, Epoch 62.6, Batch Size = 256, Examples/Sec = 3871.64, Train LB = -343.975, Loss = 356.185
[2018-06-04 20:16] Train Step 67650, Epoch 62.6, Batch Size = 256, Examples/Sec = 3822.21, Train LB = -355.983, Loss = 354.831
[2018-06-04 20:16] Train Step 67675, Epoch 62.7, Batch Size = 256, Examples/Sec = 3737.07, Train LB = -352.629, Loss = 353.426
[2018-06-04 20:16] Train Step 67700, Epoch 62.7, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -336.009, Loss = 352.250
[2018-06-04 20:16] Train Step 67725, Epoch 62.7, Batch Size = 256, Examples/Sec = 3868.00, Train LB = -367.148, Loss = 350.986
[2018-06-04 20:16] Train Step 67750, Epoch 62.7, Batch Size = 256, Examples/Sec = 3753.99, Train LB = -337.099, Loss = 351.706
[2018-06-04 20:16] Train Step 67775, Epoch 62.8, Batch Size = 256, Examples/Sec = 3859.96, Train LB = -357.497, Loss = 353.295
[2018-06-04 20:16] Train Step 67800, Epoch 62.8, Batch Size = 256, Examples/Sec = 3865.95, Train LB = -370.948, Loss = 357.226
Performance on test set:
  Test Lower Bound = -418.614, Test Loss = 418.614
[2018-06-04 20:16] Train Step 67825, Epoch 62.8, Batch Size = 256, Examples/Sec = 3860.60, Train LB = -350.358, Loss = 356.403
[2018-06-04 20:16] Train Step 67850, Epoch 62.8, Batch Size = 256, Examples/Sec = 3872.05, Train LB = -365.684, Loss = 354.760
[2018-06-04 20:16] Train Step 67875, Epoch 62.8, Batch Size = 256, Examples/Sec = 3814.57, Train LB = -360.180, Loss = 354.046
[2018-06-04 20:16] Train Step 67900, Epoch 62.9, Batch Size = 256, Examples/Sec = 3891.47, Train LB = -348.522, Loss = 353.343
[2018-06-04 20:16] Train Step 67925, Epoch 62.9, Batch Size = 256, Examples/Sec = 3846.37, Train LB = -365.405, Loss = 352.225
[2018-06-04 20:16] Train Step 67950, Epoch 62.9, Batch Size = 256, Examples/Sec = 3857.69, Train LB = -339.839, Loss = 352.296
[2018-06-04 20:16] Train Step 67975, Epoch 62.9, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -388.536, Loss = 352.784
[2018-06-04 20:16] Train Step 68000, Epoch 63.0, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -382.555, Loss = 357.042
Performance on test set:
  Test Lower Bound = -418.716, Test Loss = 418.716
[2018-06-04 20:16] Train Step 68025, Epoch 63.0, Batch Size = 256, Examples/Sec = 3854.26, Train LB = -343.881, Loss = 355.608
[2018-06-04 20:16] Train Step 68050, Epoch 63.0, Batch Size = 256, Examples/Sec = 3801.89, Train LB = -346.834, Loss = 354.568
[2018-06-04 20:16] Train Step 68075, Epoch 63.0, Batch Size = 256, Examples/Sec = 3854.33, Train LB = -340.984, Loss = 352.785
[2018-06-04 20:16] Train Step 68100, Epoch 63.1, Batch Size = 256, Examples/Sec = 3855.36, Train LB = -350.092, Loss = 352.025
[2018-06-04 20:16] Train Step 68125, Epoch 63.1, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -351.530, Loss = 351.607
[2018-06-04 20:17] Train Step 68150, Epoch 63.1, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -357.052, Loss = 352.142
[2018-06-04 20:17] Train Step 68175, Epoch 63.1, Batch Size = 256, Examples/Sec = 3843.10, Train LB = -373.559, Loss = 353.219
[2018-06-04 20:17] Train Step 68200, Epoch 63.1, Batch Size = 256, Examples/Sec = 3863.23, Train LB = -373.345, Loss = 356.523
Performance on test set:
  Test Lower Bound = -417.396, Test Loss = 417.396
[2018-06-04 20:17] Train Step 68225, Epoch 63.2, Batch Size = 256, Examples/Sec = 3868.99, Train LB = -360.242, Loss = 355.918
[2018-06-04 20:17] Train Step 68250, Epoch 63.2, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -343.908, Loss = 354.484
[2018-06-04 20:17] Train Step 68275, Epoch 63.2, Batch Size = 256, Examples/Sec = 3843.80, Train LB = -351.408, Loss = 352.627
[2018-06-04 20:17] Train Step 68300, Epoch 63.2, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -341.307, Loss = 351.551
[2018-06-04 20:17] Train Step 68325, Epoch 63.3, Batch Size = 256, Examples/Sec = 3846.66, Train LB = -346.503, Loss = 351.047
[2018-06-04 20:17] Train Step 68350, Epoch 63.3, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -365.849, Loss = 351.861
[2018-06-04 20:17] Train Step 68375, Epoch 63.3, Batch Size = 256, Examples/Sec = 3846.08, Train LB = -370.046, Loss = 352.928
[2018-06-04 20:17] Train Step 68400, Epoch 63.3, Batch Size = 256, Examples/Sec = 3845.57, Train LB = -363.034, Loss = 356.967
Performance on test set:
  Test Lower Bound = -416.703, Test Loss = 416.703
[2018-06-04 20:17] Train Step 68425, Epoch 63.4, Batch Size = 256, Examples/Sec = 3849.03, Train LB = -350.184, Loss = 355.862
[2018-06-04 20:17] Train Step 68450, Epoch 63.4, Batch Size = 256, Examples/Sec = 3819.24, Train LB = -355.362, Loss = 353.647
[2018-06-04 20:17] Train Step 68475, Epoch 63.4, Batch Size = 256, Examples/Sec = 3715.64, Train LB = -358.139, Loss = 352.423
[2018-06-04 20:17] Train Step 68500, Epoch 63.4, Batch Size = 256, Examples/Sec = 3847.60, Train LB = -354.406, Loss = 352.444
[2018-06-04 20:17] Train Step 68525, Epoch 63.4, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -347.921, Loss = 351.829
[2018-06-04 20:17] Train Step 68550, Epoch 63.5, Batch Size = 256, Examples/Sec = 3740.50, Train LB = -350.710, Loss = 351.731
[2018-06-04 20:17] Train Step 68575, Epoch 63.5, Batch Size = 256, Examples/Sec = 3848.11, Train LB = -368.046, Loss = 353.806
[2018-06-04 20:17] Train Step 68600, Epoch 63.5, Batch Size = 256, Examples/Sec = 3856.75, Train LB = -383.266, Loss = 356.905
Performance on test set:
  Test Lower Bound = -418.802, Test Loss = 418.802
[2018-06-04 20:17] Train Step 68625, Epoch 63.5, Batch Size = 256, Examples/Sec = 3858.31, Train LB = -351.007, Loss = 355.017
[2018-06-04 20:17] Train Step 68650, Epoch 63.6, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -358.525, Loss = 354.902
[2018-06-04 20:17] Train Step 68675, Epoch 63.6, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -350.712, Loss = 353.435
[2018-06-04 20:17] Train Step 68700, Epoch 63.6, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -353.238, Loss = 352.323
[2018-06-04 20:17] Train Step 68725, Epoch 63.6, Batch Size = 256, Examples/Sec = 3846.68, Train LB = -354.393, Loss = 351.595
[2018-06-04 20:17] Train Step 68750, Epoch 63.7, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -369.675, Loss = 352.179
[2018-06-04 20:17] Train Step 68775, Epoch 63.7, Batch Size = 256, Examples/Sec = 3854.03, Train LB = -362.615, Loss = 353.024
[2018-06-04 20:17] Train Step 68800, Epoch 63.7, Batch Size = 256, Examples/Sec = 3851.48, Train LB = -369.233, Loss = 356.875
Performance on test set:
  Test Lower Bound = -420.513, Test Loss = 420.513
[2018-06-04 20:17] Train Step 68825, Epoch 63.7, Batch Size = 256, Examples/Sec = 3881.73, Train LB = -357.847, Loss = 355.773
[2018-06-04 20:18] Train Step 68850, Epoch 63.8, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -344.578, Loss = 354.557
[2018-06-04 20:18] Train Step 68875, Epoch 63.8, Batch Size = 256, Examples/Sec = 3857.93, Train LB = -344.017, Loss = 353.363
[2018-06-04 20:18] Train Step 68900, Epoch 63.8, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -357.247, Loss = 352.323
[2018-06-04 20:18] Train Step 68925, Epoch 63.8, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -348.121, Loss = 351.378
[2018-06-04 20:18] Train Step 68950, Epoch 63.8, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -366.915, Loss = 351.696
[2018-06-04 20:18] Train Step 68975, Epoch 63.9, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -360.348, Loss = 353.072
[2018-06-04 20:18] Train Step 69000, Epoch 63.9, Batch Size = 256, Examples/Sec = 3858.44, Train LB = -374.409, Loss = 356.308
Performance on test set:
  Test Lower Bound = -419.593, Test Loss = 419.593
[2018-06-04 20:18] Train Step 69025, Epoch 63.9, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -385.847, Loss = 355.408
[2018-06-04 20:18] Train Step 69050, Epoch 63.9, Batch Size = 256, Examples/Sec = 3874.55, Train LB = -326.373, Loss = 354.378
[2018-06-04 20:18] Train Step 69075, Epoch 64.0, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -361.459, Loss = 352.590
[2018-06-04 20:18] Train Step 69100, Epoch 64.0, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -349.355, Loss = 352.354
[2018-06-04 20:18] Train Step 69125, Epoch 64.0, Batch Size = 256, Examples/Sec = 3873.21, Train LB = -349.379, Loss = 351.624
[2018-06-04 20:18] Train Step 69150, Epoch 64.0, Batch Size = 256, Examples/Sec = 3844.94, Train LB = -349.840, Loss = 351.867
[2018-06-04 20:18] Train Step 69175, Epoch 64.1, Batch Size = 256, Examples/Sec = 3856.76, Train LB = -359.272, Loss = 353.267
[2018-06-04 20:18] Train Step 69200, Epoch 64.1, Batch Size = 256, Examples/Sec = 3846.10, Train LB = -378.213, Loss = 357.618
Performance on test set:
  Test Lower Bound = -418.520, Test Loss = 418.520
[2018-06-04 20:18] Train Step 69225, Epoch 64.1, Batch Size = 256, Examples/Sec = 3838.32, Train LB = -352.190, Loss = 356.396
[2018-06-04 20:18] Train Step 69250, Epoch 64.1, Batch Size = 256, Examples/Sec = 3867.71, Train LB = -335.882, Loss = 354.937
[2018-06-04 20:18] Train Step 69275, Epoch 64.1, Batch Size = 256, Examples/Sec = 3738.15, Train LB = -357.472, Loss = 353.027
[2018-06-04 20:18] Train Step 69300, Epoch 64.2, Batch Size = 256, Examples/Sec = 3871.75, Train LB = -344.479, Loss = 351.730
[2018-06-04 20:18] Train Step 69325, Epoch 64.2, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -345.781, Loss = 351.488
[2018-06-04 20:18] Train Step 69350, Epoch 64.2, Batch Size = 256, Examples/Sec = 3820.22, Train LB = -344.207, Loss = 351.975
[2018-06-04 20:18] Train Step 69375, Epoch 64.2, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -383.712, Loss = 353.333
[2018-06-04 20:18] Train Step 69400, Epoch 64.3, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -378.947, Loss = 356.951
Performance on test set:
  Test Lower Bound = -420.343, Test Loss = 420.343
[2018-06-04 20:18] Train Step 69425, Epoch 64.3, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -338.555, Loss = 355.586
[2018-06-04 20:18] Train Step 69450, Epoch 64.3, Batch Size = 256, Examples/Sec = 3851.99, Train LB = -370.013, Loss = 354.076
[2018-06-04 20:18] Train Step 69475, Epoch 64.3, Batch Size = 256, Examples/Sec = 3849.92, Train LB = -346.752, Loss = 352.419
[2018-06-04 20:18] Train Step 69500, Epoch 64.4, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -333.209, Loss = 352.207
[2018-06-04 20:18] Train Step 69525, Epoch 64.4, Batch Size = 256, Examples/Sec = 3863.58, Train LB = -335.553, Loss = 351.627
[2018-06-04 20:18] Train Step 69550, Epoch 64.4, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -352.927, Loss = 351.852
[2018-06-04 20:18] Train Step 69575, Epoch 64.4, Batch Size = 256, Examples/Sec = 3859.42, Train LB = -374.665, Loss = 353.430
[2018-06-04 20:19] Train Step 69600, Epoch 64.4, Batch Size = 256, Examples/Sec = 3742.53, Train LB = -368.953, Loss = 357.237
Performance on test set:
  Test Lower Bound = -419.070, Test Loss = 419.070
[2018-06-04 20:19] Train Step 69625, Epoch 64.5, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -336.724, Loss = 356.196
[2018-06-04 20:19] Train Step 69650, Epoch 64.5, Batch Size = 256, Examples/Sec = 3826.89, Train LB = -336.808, Loss = 354.548
[2018-06-04 20:19] Train Step 69675, Epoch 64.5, Batch Size = 256, Examples/Sec = 3876.73, Train LB = -352.385, Loss = 353.560
[2018-06-04 20:19] Train Step 69700, Epoch 64.5, Batch Size = 256, Examples/Sec = 3827.98, Train LB = -357.226, Loss = 352.055
[2018-06-04 20:19] Train Step 69725, Epoch 64.6, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -337.979, Loss = 351.627
[2018-06-04 20:19] Train Step 69750, Epoch 64.6, Batch Size = 256, Examples/Sec = 3869.34, Train LB = -357.855, Loss = 351.245
[2018-06-04 20:19] Train Step 69775, Epoch 64.6, Batch Size = 256, Examples/Sec = 3847.08, Train LB = -366.764, Loss = 352.956
[2018-06-04 20:19] Train Step 69800, Epoch 64.6, Batch Size = 256, Examples/Sec = 3876.02, Train LB = -390.226, Loss = 356.871
Performance on test set:
  Test Lower Bound = -418.250, Test Loss = 418.250
[2018-06-04 20:19] Train Step 69825, Epoch 64.7, Batch Size = 256, Examples/Sec = 3851.37, Train LB = -342.515, Loss = 356.306
[2018-06-04 20:19] Train Step 69850, Epoch 64.7, Batch Size = 256, Examples/Sec = 3856.93, Train LB = -348.554, Loss = 354.363
[2018-06-04 20:19] Train Step 69875, Epoch 64.7, Batch Size = 256, Examples/Sec = 3844.42, Train LB = -344.859, Loss = 352.349
[2018-06-04 20:19] Train Step 69900, Epoch 64.7, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -353.957, Loss = 351.402
[2018-06-04 20:19] Train Step 69925, Epoch 64.7, Batch Size = 256, Examples/Sec = 3857.98, Train LB = -354.397, Loss = 351.532
[2018-06-04 20:19] Train Step 69950, Epoch 64.8, Batch Size = 256, Examples/Sec = 3844.14, Train LB = -363.470, Loss = 351.409
[2018-06-04 20:19] Train Step 69975, Epoch 64.8, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -357.208, Loss = 352.973
[2018-06-04 20:19] Train Step 70000, Epoch 64.8, Batch Size = 256, Examples/Sec = 3846.44, Train LB = -383.171, Loss = 356.688
Performance on test set:
  Test Lower Bound = -419.124, Test Loss = 419.124
[2018-06-04 20:19] Train Step 70025, Epoch 64.8, Batch Size = 256, Examples/Sec = 3820.44, Train LB = -345.974, Loss = 355.554
[2018-06-04 20:19] Train Step 70050, Epoch 64.9, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -350.936, Loss = 353.828
[2018-06-04 20:19] Train Step 70075, Epoch 64.9, Batch Size = 256, Examples/Sec = 3862.64, Train LB = -354.581, Loss = 352.641
[2018-06-04 20:19] Train Step 70100, Epoch 64.9, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -337.303, Loss = 351.672
[2018-06-04 20:19] Train Step 70125, Epoch 64.9, Batch Size = 256, Examples/Sec = 3832.40, Train LB = -354.383, Loss = 350.671
[2018-06-04 20:19] Train Step 70150, Epoch 65.0, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -355.642, Loss = 350.976
[2018-06-04 20:19] Train Step 70175, Epoch 65.0, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -351.376, Loss = 352.515
[2018-06-04 20:19] Train Step 70200, Epoch 65.0, Batch Size = 256, Examples/Sec = 3851.48, Train LB = -377.095, Loss = 356.172
Performance on test set:
  Test Lower Bound = -419.358, Test Loss = 419.358
[2018-06-04 20:19] Train Step 70225, Epoch 65.0, Batch Size = 256, Examples/Sec = 3856.36, Train LB = -360.343, Loss = 355.102
[2018-06-04 20:19] Train Step 70250, Epoch 65.0, Batch Size = 256, Examples/Sec = 3777.92, Train LB = -330.589, Loss = 353.899
[2018-06-04 20:20] Train Step 70275, Epoch 65.1, Batch Size = 256, Examples/Sec = 3829.13, Train LB = -340.472, Loss = 352.943
[2018-06-04 20:20] Train Step 70300, Epoch 65.1, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -366.343, Loss = 352.525
[2018-06-04 20:20] Train Step 70325, Epoch 65.1, Batch Size = 256, Examples/Sec = 3725.26, Train LB = -349.973, Loss = 352.526
[2018-06-04 20:20] Train Step 70350, Epoch 65.1, Batch Size = 256, Examples/Sec = 3833.19, Train LB = -341.244, Loss = 352.256
[2018-06-04 20:20] Train Step 70375, Epoch 65.2, Batch Size = 256, Examples/Sec = 3855.02, Train LB = -368.165, Loss = 353.785
[2018-06-04 20:20] Train Step 70400, Epoch 65.2, Batch Size = 256, Examples/Sec = 3735.14, Train LB = -374.259, Loss = 357.185
Performance on test set:
  Test Lower Bound = -416.952, Test Loss = 416.952
[2018-06-04 20:20] Train Step 70425, Epoch 65.2, Batch Size = 256, Examples/Sec = 3847.94, Train LB = -359.435, Loss = 356.581
[2018-06-04 20:20] Train Step 70450, Epoch 65.2, Batch Size = 256, Examples/Sec = 3863.67, Train LB = -353.204, Loss = 354.989
[2018-06-04 20:20] Train Step 70475, Epoch 65.3, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -352.959, Loss = 352.588
[2018-06-04 20:20] Train Step 70500, Epoch 65.3, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -344.102, Loss = 351.377
[2018-06-04 20:20] Train Step 70525, Epoch 65.3, Batch Size = 256, Examples/Sec = 3841.31, Train LB = -353.466, Loss = 350.594
[2018-06-04 20:20] Train Step 70550, Epoch 65.3, Batch Size = 256, Examples/Sec = 3844.60, Train LB = -349.115, Loss = 350.320
[2018-06-04 20:20] Train Step 70575, Epoch 65.3, Batch Size = 256, Examples/Sec = 3853.04, Train LB = -347.114, Loss = 352.514
[2018-06-04 20:20] Train Step 70600, Epoch 65.4, Batch Size = 256, Examples/Sec = 3851.01, Train LB = -382.697, Loss = 356.699
Performance on test set:
  Test Lower Bound = -419.325, Test Loss = 419.325
[2018-06-04 20:20] Train Step 70625, Epoch 65.4, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -340.332, Loss = 355.955
[2018-06-04 20:20] Train Step 70650, Epoch 65.4, Batch Size = 256, Examples/Sec = 3778.32, Train LB = -347.555, Loss = 353.930
[2018-06-04 20:20] Train Step 70675, Epoch 65.4, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -339.975, Loss = 352.721
[2018-06-04 20:20] Train Step 70700, Epoch 65.5, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -331.413, Loss = 351.752
[2018-06-04 20:20] Train Step 70725, Epoch 65.5, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -347.895, Loss = 351.230
[2018-06-04 20:20] Train Step 70750, Epoch 65.5, Batch Size = 256, Examples/Sec = 3859.15, Train LB = -349.099, Loss = 351.183
[2018-06-04 20:20] Train Step 70775, Epoch 65.5, Batch Size = 256, Examples/Sec = 3846.33, Train LB = -363.945, Loss = 352.805
[2018-06-04 20:20] Train Step 70800, Epoch 65.6, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -367.025, Loss = 356.369
Performance on test set:
  Test Lower Bound = -419.940, Test Loss = 419.940
[2018-06-04 20:20] Train Step 70825, Epoch 65.6, Batch Size = 256, Examples/Sec = 3847.54, Train LB = -353.302, Loss = 355.316
[2018-06-04 20:20] Train Step 70850, Epoch 65.6, Batch Size = 256, Examples/Sec = 3848.63, Train LB = -327.881, Loss = 354.156
[2018-06-04 20:20] Train Step 70875, Epoch 65.6, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -347.331, Loss = 352.221
[2018-06-04 20:20] Train Step 70900, Epoch 65.6, Batch Size = 256, Examples/Sec = 3853.97, Train LB = -353.806, Loss = 351.652
[2018-06-04 20:20] Train Step 70925, Epoch 65.7, Batch Size = 256, Examples/Sec = 3842.28, Train LB = -360.986, Loss = 350.522
[2018-06-04 20:20] Train Step 70950, Epoch 65.7, Batch Size = 256, Examples/Sec = 3835.55, Train LB = -367.634, Loss = 351.054
[2018-06-04 20:20] Train Step 70975, Epoch 65.7, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -363.669, Loss = 353.035
[2018-06-04 20:20] Train Step 71000, Epoch 65.7, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -395.311, Loss = 356.713
Performance on test set:
  Test Lower Bound = -418.494, Test Loss = 418.494
[2018-06-04 20:21] Train Step 71025, Epoch 65.8, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -364.995, Loss = 355.774
[2018-06-04 20:21] Train Step 71050, Epoch 65.8, Batch Size = 256, Examples/Sec = 3738.76, Train LB = -341.521, Loss = 354.493
[2018-06-04 20:21] Train Step 71075, Epoch 65.8, Batch Size = 256, Examples/Sec = 3849.92, Train LB = -355.498, Loss = 352.255
[2018-06-04 20:21] Train Step 71100, Epoch 65.8, Batch Size = 256, Examples/Sec = 3876.20, Train LB = -335.671, Loss = 351.499
[2018-06-04 20:21] Train Step 71125, Epoch 65.9, Batch Size = 256, Examples/Sec = 3744.44, Train LB = -341.842, Loss = 350.760
[2018-06-04 20:21] Train Step 71150, Epoch 65.9, Batch Size = 256, Examples/Sec = 3874.39, Train LB = -355.862, Loss = 350.921
[2018-06-04 20:21] Train Step 71175, Epoch 65.9, Batch Size = 256, Examples/Sec = 3849.23, Train LB = -360.244, Loss = 352.477
[2018-06-04 20:21] Train Step 71200, Epoch 65.9, Batch Size = 256, Examples/Sec = 3746.25, Train LB = -370.588, Loss = 355.768
Performance on test set:
  Test Lower Bound = -419.879, Test Loss = 419.879
[2018-06-04 20:21] Train Step 71225, Epoch 65.9, Batch Size = 256, Examples/Sec = 3845.28, Train LB = -337.876, Loss = 354.867
[2018-06-04 20:21] Train Step 71250, Epoch 66.0, Batch Size = 256, Examples/Sec = 3842.17, Train LB = -356.920, Loss = 353.408
[2018-06-04 20:21] Train Step 71275, Epoch 66.0, Batch Size = 256, Examples/Sec = 3865.04, Train LB = -343.142, Loss = 352.689
[2018-06-04 20:21] Train Step 71300, Epoch 66.0, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -334.893, Loss = 351.414
[2018-06-04 20:21] Train Step 71325, Epoch 66.0, Batch Size = 256, Examples/Sec = 3858.85, Train LB = -347.589, Loss = 350.647
[2018-06-04 20:21] Train Step 71350, Epoch 66.1, Batch Size = 256, Examples/Sec = 3840.37, Train LB = -337.740, Loss = 350.922
[2018-06-04 20:21] Train Step 71375, Epoch 66.1, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -345.776, Loss = 351.939
[2018-06-04 20:21] Train Step 71400, Epoch 66.1, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -356.825, Loss = 355.912
Performance on test set:
  Test Lower Bound = -418.382, Test Loss = 418.383
[2018-06-04 20:21] Train Step 71425, Epoch 66.1, Batch Size = 256, Examples/Sec = 3847.53, Train LB = -360.320, Loss = 354.485
[2018-06-04 20:21] Train Step 71450, Epoch 66.2, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -333.363, Loss = 353.371
[2018-06-04 20:21] Train Step 71475, Epoch 66.2, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -356.794, Loss = 351.834
[2018-06-04 20:21] Train Step 71500, Epoch 66.2, Batch Size = 256, Examples/Sec = 3859.96, Train LB = -339.722, Loss = 350.632
[2018-06-04 20:21] Train Step 71525, Epoch 66.2, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -357.397, Loss = 350.601
[2018-06-04 20:21] Train Step 71550, Epoch 66.2, Batch Size = 256, Examples/Sec = 3858.49, Train LB = -354.416, Loss = 351.014
[2018-06-04 20:21] Train Step 71575, Epoch 66.3, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -373.332, Loss = 352.604
[2018-06-04 20:21] Train Step 71600, Epoch 66.3, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -376.944, Loss = 356.569
Performance on test set:
  Test Lower Bound = -418.702, Test Loss = 418.702
[2018-06-04 20:21] Train Step 71625, Epoch 66.3, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -345.741, Loss = 355.126
[2018-06-04 20:21] Train Step 71650, Epoch 66.3, Batch Size = 256, Examples/Sec = 3882.73, Train LB = -367.399, Loss = 353.766
[2018-06-04 20:21] Train Step 71675, Epoch 66.4, Batch Size = 256, Examples/Sec = 3802.22, Train LB = -342.416, Loss = 352.150
[2018-06-04 20:21] Train Step 71700, Epoch 66.4, Batch Size = 256, Examples/Sec = 3846.62, Train LB = -351.483, Loss = 350.902
[2018-06-04 20:22] Train Step 71725, Epoch 66.4, Batch Size = 256, Examples/Sec = 3852.64, Train LB = -344.157, Loss = 350.809
[2018-06-04 20:22] Train Step 71750, Epoch 66.4, Batch Size = 256, Examples/Sec = 3801.78, Train LB = -353.602, Loss = 350.938
[2018-06-04 20:22] Train Step 71775, Epoch 66.5, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -364.412, Loss = 352.682
[2018-06-04 20:22] Train Step 71800, Epoch 66.5, Batch Size = 256, Examples/Sec = 3839.87, Train LB = -375.968, Loss = 356.024
Performance on test set:
  Test Lower Bound = -418.840, Test Loss = 418.840
[2018-06-04 20:22] Train Step 71825, Epoch 66.5, Batch Size = 256, Examples/Sec = 3856.35, Train LB = -336.712, Loss = 354.226
[2018-06-04 20:22] Train Step 71850, Epoch 66.5, Batch Size = 256, Examples/Sec = 3821.35, Train LB = -344.507, Loss = 353.634
[2018-06-04 20:22] Train Step 71875, Epoch 66.6, Batch Size = 256, Examples/Sec = 3837.16, Train LB = -336.032, Loss = 352.256
[2018-06-04 20:22] Train Step 71900, Epoch 66.6, Batch Size = 256, Examples/Sec = 3840.73, Train LB = -354.212, Loss = 351.740
[2018-06-04 20:22] Train Step 71925, Epoch 66.6, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -362.485, Loss = 350.669
[2018-06-04 20:22] Train Step 71950, Epoch 66.6, Batch Size = 256, Examples/Sec = 3854.44, Train LB = -354.574, Loss = 351.245
[2018-06-04 20:22] Train Step 71975, Epoch 66.6, Batch Size = 256, Examples/Sec = 3808.22, Train LB = -371.545, Loss = 352.225
[2018-06-04 20:22] Train Step 72000, Epoch 66.7, Batch Size = 256, Examples/Sec = 3734.23, Train LB = -386.905, Loss = 355.669
Performance on test set:
  Test Lower Bound = -418.847, Test Loss = 418.847
[2018-06-04 20:22] Train Step 72025, Epoch 66.7, Batch Size = 256, Examples/Sec = 3831.19, Train LB = -340.370, Loss = 354.293
[2018-06-04 20:22] Train Step 72050, Epoch 66.7, Batch Size = 256, Examples/Sec = 3861.46, Train LB = -355.914, Loss = 353.153
[2018-06-04 20:22] Train Step 72075, Epoch 66.7, Batch Size = 256, Examples/Sec = 3779.93, Train LB = -362.215, Loss = 351.778
[2018-06-04 20:22] Train Step 72100, Epoch 66.8, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -349.961, Loss = 350.644
[2018-06-04 20:22] Train Step 72125, Epoch 66.8, Batch Size = 256, Examples/Sec = 3855.25, Train LB = -337.383, Loss = 350.534
[2018-06-04 20:22] Train Step 72150, Epoch 66.8, Batch Size = 256, Examples/Sec = 3853.16, Train LB = -350.910, Loss = 350.952
[2018-06-04 20:22] Train Step 72175, Epoch 66.8, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -357.369, Loss = 353.219
[2018-06-04 20:22] Train Step 72200, Epoch 66.9, Batch Size = 256, Examples/Sec = 3861.77, Train LB = -366.475, Loss = 356.288
Performance on test set:
  Test Lower Bound = -419.320, Test Loss = 419.320
[2018-06-04 20:22] Train Step 72225, Epoch 66.9, Batch Size = 256, Examples/Sec = 3861.53, Train LB = -352.000, Loss = 354.274
[2018-06-04 20:22] Train Step 72250, Epoch 66.9, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -354.306, Loss = 353.537
[2018-06-04 20:22] Train Step 72275, Epoch 66.9, Batch Size = 256, Examples/Sec = 3854.85, Train LB = -355.020, Loss = 351.413
[2018-06-04 20:22] Train Step 72300, Epoch 66.9, Batch Size = 256, Examples/Sec = 3849.45, Train LB = -331.631, Loss = 350.685
[2018-06-04 20:22] Train Step 72325, Epoch 67.0, Batch Size = 256, Examples/Sec = 3845.16, Train LB = -333.351, Loss = 350.495
[2018-06-04 20:22] Train Step 72350, Epoch 67.0, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -346.268, Loss = 350.751
[2018-06-04 20:22] Train Step 72375, Epoch 67.0, Batch Size = 256, Examples/Sec = 3868.07, Train LB = -367.600, Loss = 351.558
[2018-06-04 20:22] Train Step 72400, Epoch 67.0, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -383.575, Loss = 354.841
Performance on test set:
  Test Lower Bound = -421.204, Test Loss = 421.204
[2018-06-04 20:23] Train Step 72425, Epoch 67.1, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -347.930, Loss = 353.923
[2018-06-04 20:23] Train Step 72450, Epoch 67.1, Batch Size = 256, Examples/Sec = 3847.72, Train LB = -346.776, Loss = 352.587
[2018-06-04 20:23] Train Step 72475, Epoch 67.1, Batch Size = 256, Examples/Sec = 3747.74, Train LB = -332.493, Loss = 350.595
[2018-06-04 20:23] Train Step 72500, Epoch 67.1, Batch Size = 256, Examples/Sec = 3853.21, Train LB = -354.695, Loss = 350.754
[2018-06-04 20:23] Train Step 72525, Epoch 67.2, Batch Size = 256, Examples/Sec = 3847.36, Train LB = -355.816, Loss = 349.820
[2018-06-04 20:23] Train Step 72550, Epoch 67.2, Batch Size = 256, Examples/Sec = 3836.81, Train LB = -361.508, Loss = 350.537
[2018-06-04 20:23] Train Step 72575, Epoch 67.2, Batch Size = 256, Examples/Sec = 3841.65, Train LB = -366.022, Loss = 352.611
[2018-06-04 20:23] Train Step 72600, Epoch 67.2, Batch Size = 256, Examples/Sec = 3868.41, Train LB = -367.680, Loss = 356.051
Performance on test set:
  Test Lower Bound = -420.250, Test Loss = 420.250
[2018-06-04 20:23] Train Step 72625, Epoch 67.2, Batch Size = 256, Examples/Sec = 3871.11, Train LB = -351.177, Loss = 355.092
[2018-06-04 20:23] Train Step 72650, Epoch 67.3, Batch Size = 256, Examples/Sec = 3862.30, Train LB = -342.036, Loss = 353.589
[2018-06-04 20:23] Train Step 72675, Epoch 67.3, Batch Size = 256, Examples/Sec = 3872.05, Train LB = -340.414, Loss = 352.211
[2018-06-04 20:23] Train Step 72700, Epoch 67.3, Batch Size = 256, Examples/Sec = 3822.89, Train LB = -351.999, Loss = 350.534
[2018-06-04 20:23] Train Step 72725, Epoch 67.3, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -362.821, Loss = 350.001
[2018-06-04 20:23] Train Step 72750, Epoch 67.4, Batch Size = 256, Examples/Sec = 3860.24, Train LB = -365.097, Loss = 350.041
[2018-06-04 20:23] Train Step 72775, Epoch 67.4, Batch Size = 256, Examples/Sec = 3870.16, Train LB = -356.047, Loss = 351.820
[2018-06-04 20:23] Train Step 72800, Epoch 67.4, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -357.907, Loss = 355.302
Performance on test set:
  Test Lower Bound = -421.172, Test Loss = 421.172
[2018-06-04 20:23] Train Step 72825, Epoch 67.4, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -349.556, Loss = 353.973
[2018-06-04 20:23] Train Step 72850, Epoch 67.5, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -351.395, Loss = 353.381
[2018-06-04 20:23] Train Step 72875, Epoch 67.5, Batch Size = 256, Examples/Sec = 3853.40, Train LB = -340.120, Loss = 351.661
[2018-06-04 20:23] Train Step 72900, Epoch 67.5, Batch Size = 256, Examples/Sec = 3866.61, Train LB = -343.447, Loss = 350.793
[2018-06-04 20:23] Train Step 72925, Epoch 67.5, Batch Size = 256, Examples/Sec = 3862.06, Train LB = -360.953, Loss = 349.622
[2018-06-04 20:23] Train Step 72950, Epoch 67.5, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -346.147, Loss = 349.493
[2018-06-04 20:23] Train Step 72975, Epoch 67.6, Batch Size = 256, Examples/Sec = 3846.68, Train LB = -363.367, Loss = 350.862
[2018-06-04 20:23] Train Step 73000, Epoch 67.6, Batch Size = 256, Examples/Sec = 3801.95, Train LB = -368.464, Loss = 354.791
Performance on test set:
  Test Lower Bound = -419.120, Test Loss = 419.120
[2018-06-04 20:23] Train Step 73025, Epoch 67.6, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -345.160, Loss = 354.691
[2018-06-04 20:23] Train Step 73050, Epoch 67.6, Batch Size = 256, Examples/Sec = 3837.33, Train LB = -336.148, Loss = 353.180
[2018-06-04 20:23] Train Step 73075, Epoch 67.7, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -332.010, Loss = 350.811
[2018-06-04 20:23] Train Step 73100, Epoch 67.7, Batch Size = 256, Examples/Sec = 3806.42, Train LB = -356.947, Loss = 349.900
[2018-06-04 20:23] Train Step 73125, Epoch 67.7, Batch Size = 256, Examples/Sec = 3839.51, Train LB = -349.916, Loss = 349.896
[2018-06-04 20:24] Train Step 73150, Epoch 67.7, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -349.492, Loss = 350.300
[2018-06-04 20:24] Train Step 73175, Epoch 67.8, Batch Size = 256, Examples/Sec = 3869.65, Train LB = -357.479, Loss = 351.972
[2018-06-04 20:24] Train Step 73200, Epoch 67.8, Batch Size = 256, Examples/Sec = 3843.84, Train LB = -376.743, Loss = 355.197
Performance on test set:
  Test Lower Bound = -420.790, Test Loss = 420.790
[2018-06-04 20:24] Train Step 73225, Epoch 67.8, Batch Size = 256, Examples/Sec = 3857.58, Train LB = -337.678, Loss = 354.686
[2018-06-04 20:24] Train Step 73250, Epoch 67.8, Batch Size = 256, Examples/Sec = 3861.53, Train LB = -352.905, Loss = 352.913
[2018-06-04 20:24] Train Step 73275, Epoch 67.8, Batch Size = 256, Examples/Sec = 3722.23, Train LB = -331.703, Loss = 351.127
[2018-06-04 20:24] Train Step 73300, Epoch 67.9, Batch Size = 256, Examples/Sec = 3884.91, Train LB = -336.723, Loss = 349.579
[2018-06-04 20:24] Train Step 73325, Epoch 67.9, Batch Size = 256, Examples/Sec = 3839.12, Train LB = -340.084, Loss = 349.331
[2018-06-04 20:24] Train Step 73350, Epoch 67.9, Batch Size = 256, Examples/Sec = 3735.98, Train LB = -356.769, Loss = 350.528
[2018-06-04 20:24] Train Step 73375, Epoch 67.9, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -360.532, Loss = 352.579
[2018-06-04 20:24] Train Step 73400, Epoch 68.0, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -378.928, Loss = 355.595
Performance on test set:
  Test Lower Bound = -420.454, Test Loss = 420.454
[2018-06-04 20:24] Train Step 73425, Epoch 68.0, Batch Size = 256, Examples/Sec = 3838.82, Train LB = -353.141, Loss = 354.036
[2018-06-04 20:24] Train Step 73450, Epoch 68.0, Batch Size = 256, Examples/Sec = 3848.23, Train LB = -345.573, Loss = 352.980
[2018-06-04 20:24] Train Step 73475, Epoch 68.0, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -356.825, Loss = 351.812
[2018-06-04 20:24] Train Step 73500, Epoch 68.1, Batch Size = 256, Examples/Sec = 3794.22, Train LB = -348.951, Loss = 350.650
[2018-06-04 20:24] Train Step 73525, Epoch 68.1, Batch Size = 256, Examples/Sec = 3846.26, Train LB = -355.440, Loss = 350.181
[2018-06-04 20:24] Train Step 73550, Epoch 68.1, Batch Size = 256, Examples/Sec = 3859.49, Train LB = -354.533, Loss = 350.283
[2018-06-04 20:24] Train Step 73575, Epoch 68.1, Batch Size = 256, Examples/Sec = 3850.32, Train LB = -361.733, Loss = 351.834
[2018-06-04 20:24] Train Step 73600, Epoch 68.1, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -370.743, Loss = 355.239
Performance on test set:
  Test Lower Bound = -418.375, Test Loss = 418.375
[2018-06-04 20:24] Train Step 73625, Epoch 68.2, Batch Size = 256, Examples/Sec = 3871.87, Train LB = -342.711, Loss = 353.649
[2018-06-04 20:24] Train Step 73650, Epoch 68.2, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -348.684, Loss = 352.343
[2018-06-04 20:24] Train Step 73675, Epoch 68.2, Batch Size = 256, Examples/Sec = 3853.73, Train LB = -343.170, Loss = 351.491
[2018-06-04 20:24] Train Step 73700, Epoch 68.2, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -346.662, Loss = 351.134
[2018-06-04 20:24] Train Step 73725, Epoch 68.3, Batch Size = 256, Examples/Sec = 3798.84, Train LB = -347.255, Loss = 349.662
[2018-06-04 20:24] Train Step 73750, Epoch 68.3, Batch Size = 256, Examples/Sec = 3842.06, Train LB = -341.004, Loss = 350.281
[2018-06-04 20:24] Train Step 73775, Epoch 68.3, Batch Size = 256, Examples/Sec = 3862.01, Train LB = -369.639, Loss = 351.879
[2018-06-04 20:24] Train Step 73800, Epoch 68.3, Batch Size = 256, Examples/Sec = 3844.83, Train LB = -364.094, Loss = 356.181
Performance on test set:
  Test Lower Bound = -419.129, Test Loss = 419.129
[2018-06-04 20:24] Train Step 73825, Epoch 68.4, Batch Size = 256, Examples/Sec = 3831.88, Train LB = -336.042, Loss = 354.668
[2018-06-04 20:25] Train Step 73850, Epoch 68.4, Batch Size = 256, Examples/Sec = 3878.91, Train LB = -358.851, Loss = 353.351
[2018-06-04 20:25] Train Step 73875, Epoch 68.4, Batch Size = 256, Examples/Sec = 3831.43, Train LB = -332.724, Loss = 351.535
[2018-06-04 20:25] Train Step 73900, Epoch 68.4, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -360.244, Loss = 350.535
[2018-06-04 20:25] Train Step 73925, Epoch 68.4, Batch Size = 256, Examples/Sec = 3866.59, Train LB = -351.710, Loss = 350.081
[2018-06-04 20:25] Train Step 73950, Epoch 68.5, Batch Size = 256, Examples/Sec = 3803.86, Train LB = -357.653, Loss = 350.007
[2018-06-04 20:25] Train Step 73975, Epoch 68.5, Batch Size = 256, Examples/Sec = 3856.11, Train LB = -356.912, Loss = 351.373
[2018-06-04 20:25] Train Step 74000, Epoch 68.5, Batch Size = 256, Examples/Sec = 3836.75, Train LB = -386.591, Loss = 355.503
Performance on test set:
  Test Lower Bound = -419.657, Test Loss = 419.657
[2018-06-04 20:25] Train Step 74025, Epoch 68.5, Batch Size = 256, Examples/Sec = 3869.58, Train LB = -360.753, Loss = 354.308
[2018-06-04 20:25] Train Step 74050, Epoch 68.6, Batch Size = 256, Examples/Sec = 3807.65, Train LB = -342.018, Loss = 353.701
[2018-06-04 20:25] Train Step 74075, Epoch 68.6, Batch Size = 256, Examples/Sec = 3744.88, Train LB = -344.356, Loss = 351.711
[2018-06-04 20:25] Train Step 74100, Epoch 68.6, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -347.527, Loss = 350.637
[2018-06-04 20:25] Train Step 74125, Epoch 68.6, Batch Size = 256, Examples/Sec = 3797.37, Train LB = -354.303, Loss = 349.893
[2018-06-04 20:25] Train Step 74150, Epoch 68.7, Batch Size = 256, Examples/Sec = 3745.21, Train LB = -369.786, Loss = 349.820
[2018-06-04 20:25] Train Step 74175, Epoch 68.7, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -369.852, Loss = 351.116
[2018-06-04 20:25] Train Step 74200, Epoch 68.7, Batch Size = 256, Examples/Sec = 3857.97, Train LB = -354.699, Loss = 355.188
Performance on test set:
  Test Lower Bound = -420.064, Test Loss = 420.064
[2018-06-04 20:25] Train Step 74225, Epoch 68.7, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -345.370, Loss = 353.557
[2018-06-04 20:25] Train Step 74250, Epoch 68.8, Batch Size = 256, Examples/Sec = 3883.97, Train LB = -352.307, Loss = 351.994
[2018-06-04 20:25] Train Step 74275, Epoch 68.8, Batch Size = 256, Examples/Sec = 3859.60, Train LB = -336.440, Loss = 350.881
[2018-06-04 20:25] Train Step 74300, Epoch 68.8, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -334.313, Loss = 350.516
[2018-06-04 20:25] Train Step 74325, Epoch 68.8, Batch Size = 256, Examples/Sec = 3848.65, Train LB = -333.995, Loss = 349.638
[2018-06-04 20:25] Train Step 74350, Epoch 68.8, Batch Size = 256, Examples/Sec = 3856.65, Train LB = -343.266, Loss = 349.682
[2018-06-04 20:25] Train Step 74375, Epoch 68.9, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -370.874, Loss = 350.940
[2018-06-04 20:25] Train Step 74400, Epoch 68.9, Batch Size = 256, Examples/Sec = 3863.87, Train LB = -389.485, Loss = 355.167
Performance on test set:
  Test Lower Bound = -421.358, Test Loss = 421.358
[2018-06-04 20:25] Train Step 74425, Epoch 68.9, Batch Size = 256, Examples/Sec = 3838.32, Train LB = -364.836, Loss = 354.452
[2018-06-04 20:25] Train Step 74450, Epoch 68.9, Batch Size = 256, Examples/Sec = 3876.80, Train LB = -333.542, Loss = 353.363
[2018-06-04 20:25] Train Step 74475, Epoch 69.0, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -340.720, Loss = 351.589
[2018-06-04 20:25] Train Step 74500, Epoch 69.0, Batch Size = 256, Examples/Sec = 3863.97, Train LB = -338.783, Loss = 350.285
[2018-06-04 20:25] Train Step 74525, Epoch 69.0, Batch Size = 256, Examples/Sec = 3852.40, Train LB = -353.351, Loss = 349.556
[2018-06-04 20:25] Train Step 74550, Epoch 69.0, Batch Size = 256, Examples/Sec = 3845.41, Train LB = -361.190, Loss = 349.852
[2018-06-04 20:26] Train Step 74575, Epoch 69.1, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -355.175, Loss = 351.678
[2018-06-04 20:26] Train Step 74600, Epoch 69.1, Batch Size = 256, Examples/Sec = 3878.79, Train LB = -365.913, Loss = 354.845
Performance on test set:
  Test Lower Bound = -420.260, Test Loss = 420.260
[2018-06-04 20:26] Train Step 74625, Epoch 69.1, Batch Size = 256, Examples/Sec = 3738.64, Train LB = -350.258, Loss = 353.864
[2018-06-04 20:26] Train Step 74650, Epoch 69.1, Batch Size = 256, Examples/Sec = 3852.24, Train LB = -351.284, Loss = 352.363
[2018-06-04 20:26] Train Step 74675, Epoch 69.1, Batch Size = 256, Examples/Sec = 3861.48, Train LB = -336.097, Loss = 350.859
[2018-06-04 20:26] Train Step 74700, Epoch 69.2, Batch Size = 256, Examples/Sec = 3814.47, Train LB = -358.814, Loss = 350.033
[2018-06-04 20:26] Train Step 74725, Epoch 69.2, Batch Size = 256, Examples/Sec = 3847.43, Train LB = -367.112, Loss = 349.720
[2018-06-04 20:26] Train Step 74750, Epoch 69.2, Batch Size = 256, Examples/Sec = 3872.28, Train LB = -355.125, Loss = 350.909
[2018-06-04 20:26] Train Step 74775, Epoch 69.2, Batch Size = 256, Examples/Sec = 3869.41, Train LB = -353.222, Loss = 352.267
[2018-06-04 20:26] Train Step 74800, Epoch 69.3, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -377.671, Loss = 355.498
Performance on test set:
  Test Lower Bound = -421.346, Test Loss = 421.346
[2018-06-04 20:26] Train Step 74825, Epoch 69.3, Batch Size = 256, Examples/Sec = 3833.25, Train LB = -338.546, Loss = 354.662
[2018-06-04 20:26] Train Step 74850, Epoch 69.3, Batch Size = 256, Examples/Sec = 3800.87, Train LB = -338.803, Loss = 352.975
[2018-06-04 20:26] Train Step 74875, Epoch 69.3, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -350.833, Loss = 351.698
[2018-06-04 20:26] Train Step 74900, Epoch 69.4, Batch Size = 256, Examples/Sec = 3839.00, Train LB = -347.315, Loss = 349.617
[2018-06-04 20:26] Train Step 74925, Epoch 69.4, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -356.164, Loss = 349.329
[2018-06-04 20:26] Train Step 74950, Epoch 69.4, Batch Size = 256, Examples/Sec = 3811.11, Train LB = -333.169, Loss = 350.331
[2018-06-04 20:26] Train Step 74975, Epoch 69.4, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -359.875, Loss = 352.184
[2018-06-04 20:26] Train Step 75000, Epoch 69.4, Batch Size = 256, Examples/Sec = 3848.98, Train LB = -369.063, Loss = 355.528
Performance on test set:
  Test Lower Bound = -421.494, Test Loss = 421.494
[2018-06-04 20:26] Train Step 75025, Epoch 69.5, Batch Size = 256, Examples/Sec = 3845.35, Train LB = -331.897, Loss = 354.628
[2018-06-04 20:26] Train Step 75050, Epoch 69.5, Batch Size = 256, Examples/Sec = 3874.14, Train LB = -352.439, Loss = 352.593
[2018-06-04 20:26] Train Step 75075, Epoch 69.5, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -336.330, Loss = 351.103
[2018-06-04 20:26] Train Step 75100, Epoch 69.5, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -336.793, Loss = 349.974
[2018-06-04 20:26] Train Step 75125, Epoch 69.6, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -358.379, Loss = 349.788
[2018-06-04 20:26] Train Step 75150, Epoch 69.6, Batch Size = 256, Examples/Sec = 3845.23, Train LB = -347.241, Loss = 350.051
[2018-06-04 20:26] Train Step 75175, Epoch 69.6, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -367.372, Loss = 351.343
[2018-06-04 20:26] Train Step 75200, Epoch 69.6, Batch Size = 256, Examples/Sec = 3855.31, Train LB = -378.915, Loss = 354.515
Performance on test set:
  Test Lower Bound = -419.047, Test Loss = 419.047
[2018-06-04 20:26] Train Step 75225, Epoch 69.7, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -336.947, Loss = 353.084
[2018-06-04 20:26] Train Step 75250, Epoch 69.7, Batch Size = 256, Examples/Sec = 3860.66, Train LB = -339.343, Loss = 352.077
[2018-06-04 20:27] Train Step 75275, Epoch 69.7, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -341.703, Loss = 350.419
[2018-06-04 20:27] Train Step 75300, Epoch 69.7, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -342.300, Loss = 349.411
[2018-06-04 20:27] Train Step 75325, Epoch 69.7, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -347.912, Loss = 349.381
[2018-06-04 20:27] Train Step 75350, Epoch 69.8, Batch Size = 256, Examples/Sec = 3863.62, Train LB = -348.223, Loss = 349.761
[2018-06-04 20:27] Train Step 75375, Epoch 69.8, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -366.109, Loss = 351.310
[2018-06-04 20:27] Train Step 75400, Epoch 69.8, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -390.906, Loss = 354.886
Performance on test set:
  Test Lower Bound = -422.569, Test Loss = 422.569
[2018-06-04 20:27] Train Step 75425, Epoch 69.8, Batch Size = 256, Examples/Sec = 3860.77, Train LB = -368.978, Loss = 353.382
[2018-06-04 20:27] Train Step 75450, Epoch 69.9, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -346.811, Loss = 352.018
[2018-06-04 20:27] Train Step 75475, Epoch 69.9, Batch Size = 256, Examples/Sec = 3816.00, Train LB = -353.925, Loss = 350.493
[2018-06-04 20:27] Train Step 75500, Epoch 69.9, Batch Size = 256, Examples/Sec = 3862.17, Train LB = -347.522, Loss = 349.988
[2018-06-04 20:27] Train Step 75525, Epoch 69.9, Batch Size = 256, Examples/Sec = 3879.32, Train LB = -346.274, Loss = 348.995
[2018-06-04 20:27] Train Step 75550, Epoch 70.0, Batch Size = 256, Examples/Sec = 3852.40, Train LB = -339.595, Loss = 349.628
[2018-06-04 20:27] Train Step 75575, Epoch 70.0, Batch Size = 256, Examples/Sec = 3836.77, Train LB = -369.789, Loss = 350.798
[2018-06-04 20:27] Train Step 75600, Epoch 70.0, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -374.108, Loss = 354.800
Performance on test set:
  Test Lower Bound = -420.624, Test Loss = 420.625
[2018-06-04 20:27] Train Step 75625, Epoch 70.0, Batch Size = 256, Examples/Sec = 3866.01, Train LB = -342.925, Loss = 353.285
[2018-06-04 20:27] Train Step 75650, Epoch 70.0, Batch Size = 256, Examples/Sec = 3860.84, Train LB = -348.578, Loss = 351.538
[2018-06-04 20:27] Train Step 75675, Epoch 70.1, Batch Size = 256, Examples/Sec = 3762.78, Train LB = -341.187, Loss = 350.008
[2018-06-04 20:27] Train Step 75700, Epoch 70.1, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -341.388, Loss = 349.023
[2018-06-04 20:27] Train Step 75725, Epoch 70.1, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -347.338, Loss = 348.661
[2018-06-04 20:27] Train Step 75750, Epoch 70.1, Batch Size = 256, Examples/Sec = 3720.98, Train LB = -349.309, Loss = 349.489
[2018-06-04 20:27] Train Step 75775, Epoch 70.2, Batch Size = 256, Examples/Sec = 3863.23, Train LB = -354.848, Loss = 350.928
[2018-06-04 20:27] Train Step 75800, Epoch 70.2, Batch Size = 256, Examples/Sec = 3842.11, Train LB = -383.357, Loss = 354.528
Performance on test set:
  Test Lower Bound = -420.906, Test Loss = 420.906
[2018-06-04 20:27] Train Step 75825, Epoch 70.2, Batch Size = 256, Examples/Sec = 3847.94, Train LB = -344.717, Loss = 353.407
[2018-06-04 20:27] Train Step 75850, Epoch 70.2, Batch Size = 256, Examples/Sec = 3832.96, Train LB = -336.807, Loss = 352.035
[2018-06-04 20:27] Train Step 75875, Epoch 70.3, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -349.927, Loss = 350.533
[2018-06-04 20:27] Train Step 75900, Epoch 70.3, Batch Size = 256, Examples/Sec = 3855.71, Train LB = -340.652, Loss = 350.203
[2018-06-04 20:27] Train Step 75925, Epoch 70.3, Batch Size = 256, Examples/Sec = 3838.21, Train LB = -343.744, Loss = 349.342
[2018-06-04 20:27] Train Step 75950, Epoch 70.3, Batch Size = 256, Examples/Sec = 3843.55, Train LB = -336.219, Loss = 349.715
[2018-06-04 20:27] Train Step 75975, Epoch 70.3, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -357.507, Loss = 351.495
[2018-06-04 20:27] Train Step 76000, Epoch 70.4, Batch Size = 256, Examples/Sec = 3855.24, Train LB = -375.968, Loss = 354.881
Performance on test set:
  Test Lower Bound = -421.350, Test Loss = 421.350
[2018-06-04 20:28] Train Step 76025, Epoch 70.4, Batch Size = 256, Examples/Sec = 3847.54, Train LB = -347.425, Loss = 353.746
[2018-06-04 20:28] Train Step 76050, Epoch 70.4, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -333.908, Loss = 352.495
[2018-06-04 20:28] Train Step 76075, Epoch 70.4, Batch Size = 256, Examples/Sec = 3843.15, Train LB = -357.146, Loss = 351.223
[2018-06-04 20:28] Train Step 76100, Epoch 70.5, Batch Size = 256, Examples/Sec = 3789.45, Train LB = -351.484, Loss = 350.419
[2018-06-04 20:28] Train Step 76125, Epoch 70.5, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -357.507, Loss = 349.639
[2018-06-04 20:28] Train Step 76150, Epoch 70.5, Batch Size = 256, Examples/Sec = 3828.56, Train LB = -352.519, Loss = 349.646
[2018-06-04 20:28] Train Step 76175, Epoch 70.5, Batch Size = 256, Examples/Sec = 3857.62, Train LB = -375.622, Loss = 351.498
[2018-06-04 20:28] Train Step 76200, Epoch 70.6, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -374.192, Loss = 354.731
Performance on test set:
  Test Lower Bound = -421.751, Test Loss = 421.751
[2018-06-04 20:28] Train Step 76225, Epoch 70.6, Batch Size = 256, Examples/Sec = 3874.74, Train LB = -337.433, Loss = 353.408
[2018-06-04 20:28] Train Step 76250, Epoch 70.6, Batch Size = 256, Examples/Sec = 3837.56, Train LB = -338.160, Loss = 351.879
[2018-06-04 20:28] Train Step 76275, Epoch 70.6, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -340.476, Loss = 350.444
[2018-06-04 20:28] Train Step 76300, Epoch 70.6, Batch Size = 256, Examples/Sec = 3873.21, Train LB = -364.846, Loss = 349.392
[2018-06-04 20:28] Train Step 76325, Epoch 70.7, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -349.591, Loss = 349.516
[2018-06-04 20:28] Train Step 76350, Epoch 70.7, Batch Size = 256, Examples/Sec = 3859.62, Train LB = -347.085, Loss = 349.130
[2018-06-04 20:28] Train Step 76375, Epoch 70.7, Batch Size = 256, Examples/Sec = 3842.23, Train LB = -359.607, Loss = 350.629
[2018-06-04 20:28] Train Step 76400, Epoch 70.7, Batch Size = 256, Examples/Sec = 3815.09, Train LB = -389.568, Loss = 353.831
Performance on test set:
  Test Lower Bound = -422.994, Test Loss = 422.994
[2018-06-04 20:28] Train Step 76425, Epoch 70.8, Batch Size = 256, Examples/Sec = 3849.21, Train LB = -341.571, Loss = 353.645
[2018-06-04 20:28] Train Step 76450, Epoch 70.8, Batch Size = 256, Examples/Sec = 3857.75, Train LB = -350.642, Loss = 352.518
[2018-06-04 20:28] Train Step 76475, Epoch 70.8, Batch Size = 256, Examples/Sec = 3779.88, Train LB = -337.489, Loss = 350.757
[2018-06-04 20:28] Train Step 76500, Epoch 70.8, Batch Size = 256, Examples/Sec = 3839.29, Train LB = -334.699, Loss = 349.553
[2018-06-04 20:28] Train Step 76525, Epoch 70.9, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -342.642, Loss = 348.663
[2018-06-04 20:28] Train Step 76550, Epoch 70.9, Batch Size = 256, Examples/Sec = 3711.81, Train LB = -351.462, Loss = 348.894
[2018-06-04 20:28] Train Step 76575, Epoch 70.9, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -366.289, Loss = 351.618
[2018-06-04 20:28] Train Step 76600, Epoch 70.9, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -382.403, Loss = 354.744
Performance on test set:
  Test Lower Bound = -421.332, Test Loss = 421.333
[2018-06-04 20:28] Train Step 76625, Epoch 70.9, Batch Size = 256, Examples/Sec = 3867.25, Train LB = -332.672, Loss = 353.631
[2018-06-04 20:28] Train Step 76650, Epoch 71.0, Batch Size = 256, Examples/Sec = 3853.15, Train LB = -341.225, Loss = 351.899
[2018-06-04 20:28] Train Step 76675, Epoch 71.0, Batch Size = 256, Examples/Sec = 3848.36, Train LB = -348.050, Loss = 350.904
[2018-06-04 20:29] Train Step 76700, Epoch 71.0, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -336.812, Loss = 349.419
[2018-06-04 20:29] Train Step 76725, Epoch 71.0, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -341.911, Loss = 349.111
[2018-06-04 20:29] Train Step 76750, Epoch 71.1, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -346.246, Loss = 349.504
[2018-06-04 20:29] Train Step 76775, Epoch 71.1, Batch Size = 256, Examples/Sec = 3860.89, Train LB = -367.480, Loss = 350.723
[2018-06-04 20:29] Train Step 76800, Epoch 71.1, Batch Size = 256, Examples/Sec = 3806.18, Train LB = -380.813, Loss = 354.860
Performance on test set:
  Test Lower Bound = -421.421, Test Loss = 421.421
[2018-06-04 20:29] Train Step 76825, Epoch 71.1, Batch Size = 256, Examples/Sec = 3803.47, Train LB = -351.124, Loss = 354.067
[2018-06-04 20:29] Train Step 76850, Epoch 71.2, Batch Size = 256, Examples/Sec = 3856.17, Train LB = -354.625, Loss = 351.616
[2018-06-04 20:29] Train Step 76875, Epoch 71.2, Batch Size = 256, Examples/Sec = 3849.68, Train LB = -336.968, Loss = 349.805
[2018-06-04 20:29] Train Step 76900, Epoch 71.2, Batch Size = 256, Examples/Sec = 3867.54, Train LB = -347.219, Loss = 349.515
[2018-06-04 20:29] Train Step 76925, Epoch 71.2, Batch Size = 256, Examples/Sec = 3854.49, Train LB = -345.438, Loss = 348.850
[2018-06-04 20:29] Train Step 76950, Epoch 71.2, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -353.790, Loss = 349.129
[2018-06-04 20:29] Train Step 76975, Epoch 71.3, Batch Size = 256, Examples/Sec = 3857.29, Train LB = -351.800, Loss = 350.301
[2018-06-04 20:29] Train Step 77000, Epoch 71.3, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -379.408, Loss = 353.718
Performance on test set:
  Test Lower Bound = -421.328, Test Loss = 421.328
[2018-06-04 20:29] Train Step 77025, Epoch 71.3, Batch Size = 256, Examples/Sec = 3736.24, Train LB = -342.771, Loss = 353.299
[2018-06-04 20:29] Train Step 77050, Epoch 71.3, Batch Size = 256, Examples/Sec = 3839.00, Train LB = -347.128, Loss = 351.821
[2018-06-04 20:29] Train Step 77075, Epoch 71.4, Batch Size = 256, Examples/Sec = 3853.68, Train LB = -342.140, Loss = 350.372
[2018-06-04 20:29] Train Step 77100, Epoch 71.4, Batch Size = 256, Examples/Sec = 3743.13, Train LB = -335.815, Loss = 348.809
[2018-06-04 20:29] Train Step 77125, Epoch 71.4, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -350.173, Loss = 348.498
[2018-06-04 20:29] Train Step 77150, Epoch 71.4, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -355.345, Loss = 348.593
[2018-06-04 20:29] Train Step 77175, Epoch 71.5, Batch Size = 256, Examples/Sec = 3751.52, Train LB = -355.668, Loss = 350.613
[2018-06-04 20:29] Train Step 77200, Epoch 71.5, Batch Size = 256, Examples/Sec = 3856.06, Train LB = -376.563, Loss = 354.373
Performance on test set:
  Test Lower Bound = -420.474, Test Loss = 420.474
[2018-06-04 20:29] Train Step 77225, Epoch 71.5, Batch Size = 256, Examples/Sec = 3843.49, Train LB = -354.254, Loss = 353.860
[2018-06-04 20:29] Train Step 77250, Epoch 71.5, Batch Size = 256, Examples/Sec = 3848.29, Train LB = -328.628, Loss = 351.915
[2018-06-04 20:29] Train Step 77275, Epoch 71.6, Batch Size = 256, Examples/Sec = 3833.83, Train LB = -332.243, Loss = 349.696
[2018-06-04 20:29] Train Step 77300, Epoch 71.6, Batch Size = 256, Examples/Sec = 3839.63, Train LB = -332.300, Loss = 348.404
[2018-06-04 20:29] Train Step 77325, Epoch 71.6, Batch Size = 256, Examples/Sec = 3844.94, Train LB = -340.436, Loss = 348.049
[2018-06-04 20:29] Train Step 77350, Epoch 71.6, Batch Size = 256, Examples/Sec = 3868.77, Train LB = -347.904, Loss = 348.955
[2018-06-04 20:29] Train Step 77375, Epoch 71.6, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -345.304, Loss = 350.534
[2018-06-04 20:29] Train Step 77400, Epoch 71.7, Batch Size = 256, Examples/Sec = 3854.37, Train LB = -366.860, Loss = 354.047
Performance on test set:
  Test Lower Bound = -422.836, Test Loss = 422.836
[2018-06-04 20:30] Train Step 77425, Epoch 71.7, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -350.543, Loss = 353.184
[2018-06-04 20:30] Train Step 77450, Epoch 71.7, Batch Size = 256, Examples/Sec = 3867.93, Train LB = -329.449, Loss = 352.460
[2018-06-04 20:30] Train Step 77475, Epoch 71.7, Batch Size = 256, Examples/Sec = 3862.81, Train LB = -347.554, Loss = 350.142
[2018-06-04 20:30] Train Step 77500, Epoch 71.8, Batch Size = 256, Examples/Sec = 3869.83, Train LB = -359.137, Loss = 349.494
[2018-06-04 20:30] Train Step 77525, Epoch 71.8, Batch Size = 256, Examples/Sec = 3804.53, Train LB = -351.526, Loss = 348.861
[2018-06-04 20:30] Train Step 77550, Epoch 71.8, Batch Size = 256, Examples/Sec = 3848.70, Train LB = -360.070, Loss = 348.831
[2018-06-04 20:30] Train Step 77575, Epoch 71.8, Batch Size = 256, Examples/Sec = 3866.61, Train LB = -346.514, Loss = 350.566
[2018-06-04 20:30] Train Step 77600, Epoch 71.9, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -380.991, Loss = 354.623
Performance on test set:
  Test Lower Bound = -421.414, Test Loss = 421.414
[2018-06-04 20:30] Train Step 77625, Epoch 71.9, Batch Size = 256, Examples/Sec = 3874.49, Train LB = -354.355, Loss = 353.398
[2018-06-04 20:30] Train Step 77650, Epoch 71.9, Batch Size = 256, Examples/Sec = 3867.47, Train LB = -353.387, Loss = 351.798
[2018-06-04 20:30] Train Step 77675, Epoch 71.9, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -346.967, Loss = 350.329
[2018-06-04 20:30] Train Step 77700, Epoch 71.9, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -337.538, Loss = 349.200
[2018-06-04 20:30] Train Step 77725, Epoch 72.0, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -342.900, Loss = 348.268
[2018-06-04 20:30] Train Step 77750, Epoch 72.0, Batch Size = 256, Examples/Sec = 3797.15, Train LB = -351.924, Loss = 348.873
[2018-06-04 20:30] Train Step 77775, Epoch 72.0, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -349.158, Loss = 350.322
[2018-06-04 20:30] Train Step 77800, Epoch 72.0, Batch Size = 256, Examples/Sec = 3859.09, Train LB = -390.655, Loss = 354.225
Performance on test set:
  Test Lower Bound = -421.688, Test Loss = 421.688
[2018-06-04 20:30] Train Step 77825, Epoch 72.1, Batch Size = 256, Examples/Sec = 3818.67, Train LB = -353.202, Loss = 353.317
[2018-06-04 20:30] Train Step 77850, Epoch 72.1, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -353.229, Loss = 351.514
[2018-06-04 20:30] Train Step 77875, Epoch 72.1, Batch Size = 256, Examples/Sec = 3863.85, Train LB = -348.289, Loss = 350.177
[2018-06-04 20:30] Train Step 77900, Epoch 72.1, Batch Size = 256, Examples/Sec = 3873.22, Train LB = -333.805, Loss = 349.010
[2018-06-04 20:30] Train Step 77925, Epoch 72.2, Batch Size = 256, Examples/Sec = 3797.88, Train LB = -347.598, Loss = 348.011
[2018-06-04 20:30] Train Step 77950, Epoch 72.2, Batch Size = 256, Examples/Sec = 3863.98, Train LB = -343.183, Loss = 347.879
[2018-06-04 20:30] Train Step 77975, Epoch 72.2, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -365.759, Loss = 350.092
[2018-06-04 20:30] Train Step 78000, Epoch 72.2, Batch Size = 256, Examples/Sec = 3843.56, Train LB = -366.826, Loss = 354.243
Performance on test set:
  Test Lower Bound = -422.775, Test Loss = 422.775
[2018-06-04 20:30] Train Step 78025, Epoch 72.2, Batch Size = 256, Examples/Sec = 3854.27, Train LB = -347.324, Loss = 352.680
[2018-06-04 20:30] Train Step 78050, Epoch 72.3, Batch Size = 256, Examples/Sec = 3860.89, Train LB = -334.130, Loss = 351.557
[2018-06-04 20:30] Train Step 78075, Epoch 72.3, Batch Size = 256, Examples/Sec = 3776.75, Train LB = -344.310, Loss = 349.520
[2018-06-04 20:30] Train Step 78100, Epoch 72.3, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -341.711, Loss = 348.331
[2018-06-04 20:30] Train Step 78125, Epoch 72.3, Batch Size = 256, Examples/Sec = 3866.37, Train LB = -353.726, Loss = 348.530
[2018-06-04 20:31] Train Step 78150, Epoch 72.4, Batch Size = 256, Examples/Sec = 3712.72, Train LB = -367.796, Loss = 348.053
[2018-06-04 20:31] Train Step 78175, Epoch 72.4, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -350.447, Loss = 349.904
[2018-06-04 20:31] Train Step 78200, Epoch 72.4, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -394.433, Loss = 353.991
Performance on test set:
  Test Lower Bound = -420.568, Test Loss = 420.568
[2018-06-04 20:31] Train Step 78225, Epoch 72.4, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -355.619, Loss = 352.588
[2018-06-04 20:31] Train Step 78250, Epoch 72.5, Batch Size = 256, Examples/Sec = 3870.05, Train LB = -343.058, Loss = 351.855
[2018-06-04 20:31] Train Step 78275, Epoch 72.5, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -348.485, Loss = 350.223
[2018-06-04 20:31] Train Step 78300, Epoch 72.5, Batch Size = 256, Examples/Sec = 3808.84, Train LB = -336.662, Loss = 349.060
[2018-06-04 20:31] Train Step 78325, Epoch 72.5, Batch Size = 256, Examples/Sec = 3847.42, Train LB = -350.829, Loss = 348.678
[2018-06-04 20:31] Train Step 78350, Epoch 72.5, Batch Size = 256, Examples/Sec = 3864.15, Train LB = -354.527, Loss = 348.817
[2018-06-04 20:31] Train Step 78375, Epoch 72.6, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -359.220, Loss = 350.953
[2018-06-04 20:31] Train Step 78400, Epoch 72.6, Batch Size = 256, Examples/Sec = 3881.55, Train LB = -359.564, Loss = 354.016
Performance on test set:
  Test Lower Bound = -421.404, Test Loss = 421.404
[2018-06-04 20:31] Train Step 78425, Epoch 72.6, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -358.235, Loss = 352.955
[2018-06-04 20:31] Train Step 78450, Epoch 72.6, Batch Size = 256, Examples/Sec = 3836.41, Train LB = -328.048, Loss = 351.263
[2018-06-04 20:31] Train Step 78475, Epoch 72.7, Batch Size = 256, Examples/Sec = 3813.90, Train LB = -343.774, Loss = 350.254
[2018-06-04 20:31] Train Step 78500, Epoch 72.7, Batch Size = 256, Examples/Sec = 3856.87, Train LB = -358.114, Loss = 348.600
[2018-06-04 20:31] Train Step 78525, Epoch 72.7, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -338.083, Loss = 348.413
[2018-06-04 20:31] Train Step 78550, Epoch 72.7, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -367.077, Loss = 348.739
[2018-06-04 20:31] Train Step 78575, Epoch 72.8, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -363.483, Loss = 350.367
[2018-06-04 20:31] Train Step 78600, Epoch 72.8, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -364.205, Loss = 354.017
Performance on test set:
  Test Lower Bound = -421.534, Test Loss = 421.534
[2018-06-04 20:31] Train Step 78625, Epoch 72.8, Batch Size = 256, Examples/Sec = 3754.93, Train LB = -336.322, Loss = 353.032
[2018-06-04 20:31] Train Step 78650, Epoch 72.8, Batch Size = 256, Examples/Sec = 3872.23, Train LB = -334.408, Loss = 350.824
[2018-06-04 20:31] Train Step 78675, Epoch 72.8, Batch Size = 256, Examples/Sec = 3861.58, Train LB = -358.854, Loss = 349.431
[2018-06-04 20:31] Train Step 78700, Epoch 72.9, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -348.889, Loss = 348.624
[2018-06-04 20:31] Train Step 78725, Epoch 72.9, Batch Size = 256, Examples/Sec = 3864.45, Train LB = -338.096, Loss = 347.805
[2018-06-04 20:31] Train Step 78750, Epoch 72.9, Batch Size = 256, Examples/Sec = 3839.58, Train LB = -357.848, Loss = 349.351
[2018-06-04 20:31] Train Step 78775, Epoch 72.9, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -365.240, Loss = 350.467
[2018-06-04 20:31] Train Step 78800, Epoch 73.0, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -389.164, Loss = 354.231
Performance on test set:
  Test Lower Bound = -422.394, Test Loss = 422.394
[2018-06-04 20:32] Train Step 78825, Epoch 73.0, Batch Size = 256, Examples/Sec = 3846.91, Train LB = -348.484, Loss = 352.971
[2018-06-04 20:32] Train Step 78850, Epoch 73.0, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -328.999, Loss = 351.009
[2018-06-04 20:32] Train Step 78875, Epoch 73.0, Batch Size = 256, Examples/Sec = 3855.71, Train LB = -336.857, Loss = 350.114
[2018-06-04 20:32] Train Step 78900, Epoch 73.1, Batch Size = 256, Examples/Sec = 3855.20, Train LB = -349.571, Loss = 348.912
[2018-06-04 20:32] Train Step 78925, Epoch 73.1, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -352.218, Loss = 348.752
[2018-06-04 20:32] Train Step 78950, Epoch 73.1, Batch Size = 256, Examples/Sec = 3731.95, Train LB = -348.699, Loss = 349.420
[2018-06-04 20:32] Train Step 78975, Epoch 73.1, Batch Size = 256, Examples/Sec = 3856.89, Train LB = -357.461, Loss = 350.493
[2018-06-04 20:32] Train Step 79000, Epoch 73.1, Batch Size = 256, Examples/Sec = 3870.51, Train LB = -372.505, Loss = 354.189
Performance on test set:
  Test Lower Bound = -422.183, Test Loss = 422.183
[2018-06-04 20:32] Train Step 79025, Epoch 73.2, Batch Size = 256, Examples/Sec = 3879.67, Train LB = -349.045, Loss = 352.337
[2018-06-04 20:32] Train Step 79050, Epoch 73.2, Batch Size = 256, Examples/Sec = 3864.15, Train LB = -349.769, Loss = 351.681
[2018-06-04 20:32] Train Step 79075, Epoch 73.2, Batch Size = 256, Examples/Sec = 3843.38, Train LB = -359.490, Loss = 349.822
[2018-06-04 20:32] Train Step 79100, Epoch 73.2, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -359.094, Loss = 349.013
[2018-06-04 20:32] Train Step 79125, Epoch 73.3, Batch Size = 256, Examples/Sec = 3864.86, Train LB = -342.053, Loss = 348.759
[2018-06-04 20:32] Train Step 79150, Epoch 73.3, Batch Size = 256, Examples/Sec = 3846.10, Train LB = -357.153, Loss = 348.657
[2018-06-04 20:32] Train Step 79175, Epoch 73.3, Batch Size = 256, Examples/Sec = 3832.00, Train LB = -359.568, Loss = 350.398
[2018-06-04 20:32] Train Step 79200, Epoch 73.3, Batch Size = 256, Examples/Sec = 3851.60, Train LB = -364.570, Loss = 354.383
Performance on test set:
  Test Lower Bound = -420.643, Test Loss = 420.643
[2018-06-04 20:32] Train Step 79225, Epoch 73.4, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -348.285, Loss = 353.352
[2018-06-04 20:32] Train Step 79250, Epoch 73.4, Batch Size = 256, Examples/Sec = 3856.60, Train LB = -340.355, Loss = 351.506
[2018-06-04 20:32] Train Step 79275, Epoch 73.4, Batch Size = 256, Examples/Sec = 3838.89, Train LB = -344.265, Loss = 349.928
[2018-06-04 20:32] Train Step 79300, Epoch 73.4, Batch Size = 256, Examples/Sec = 3851.37, Train LB = -338.973, Loss = 348.596
[2018-06-04 20:32] Train Step 79325, Epoch 73.4, Batch Size = 256, Examples/Sec = 3874.80, Train LB = -341.405, Loss = 348.472
[2018-06-04 20:32] Train Step 79350, Epoch 73.5, Batch Size = 256, Examples/Sec = 3849.61, Train LB = -336.413, Loss = 348.775
[2018-06-04 20:32] Train Step 79375, Epoch 73.5, Batch Size = 256, Examples/Sec = 3843.21, Train LB = -352.695, Loss = 350.251
[2018-06-04 20:32] Train Step 79400, Epoch 73.5, Batch Size = 256, Examples/Sec = 3870.29, Train LB = -376.181, Loss = 354.026
Performance on test set:
  Test Lower Bound = -421.053, Test Loss = 421.053
[2018-06-04 20:32] Train Step 79425, Epoch 73.5, Batch Size = 256, Examples/Sec = 3827.00, Train LB = -342.350, Loss = 352.485
[2018-06-04 20:32] Train Step 79450, Epoch 73.6, Batch Size = 256, Examples/Sec = 3847.71, Train LB = -337.730, Loss = 350.668
[2018-06-04 20:32] Train Step 79475, Epoch 73.6, Batch Size = 256, Examples/Sec = 3854.26, Train LB = -333.141, Loss = 349.346
[2018-06-04 20:32] Train Step 79500, Epoch 73.6, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -349.027, Loss = 348.289
[2018-06-04 20:32] Train Step 79525, Epoch 73.6, Batch Size = 256, Examples/Sec = 3853.92, Train LB = -343.810, Loss = 347.823
[2018-06-04 20:32] Train Step 79550, Epoch 73.7, Batch Size = 256, Examples/Sec = 3863.63, Train LB = -331.945, Loss = 348.222
[2018-06-04 20:33] Train Step 79575, Epoch 73.7, Batch Size = 256, Examples/Sec = 3850.72, Train LB = -366.693, Loss = 350.204
[2018-06-04 20:33] Train Step 79600, Epoch 73.7, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -370.318, Loss = 353.270
Performance on test set:
  Test Lower Bound = -424.256, Test Loss = 424.256
[2018-06-04 20:33] Train Step 79625, Epoch 73.7, Batch Size = 256, Examples/Sec = 3846.21, Train LB = -327.416, Loss = 352.639
[2018-06-04 20:33] Train Step 79650, Epoch 73.8, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -363.914, Loss = 350.703
[2018-06-04 20:33] Train Step 79675, Epoch 73.8, Batch Size = 256, Examples/Sec = 3764.42, Train LB = -359.148, Loss = 349.579
[2018-06-04 20:33] Train Step 79700, Epoch 73.8, Batch Size = 256, Examples/Sec = 3851.82, Train LB = -331.455, Loss = 349.176
[2018-06-04 20:33] Train Step 79725, Epoch 73.8, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -357.187, Loss = 347.942
[2018-06-04 20:33] Train Step 79750, Epoch 73.8, Batch Size = 256, Examples/Sec = 3745.49, Train LB = -344.532, Loss = 348.503
[2018-06-04 20:33] Train Step 79775, Epoch 73.9, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -355.628, Loss = 349.506
[2018-06-04 20:33] Train Step 79800, Epoch 73.9, Batch Size = 256, Examples/Sec = 3869.28, Train LB = -373.682, Loss = 353.424
Performance on test set:
  Test Lower Bound = -421.819, Test Loss = 421.819
[2018-06-04 20:33] Train Step 79825, Epoch 73.9, Batch Size = 256, Examples/Sec = 3877.32, Train LB = -356.502, Loss = 351.819
[2018-06-04 20:33] Train Step 79850, Epoch 73.9, Batch Size = 256, Examples/Sec = 3848.63, Train LB = -339.411, Loss = 350.654
[2018-06-04 20:33] Train Step 79875, Epoch 74.0, Batch Size = 256, Examples/Sec = 3839.87, Train LB = -332.067, Loss = 349.528
[2018-06-04 20:33] Train Step 79900, Epoch 74.0, Batch Size = 256, Examples/Sec = 3852.53, Train LB = -359.498, Loss = 348.130
[2018-06-04 20:33] Train Step 79925, Epoch 74.0, Batch Size = 256, Examples/Sec = 3865.83, Train LB = -352.964, Loss = 348.381
[2018-06-04 20:33] Train Step 79950, Epoch 74.0, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -359.011, Loss = 348.694
[2018-06-04 20:33] Train Step 79975, Epoch 74.1, Batch Size = 256, Examples/Sec = 3855.60, Train LB = -344.060, Loss = 349.660
[2018-06-04 20:33] Train Step 80000, Epoch 74.1, Batch Size = 256, Examples/Sec = 3843.55, Train LB = -378.534, Loss = 353.230
Performance on test set:
  Test Lower Bound = -422.242, Test Loss = 422.242
[2018-06-04 20:33] Train Step 80025, Epoch 74.1, Batch Size = 256, Examples/Sec = 3871.39, Train LB = -327.292, Loss = 352.329
[2018-06-04 20:33] Train Step 80050, Epoch 74.1, Batch Size = 256, Examples/Sec = 3861.99, Train LB = -349.626, Loss = 351.102
[2018-06-04 20:33] Train Step 80075, Epoch 74.1, Batch Size = 256, Examples/Sec = 3847.49, Train LB = -347.375, Loss = 349.542
[2018-06-04 20:33] Train Step 80100, Epoch 74.2, Batch Size = 256, Examples/Sec = 3843.21, Train LB = -326.513, Loss = 348.654
[2018-06-04 20:33] Train Step 80125, Epoch 74.2, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -345.422, Loss = 347.929
[2018-06-04 20:33] Train Step 80150, Epoch 74.2, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -350.053, Loss = 348.748
[2018-06-04 20:33] Train Step 80175, Epoch 74.2, Batch Size = 256, Examples/Sec = 3857.51, Train LB = -371.876, Loss = 350.564
[2018-06-04 20:33] Train Step 80200, Epoch 74.3, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -375.660, Loss = 353.550
Performance on test set:
  Test Lower Bound = -422.659, Test Loss = 422.659
[2018-06-04 20:33] Train Step 80225, Epoch 74.3, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -352.315, Loss = 352.532
[2018-06-04 20:33] Train Step 80250, Epoch 74.3, Batch Size = 256, Examples/Sec = 3863.10, Train LB = -345.667, Loss = 350.881
[2018-06-04 20:34] Train Step 80275, Epoch 74.3, Batch Size = 256, Examples/Sec = 3870.22, Train LB = -323.889, Loss = 349.476
[2018-06-04 20:34] Train Step 80300, Epoch 74.4, Batch Size = 256, Examples/Sec = 3862.63, Train LB = -340.052, Loss = 347.872
[2018-06-04 20:34] Train Step 80325, Epoch 74.4, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -356.308, Loss = 347.818
[2018-06-04 20:34] Train Step 80350, Epoch 74.4, Batch Size = 256, Examples/Sec = 3879.85, Train LB = -350.404, Loss = 348.395
[2018-06-04 20:34] Train Step 80375, Epoch 74.4, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -366.542, Loss = 350.086
[2018-06-04 20:34] Train Step 80400, Epoch 74.4, Batch Size = 256, Examples/Sec = 3851.30, Train LB = -376.660, Loss = 353.493
Performance on test set:
  Test Lower Bound = -423.544, Test Loss = 423.544
[2018-06-04 20:34] Train Step 80425, Epoch 74.5, Batch Size = 256, Examples/Sec = 3856.46, Train LB = -335.350, Loss = 352.503
[2018-06-04 20:34] Train Step 80450, Epoch 74.5, Batch Size = 256, Examples/Sec = 3846.50, Train LB = -346.930, Loss = 350.426
[2018-06-04 20:34] Train Step 80475, Epoch 74.5, Batch Size = 256, Examples/Sec = 3776.21, Train LB = -336.718, Loss = 349.303
[2018-06-04 20:34] Train Step 80500, Epoch 74.5, Batch Size = 256, Examples/Sec = 3865.90, Train LB = -347.746, Loss = 348.716
[2018-06-04 20:34] Train Step 80525, Epoch 74.6, Batch Size = 256, Examples/Sec = 3814.24, Train LB = -345.327, Loss = 347.770
[2018-06-04 20:34] Train Step 80550, Epoch 74.6, Batch Size = 256, Examples/Sec = 3742.53, Train LB = -343.020, Loss = 348.247
[2018-06-04 20:34] Train Step 80575, Epoch 74.6, Batch Size = 256, Examples/Sec = 3860.35, Train LB = -358.474, Loss = 350.158
[2018-06-04 20:34] Train Step 80600, Epoch 74.6, Batch Size = 256, Examples/Sec = 3835.89, Train LB = -369.386, Loss = 353.492
Performance on test set:
  Test Lower Bound = -423.032, Test Loss = 423.032
[2018-06-04 20:34] Train Step 80625, Epoch 74.7, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -345.157, Loss = 352.285
[2018-06-04 20:34] Train Step 80650, Epoch 74.7, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -351.117, Loss = 350.485
[2018-06-04 20:34] Train Step 80675, Epoch 74.7, Batch Size = 256, Examples/Sec = 3859.27, Train LB = -334.782, Loss = 348.865
[2018-06-04 20:34] Train Step 80700, Epoch 74.7, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -343.184, Loss = 348.385
[2018-06-04 20:34] Train Step 80725, Epoch 74.7, Batch Size = 256, Examples/Sec = 3872.34, Train LB = -351.603, Loss = 347.324
[2018-06-04 20:34] Train Step 80750, Epoch 74.8, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -347.016, Loss = 347.930
[2018-06-04 20:34] Train Step 80775, Epoch 74.8, Batch Size = 256, Examples/Sec = 3856.47, Train LB = -357.385, Loss = 349.046
[2018-06-04 20:34] Train Step 80800, Epoch 74.8, Batch Size = 256, Examples/Sec = 3879.73, Train LB = -387.028, Loss = 352.785
Performance on test set:
  Test Lower Bound = -422.955, Test Loss = 422.954
[2018-06-04 20:34] Train Step 80825, Epoch 74.8, Batch Size = 256, Examples/Sec = 3850.03, Train LB = -353.516, Loss = 351.743
[2018-06-04 20:34] Train Step 80850, Epoch 74.9, Batch Size = 256, Examples/Sec = 3838.77, Train LB = -336.040, Loss = 350.592
[2018-06-04 20:34] Train Step 80875, Epoch 74.9, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -345.551, Loss = 348.818
[2018-06-04 20:34] Train Step 80900, Epoch 74.9, Batch Size = 256, Examples/Sec = 3840.50, Train LB = -382.211, Loss = 347.383
[2018-06-04 20:34] Train Step 80925, Epoch 74.9, Batch Size = 256, Examples/Sec = 3823.46, Train LB = -342.001, Loss = 347.680
[2018-06-04 20:34] Train Step 80950, Epoch 75.0, Batch Size = 256, Examples/Sec = 3850.77, Train LB = -361.694, Loss = 347.489
[2018-06-04 20:34] Train Step 80975, Epoch 75.0, Batch Size = 256, Examples/Sec = 3853.05, Train LB = -364.513, Loss = 349.469
[2018-06-04 20:35] Train Step 81000, Epoch 75.0, Batch Size = 256, Examples/Sec = 3846.10, Train LB = -369.366, Loss = 353.442
Performance on test set:
  Test Lower Bound = -421.567, Test Loss = 421.567
[2018-06-04 20:35] Train Step 81025, Epoch 75.0, Batch Size = 256, Examples/Sec = 3742.97, Train LB = -322.707, Loss = 352.484
[2018-06-04 20:35] Train Step 81050, Epoch 75.0, Batch Size = 256, Examples/Sec = 3846.15, Train LB = -353.879, Loss = 350.169
[2018-06-04 20:35] Train Step 81075, Epoch 75.1, Batch Size = 256, Examples/Sec = 3842.11, Train LB = -344.643, Loss = 349.567
[2018-06-04 20:35] Train Step 81100, Epoch 75.1, Batch Size = 256, Examples/Sec = 3735.75, Train LB = -344.328, Loss = 348.499
[2018-06-04 20:35] Train Step 81125, Epoch 75.1, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -346.176, Loss = 347.732
[2018-06-04 20:35] Train Step 81150, Epoch 75.1, Batch Size = 256, Examples/Sec = 3846.79, Train LB = -360.497, Loss = 348.405
[2018-06-04 20:35] Train Step 81175, Epoch 75.2, Batch Size = 256, Examples/Sec = 3819.24, Train LB = -368.884, Loss = 349.531
[2018-06-04 20:35] Train Step 81200, Epoch 75.2, Batch Size = 256, Examples/Sec = 3837.27, Train LB = -379.471, Loss = 353.852
Performance on test set:
  Test Lower Bound = -421.102, Test Loss = 421.102
[2018-06-04 20:35] Train Step 81225, Epoch 75.2, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -336.094, Loss = 352.057
[2018-06-04 20:35] Train Step 81250, Epoch 75.2, Batch Size = 256, Examples/Sec = 3858.62, Train LB = -351.811, Loss = 350.585
[2018-06-04 20:35] Train Step 81275, Epoch 75.3, Batch Size = 256, Examples/Sec = 3839.06, Train LB = -343.731, Loss = 349.449
[2018-06-04 20:35] Train Step 81300, Epoch 75.3, Batch Size = 256, Examples/Sec = 3837.67, Train LB = -353.553, Loss = 348.766
[2018-06-04 20:35] Train Step 81325, Epoch 75.3, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -359.257, Loss = 347.741
[2018-06-04 20:35] Train Step 81350, Epoch 75.3, Batch Size = 256, Examples/Sec = 3853.68, Train LB = -354.738, Loss = 348.556
[2018-06-04 20:35] Train Step 81375, Epoch 75.3, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -357.755, Loss = 349.733
[2018-06-04 20:35] Train Step 81400, Epoch 75.4, Batch Size = 256, Examples/Sec = 3835.26, Train LB = -386.697, Loss = 353.954
Performance on test set:
  Test Lower Bound = -421.134, Test Loss = 421.134
[2018-06-04 20:35] Train Step 81425, Epoch 75.4, Batch Size = 256, Examples/Sec = 3834.52, Train LB = -341.436, Loss = 352.892
[2018-06-04 20:35] Train Step 81450, Epoch 75.4, Batch Size = 256, Examples/Sec = 3851.26, Train LB = -347.877, Loss = 351.761
[2018-06-04 20:35] Train Step 81475, Epoch 75.4, Batch Size = 256, Examples/Sec = 3859.04, Train LB = -359.963, Loss = 350.073
[2018-06-04 20:35] Train Step 81500, Epoch 75.5, Batch Size = 256, Examples/Sec = 3852.40, Train LB = -328.763, Loss = 349.514
[2018-06-04 20:35] Train Step 81525, Epoch 75.5, Batch Size = 256, Examples/Sec = 3862.74, Train LB = -335.147, Loss = 348.234
[2018-06-04 20:35] Train Step 81550, Epoch 75.5, Batch Size = 256, Examples/Sec = 3853.73, Train LB = -353.714, Loss = 348.676
[2018-06-04 20:35] Train Step 81575, Epoch 75.5, Batch Size = 256, Examples/Sec = 3855.20, Train LB = -367.513, Loss = 349.928
[2018-06-04 20:35] Train Step 81600, Epoch 75.6, Batch Size = 256, Examples/Sec = 3864.20, Train LB = -364.154, Loss = 353.615
Performance on test set:
  Test Lower Bound = -422.720, Test Loss = 422.720
[2018-06-04 20:35] Train Step 81625, Epoch 75.6, Batch Size = 256, Examples/Sec = 3866.19, Train LB = -340.644, Loss = 352.221
[2018-06-04 20:35] Train Step 81650, Epoch 75.6, Batch Size = 256, Examples/Sec = 3812.48, Train LB = -338.909, Loss = 350.362
[2018-06-04 20:35] Train Step 81675, Epoch 75.6, Batch Size = 256, Examples/Sec = 3845.28, Train LB = -320.277, Loss = 349.021
[2018-06-04 20:36] Train Step 81700, Epoch 75.6, Batch Size = 256, Examples/Sec = 3817.88, Train LB = -361.126, Loss = 347.220
[2018-06-04 20:36] Train Step 81725, Epoch 75.7, Batch Size = 256, Examples/Sec = 3870.47, Train LB = -359.799, Loss = 347.124
[2018-06-04 20:36] Train Step 81750, Epoch 75.7, Batch Size = 256, Examples/Sec = 3847.36, Train LB = -354.865, Loss = 347.614
[2018-06-04 20:36] Train Step 81775, Epoch 75.7, Batch Size = 256, Examples/Sec = 3811.34, Train LB = -356.521, Loss = 349.137
[2018-06-04 20:36] Train Step 81800, Epoch 75.7, Batch Size = 256, Examples/Sec = 3874.16, Train LB = -379.032, Loss = 353.116
Performance on test set:
  Test Lower Bound = -423.437, Test Loss = 423.437
[2018-06-04 20:36] Train Step 81825, Epoch 75.8, Batch Size = 256, Examples/Sec = 3740.56, Train LB = -353.536, Loss = 352.487
[2018-06-04 20:36] Train Step 81850, Epoch 75.8, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -340.526, Loss = 350.673
[2018-06-04 20:36] Train Step 81875, Epoch 75.8, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -348.778, Loss = 348.794
[2018-06-04 20:36] Train Step 81900, Epoch 75.8, Batch Size = 256, Examples/Sec = 3739.36, Train LB = -356.398, Loss = 347.701
[2018-06-04 20:36] Train Step 81925, Epoch 75.9, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -344.477, Loss = 347.004
[2018-06-04 20:36] Train Step 81950, Epoch 75.9, Batch Size = 256, Examples/Sec = 3843.67, Train LB = -345.321, Loss = 347.763
[2018-06-04 20:36] Train Step 81975, Epoch 75.9, Batch Size = 256, Examples/Sec = 3810.49, Train LB = -361.140, Loss = 349.668
[2018-06-04 20:36] Train Step 82000, Epoch 75.9, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -360.516, Loss = 352.644
Performance on test set:
  Test Lower Bound = -424.783, Test Loss = 424.783
[2018-06-04 20:36] Train Step 82025, Epoch 75.9, Batch Size = 256, Examples/Sec = 3867.24, Train LB = -368.329, Loss = 351.263
[2018-06-04 20:36] Train Step 82050, Epoch 76.0, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -337.182, Loss = 350.041
[2018-06-04 20:36] Train Step 82075, Epoch 76.0, Batch Size = 256, Examples/Sec = 3835.50, Train LB = -338.623, Loss = 348.827
[2018-06-04 20:36] Train Step 82100, Epoch 76.0, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -359.355, Loss = 347.725
[2018-06-04 20:36] Train Step 82125, Epoch 76.0, Batch Size = 256, Examples/Sec = 3849.68, Train LB = -338.866, Loss = 347.157
[2018-06-04 20:36] Train Step 82150, Epoch 76.1, Batch Size = 256, Examples/Sec = 3851.01, Train LB = -341.383, Loss = 347.355
[2018-06-04 20:36] Train Step 82175, Epoch 76.1, Batch Size = 256, Examples/Sec = 3812.87, Train LB = -363.156, Loss = 348.473
[2018-06-04 20:36] Train Step 82200, Epoch 76.1, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -396.692, Loss = 351.910
Performance on test set:
  Test Lower Bound = -421.929, Test Loss = 421.929
[2018-06-04 20:36] Train Step 82225, Epoch 76.1, Batch Size = 256, Examples/Sec = 3835.27, Train LB = -358.389, Loss = 351.523
[2018-06-04 20:36] Train Step 82250, Epoch 76.2, Batch Size = 256, Examples/Sec = 3845.17, Train LB = -352.243, Loss = 350.200
[2018-06-04 20:36] Train Step 82275, Epoch 76.2, Batch Size = 256, Examples/Sec = 3816.68, Train LB = -337.287, Loss = 348.159
[2018-06-04 20:36] Train Step 82300, Epoch 76.2, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -358.580, Loss = 347.372
[2018-06-04 20:36] Train Step 82325, Epoch 76.2, Batch Size = 256, Examples/Sec = 3857.39, Train LB = -342.747, Loss = 346.187
[2018-06-04 20:36] Train Step 82350, Epoch 76.2, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -358.039, Loss = 347.170
[2018-06-04 20:36] Train Step 82375, Epoch 76.3, Batch Size = 256, Examples/Sec = 3880.91, Train LB = -351.667, Loss = 349.518
[2018-06-04 20:36] Train Step 82400, Epoch 76.3, Batch Size = 256, Examples/Sec = 3867.49, Train LB = -378.325, Loss = 353.191
Performance on test set:
  Test Lower Bound = -423.413, Test Loss = 423.413
[2018-06-04 20:37] Train Step 82425, Epoch 76.3, Batch Size = 256, Examples/Sec = 3864.15, Train LB = -348.441, Loss = 351.983
[2018-06-04 20:37] Train Step 82450, Epoch 76.3, Batch Size = 256, Examples/Sec = 3842.34, Train LB = -362.247, Loss = 350.250
[2018-06-04 20:37] Train Step 82475, Epoch 76.4, Batch Size = 256, Examples/Sec = 3850.61, Train LB = -350.178, Loss = 349.435
[2018-06-04 20:37] Train Step 82500, Epoch 76.4, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -329.803, Loss = 348.174
[2018-06-04 20:37] Train Step 82525, Epoch 76.4, Batch Size = 256, Examples/Sec = 3863.98, Train LB = -328.483, Loss = 347.184
[2018-06-04 20:37] Train Step 82550, Epoch 76.4, Batch Size = 256, Examples/Sec = 3873.79, Train LB = -342.374, Loss = 347.165
[2018-06-04 20:37] Train Step 82575, Epoch 76.5, Batch Size = 256, Examples/Sec = 3842.11, Train LB = -361.096, Loss = 348.926
[2018-06-04 20:37] Train Step 82600, Epoch 76.5, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -383.490, Loss = 352.747
Performance on test set:
  Test Lower Bound = -422.832, Test Loss = 422.832
[2018-06-04 20:37] Train Step 82625, Epoch 76.5, Batch Size = 256, Examples/Sec = 3737.67, Train LB = -338.422, Loss = 351.647
[2018-06-04 20:37] Train Step 82650, Epoch 76.5, Batch Size = 256, Examples/Sec = 3859.13, Train LB = -356.144, Loss = 349.971
[2018-06-04 20:37] Train Step 82675, Epoch 76.6, Batch Size = 256, Examples/Sec = 3799.75, Train LB = -350.490, Loss = 348.695
[2018-06-04 20:37] Train Step 82700, Epoch 76.6, Batch Size = 256, Examples/Sec = 3744.10, Train LB = -341.237, Loss = 347.252
[2018-06-04 20:37] Train Step 82725, Epoch 76.6, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -356.606, Loss = 347.274
[2018-06-04 20:37] Train Step 82750, Epoch 76.6, Batch Size = 256, Examples/Sec = 3851.95, Train LB = -347.641, Loss = 347.819
[2018-06-04 20:37] Train Step 82775, Epoch 76.6, Batch Size = 256, Examples/Sec = 3806.25, Train LB = -373.303, Loss = 348.841
[2018-06-04 20:37] Train Step 82800, Epoch 76.7, Batch Size = 256, Examples/Sec = 3863.85, Train LB = -375.744, Loss = 352.519
Performance on test set:
  Test Lower Bound = -422.983, Test Loss = 422.983
[2018-06-04 20:37] Train Step 82825, Epoch 76.7, Batch Size = 256, Examples/Sec = 3845.99, Train LB = -337.158, Loss = 351.577
[2018-06-04 20:37] Train Step 82850, Epoch 76.7, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -335.968, Loss = 350.190
[2018-06-04 20:37] Train Step 82875, Epoch 76.7, Batch Size = 256, Examples/Sec = 3801.72, Train LB = -363.840, Loss = 347.890
[2018-06-04 20:37] Train Step 82900, Epoch 76.8, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -334.379, Loss = 346.368
[2018-06-04 20:37] Train Step 82925, Epoch 76.8, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -359.567, Loss = 346.248
[2018-06-04 20:37] Train Step 82950, Epoch 76.8, Batch Size = 256, Examples/Sec = 3852.62, Train LB = -358.372, Loss = 347.049
[2018-06-04 20:37] Train Step 82975, Epoch 76.8, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -378.101, Loss = 348.436
[2018-06-04 20:37] Train Step 83000, Epoch 76.9, Batch Size = 256, Examples/Sec = 3846.46, Train LB = -382.683, Loss = 352.086
Performance on test set:
  Test Lower Bound = -422.378, Test Loss = 422.378
[2018-06-04 20:37] Train Step 83025, Epoch 76.9, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -332.066, Loss = 350.931
[2018-06-04 20:37] Train Step 83050, Epoch 76.9, Batch Size = 256, Examples/Sec = 3861.87, Train LB = -353.147, Loss = 349.845
[2018-06-04 20:37] Train Step 83075, Epoch 76.9, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -340.945, Loss = 348.348
[2018-06-04 20:37] Train Step 83100, Epoch 76.9, Batch Size = 256, Examples/Sec = 3837.79, Train LB = -339.066, Loss = 347.157
[2018-06-04 20:38] Train Step 83125, Epoch 77.0, Batch Size = 256, Examples/Sec = 3831.19, Train LB = -350.434, Loss = 347.336
[2018-06-04 20:38] Train Step 83150, Epoch 77.0, Batch Size = 256, Examples/Sec = 3855.18, Train LB = -354.860, Loss = 347.808
[2018-06-04 20:38] Train Step 83175, Epoch 77.0, Batch Size = 256, Examples/Sec = 3839.63, Train LB = -336.379, Loss = 349.807
[2018-06-04 20:38] Train Step 83200, Epoch 77.0, Batch Size = 256, Examples/Sec = 3798.27, Train LB = -362.604, Loss = 353.001
Performance on test set:
  Test Lower Bound = -423.287, Test Loss = 423.287
[2018-06-04 20:38] Train Step 83225, Epoch 77.1, Batch Size = 256, Examples/Sec = 3873.79, Train LB = -354.785, Loss = 351.704
[2018-06-04 20:38] Train Step 83250, Epoch 77.1, Batch Size = 256, Examples/Sec = 3854.33, Train LB = -336.964, Loss = 349.644
[2018-06-04 20:38] Train Step 83275, Epoch 77.1, Batch Size = 256, Examples/Sec = 3839.00, Train LB = -341.732, Loss = 348.002
[2018-06-04 20:38] Train Step 83300, Epoch 77.1, Batch Size = 256, Examples/Sec = 3821.13, Train LB = -353.439, Loss = 346.782
[2018-06-04 20:38] Train Step 83325, Epoch 77.2, Batch Size = 256, Examples/Sec = 3849.28, Train LB = -353.268, Loss = 346.929
[2018-06-04 20:38] Train Step 83350, Epoch 77.2, Batch Size = 256, Examples/Sec = 3874.56, Train LB = -349.302, Loss = 347.641
[2018-06-04 20:38] Train Step 83375, Epoch 77.2, Batch Size = 256, Examples/Sec = 3851.30, Train LB = -356.280, Loss = 349.065
[2018-06-04 20:38] Train Step 83400, Epoch 77.2, Batch Size = 256, Examples/Sec = 3843.61, Train LB = -388.488, Loss = 352.843
Performance on test set:
  Test Lower Bound = -421.934, Test Loss = 421.934
[2018-06-04 20:38] Train Step 83425, Epoch 77.2, Batch Size = 256, Examples/Sec = 3735.64, Train LB = -343.072, Loss = 351.410
[2018-06-04 20:38] Train Step 83450, Epoch 77.3, Batch Size = 256, Examples/Sec = 3841.13, Train LB = -353.198, Loss = 350.064
[2018-06-04 20:38] Train Step 83475, Epoch 77.3, Batch Size = 256, Examples/Sec = 3872.21, Train LB = -337.043, Loss = 348.688
[2018-06-04 20:38] Train Step 83500, Epoch 77.3, Batch Size = 256, Examples/Sec = 3717.79, Train LB = -345.689, Loss = 347.186
[2018-06-04 20:38] Train Step 83525, Epoch 77.3, Batch Size = 256, Examples/Sec = 3861.77, Train LB = -343.688, Loss = 346.895
[2018-06-04 20:38] Train Step 83550, Epoch 77.4, Batch Size = 256, Examples/Sec = 3868.94, Train LB = -342.130, Loss = 347.265
[2018-06-04 20:38] Train Step 83575, Epoch 77.4, Batch Size = 256, Examples/Sec = 3816.98, Train LB = -368.075, Loss = 348.644
[2018-06-04 20:38] Train Step 83600, Epoch 77.4, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -380.892, Loss = 352.241
Performance on test set:
  Test Lower Bound = -423.290, Test Loss = 423.290
[2018-06-04 20:38] Train Step 83625, Epoch 77.4, Batch Size = 256, Examples/Sec = 3869.05, Train LB = -331.038, Loss = 350.640
[2018-06-04 20:38] Train Step 83650, Epoch 77.5, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -335.531, Loss = 349.188
[2018-06-04 20:38] Train Step 83675, Epoch 77.5, Batch Size = 256, Examples/Sec = 3843.91, Train LB = -350.436, Loss = 348.011
[2018-06-04 20:38] Train Step 83700, Epoch 77.5, Batch Size = 256, Examples/Sec = 3812.02, Train LB = -343.499, Loss = 347.148
[2018-06-04 20:38] Train Step 83725, Epoch 77.5, Batch Size = 256, Examples/Sec = 3860.19, Train LB = -347.065, Loss = 346.566
[2018-06-04 20:38] Train Step 83750, Epoch 77.5, Batch Size = 256, Examples/Sec = 3844.77, Train LB = -345.834, Loss = 346.798
[2018-06-04 20:38] Train Step 83775, Epoch 77.6, Batch Size = 256, Examples/Sec = 3858.62, Train LB = -372.892, Loss = 348.462
[2018-06-04 20:38] Train Step 83800, Epoch 77.6, Batch Size = 256, Examples/Sec = 3857.34, Train LB = -364.335, Loss = 352.997
Performance on test set:
  Test Lower Bound = -423.050, Test Loss = 423.050
[2018-06-04 20:39] Train Step 83825, Epoch 77.6, Batch Size = 256, Examples/Sec = 3866.37, Train LB = -331.300, Loss = 351.273
[2018-06-04 20:39] Train Step 83850, Epoch 77.6, Batch Size = 256, Examples/Sec = 3796.86, Train LB = -333.376, Loss = 349.780
[2018-06-04 20:39] Train Step 83875, Epoch 77.7, Batch Size = 256, Examples/Sec = 3870.53, Train LB = -343.143, Loss = 348.126
[2018-06-04 20:39] Train Step 83900, Epoch 77.7, Batch Size = 256, Examples/Sec = 3844.25, Train LB = -356.530, Loss = 347.251
[2018-06-04 20:39] Train Step 83925, Epoch 77.7, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -350.735, Loss = 347.489
[2018-06-04 20:39] Train Step 83950, Epoch 77.7, Batch Size = 256, Examples/Sec = 3848.40, Train LB = -362.416, Loss = 347.656
[2018-06-04 20:39] Train Step 83975, Epoch 77.8, Batch Size = 256, Examples/Sec = 3831.64, Train LB = -347.507, Loss = 348.569
[2018-06-04 20:39] Train Step 84000, Epoch 77.8, Batch Size = 256, Examples/Sec = 3873.97, Train LB = -379.598, Loss = 352.709
Performance on test set:
  Test Lower Bound = -423.702, Test Loss = 423.702
[2018-06-04 20:39] Train Step 84025, Epoch 77.8, Batch Size = 256, Examples/Sec = 3814.34, Train LB = -333.381, Loss = 351.318
[2018-06-04 20:39] Train Step 84050, Epoch 77.8, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -336.235, Loss = 349.197
[2018-06-04 20:39] Train Step 84075, Epoch 77.8, Batch Size = 256, Examples/Sec = 3860.53, Train LB = -346.380, Loss = 348.192
[2018-06-04 20:39] Train Step 84100, Epoch 77.9, Batch Size = 256, Examples/Sec = 3865.50, Train LB = -337.614, Loss = 347.453
[2018-06-04 20:39] Train Step 84125, Epoch 77.9, Batch Size = 256, Examples/Sec = 3865.97, Train LB = -345.922, Loss = 346.742
[2018-06-04 20:39] Train Step 84150, Epoch 77.9, Batch Size = 256, Examples/Sec = 3860.66, Train LB = -357.671, Loss = 346.658
[2018-06-04 20:39] Train Step 84175, Epoch 77.9, Batch Size = 256, Examples/Sec = 3858.22, Train LB = -374.254, Loss = 348.159
[2018-06-04 20:39] Train Step 84200, Epoch 78.0, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -383.148, Loss = 352.181
Performance on test set:
  Test Lower Bound = -423.821, Test Loss = 423.821
[2018-06-04 20:39] Train Step 84225, Epoch 78.0, Batch Size = 256, Examples/Sec = 3738.54, Train LB = -343.203, Loss = 351.038
[2018-06-04 20:39] Train Step 84250, Epoch 78.0, Batch Size = 256, Examples/Sec = 3835.83, Train LB = -337.468, Loss = 350.163
[2018-06-04 20:39] Train Step 84275, Epoch 78.0, Batch Size = 256, Examples/Sec = 3862.17, Train LB = -345.368, Loss = 348.048
[2018-06-04 20:39] Train Step 84300, Epoch 78.1, Batch Size = 256, Examples/Sec = 3733.35, Train LB = -322.188, Loss = 346.339
[2018-06-04 20:39] Train Step 84325, Epoch 78.1, Batch Size = 256, Examples/Sec = 3851.99, Train LB = -341.336, Loss = 346.019
[2018-06-04 20:39] Train Step 84350, Epoch 78.1, Batch Size = 256, Examples/Sec = 3844.14, Train LB = -343.691, Loss = 346.333
[2018-06-04 20:39] Train Step 84375, Epoch 78.1, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -354.418, Loss = 347.735
[2018-06-04 20:39] Train Step 84400, Epoch 78.1, Batch Size = 256, Examples/Sec = 3849.34, Train LB = -367.520, Loss = 352.072
Performance on test set:
  Test Lower Bound = -424.328, Test Loss = 424.328
[2018-06-04 20:39] Train Step 84425, Epoch 78.2, Batch Size = 256, Examples/Sec = 3815.88, Train LB = -333.060, Loss = 351.066
[2018-06-04 20:39] Train Step 84450, Epoch 78.2, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -342.017, Loss = 349.369
[2018-06-04 20:39] Train Step 84475, Epoch 78.2, Batch Size = 256, Examples/Sec = 3857.33, Train LB = -322.485, Loss = 348.510
[2018-06-04 20:39] Train Step 84500, Epoch 78.2, Batch Size = 256, Examples/Sec = 3849.50, Train LB = -347.606, Loss = 346.863
[2018-06-04 20:39] Train Step 84525, Epoch 78.3, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -339.835, Loss = 346.408
[2018-06-04 20:39] Train Step 84550, Epoch 78.3, Batch Size = 256, Examples/Sec = 3847.43, Train LB = -355.423, Loss = 346.819
[2018-06-04 20:40] Train Step 84575, Epoch 78.3, Batch Size = 256, Examples/Sec = 3842.99, Train LB = -363.776, Loss = 348.940
[2018-06-04 20:40] Train Step 84600, Epoch 78.3, Batch Size = 256, Examples/Sec = 3862.81, Train LB = -380.900, Loss = 352.658
Performance on test set:
  Test Lower Bound = -424.234, Test Loss = 424.234
[2018-06-04 20:40] Train Step 84625, Epoch 78.4, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -348.422, Loss = 351.591
[2018-06-04 20:40] Train Step 84650, Epoch 78.4, Batch Size = 256, Examples/Sec = 3811.34, Train LB = -351.339, Loss = 350.385
[2018-06-04 20:40] Train Step 84675, Epoch 78.4, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -334.259, Loss = 348.341
[2018-06-04 20:40] Train Step 84700, Epoch 78.4, Batch Size = 256, Examples/Sec = 3870.18, Train LB = -344.252, Loss = 346.631
[2018-06-04 20:40] Train Step 84725, Epoch 78.4, Batch Size = 256, Examples/Sec = 3849.81, Train LB = -346.308, Loss = 346.164
[2018-06-04 20:40] Train Step 84750, Epoch 78.5, Batch Size = 256, Examples/Sec = 3840.50, Train LB = -346.295, Loss = 346.945
[2018-06-04 20:40] Train Step 84775, Epoch 78.5, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -372.525, Loss = 348.729
[2018-06-04 20:40] Train Step 84800, Epoch 78.5, Batch Size = 256, Examples/Sec = 3846.10, Train LB = -360.972, Loss = 352.692
Performance on test set:
  Test Lower Bound = -423.622, Test Loss = 423.622
[2018-06-04 20:40] Train Step 84825, Epoch 78.5, Batch Size = 256, Examples/Sec = 3872.58, Train LB = -327.424, Loss = 351.596
[2018-06-04 20:40] Train Step 84850, Epoch 78.6, Batch Size = 256, Examples/Sec = 3875.08, Train LB = -336.061, Loss = 349.847
[2018-06-04 20:40] Train Step 84875, Epoch 78.6, Batch Size = 256, Examples/Sec = 3807.65, Train LB = -349.086, Loss = 347.581
[2018-06-04 20:40] Train Step 84900, Epoch 78.6, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -345.793, Loss = 346.599
[2018-06-04 20:40] Train Step 84925, Epoch 78.6, Batch Size = 256, Examples/Sec = 3836.30, Train LB = -338.244, Loss = 346.270
[2018-06-04 20:40] Train Step 84950, Epoch 78.7, Batch Size = 256, Examples/Sec = 3873.92, Train LB = -348.412, Loss = 346.105
[2018-06-04 20:40] Train Step 84975, Epoch 78.7, Batch Size = 256, Examples/Sec = 3839.52, Train LB = -362.384, Loss = 348.262
[2018-06-04 20:40] Train Step 85000, Epoch 78.7, Batch Size = 256, Examples/Sec = 3822.66, Train LB = -379.416, Loss = 352.003
Performance on test set:
  Test Lower Bound = -424.682, Test Loss = 424.682
[2018-06-04 20:40] Train Step 85025, Epoch 78.7, Batch Size = 256, Examples/Sec = 3727.16, Train LB = -334.022, Loss = 350.955
[2018-06-04 20:40] Train Step 85050, Epoch 78.8, Batch Size = 256, Examples/Sec = 3873.79, Train LB = -332.273, Loss = 349.188
[2018-06-04 20:40] Train Step 85075, Epoch 78.8, Batch Size = 256, Examples/Sec = 3871.98, Train LB = -356.121, Loss = 347.435
[2018-06-04 20:40] Train Step 85100, Epoch 78.8, Batch Size = 256, Examples/Sec = 3741.87, Train LB = -352.009, Loss = 346.422
[2018-06-04 20:40] Train Step 85125, Epoch 78.8, Batch Size = 256, Examples/Sec = 3866.48, Train LB = -348.181, Loss = 346.457
[2018-06-04 20:40] Train Step 85150, Epoch 78.8, Batch Size = 256, Examples/Sec = 3852.22, Train LB = -326.403, Loss = 346.833
[2018-06-04 20:40] Train Step 85175, Epoch 78.9, Batch Size = 256, Examples/Sec = 3813.38, Train LB = -361.704, Loss = 348.363
[2018-06-04 20:40] Train Step 85200, Epoch 78.9, Batch Size = 256, Examples/Sec = 3860.01, Train LB = -371.977, Loss = 352.037
Performance on test set:
  Test Lower Bound = -426.654, Test Loss = 426.654
[2018-06-04 20:40] Train Step 85225, Epoch 78.9, Batch Size = 256, Examples/Sec = 3870.34, Train LB = -344.766, Loss = 350.825
[2018-06-04 20:41] Train Step 85250, Epoch 78.9, Batch Size = 256, Examples/Sec = 3873.63, Train LB = -361.946, Loss = 349.693
[2018-06-04 20:41] Train Step 85275, Epoch 79.0, Batch Size = 256, Examples/Sec = 3839.29, Train LB = -360.398, Loss = 348.734
[2018-06-04 20:41] Train Step 85300, Epoch 79.0, Batch Size = 256, Examples/Sec = 3862.17, Train LB = -349.605, Loss = 347.539
[2018-06-04 20:41] Train Step 85325, Epoch 79.0, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -338.925, Loss = 347.084
[2018-06-04 20:41] Train Step 85350, Epoch 79.0, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -343.572, Loss = 346.354
[2018-06-04 20:41] Train Step 85375, Epoch 79.1, Batch Size = 256, Examples/Sec = 3863.80, Train LB = -359.386, Loss = 348.224
[2018-06-04 20:41] Train Step 85400, Epoch 79.1, Batch Size = 256, Examples/Sec = 3864.67, Train LB = -388.161, Loss = 352.000
Performance on test set:
  Test Lower Bound = -426.274, Test Loss = 426.274
[2018-06-04 20:41] Train Step 85425, Epoch 79.1, Batch Size = 256, Examples/Sec = 3849.61, Train LB = -340.786, Loss = 350.550
[2018-06-04 20:41] Train Step 85450, Epoch 79.1, Batch Size = 256, Examples/Sec = 3794.05, Train LB = -346.771, Loss = 349.208
[2018-06-04 20:41] Train Step 85475, Epoch 79.1, Batch Size = 256, Examples/Sec = 3853.15, Train LB = -332.063, Loss = 347.576
[2018-06-04 20:41] Train Step 85500, Epoch 79.2, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -347.565, Loss = 347.150
[2018-06-04 20:41] Train Step 85525, Epoch 79.2, Batch Size = 256, Examples/Sec = 3866.02, Train LB = -337.891, Loss = 346.984
[2018-06-04 20:41] Train Step 85550, Epoch 79.2, Batch Size = 256, Examples/Sec = 3847.94, Train LB = -341.594, Loss = 346.422
[2018-06-04 20:41] Train Step 85575, Epoch 79.2, Batch Size = 256, Examples/Sec = 3863.40, Train LB = -368.053, Loss = 348.445
[2018-06-04 20:41] Train Step 85600, Epoch 79.3, Batch Size = 256, Examples/Sec = 3862.45, Train LB = -361.498, Loss = 352.728
Performance on test set:
  Test Lower Bound = -425.508, Test Loss = 425.508
[2018-06-04 20:41] Train Step 85625, Epoch 79.3, Batch Size = 256, Examples/Sec = 3831.36, Train LB = -330.614, Loss = 351.518
[2018-06-04 20:41] Train Step 85650, Epoch 79.3, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -352.482, Loss = 349.724
[2018-06-04 20:41] Train Step 85675, Epoch 79.3, Batch Size = 256, Examples/Sec = 3866.89, Train LB = -344.113, Loss = 348.088
[2018-06-04 20:41] Train Step 85700, Epoch 79.4, Batch Size = 256, Examples/Sec = 3852.82, Train LB = -337.593, Loss = 347.116
[2018-06-04 20:41] Train Step 85725, Epoch 79.4, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -339.331, Loss = 346.345
[2018-06-04 20:41] Train Step 85750, Epoch 79.4, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -355.888, Loss = 346.712
[2018-06-04 20:41] Train Step 85775, Epoch 79.4, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -339.355, Loss = 348.144
[2018-06-04 20:41] Train Step 85800, Epoch 79.4, Batch Size = 256, Examples/Sec = 3840.44, Train LB = -368.952, Loss = 351.811
Performance on test set:
  Test Lower Bound = -425.192, Test Loss = 425.192
[2018-06-04 20:41] Train Step 85825, Epoch 79.5, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -340.332, Loss = 351.233
[2018-06-04 20:41] Train Step 85850, Epoch 79.5, Batch Size = 256, Examples/Sec = 3862.16, Train LB = -330.404, Loss = 349.089
[2018-06-04 20:41] Train Step 85875, Epoch 79.5, Batch Size = 256, Examples/Sec = 3843.84, Train LB = -337.523, Loss = 347.792
[2018-06-04 20:41] Train Step 85900, Epoch 79.5, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -343.444, Loss = 346.642
[2018-06-04 20:41] Train Step 85925, Epoch 79.6, Batch Size = 256, Examples/Sec = 3858.33, Train LB = -341.730, Loss = 345.214
[2018-06-04 20:41] Train Step 85950, Epoch 79.6, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -341.615, Loss = 346.178
[2018-06-04 20:41] Train Step 85975, Epoch 79.6, Batch Size = 256, Examples/Sec = 3869.81, Train LB = -360.090, Loss = 347.227
[2018-06-04 20:42] Train Step 86000, Epoch 79.6, Batch Size = 256, Examples/Sec = 3872.45, Train LB = -371.870, Loss = 351.717
Performance on test set:
  Test Lower Bound = -425.620, Test Loss = 425.620
[2018-06-04 20:42] Train Step 86025, Epoch 79.7, Batch Size = 256, Examples/Sec = 3750.92, Train LB = -338.733, Loss = 350.401
[2018-06-04 20:42] Train Step 86050, Epoch 79.7, Batch Size = 256, Examples/Sec = 3877.50, Train LB = -352.482, Loss = 348.490
[2018-06-04 20:42] Train Step 86075, Epoch 79.7, Batch Size = 256, Examples/Sec = 3871.75, Train LB = -339.474, Loss = 347.048
[2018-06-04 20:42] Train Step 86100, Epoch 79.7, Batch Size = 256, Examples/Sec = 3752.12, Train LB = -333.951, Loss = 346.296
[2018-06-04 20:42] Train Step 86125, Epoch 79.7, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -340.717, Loss = 346.145
[2018-06-04 20:42] Train Step 86150, Epoch 79.8, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -353.272, Loss = 346.654
[2018-06-04 20:42] Train Step 86175, Epoch 79.8, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -356.349, Loss = 347.667
[2018-06-04 20:42] Train Step 86200, Epoch 79.8, Batch Size = 256, Examples/Sec = 3842.68, Train LB = -383.747, Loss = 351.267
Performance on test set:
  Test Lower Bound = -424.694, Test Loss = 424.694
[2018-06-04 20:42] Train Step 86225, Epoch 79.8, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -341.745, Loss = 350.437
[2018-06-04 20:42] Train Step 86250, Epoch 79.9, Batch Size = 256, Examples/Sec = 3862.98, Train LB = -336.191, Loss = 348.856
[2018-06-04 20:42] Train Step 86275, Epoch 79.9, Batch Size = 256, Examples/Sec = 3865.95, Train LB = -343.552, Loss = 347.342
[2018-06-04 20:42] Train Step 86300, Epoch 79.9, Batch Size = 256, Examples/Sec = 3835.15, Train LB = -335.763, Loss = 346.071
[2018-06-04 20:42] Train Step 86325, Epoch 79.9, Batch Size = 256, Examples/Sec = 3790.56, Train LB = -336.827, Loss = 345.661
[2018-06-04 20:42] Train Step 86350, Epoch 80.0, Batch Size = 256, Examples/Sec = 3845.35, Train LB = -364.434, Loss = 345.532
[2018-06-04 20:42] Train Step 86375, Epoch 80.0, Batch Size = 256, Examples/Sec = 3835.55, Train LB = -357.003, Loss = 348.084
[2018-06-04 20:42] Train Step 86400, Epoch 80.0, Batch Size = 256, Examples/Sec = 3863.80, Train LB = -366.539, Loss = 351.922
Performance on test set:
  Test Lower Bound = -423.856, Test Loss = 423.856
[2018-06-04 20:42] Train Step 86425, Epoch 80.0, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -339.400, Loss = 350.456
[2018-06-04 20:42] Train Step 86450, Epoch 80.0, Batch Size = 256, Examples/Sec = 3885.15, Train LB = -327.853, Loss = 348.553
[2018-06-04 20:42] Train Step 86475, Epoch 80.1, Batch Size = 256, Examples/Sec = 3850.90, Train LB = -345.971, Loss = 347.288
[2018-06-04 20:42] Train Step 86500, Epoch 80.1, Batch Size = 256, Examples/Sec = 3876.16, Train LB = -360.940, Loss = 346.706
[2018-06-04 20:42] Train Step 86525, Epoch 80.1, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -347.859, Loss = 345.827
[2018-06-04 20:42] Train Step 86550, Epoch 80.1, Batch Size = 256, Examples/Sec = 3856.82, Train LB = -343.219, Loss = 346.260
[2018-06-04 20:42] Train Step 86575, Epoch 80.2, Batch Size = 256, Examples/Sec = 3850.19, Train LB = -361.800, Loss = 347.608
[2018-06-04 20:42] Train Step 86600, Epoch 80.2, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -361.964, Loss = 351.318
Performance on test set:
  Test Lower Bound = -425.103, Test Loss = 425.103
[2018-06-04 20:42] Train Step 86625, Epoch 80.2, Batch Size = 256, Examples/Sec = 3853.86, Train LB = -351.902, Loss = 349.674
[2018-06-04 20:42] Train Step 86650, Epoch 80.2, Batch Size = 256, Examples/Sec = 3868.18, Train LB = -323.108, Loss = 348.488
[2018-06-04 20:42] Train Step 86675, Epoch 80.3, Batch Size = 256, Examples/Sec = 3874.44, Train LB = -341.551, Loss = 346.418
[2018-06-04 20:43] Train Step 86700, Epoch 80.3, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -376.117, Loss = 345.990
[2018-06-04 20:43] Train Step 86725, Epoch 80.3, Batch Size = 256, Examples/Sec = 3843.03, Train LB = -341.306, Loss = 345.798
[2018-06-04 20:43] Train Step 86750, Epoch 80.3, Batch Size = 256, Examples/Sec = 3861.53, Train LB = -353.972, Loss = 346.200
[2018-06-04 20:43] Train Step 86775, Epoch 80.3, Batch Size = 256, Examples/Sec = 3856.40, Train LB = -359.132, Loss = 347.917
[2018-06-04 20:43] Train Step 86800, Epoch 80.4, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -363.157, Loss = 351.983
Performance on test set:
  Test Lower Bound = -423.828, Test Loss = 423.828
[2018-06-04 20:43] Train Step 86825, Epoch 80.4, Batch Size = 256, Examples/Sec = 3716.77, Train LB = -362.234, Loss = 350.707
[2018-06-04 20:43] Train Step 86850, Epoch 80.4, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -339.582, Loss = 349.285
[2018-06-04 20:43] Train Step 86875, Epoch 80.4, Batch Size = 256, Examples/Sec = 3848.70, Train LB = -332.281, Loss = 347.200
[2018-06-04 20:43] Train Step 86900, Epoch 80.5, Batch Size = 256, Examples/Sec = 3735.70, Train LB = -348.038, Loss = 345.942
[2018-06-04 20:43] Train Step 86925, Epoch 80.5, Batch Size = 256, Examples/Sec = 3850.37, Train LB = -338.711, Loss = 345.391
[2018-06-04 20:43] Train Step 86950, Epoch 80.5, Batch Size = 256, Examples/Sec = 3806.07, Train LB = -347.765, Loss = 345.076
[2018-06-04 20:43] Train Step 86975, Epoch 80.5, Batch Size = 256, Examples/Sec = 3821.97, Train LB = -352.784, Loss = 347.543
[2018-06-04 20:43] Train Step 87000, Epoch 80.6, Batch Size = 256, Examples/Sec = 3878.55, Train LB = -368.024, Loss = 351.745
Performance on test set:
  Test Lower Bound = -424.248, Test Loss = 424.248
[2018-06-04 20:43] Train Step 87025, Epoch 80.6, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -328.329, Loss = 350.953
[2018-06-04 20:43] Train Step 87050, Epoch 80.6, Batch Size = 256, Examples/Sec = 3814.45, Train LB = -336.230, Loss = 348.704
[2018-06-04 20:43] Train Step 87075, Epoch 80.6, Batch Size = 256, Examples/Sec = 3847.08, Train LB = -335.736, Loss = 346.557
[2018-06-04 20:43] Train Step 87100, Epoch 80.6, Batch Size = 256, Examples/Sec = 3857.69, Train LB = -362.277, Loss = 346.077
[2018-06-04 20:43] Train Step 87125, Epoch 80.7, Batch Size = 256, Examples/Sec = 3866.30, Train LB = -339.890, Loss = 346.005
[2018-06-04 20:43] Train Step 87150, Epoch 80.7, Batch Size = 256, Examples/Sec = 3879.21, Train LB = -338.415, Loss = 346.209
[2018-06-04 20:43] Train Step 87175, Epoch 80.7, Batch Size = 256, Examples/Sec = 3863.63, Train LB = -366.177, Loss = 347.695
[2018-06-04 20:43] Train Step 87200, Epoch 80.7, Batch Size = 256, Examples/Sec = 3851.01, Train LB = -367.348, Loss = 352.131
Performance on test set:
  Test Lower Bound = -425.679, Test Loss = 425.679
[2018-06-04 20:43] Train Step 87225, Epoch 80.8, Batch Size = 256, Examples/Sec = 3849.63, Train LB = -342.676, Loss = 351.117
[2018-06-04 20:43] Train Step 87250, Epoch 80.8, Batch Size = 256, Examples/Sec = 3856.07, Train LB = -323.916, Loss = 349.503
[2018-06-04 20:43] Train Step 87275, Epoch 80.8, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -325.860, Loss = 347.357
[2018-06-04 20:43] Train Step 87300, Epoch 80.8, Batch Size = 256, Examples/Sec = 3860.37, Train LB = -335.256, Loss = 345.744
[2018-06-04 20:43] Train Step 87325, Epoch 80.9, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -353.923, Loss = 345.498
[2018-06-04 20:43] Train Step 87350, Epoch 80.9, Batch Size = 256, Examples/Sec = 3833.94, Train LB = -347.778, Loss = 345.898
[2018-06-04 20:43] Train Step 87375, Epoch 80.9, Batch Size = 256, Examples/Sec = 3877.67, Train LB = -360.011, Loss = 347.201
[2018-06-04 20:43] Train Step 87400, Epoch 80.9, Batch Size = 256, Examples/Sec = 3858.33, Train LB = -383.449, Loss = 351.436
Performance on test set:
  Test Lower Bound = -427.586, Test Loss = 427.586
[2018-06-04 20:44] Train Step 87425, Epoch 80.9, Batch Size = 256, Examples/Sec = 3870.51, Train LB = -344.279, Loss = 350.604
[2018-06-04 20:44] Train Step 87450, Epoch 81.0, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -348.439, Loss = 348.525
[2018-06-04 20:44] Train Step 87475, Epoch 81.0, Batch Size = 256, Examples/Sec = 3843.32, Train LB = -327.273, Loss = 346.765
[2018-06-04 20:44] Train Step 87500, Epoch 81.0, Batch Size = 256, Examples/Sec = 3854.89, Train LB = -337.552, Loss = 345.627
[2018-06-04 20:44] Train Step 87525, Epoch 81.0, Batch Size = 256, Examples/Sec = 3846.91, Train LB = -352.032, Loss = 345.361
[2018-06-04 20:44] Train Step 87550, Epoch 81.1, Batch Size = 256, Examples/Sec = 3846.50, Train LB = -342.381, Loss = 346.334
[2018-06-04 20:44] Train Step 87575, Epoch 81.1, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -372.963, Loss = 347.924
[2018-06-04 20:44] Train Step 87600, Epoch 81.1, Batch Size = 256, Examples/Sec = 3852.29, Train LB = -359.658, Loss = 351.467
Performance on test set:
  Test Lower Bound = -426.539, Test Loss = 426.539
[2018-06-04 20:44] Train Step 87625, Epoch 81.1, Batch Size = 256, Examples/Sec = 3742.53, Train LB = -334.380, Loss = 350.064
[2018-06-04 20:44] Train Step 87650, Epoch 81.2, Batch Size = 256, Examples/Sec = 3859.78, Train LB = -341.971, Loss = 347.610
[2018-06-04 20:44] Train Step 87675, Epoch 81.2, Batch Size = 256, Examples/Sec = 3802.79, Train LB = -348.339, Loss = 346.808
[2018-06-04 20:44] Train Step 87700, Epoch 81.2, Batch Size = 256, Examples/Sec = 3745.71, Train LB = -345.394, Loss = 345.510
[2018-06-04 20:44] Train Step 87725, Epoch 81.2, Batch Size = 256, Examples/Sec = 3819.70, Train LB = -340.958, Loss = 344.747
[2018-06-04 20:44] Train Step 87750, Epoch 81.2, Batch Size = 256, Examples/Sec = 3843.84, Train LB = -341.237, Loss = 345.618
[2018-06-04 20:44] Train Step 87775, Epoch 81.3, Batch Size = 256, Examples/Sec = 3819.12, Train LB = -359.914, Loss = 348.298
[2018-06-04 20:44] Train Step 87800, Epoch 81.3, Batch Size = 256, Examples/Sec = 3846.62, Train LB = -370.315, Loss = 352.431
Performance on test set:
  Test Lower Bound = -424.655, Test Loss = 424.655
[2018-06-04 20:44] Train Step 87825, Epoch 81.3, Batch Size = 256, Examples/Sec = 3830.62, Train LB = -343.419, Loss = 351.248
[2018-06-04 20:44] Train Step 87850, Epoch 81.3, Batch Size = 256, Examples/Sec = 3843.15, Train LB = -342.425, Loss = 349.546
[2018-06-04 20:44] Train Step 87875, Epoch 81.4, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -333.644, Loss = 347.812
[2018-06-04 20:44] Train Step 87900, Epoch 81.4, Batch Size = 256, Examples/Sec = 3853.50, Train LB = -337.762, Loss = 346.822
[2018-06-04 20:44] Train Step 87925, Epoch 81.4, Batch Size = 256, Examples/Sec = 3854.78, Train LB = -373.077, Loss = 345.942
[2018-06-04 20:44] Train Step 87950, Epoch 81.4, Batch Size = 256, Examples/Sec = 3731.29, Train LB = -361.239, Loss = 346.021
[2018-06-04 20:44] Train Step 87975, Epoch 81.5, Batch Size = 256, Examples/Sec = 3866.96, Train LB = -367.375, Loss = 348.097
[2018-06-04 20:44] Train Step 88000, Epoch 81.5, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -381.528, Loss = 350.920
Performance on test set:
  Test Lower Bound = -427.057, Test Loss = 427.057
[2018-06-04 20:44] Train Step 88025, Epoch 81.5, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -340.468, Loss = 350.616
[2018-06-04 20:44] Train Step 88050, Epoch 81.5, Batch Size = 256, Examples/Sec = 3840.15, Train LB = -349.818, Loss = 349.101
[2018-06-04 20:44] Train Step 88075, Epoch 81.6, Batch Size = 256, Examples/Sec = 3842.30, Train LB = -353.433, Loss = 347.397
[2018-06-04 20:44] Train Step 88100, Epoch 81.6, Batch Size = 256, Examples/Sec = 3864.40, Train LB = -344.121, Loss = 346.452
[2018-06-04 20:45] Train Step 88125, Epoch 81.6, Batch Size = 256, Examples/Sec = 3819.58, Train LB = -340.933, Loss = 345.953
[2018-06-04 20:45] Train Step 88150, Epoch 81.6, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -340.384, Loss = 346.475
[2018-06-04 20:45] Train Step 88175, Epoch 81.6, Batch Size = 256, Examples/Sec = 3851.66, Train LB = -347.540, Loss = 347.428
[2018-06-04 20:45] Train Step 88200, Epoch 81.7, Batch Size = 256, Examples/Sec = 3855.24, Train LB = -381.484, Loss = 351.851
Performance on test set:
  Test Lower Bound = -423.772, Test Loss = 423.772
[2018-06-04 20:45] Train Step 88225, Epoch 81.7, Batch Size = 256, Examples/Sec = 3868.70, Train LB = -349.340, Loss = 350.905
[2018-06-04 20:45] Train Step 88250, Epoch 81.7, Batch Size = 256, Examples/Sec = 3795.12, Train LB = -336.055, Loss = 349.428
[2018-06-04 20:45] Train Step 88275, Epoch 81.7, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -334.076, Loss = 347.380
[2018-06-04 20:45] Train Step 88300, Epoch 81.8, Batch Size = 256, Examples/Sec = 3860.35, Train LB = -338.116, Loss = 346.002
[2018-06-04 20:45] Train Step 88325, Epoch 81.8, Batch Size = 256, Examples/Sec = 3888.99, Train LB = -334.917, Loss = 344.965
[2018-06-04 20:45] Train Step 88350, Epoch 81.8, Batch Size = 256, Examples/Sec = 3806.07, Train LB = -354.029, Loss = 345.385
[2018-06-04 20:45] Train Step 88375, Epoch 81.8, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -357.444, Loss = 347.631
[2018-06-04 20:45] Train Step 88400, Epoch 81.9, Batch Size = 256, Examples/Sec = 3861.83, Train LB = -390.853, Loss = 351.826
Performance on test set:
  Test Lower Bound = -424.519, Test Loss = 424.519
[2018-06-04 20:45] Train Step 88425, Epoch 81.9, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -347.333, Loss = 350.075
[2018-06-04 20:45] Train Step 88450, Epoch 81.9, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -340.778, Loss = 348.787
[2018-06-04 20:45] Train Step 88475, Epoch 81.9, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -342.587, Loss = 347.555
[2018-06-04 20:45] Train Step 88500, Epoch 81.9, Batch Size = 256, Examples/Sec = 3772.69, Train LB = -336.127, Loss = 346.152
[2018-06-04 20:45] Train Step 88525, Epoch 82.0, Batch Size = 256, Examples/Sec = 3834.40, Train LB = -361.066, Loss = 345.022
[2018-06-04 20:45] Train Step 88550, Epoch 82.0, Batch Size = 256, Examples/Sec = 3854.96, Train LB = -356.569, Loss = 345.470
[2018-06-04 20:45] Train Step 88575, Epoch 82.0, Batch Size = 256, Examples/Sec = 3729.60, Train LB = -362.736, Loss = 347.201
[2018-06-04 20:45] Train Step 88600, Epoch 82.0, Batch Size = 256, Examples/Sec = 3861.58, Train LB = -364.544, Loss = 351.365
Performance on test set:
  Test Lower Bound = -423.074, Test Loss = 423.074
[2018-06-04 20:45] Train Step 88625, Epoch 82.1, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -354.152, Loss = 350.457
[2018-06-04 20:45] Train Step 88650, Epoch 82.1, Batch Size = 256, Examples/Sec = 3852.40, Train LB = -338.167, Loss = 349.770
[2018-06-04 20:45] Train Step 88675, Epoch 82.1, Batch Size = 256, Examples/Sec = 3839.29, Train LB = -329.166, Loss = 347.726
[2018-06-04 20:45] Train Step 88700, Epoch 82.1, Batch Size = 256, Examples/Sec = 3794.01, Train LB = -349.450, Loss = 346.328
[2018-06-04 20:45] Train Step 88725, Epoch 82.2, Batch Size = 256, Examples/Sec = 3866.66, Train LB = -345.614, Loss = 345.844
[2018-06-04 20:45] Train Step 88750, Epoch 82.2, Batch Size = 256, Examples/Sec = 3876.86, Train LB = -352.364, Loss = 345.543
[2018-06-04 20:45] Train Step 88775, Epoch 82.2, Batch Size = 256, Examples/Sec = 3857.68, Train LB = -356.903, Loss = 347.394
[2018-06-04 20:45] Train Step 88800, Epoch 82.2, Batch Size = 256, Examples/Sec = 3862.41, Train LB = -367.254, Loss = 351.187
Performance on test set:
  Test Lower Bound = -424.388, Test Loss = 424.388
[2018-06-04 20:46] Train Step 88825, Epoch 82.2, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -345.708, Loss = 349.451
[2018-06-04 20:46] Train Step 88850, Epoch 82.3, Batch Size = 256, Examples/Sec = 3857.00, Train LB = -360.119, Loss = 348.092
[2018-06-04 20:46] Train Step 88875, Epoch 82.3, Batch Size = 256, Examples/Sec = 3867.42, Train LB = -334.613, Loss = 346.777
[2018-06-04 20:46] Train Step 88900, Epoch 82.3, Batch Size = 256, Examples/Sec = 3836.98, Train LB = -342.244, Loss = 346.076
[2018-06-04 20:46] Train Step 88925, Epoch 82.3, Batch Size = 256, Examples/Sec = 3863.05, Train LB = -366.948, Loss = 345.314
[2018-06-04 20:46] Train Step 88950, Epoch 82.4, Batch Size = 256, Examples/Sec = 3839.70, Train LB = -342.065, Loss = 346.009
[2018-06-04 20:46] Train Step 88975, Epoch 82.4, Batch Size = 256, Examples/Sec = 3868.41, Train LB = -373.912, Loss = 347.183
[2018-06-04 20:46] Train Step 89000, Epoch 82.4, Batch Size = 256, Examples/Sec = 3785.98, Train LB = -360.080, Loss = 350.944
Performance on test set:
  Test Lower Bound = -427.029, Test Loss = 427.029
[2018-06-04 20:46] Train Step 89025, Epoch 82.4, Batch Size = 256, Examples/Sec = 3831.59, Train LB = -352.992, Loss = 349.502
[2018-06-04 20:46] Train Step 89050, Epoch 82.5, Batch Size = 256, Examples/Sec = 3716.23, Train LB = -345.645, Loss = 347.976
[2018-06-04 20:46] Train Step 89075, Epoch 82.5, Batch Size = 256, Examples/Sec = 3857.11, Train LB = -342.561, Loss = 345.893
[2018-06-04 20:46] Train Step 89100, Epoch 82.5, Batch Size = 256, Examples/Sec = 3848.92, Train LB = -342.662, Loss = 345.628
[2018-06-04 20:46] Train Step 89125, Epoch 82.5, Batch Size = 256, Examples/Sec = 3727.97, Train LB = -336.022, Loss = 345.299
[2018-06-04 20:46] Train Step 89150, Epoch 82.5, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -333.755, Loss = 345.276
[2018-06-04 20:46] Train Step 89175, Epoch 82.6, Batch Size = 256, Examples/Sec = 3851.59, Train LB = -362.315, Loss = 346.745
[2018-06-04 20:46] Train Step 89200, Epoch 82.6, Batch Size = 256, Examples/Sec = 3842.30, Train LB = -361.031, Loss = 350.884
Performance on test set:
  Test Lower Bound = -424.311, Test Loss = 424.311
[2018-06-04 20:46] Train Step 89225, Epoch 82.6, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -353.868, Loss = 349.368
[2018-06-04 20:46] Train Step 89250, Epoch 82.6, Batch Size = 256, Examples/Sec = 3869.01, Train LB = -346.256, Loss = 348.510
[2018-06-04 20:46] Train Step 89275, Epoch 82.7, Batch Size = 256, Examples/Sec = 3843.96, Train LB = -335.359, Loss = 347.190
[2018-06-04 20:46] Train Step 89300, Epoch 82.7, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -338.533, Loss = 345.540
[2018-06-04 20:46] Train Step 89325, Epoch 82.7, Batch Size = 256, Examples/Sec = 3846.62, Train LB = -341.381, Loss = 345.854
[2018-06-04 20:46] Train Step 89350, Epoch 82.7, Batch Size = 256, Examples/Sec = 3847.13, Train LB = -344.572, Loss = 345.796
[2018-06-04 20:46] Train Step 89375, Epoch 82.8, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -367.139, Loss = 346.631
[2018-06-04 20:46] Train Step 89400, Epoch 82.8, Batch Size = 256, Examples/Sec = 3874.09, Train LB = -383.032, Loss = 350.773
Performance on test set:
  Test Lower Bound = -428.432, Test Loss = 428.432
[2018-06-04 20:46] Train Step 89425, Epoch 82.8, Batch Size = 256, Examples/Sec = 3849.79, Train LB = -333.067, Loss = 349.684
[2018-06-04 20:46] Train Step 89450, Epoch 82.8, Batch Size = 256, Examples/Sec = 3848.87, Train LB = -332.430, Loss = 348.229
[2018-06-04 20:46] Train Step 89475, Epoch 82.8, Batch Size = 256, Examples/Sec = 3878.84, Train LB = -335.751, Loss = 346.993
[2018-06-04 20:46] Train Step 89500, Epoch 82.9, Batch Size = 256, Examples/Sec = 3844.71, Train LB = -334.973, Loss = 346.216
[2018-06-04 20:46] Train Step 89525, Epoch 82.9, Batch Size = 256, Examples/Sec = 3870.80, Train LB = -359.988, Loss = 344.986
[2018-06-04 20:47] Train Step 89550, Epoch 82.9, Batch Size = 256, Examples/Sec = 3782.39, Train LB = -341.129, Loss = 345.591
[2018-06-04 20:47] Train Step 89575, Epoch 82.9, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -357.779, Loss = 347.454
[2018-06-04 20:47] Train Step 89600, Epoch 83.0, Batch Size = 256, Examples/Sec = 3858.55, Train LB = -372.365, Loss = 350.933
Performance on test set:
  Test Lower Bound = -425.084, Test Loss = 425.084
[2018-06-04 20:47] Train Step 89625, Epoch 83.0, Batch Size = 256, Examples/Sec = 3844.31, Train LB = -347.285, Loss = 350.295
[2018-06-04 20:47] Train Step 89650, Epoch 83.0, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -339.675, Loss = 348.707
[2018-06-04 20:47] Train Step 89675, Epoch 83.0, Batch Size = 256, Examples/Sec = 3869.12, Train LB = -327.932, Loss = 347.243
[2018-06-04 20:47] Train Step 89700, Epoch 83.1, Batch Size = 256, Examples/Sec = 3851.01, Train LB = -350.532, Loss = 346.612
[2018-06-04 20:47] Train Step 89725, Epoch 83.1, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -336.222, Loss = 345.013
[2018-06-04 20:47] Train Step 89750, Epoch 83.1, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -343.984, Loss = 345.367
[2018-06-04 20:47] Train Step 89775, Epoch 83.1, Batch Size = 256, Examples/Sec = 3871.33, Train LB = -375.176, Loss = 346.507
[2018-06-04 20:47] Train Step 89800, Epoch 83.1, Batch Size = 256, Examples/Sec = 3865.38, Train LB = -357.399, Loss = 350.521
Performance on test set:
  Test Lower Bound = -425.812, Test Loss = 425.812
[2018-06-04 20:47] Train Step 89825, Epoch 83.2, Batch Size = 256, Examples/Sec = 3868.71, Train LB = -333.591, Loss = 349.371
[2018-06-04 20:47] Train Step 89850, Epoch 83.2, Batch Size = 256, Examples/Sec = 3735.36, Train LB = -348.312, Loss = 347.733
[2018-06-04 20:47] Train Step 89875, Epoch 83.2, Batch Size = 256, Examples/Sec = 3851.06, Train LB = -332.400, Loss = 346.705
[2018-06-04 20:47] Train Step 89900, Epoch 83.2, Batch Size = 256, Examples/Sec = 3861.53, Train LB = -335.157, Loss = 345.229
[2018-06-04 20:47] Train Step 89925, Epoch 83.3, Batch Size = 256, Examples/Sec = 3811.62, Train LB = -341.968, Loss = 344.774
[2018-06-04 20:47] Train Step 89950, Epoch 83.3, Batch Size = 256, Examples/Sec = 3816.68, Train LB = -352.775, Loss = 344.890
[2018-06-04 20:47] Train Step 89975, Epoch 83.3, Batch Size = 256, Examples/Sec = 3851.06, Train LB = -363.642, Loss = 347.410
[2018-06-04 20:47] Train Step 90000, Epoch 83.3, Batch Size = 256, Examples/Sec = 3872.51, Train LB = -357.650, Loss = 352.150
Performance on test set:
  Test Lower Bound = -427.827, Test Loss = 427.827
[2018-06-04 20:47] Train Step 90025, Epoch 83.4, Batch Size = 256, Examples/Sec = 3824.10, Train LB = -343.649, Loss = 350.733
[2018-06-04 20:47] Train Step 90050, Epoch 83.4, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -334.840, Loss = 349.089
[2018-06-04 20:47] Train Step 90075, Epoch 83.4, Batch Size = 256, Examples/Sec = 3841.54, Train LB = -340.510, Loss = 347.455
[2018-06-04 20:47] Train Step 90100, Epoch 83.4, Batch Size = 256, Examples/Sec = 3867.19, Train LB = -336.338, Loss = 346.181
[2018-06-04 20:47] Train Step 90125, Epoch 83.4, Batch Size = 256, Examples/Sec = 3851.89, Train LB = -366.156, Loss = 345.887
[2018-06-04 20:47] Train Step 90150, Epoch 83.5, Batch Size = 256, Examples/Sec = 3851.93, Train LB = -342.347, Loss = 345.908
[2018-06-04 20:47] Train Step 90175, Epoch 83.5, Batch Size = 256, Examples/Sec = 3757.86, Train LB = -374.800, Loss = 347.474
[2018-06-04 20:47] Train Step 90200, Epoch 83.5, Batch Size = 256, Examples/Sec = 3864.03, Train LB = -371.674, Loss = 351.896
Performance on test set:
  Test Lower Bound = -427.182, Test Loss = 427.182
[2018-06-04 20:47] Train Step 90225, Epoch 83.5, Batch Size = 256, Examples/Sec = 3839.92, Train LB = -336.868, Loss = 350.366
[2018-06-04 20:48] Train Step 90250, Epoch 83.6, Batch Size = 256, Examples/Sec = 3862.64, Train LB = -333.740, Loss = 349.221
[2018-06-04 20:48] Train Step 90275, Epoch 83.6, Batch Size = 256, Examples/Sec = 3861.59, Train LB = -337.284, Loss = 347.112
[2018-06-04 20:48] Train Step 90300, Epoch 83.6, Batch Size = 256, Examples/Sec = 3848.87, Train LB = -336.494, Loss = 346.603
[2018-06-04 20:48] Train Step 90325, Epoch 83.6, Batch Size = 256, Examples/Sec = 3877.56, Train LB = -347.977, Loss = 346.349
[2018-06-04 20:48] Train Step 90350, Epoch 83.7, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -343.716, Loss = 346.481
[2018-06-04 20:48] Train Step 90375, Epoch 83.7, Batch Size = 256, Examples/Sec = 3859.26, Train LB = -364.859, Loss = 347.190
[2018-06-04 20:48] Train Step 90400, Epoch 83.7, Batch Size = 256, Examples/Sec = 3855.20, Train LB = -374.140, Loss = 351.357
Performance on test set:
  Test Lower Bound = -424.995, Test Loss = 424.995
[2018-06-04 20:48] Train Step 90425, Epoch 83.7, Batch Size = 256, Examples/Sec = 3849.92, Train LB = -342.488, Loss = 349.937
[2018-06-04 20:48] Train Step 90450, Epoch 83.8, Batch Size = 256, Examples/Sec = 3847.02, Train LB = -341.193, Loss = 348.419
[2018-06-04 20:48] Train Step 90475, Epoch 83.8, Batch Size = 256, Examples/Sec = 3864.97, Train LB = -344.476, Loss = 346.583
[2018-06-04 20:48] Train Step 90500, Epoch 83.8, Batch Size = 256, Examples/Sec = 3859.62, Train LB = -354.104, Loss = 345.366
[2018-06-04 20:48] Train Step 90525, Epoch 83.8, Batch Size = 256, Examples/Sec = 3866.43, Train LB = -349.268, Loss = 344.986
[2018-06-04 20:48] Train Step 90550, Epoch 83.8, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -347.204, Loss = 345.021
[2018-06-04 20:48] Train Step 90575, Epoch 83.9, Batch Size = 256, Examples/Sec = 3877.61, Train LB = -364.272, Loss = 346.453
[2018-06-04 20:48] Train Step 90600, Epoch 83.9, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -360.158, Loss = 350.799
Performance on test set:
  Test Lower Bound = -427.195, Test Loss = 427.195
[2018-06-04 20:48] Train Step 90625, Epoch 83.9, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -335.228, Loss = 349.282
[2018-06-04 20:48] Train Step 90650, Epoch 83.9, Batch Size = 256, Examples/Sec = 3757.14, Train LB = -341.840, Loss = 348.286
[2018-06-04 20:48] Train Step 90675, Epoch 84.0, Batch Size = 256, Examples/Sec = 3867.72, Train LB = -339.891, Loss = 347.535
[2018-06-04 20:48] Train Step 90700, Epoch 84.0, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -336.936, Loss = 346.104
[2018-06-04 20:48] Train Step 90725, Epoch 84.0, Batch Size = 256, Examples/Sec = 3741.31, Train LB = -358.941, Loss = 345.219
[2018-06-04 20:48] Train Step 90750, Epoch 84.0, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -346.523, Loss = 346.222
[2018-06-04 20:48] Train Step 90775, Epoch 84.1, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -353.362, Loss = 347.568
[2018-06-04 20:48] Train Step 90800, Epoch 84.1, Batch Size = 256, Examples/Sec = 3852.75, Train LB = -364.161, Loss = 350.805
Performance on test set:
  Test Lower Bound = -427.700, Test Loss = 427.700
[2018-06-04 20:48] Train Step 90825, Epoch 84.1, Batch Size = 256, Examples/Sec = 3854.73, Train LB = -343.062, Loss = 348.827
[2018-06-04 20:48] Train Step 90850, Epoch 84.1, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -334.630, Loss = 348.361
[2018-06-04 20:48] Train Step 90875, Epoch 84.1, Batch Size = 256, Examples/Sec = 3844.36, Train LB = -351.506, Loss = 346.784
[2018-06-04 20:48] Train Step 90900, Epoch 84.2, Batch Size = 256, Examples/Sec = 3875.44, Train LB = -345.192, Loss = 346.495
[2018-06-04 20:48] Train Step 90925, Epoch 84.2, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -328.525, Loss = 345.269
[2018-06-04 20:48] Train Step 90950, Epoch 84.2, Batch Size = 256, Examples/Sec = 3888.69, Train LB = -336.125, Loss = 345.269
[2018-06-04 20:48] Train Step 90975, Epoch 84.2, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -367.968, Loss = 346.487
[2018-06-04 20:49] Train Step 91000, Epoch 84.3, Batch Size = 256, Examples/Sec = 3839.81, Train LB = -358.847, Loss = 350.849
Performance on test set:
  Test Lower Bound = -425.484, Test Loss = 425.484
[2018-06-04 20:49] Train Step 91025, Epoch 84.3, Batch Size = 256, Examples/Sec = 3831.23, Train LB = -349.885, Loss = 349.540
[2018-06-04 20:49] Train Step 91050, Epoch 84.3, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -327.638, Loss = 347.860
[2018-06-04 20:49] Train Step 91075, Epoch 84.3, Batch Size = 256, Examples/Sec = 3844.54, Train LB = -327.853, Loss = 346.027
[2018-06-04 20:49] Train Step 91100, Epoch 84.4, Batch Size = 256, Examples/Sec = 3857.86, Train LB = -344.354, Loss = 345.680
[2018-06-04 20:49] Train Step 91125, Epoch 84.4, Batch Size = 256, Examples/Sec = 3845.11, Train LB = -334.773, Loss = 345.256
[2018-06-04 20:49] Train Step 91150, Epoch 84.4, Batch Size = 256, Examples/Sec = 3845.01, Train LB = -358.927, Loss = 345.104
[2018-06-04 20:49] Train Step 91175, Epoch 84.4, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -348.789, Loss = 347.098
[2018-06-04 20:49] Train Step 91200, Epoch 84.4, Batch Size = 256, Examples/Sec = 3842.57, Train LB = -360.066, Loss = 350.753
Performance on test set:
  Test Lower Bound = -426.565, Test Loss = 426.565
[2018-06-04 20:49] Train Step 91225, Epoch 84.5, Batch Size = 256, Examples/Sec = 3849.21, Train LB = -340.697, Loss = 349.165
[2018-06-04 20:49] Train Step 91250, Epoch 84.5, Batch Size = 256, Examples/Sec = 3855.07, Train LB = -337.791, Loss = 348.021
[2018-06-04 20:49] Train Step 91275, Epoch 84.5, Batch Size = 256, Examples/Sec = 3814.40, Train LB = -341.807, Loss = 346.862
[2018-06-04 20:49] Train Step 91300, Epoch 84.5, Batch Size = 256, Examples/Sec = 3845.00, Train LB = -328.713, Loss = 345.580
[2018-06-04 20:49] Train Step 91325, Epoch 84.6, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -368.596, Loss = 344.829
[2018-06-04 20:49] Train Step 91350, Epoch 84.6, Batch Size = 256, Examples/Sec = 3859.04, Train LB = -351.435, Loss = 345.475
[2018-06-04 20:49] Train Step 91375, Epoch 84.6, Batch Size = 256, Examples/Sec = 3809.35, Train LB = -332.439, Loss = 347.067
[2018-06-04 20:49] Train Step 91400, Epoch 84.6, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -378.344, Loss = 350.837
Performance on test set:
  Test Lower Bound = -425.799, Test Loss = 425.799
[2018-06-04 20:49] Train Step 91425, Epoch 84.7, Batch Size = 256, Examples/Sec = 3857.22, Train LB = -330.841, Loss = 349.725
[2018-06-04 20:49] Train Step 91450, Epoch 84.7, Batch Size = 256, Examples/Sec = 3869.17, Train LB = -336.268, Loss = 348.551
[2018-06-04 20:49] Train Step 91475, Epoch 84.7, Batch Size = 256, Examples/Sec = 3813.84, Train LB = -326.845, Loss = 347.066
[2018-06-04 20:49] Train Step 91500, Epoch 84.7, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -329.875, Loss = 345.413
[2018-06-04 20:49] Train Step 91525, Epoch 84.7, Batch Size = 256, Examples/Sec = 3844.60, Train LB = -344.566, Loss = 344.047
[2018-06-04 20:49] Train Step 91550, Epoch 84.8, Batch Size = 256, Examples/Sec = 3869.88, Train LB = -360.612, Loss = 344.786
[2018-06-04 20:49] Train Step 91575, Epoch 84.8, Batch Size = 256, Examples/Sec = 3878.90, Train LB = -344.535, Loss = 346.851
[2018-06-04 20:49] Train Step 91600, Epoch 84.8, Batch Size = 256, Examples/Sec = 3743.62, Train LB = -371.576, Loss = 350.468
Performance on test set:
  Test Lower Bound = -427.850, Test Loss = 427.850
[2018-06-04 20:49] Train Step 91625, Epoch 84.8, Batch Size = 256, Examples/Sec = 3848.70, Train LB = -359.730, Loss = 349.267
[2018-06-04 20:49] Train Step 91650, Epoch 84.9, Batch Size = 256, Examples/Sec = 3835.67, Train LB = -328.482, Loss = 347.575
[2018-06-04 20:50] Train Step 91675, Epoch 84.9, Batch Size = 256, Examples/Sec = 3854.31, Train LB = -332.099, Loss = 346.239
[2018-06-04 20:50] Train Step 91700, Epoch 84.9, Batch Size = 256, Examples/Sec = 3853.45, Train LB = -335.333, Loss = 345.110
[2018-06-04 20:50] Train Step 91725, Epoch 84.9, Batch Size = 256, Examples/Sec = 3872.86, Train LB = -339.391, Loss = 344.606
[2018-06-04 20:50] Train Step 91750, Epoch 85.0, Batch Size = 256, Examples/Sec = 3853.56, Train LB = -361.597, Loss = 345.284
[2018-06-04 20:50] Train Step 91775, Epoch 85.0, Batch Size = 256, Examples/Sec = 3857.34, Train LB = -348.935, Loss = 347.143
[2018-06-04 20:50] Train Step 91800, Epoch 85.0, Batch Size = 256, Examples/Sec = 3880.08, Train LB = -398.172, Loss = 350.720
Performance on test set:
  Test Lower Bound = -424.767, Test Loss = 424.767
[2018-06-04 20:50] Train Step 91825, Epoch 85.0, Batch Size = 256, Examples/Sec = 3878.03, Train LB = -346.351, Loss = 349.402
[2018-06-04 20:50] Train Step 91850, Epoch 85.0, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -335.702, Loss = 347.978
[2018-06-04 20:50] Train Step 91875, Epoch 85.1, Batch Size = 256, Examples/Sec = 3859.95, Train LB = -336.296, Loss = 346.630
[2018-06-04 20:50] Train Step 91900, Epoch 85.1, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -337.972, Loss = 345.241
[2018-06-04 20:50] Train Step 91925, Epoch 85.1, Batch Size = 256, Examples/Sec = 3870.57, Train LB = -355.040, Loss = 344.151
[2018-06-04 20:50] Train Step 91950, Epoch 85.1, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -337.190, Loss = 344.837
[2018-06-04 20:50] Train Step 91975, Epoch 85.2, Batch Size = 256, Examples/Sec = 3876.38, Train LB = -350.424, Loss = 346.523
[2018-06-04 20:50] Train Step 92000, Epoch 85.2, Batch Size = 256, Examples/Sec = 3842.68, Train LB = -372.092, Loss = 350.531
Performance on test set:
  Test Lower Bound = -426.072, Test Loss = 426.072
[2018-06-04 20:50] Train Step 92025, Epoch 85.2, Batch Size = 256, Examples/Sec = 3840.26, Train LB = -347.172, Loss = 350.335
[2018-06-04 20:50] Train Step 92050, Epoch 85.2, Batch Size = 256, Examples/Sec = 3869.70, Train LB = -342.619, Loss = 348.335
[2018-06-04 20:50] Train Step 92075, Epoch 85.3, Batch Size = 256, Examples/Sec = 3812.25, Train LB = -352.075, Loss = 346.299
[2018-06-04 20:50] Train Step 92100, Epoch 85.3, Batch Size = 256, Examples/Sec = 3879.74, Train LB = -328.729, Loss = 344.790
[2018-06-04 20:50] Train Step 92125, Epoch 85.3, Batch Size = 256, Examples/Sec = 3867.43, Train LB = -365.695, Loss = 344.230
[2018-06-04 20:50] Train Step 92150, Epoch 85.3, Batch Size = 256, Examples/Sec = 3824.32, Train LB = -349.210, Loss = 344.861
[2018-06-04 20:50] Train Step 92175, Epoch 85.3, Batch Size = 256, Examples/Sec = 3807.14, Train LB = -345.354, Loss = 346.024
[2018-06-04 20:50] Train Step 92200, Epoch 85.4, Batch Size = 256, Examples/Sec = 3848.01, Train LB = -367.424, Loss = 349.854
Performance on test set:
  Test Lower Bound = -426.923, Test Loss = 426.923
[2018-06-04 20:50] Train Step 92225, Epoch 85.4, Batch Size = 256, Examples/Sec = 3879.91, Train LB = -338.586, Loss = 349.348
[2018-06-04 20:50] Train Step 92250, Epoch 85.4, Batch Size = 256, Examples/Sec = 3877.96, Train LB = -344.198, Loss = 347.952
[2018-06-04 20:50] Train Step 92275, Epoch 85.4, Batch Size = 256, Examples/Sec = 3857.23, Train LB = -325.896, Loss = 346.732
[2018-06-04 20:50] Train Step 92300, Epoch 85.5, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -344.878, Loss = 345.527
[2018-06-04 20:50] Train Step 92325, Epoch 85.5, Batch Size = 256, Examples/Sec = 3848.05, Train LB = -339.412, Loss = 344.960
[2018-06-04 20:50] Train Step 92350, Epoch 85.5, Batch Size = 256, Examples/Sec = 3872.80, Train LB = -347.889, Loss = 344.642
[2018-06-04 20:50] Train Step 92375, Epoch 85.5, Batch Size = 256, Examples/Sec = 3860.37, Train LB = -356.064, Loss = 345.717
[2018-06-04 20:50] Train Step 92400, Epoch 85.6, Batch Size = 256, Examples/Sec = 3753.94, Train LB = -372.609, Loss = 349.916
Performance on test set:
  Test Lower Bound = -426.538, Test Loss = 426.538
[2018-06-04 20:51] Train Step 92425, Epoch 85.6, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -341.431, Loss = 349.243
[2018-06-04 20:51] Train Step 92450, Epoch 85.6, Batch Size = 256, Examples/Sec = 3846.73, Train LB = -337.129, Loss = 347.015
[2018-06-04 20:51] Train Step 92475, Epoch 85.6, Batch Size = 256, Examples/Sec = 3841.54, Train LB = -334.149, Loss = 345.025
[2018-06-04 20:51] Train Step 92500, Epoch 85.6, Batch Size = 256, Examples/Sec = 3797.71, Train LB = -342.170, Loss = 344.135
[2018-06-04 20:51] Train Step 92525, Epoch 85.7, Batch Size = 256, Examples/Sec = 3850.10, Train LB = -353.741, Loss = 343.196
[2018-06-04 20:51] Train Step 92550, Epoch 85.7, Batch Size = 256, Examples/Sec = 3829.31, Train LB = -351.458, Loss = 344.000
[2018-06-04 20:51] Train Step 92575, Epoch 85.7, Batch Size = 256, Examples/Sec = 3874.27, Train LB = -358.039, Loss = 345.262
[2018-06-04 20:51] Train Step 92600, Epoch 85.7, Batch Size = 256, Examples/Sec = 3865.44, Train LB = -352.724, Loss = 349.900
Performance on test set:
  Test Lower Bound = -428.849, Test Loss = 428.849
[2018-06-04 20:51] Train Step 92625, Epoch 85.8, Batch Size = 256, Examples/Sec = 3855.00, Train LB = -336.681, Loss = 348.271
[2018-06-04 20:51] Train Step 92650, Epoch 85.8, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -351.979, Loss = 346.754
[2018-06-04 20:51] Train Step 92675, Epoch 85.8, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -343.667, Loss = 345.240
[2018-06-04 20:51] Train Step 92700, Epoch 85.8, Batch Size = 256, Examples/Sec = 3802.34, Train LB = -343.011, Loss = 344.961
[2018-06-04 20:51] Train Step 92725, Epoch 85.9, Batch Size = 256, Examples/Sec = 3854.89, Train LB = -338.956, Loss = 344.245
[2018-06-04 20:51] Train Step 92750, Epoch 85.9, Batch Size = 256, Examples/Sec = 3884.33, Train LB = -337.965, Loss = 344.949
[2018-06-04 20:51] Train Step 92775, Epoch 85.9, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -372.060, Loss = 345.823
[2018-06-04 20:51] Train Step 92800, Epoch 85.9, Batch Size = 256, Examples/Sec = 3813.61, Train LB = -376.348, Loss = 350.301
Performance on test set:
  Test Lower Bound = -427.089, Test Loss = 427.089
[2018-06-04 20:51] Train Step 92825, Epoch 85.9, Batch Size = 256, Examples/Sec = 3784.41, Train LB = -336.908, Loss = 348.999
[2018-06-04 20:51] Train Step 92850, Epoch 86.0, Batch Size = 256, Examples/Sec = 3862.23, Train LB = -344.172, Loss = 347.943
[2018-06-04 20:51] Train Step 92875, Epoch 86.0, Batch Size = 256, Examples/Sec = 3753.00, Train LB = -342.654, Loss = 345.555
[2018-06-04 20:51] Train Step 92900, Epoch 86.0, Batch Size = 256, Examples/Sec = 3862.70, Train LB = -350.999, Loss = 344.386
[2018-06-04 20:51] Train Step 92925, Epoch 86.0, Batch Size = 256, Examples/Sec = 3850.32, Train LB = -348.965, Loss = 344.486
[2018-06-04 20:51] Train Step 92950, Epoch 86.1, Batch Size = 256, Examples/Sec = 3862.28, Train LB = -341.861, Loss = 344.726
[2018-06-04 20:51] Train Step 92975, Epoch 86.1, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -359.677, Loss = 345.914
[2018-06-04 20:51] Train Step 93000, Epoch 86.1, Batch Size = 256, Examples/Sec = 3860.59, Train LB = -378.096, Loss = 350.104
Performance on test set:
  Test Lower Bound = -426.148, Test Loss = 426.148
[2018-06-04 20:51] Train Step 93025, Epoch 86.1, Batch Size = 256, Examples/Sec = 3859.04, Train LB = -340.101, Loss = 348.904
[2018-06-04 20:51] Train Step 93050, Epoch 86.2, Batch Size = 256, Examples/Sec = 3844.94, Train LB = -328.241, Loss = 347.307
[2018-06-04 20:51] Train Step 93075, Epoch 86.2, Batch Size = 256, Examples/Sec = 3844.42, Train LB = -326.764, Loss = 345.678
[2018-06-04 20:51] Train Step 93100, Epoch 86.2, Batch Size = 256, Examples/Sec = 3857.80, Train LB = -354.155, Loss = 344.139
[2018-06-04 20:52] Train Step 93125, Epoch 86.2, Batch Size = 256, Examples/Sec = 3869.06, Train LB = -334.129, Loss = 343.746
[2018-06-04 20:52] Train Step 93150, Epoch 86.2, Batch Size = 256, Examples/Sec = 3861.12, Train LB = -338.411, Loss = 344.215
[2018-06-04 20:52] Train Step 93175, Epoch 86.3, Batch Size = 256, Examples/Sec = 3808.11, Train LB = -346.909, Loss = 345.435
[2018-06-04 20:52] Train Step 93200, Epoch 86.3, Batch Size = 256, Examples/Sec = 3808.80, Train LB = -371.998, Loss = 350.584
Performance on test set:
  Test Lower Bound = -426.618, Test Loss = 426.618
[2018-06-04 20:52] Train Step 93225, Epoch 86.3, Batch Size = 256, Examples/Sec = 3871.28, Train LB = -338.240, Loss = 349.142
[2018-06-04 20:52] Train Step 93250, Epoch 86.3, Batch Size = 256, Examples/Sec = 3860.84, Train LB = -330.738, Loss = 347.737
[2018-06-04 20:52] Train Step 93275, Epoch 86.4, Batch Size = 256, Examples/Sec = 3865.04, Train LB = -331.494, Loss = 346.861
[2018-06-04 20:52] Train Step 93300, Epoch 86.4, Batch Size = 256, Examples/Sec = 3852.47, Train LB = -361.332, Loss = 345.647
[2018-06-04 20:52] Train Step 93325, Epoch 86.4, Batch Size = 256, Examples/Sec = 3864.80, Train LB = -339.696, Loss = 344.966
[2018-06-04 20:52] Train Step 93350, Epoch 86.4, Batch Size = 256, Examples/Sec = 3866.07, Train LB = -349.053, Loss = 345.663
[2018-06-04 20:52] Train Step 93375, Epoch 86.5, Batch Size = 256, Examples/Sec = 3856.07, Train LB = -349.022, Loss = 346.602
[2018-06-04 20:52] Train Step 93400, Epoch 86.5, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -368.241, Loss = 350.831
Performance on test set:
  Test Lower Bound = -427.757, Test Loss = 427.757
[2018-06-04 20:52] Train Step 93425, Epoch 86.5, Batch Size = 256, Examples/Sec = 3790.18, Train LB = -338.960, Loss = 349.688
[2018-06-04 20:52] Train Step 93450, Epoch 86.5, Batch Size = 256, Examples/Sec = 3869.59, Train LB = -343.732, Loss = 348.023
[2018-06-04 20:52] Train Step 93475, Epoch 86.6, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -347.502, Loss = 346.566
[2018-06-04 20:52] Train Step 93500, Epoch 86.6, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -340.379, Loss = 345.818
[2018-06-04 20:52] Train Step 93525, Epoch 86.6, Batch Size = 256, Examples/Sec = 3849.75, Train LB = -364.499, Loss = 344.387
[2018-06-04 20:52] Train Step 93550, Epoch 86.6, Batch Size = 256, Examples/Sec = 3850.55, Train LB = -336.092, Loss = 344.518
[2018-06-04 20:52] Train Step 93575, Epoch 86.6, Batch Size = 256, Examples/Sec = 3812.58, Train LB = -367.464, Loss = 346.135
[2018-06-04 20:52] Train Step 93600, Epoch 86.7, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -390.718, Loss = 350.703
Performance on test set:
  Test Lower Bound = -426.037, Test Loss = 426.037
[2018-06-04 20:52] Train Step 93625, Epoch 86.7, Batch Size = 256, Examples/Sec = 3886.14, Train LB = -338.418, Loss = 349.864
[2018-06-04 20:52] Train Step 93650, Epoch 86.7, Batch Size = 256, Examples/Sec = 3841.14, Train LB = -332.559, Loss = 348.037
[2018-06-04 20:52] Train Step 93675, Epoch 86.7, Batch Size = 256, Examples/Sec = 3740.23, Train LB = -340.381, Loss = 346.179
[2018-06-04 20:52] Train Step 93700, Epoch 86.8, Batch Size = 256, Examples/Sec = 3853.80, Train LB = -336.437, Loss = 345.130
[2018-06-04 20:52] Train Step 93725, Epoch 86.8, Batch Size = 256, Examples/Sec = 3869.94, Train LB = -343.067, Loss = 344.792
[2018-06-04 20:52] Train Step 93750, Epoch 86.8, Batch Size = 256, Examples/Sec = 3738.32, Train LB = -352.117, Loss = 344.764
[2018-06-04 20:52] Train Step 93775, Epoch 86.8, Batch Size = 256, Examples/Sec = 3850.73, Train LB = -359.093, Loss = 345.592
[2018-06-04 20:52] Train Step 93800, Epoch 86.9, Batch Size = 256, Examples/Sec = 3849.85, Train LB = -373.430, Loss = 350.028
Performance on test set:
  Test Lower Bound = -427.088, Test Loss = 427.088
[2018-06-04 20:53] Train Step 93825, Epoch 86.9, Batch Size = 256, Examples/Sec = 3856.53, Train LB = -347.194, Loss = 349.322
[2018-06-04 20:53] Train Step 93850, Epoch 86.9, Batch Size = 256, Examples/Sec = 3863.69, Train LB = -324.796, Loss = 348.020
[2018-06-04 20:53] Train Step 93875, Epoch 86.9, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -335.572, Loss = 345.472
[2018-06-04 20:53] Train Step 93900, Epoch 86.9, Batch Size = 256, Examples/Sec = 3848.18, Train LB = -356.689, Loss = 344.358
[2018-06-04 20:53] Train Step 93925, Epoch 87.0, Batch Size = 256, Examples/Sec = 3858.84, Train LB = -338.614, Loss = 344.176
[2018-06-04 20:53] Train Step 93950, Epoch 87.0, Batch Size = 256, Examples/Sec = 3862.76, Train LB = -326.017, Loss = 345.219
[2018-06-04 20:53] Train Step 93975, Epoch 87.0, Batch Size = 256, Examples/Sec = 3887.33, Train LB = -349.390, Loss = 346.166
[2018-06-04 20:53] Train Step 94000, Epoch 87.0, Batch Size = 256, Examples/Sec = 3837.04, Train LB = -380.406, Loss = 350.365
Performance on test set:
  Test Lower Bound = -427.215, Test Loss = 427.215
[2018-06-04 20:53] Train Step 94025, Epoch 87.1, Batch Size = 256, Examples/Sec = 3853.74, Train LB = -343.314, Loss = 349.006
[2018-06-04 20:53] Train Step 94050, Epoch 87.1, Batch Size = 256, Examples/Sec = 3860.37, Train LB = -343.166, Loss = 347.959
[2018-06-04 20:53] Train Step 94075, Epoch 87.1, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -345.736, Loss = 345.834
[2018-06-04 20:53] Train Step 94100, Epoch 87.1, Batch Size = 256, Examples/Sec = 3858.33, Train LB = -324.973, Loss = 344.488
[2018-06-04 20:53] Train Step 94125, Epoch 87.2, Batch Size = 256, Examples/Sec = 3866.25, Train LB = -349.858, Loss = 344.154
[2018-06-04 20:53] Train Step 94150, Epoch 87.2, Batch Size = 256, Examples/Sec = 3798.85, Train LB = -339.379, Loss = 344.595
[2018-06-04 20:53] Train Step 94175, Epoch 87.2, Batch Size = 256, Examples/Sec = 3859.09, Train LB = -358.493, Loss = 346.651
[2018-06-04 20:53] Train Step 94200, Epoch 87.2, Batch Size = 256, Examples/Sec = 3850.37, Train LB = -388.185, Loss = 350.793
Performance on test set:
  Test Lower Bound = -427.351, Test Loss = 427.351
[2018-06-04 20:53] Train Step 94225, Epoch 87.2, Batch Size = 256, Examples/Sec = 3854.89, Train LB = -341.487, Loss = 350.136
[2018-06-04 20:53] Train Step 94250, Epoch 87.3, Batch Size = 256, Examples/Sec = 3813.95, Train LB = -352.263, Loss = 347.889
[2018-06-04 20:53] Train Step 94275, Epoch 87.3, Batch Size = 256, Examples/Sec = 3841.19, Train LB = -358.365, Loss = 346.121
[2018-06-04 20:53] Train Step 94300, Epoch 87.3, Batch Size = 256, Examples/Sec = 3873.28, Train LB = -339.324, Loss = 345.103
[2018-06-04 20:53] Train Step 94325, Epoch 87.3, Batch Size = 256, Examples/Sec = 3847.89, Train LB = -347.796, Loss = 344.731
[2018-06-04 20:53] Train Step 94350, Epoch 87.4, Batch Size = 256, Examples/Sec = 3847.65, Train LB = -340.028, Loss = 344.799
[2018-06-04 20:53] Train Step 94375, Epoch 87.4, Batch Size = 256, Examples/Sec = 3876.31, Train LB = -369.852, Loss = 345.493
[2018-06-04 20:53] Train Step 94400, Epoch 87.4, Batch Size = 256, Examples/Sec = 3868.11, Train LB = -374.038, Loss = 350.301
Performance on test set:
  Test Lower Bound = -428.177, Test Loss = 428.177
[2018-06-04 20:53] Train Step 94425, Epoch 87.4, Batch Size = 256, Examples/Sec = 3860.83, Train LB = -332.517, Loss = 349.337
[2018-06-04 20:53] Train Step 94450, Epoch 87.5, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -335.462, Loss = 347.398
[2018-06-04 20:53] Train Step 94475, Epoch 87.5, Batch Size = 256, Examples/Sec = 3732.55, Train LB = -345.774, Loss = 345.723
[2018-06-04 20:53] Train Step 94500, Epoch 87.5, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -343.788, Loss = 344.841
[2018-06-04 20:53] Train Step 94525, Epoch 87.5, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -346.741, Loss = 344.407
[2018-06-04 20:54] Train Step 94550, Epoch 87.5, Batch Size = 256, Examples/Sec = 3722.83, Train LB = -362.116, Loss = 345.081
[2018-06-04 20:54] Train Step 94575, Epoch 87.6, Batch Size = 256, Examples/Sec = 3870.22, Train LB = -367.236, Loss = 346.222
[2018-06-04 20:54] Train Step 94600, Epoch 87.6, Batch Size = 256, Examples/Sec = 3869.59, Train LB = -366.158, Loss = 350.222
Performance on test set:
  Test Lower Bound = -429.447, Test Loss = 429.447
[2018-06-04 20:54] Train Step 94625, Epoch 87.6, Batch Size = 256, Examples/Sec = 3843.84, Train LB = -326.906, Loss = 349.316
[2018-06-04 20:54] Train Step 94650, Epoch 87.6, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -333.049, Loss = 347.228
[2018-06-04 20:54] Train Step 94675, Epoch 87.7, Batch Size = 256, Examples/Sec = 3844.42, Train LB = -346.034, Loss = 345.907
[2018-06-04 20:54] Train Step 94700, Epoch 87.7, Batch Size = 256, Examples/Sec = 3836.64, Train LB = -327.826, Loss = 345.027
[2018-06-04 20:54] Train Step 94725, Epoch 87.7, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -340.687, Loss = 343.538
[2018-06-04 20:54] Train Step 94750, Epoch 87.7, Batch Size = 256, Examples/Sec = 3870.99, Train LB = -355.524, Loss = 344.361
[2018-06-04 20:54] Train Step 94775, Epoch 87.8, Batch Size = 256, Examples/Sec = 3860.02, Train LB = -351.076, Loss = 345.952
[2018-06-04 20:54] Train Step 94800, Epoch 87.8, Batch Size = 256, Examples/Sec = 3873.16, Train LB = -371.019, Loss = 350.428
Performance on test set:
  Test Lower Bound = -426.466, Test Loss = 426.466
[2018-06-04 20:54] Train Step 94825, Epoch 87.8, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -334.369, Loss = 349.004
[2018-06-04 20:54] Train Step 94850, Epoch 87.8, Batch Size = 256, Examples/Sec = 3850.08, Train LB = -331.108, Loss = 347.608
[2018-06-04 20:54] Train Step 94875, Epoch 87.8, Batch Size = 256, Examples/Sec = 3808.61, Train LB = -355.265, Loss = 345.721
[2018-06-04 20:54] Train Step 94900, Epoch 87.9, Batch Size = 256, Examples/Sec = 3865.84, Train LB = -348.705, Loss = 344.566
[2018-06-04 20:54] Train Step 94925, Epoch 87.9, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -336.009, Loss = 344.081
[2018-06-04 20:54] Train Step 94950, Epoch 87.9, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -362.720, Loss = 344.651
[2018-06-04 20:54] Train Step 94975, Epoch 87.9, Batch Size = 256, Examples/Sec = 3866.66, Train LB = -360.397, Loss = 346.020
[2018-06-04 20:54] Train Step 95000, Epoch 88.0, Batch Size = 256, Examples/Sec = 3882.80, Train LB = -376.902, Loss = 350.041
Performance on test set:
  Test Lower Bound = -428.838, Test Loss = 428.838
[2018-06-04 20:54] Train Step 95025, Epoch 88.0, Batch Size = 256, Examples/Sec = 3855.53, Train LB = -349.927, Loss = 349.301
[2018-06-04 20:54] Train Step 95050, Epoch 88.0, Batch Size = 256, Examples/Sec = 3852.06, Train LB = -349.883, Loss = 347.269
[2018-06-04 20:54] Train Step 95075, Epoch 88.0, Batch Size = 256, Examples/Sec = 3842.86, Train LB = -327.393, Loss = 345.733
[2018-06-04 20:54] Train Step 95100, Epoch 88.1, Batch Size = 256, Examples/Sec = 3858.16, Train LB = -325.202, Loss = 344.937
[2018-06-04 20:54] Train Step 95125, Epoch 88.1, Batch Size = 256, Examples/Sec = 3870.69, Train LB = -347.356, Loss = 343.640
[2018-06-04 20:54] Train Step 95150, Epoch 88.1, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -339.814, Loss = 344.020
[2018-06-04 20:54] Train Step 95175, Epoch 88.1, Batch Size = 256, Examples/Sec = 3860.55, Train LB = -357.100, Loss = 346.339
[2018-06-04 20:54] Train Step 95200, Epoch 88.1, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -372.711, Loss = 350.361
Performance on test set:
  Test Lower Bound = -426.534, Test Loss = 426.534
[2018-06-04 20:54] Train Step 95225, Epoch 88.2, Batch Size = 256, Examples/Sec = 3850.37, Train LB = -320.167, Loss = 348.991
[2018-06-04 20:55] Train Step 95250, Epoch 88.2, Batch Size = 256, Examples/Sec = 3862.99, Train LB = -356.882, Loss = 346.879
[2018-06-04 20:55] Train Step 95275, Epoch 88.2, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -334.346, Loss = 345.720
[2018-06-04 20:55] Train Step 95300, Epoch 88.2, Batch Size = 256, Examples/Sec = 3865.44, Train LB = -347.469, Loss = 345.002
[2018-06-04 20:55] Train Step 95325, Epoch 88.3, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -342.938, Loss = 344.143
[2018-06-04 20:55] Train Step 95350, Epoch 88.3, Batch Size = 256, Examples/Sec = 3731.07, Train LB = -342.256, Loss = 344.762
[2018-06-04 20:55] Train Step 95375, Epoch 88.3, Batch Size = 256, Examples/Sec = 3847.78, Train LB = -345.979, Loss = 346.190
[2018-06-04 20:55] Train Step 95400, Epoch 88.3, Batch Size = 256, Examples/Sec = 3845.99, Train LB = -398.728, Loss = 349.523
Performance on test set:
  Test Lower Bound = -429.661, Test Loss = 429.661
[2018-06-04 20:55] Train Step 95425, Epoch 88.4, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -342.685, Loss = 349.193
[2018-06-04 20:55] Train Step 95450, Epoch 88.4, Batch Size = 256, Examples/Sec = 3839.29, Train LB = -332.626, Loss = 347.326
[2018-06-04 20:55] Train Step 95475, Epoch 88.4, Batch Size = 256, Examples/Sec = 3861.52, Train LB = -367.527, Loss = 345.223
[2018-06-04 20:55] Train Step 95500, Epoch 88.4, Batch Size = 256, Examples/Sec = 3856.29, Train LB = -331.823, Loss = 344.207
[2018-06-04 20:55] Train Step 95525, Epoch 88.4, Batch Size = 256, Examples/Sec = 3863.87, Train LB = -345.113, Loss = 343.484
[2018-06-04 20:55] Train Step 95550, Epoch 88.5, Batch Size = 256, Examples/Sec = 3815.43, Train LB = -354.443, Loss = 343.405
[2018-06-04 20:55] Train Step 95575, Epoch 88.5, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -366.020, Loss = 345.559
[2018-06-04 20:55] Train Step 95600, Epoch 88.5, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -374.181, Loss = 349.810
Performance on test set:
  Test Lower Bound = -427.270, Test Loss = 427.270
[2018-06-04 20:55] Train Step 95625, Epoch 88.5, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -332.541, Loss = 349.048
[2018-06-04 20:55] Train Step 95650, Epoch 88.6, Batch Size = 256, Examples/Sec = 3850.66, Train LB = -339.373, Loss = 347.728
[2018-06-04 20:55] Train Step 95675, Epoch 88.6, Batch Size = 256, Examples/Sec = 3855.89, Train LB = -339.869, Loss = 345.828
[2018-06-04 20:55] Train Step 95700, Epoch 88.6, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -335.991, Loss = 345.346
[2018-06-04 20:55] Train Step 95725, Epoch 88.6, Batch Size = 256, Examples/Sec = 3847.60, Train LB = -338.754, Loss = 343.803
[2018-06-04 20:55] Train Step 95750, Epoch 88.7, Batch Size = 256, Examples/Sec = 3883.67, Train LB = -340.986, Loss = 343.448
[2018-06-04 20:55] Train Step 95775, Epoch 88.7, Batch Size = 256, Examples/Sec = 3837.45, Train LB = -354.193, Loss = 345.880
[2018-06-04 20:55] Train Step 95800, Epoch 88.7, Batch Size = 256, Examples/Sec = 3833.31, Train LB = -366.141, Loss = 349.828
Performance on test set:
  Test Lower Bound = -427.735, Test Loss = 427.735
[2018-06-04 20:55] Train Step 95825, Epoch 88.7, Batch Size = 256, Examples/Sec = 3843.38, Train LB = -326.922, Loss = 348.307
[2018-06-04 20:55] Train Step 95850, Epoch 88.8, Batch Size = 256, Examples/Sec = 3882.60, Train LB = -351.260, Loss = 347.248
[2018-06-04 20:55] Train Step 95875, Epoch 88.8, Batch Size = 256, Examples/Sec = 3854.38, Train LB = -355.350, Loss = 345.506
[2018-06-04 20:55] Train Step 95900, Epoch 88.8, Batch Size = 256, Examples/Sec = 3872.28, Train LB = -345.840, Loss = 344.848
[2018-06-04 20:55] Train Step 95925, Epoch 88.8, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -355.162, Loss = 344.237
[2018-06-04 20:55] Train Step 95950, Epoch 88.8, Batch Size = 256, Examples/Sec = 3868.29, Train LB = -362.235, Loss = 344.046
[2018-06-04 20:56] Train Step 95975, Epoch 88.9, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -362.449, Loss = 346.115
[2018-06-04 20:56] Train Step 96000, Epoch 88.9, Batch Size = 256, Examples/Sec = 3858.44, Train LB = -377.864, Loss = 349.799
Performance on test set:
  Test Lower Bound = -429.259, Test Loss = 429.259
[2018-06-04 20:56] Train Step 96025, Epoch 88.9, Batch Size = 256, Examples/Sec = 3843.27, Train LB = -335.127, Loss = 348.274
[2018-06-04 20:56] Train Step 96050, Epoch 88.9, Batch Size = 256, Examples/Sec = 3845.57, Train LB = -320.674, Loss = 347.314
[2018-06-04 20:56] Train Step 96075, Epoch 89.0, Batch Size = 256, Examples/Sec = 3822.38, Train LB = -334.277, Loss = 345.018
[2018-06-04 20:56] Train Step 96100, Epoch 89.0, Batch Size = 256, Examples/Sec = 3870.80, Train LB = -343.572, Loss = 343.541
[2018-06-04 20:56] Train Step 96125, Epoch 89.0, Batch Size = 256, Examples/Sec = 3836.24, Train LB = -325.813, Loss = 342.843
[2018-06-04 20:56] Train Step 96150, Epoch 89.0, Batch Size = 256, Examples/Sec = 3797.76, Train LB = -357.022, Loss = 342.721
[2018-06-04 20:56] Train Step 96175, Epoch 89.1, Batch Size = 256, Examples/Sec = 3810.49, Train LB = -362.406, Loss = 345.044
[2018-06-04 20:56] Train Step 96200, Epoch 89.1, Batch Size = 256, Examples/Sec = 3835.72, Train LB = -376.029, Loss = 349.001
Performance on test set:
  Test Lower Bound = -427.467, Test Loss = 427.467
[2018-06-04 20:56] Train Step 96225, Epoch 89.1, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -345.034, Loss = 347.901
[2018-06-04 20:56] Train Step 96250, Epoch 89.1, Batch Size = 256, Examples/Sec = 3854.89, Train LB = -333.712, Loss = 346.007
[2018-06-04 20:56] Train Step 96275, Epoch 89.1, Batch Size = 256, Examples/Sec = 3852.69, Train LB = -322.049, Loss = 345.137
[2018-06-04 20:56] Train Step 96300, Epoch 89.2, Batch Size = 256, Examples/Sec = 3845.17, Train LB = -332.751, Loss = 343.696
[2018-06-04 20:56] Train Step 96325, Epoch 89.2, Batch Size = 256, Examples/Sec = 3842.86, Train LB = -339.463, Loss = 342.736
[2018-06-04 20:56] Train Step 96350, Epoch 89.2, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -341.373, Loss = 343.601
[2018-06-04 20:56] Train Step 96375, Epoch 89.2, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -354.441, Loss = 345.107
[2018-06-04 20:56] Train Step 96400, Epoch 89.3, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -369.298, Loss = 349.693
Performance on test set:
  Test Lower Bound = -429.391, Test Loss = 429.391
[2018-06-04 20:56] Train Step 96425, Epoch 89.3, Batch Size = 256, Examples/Sec = 3852.22, Train LB = -344.902, Loss = 348.142
[2018-06-04 20:56] Train Step 96450, Epoch 89.3, Batch Size = 256, Examples/Sec = 3849.85, Train LB = -356.131, Loss = 346.680
[2018-06-04 20:56] Train Step 96475, Epoch 89.3, Batch Size = 256, Examples/Sec = 3858.15, Train LB = -331.725, Loss = 345.612
[2018-06-04 20:56] Train Step 96500, Epoch 89.4, Batch Size = 256, Examples/Sec = 3842.35, Train LB = -331.909, Loss = 344.960
[2018-06-04 20:56] Train Step 96525, Epoch 89.4, Batch Size = 256, Examples/Sec = 3878.68, Train LB = -350.634, Loss = 344.626
[2018-06-04 20:56] Train Step 96550, Epoch 89.4, Batch Size = 256, Examples/Sec = 3855.47, Train LB = -351.466, Loss = 344.738
[2018-06-04 20:56] Train Step 96575, Epoch 89.4, Batch Size = 256, Examples/Sec = 3880.74, Train LB = -355.397, Loss = 346.144
[2018-06-04 20:56] Train Step 96600, Epoch 89.4, Batch Size = 256, Examples/Sec = 3866.08, Train LB = -373.518, Loss = 350.323
Performance on test set:
  Test Lower Bound = -426.887, Test Loss = 426.887
[2018-06-04 20:56] Train Step 96625, Epoch 89.5, Batch Size = 256, Examples/Sec = 3801.43, Train LB = -340.884, Loss = 349.098
[2018-06-04 20:56] Train Step 96650, Epoch 89.5, Batch Size = 256, Examples/Sec = 3855.82, Train LB = -337.236, Loss = 347.439
[2018-06-04 20:57] Train Step 96675, Epoch 89.5, Batch Size = 256, Examples/Sec = 3852.80, Train LB = -335.842, Loss = 344.936
[2018-06-04 20:57] Train Step 96700, Epoch 89.5, Batch Size = 256, Examples/Sec = 3870.16, Train LB = -359.380, Loss = 343.261
[2018-06-04 20:57] Train Step 96725, Epoch 89.6, Batch Size = 256, Examples/Sec = 3872.10, Train LB = -334.162, Loss = 342.804
[2018-06-04 20:57] Train Step 96750, Epoch 89.6, Batch Size = 256, Examples/Sec = 3841.71, Train LB = -369.434, Loss = 343.445
[2018-06-04 20:57] Train Step 96775, Epoch 89.6, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -369.674, Loss = 345.677
[2018-06-04 20:57] Train Step 96800, Epoch 89.6, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -366.517, Loss = 349.511
Performance on test set:
  Test Lower Bound = -429.191, Test Loss = 429.191
[2018-06-04 20:57] Train Step 96825, Epoch 89.7, Batch Size = 256, Examples/Sec = 3866.26, Train LB = -334.522, Loss = 348.463
[2018-06-04 20:57] Train Step 96850, Epoch 89.7, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -335.136, Loss = 347.446
[2018-06-04 20:57] Train Step 96875, Epoch 89.7, Batch Size = 256, Examples/Sec = 3716.35, Train LB = -338.098, Loss = 345.581
[2018-06-04 20:57] Train Step 96900, Epoch 89.7, Batch Size = 256, Examples/Sec = 3852.69, Train LB = -352.649, Loss = 343.962
[2018-06-04 20:57] Train Step 96925, Epoch 89.7, Batch Size = 256, Examples/Sec = 3838.19, Train LB = -330.432, Loss = 342.879
[2018-06-04 20:57] Train Step 96950, Epoch 89.8, Batch Size = 256, Examples/Sec = 3708.70, Train LB = -345.175, Loss = 343.236
[2018-06-04 20:57] Train Step 96975, Epoch 89.8, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -357.121, Loss = 345.025
[2018-06-04 20:57] Train Step 97000, Epoch 89.8, Batch Size = 256, Examples/Sec = 3863.62, Train LB = -369.134, Loss = 349.082
Performance on test set:
  Test Lower Bound = -429.349, Test Loss = 429.349
[2018-06-04 20:57] Train Step 97025, Epoch 89.8, Batch Size = 256, Examples/Sec = 3839.40, Train LB = -327.931, Loss = 348.010
[2018-06-04 20:57] Train Step 97050, Epoch 89.9, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -339.765, Loss = 346.512
[2018-06-04 20:57] Train Step 97075, Epoch 89.9, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -338.620, Loss = 345.279
[2018-06-04 20:57] Train Step 97100, Epoch 89.9, Batch Size = 256, Examples/Sec = 3876.32, Train LB = -329.012, Loss = 344.119
[2018-06-04 20:57] Train Step 97125, Epoch 89.9, Batch Size = 256, Examples/Sec = 3839.29, Train LB = -333.259, Loss = 342.812
[2018-06-04 20:57] Train Step 97150, Epoch 90.0, Batch Size = 256, Examples/Sec = 3834.75, Train LB = -345.899, Loss = 343.167
[2018-06-04 20:57] Train Step 97175, Epoch 90.0, Batch Size = 256, Examples/Sec = 3856.40, Train LB = -365.170, Loss = 345.811
[2018-06-04 20:57] Train Step 97200, Epoch 90.0, Batch Size = 256, Examples/Sec = 3866.55, Train LB = -362.852, Loss = 350.035
Performance on test set:
  Test Lower Bound = -428.474, Test Loss = 428.474
[2018-06-04 20:57] Train Step 97225, Epoch 90.0, Batch Size = 256, Examples/Sec = 3866.78, Train LB = -338.102, Loss = 348.053
[2018-06-04 20:57] Train Step 97250, Epoch 90.0, Batch Size = 256, Examples/Sec = 3861.52, Train LB = -336.934, Loss = 346.463
[2018-06-04 20:57] Train Step 97275, Epoch 90.1, Batch Size = 256, Examples/Sec = 3852.58, Train LB = -341.304, Loss = 345.783
[2018-06-04 20:57] Train Step 97300, Epoch 90.1, Batch Size = 256, Examples/Sec = 3861.01, Train LB = -336.026, Loss = 343.818
[2018-06-04 20:57] Train Step 97325, Epoch 90.1, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -342.919, Loss = 343.521
[2018-06-04 20:57] Train Step 97350, Epoch 90.1, Batch Size = 256, Examples/Sec = 3795.23, Train LB = -362.158, Loss = 344.222
[2018-06-04 20:57] Train Step 97375, Epoch 90.2, Batch Size = 256, Examples/Sec = 3813.33, Train LB = -353.598, Loss = 346.493
[2018-06-04 20:57] Train Step 97400, Epoch 90.2, Batch Size = 256, Examples/Sec = 3875.55, Train LB = -384.740, Loss = 349.830
Performance on test set:
  Test Lower Bound = -428.950, Test Loss = 428.950
[2018-06-04 20:58] Train Step 97425, Epoch 90.2, Batch Size = 256, Examples/Sec = 3741.21, Train LB = -339.442, Loss = 348.348
[2018-06-04 20:58] Train Step 97450, Epoch 90.2, Batch Size = 256, Examples/Sec = 3837.63, Train LB = -332.033, Loss = 346.905
[2018-06-04 20:58] Train Step 97475, Epoch 90.3, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -337.773, Loss = 345.221
[2018-06-04 20:58] Train Step 97500, Epoch 90.3, Batch Size = 256, Examples/Sec = 3785.42, Train LB = -324.842, Loss = 344.232
[2018-06-04 20:58] Train Step 97525, Epoch 90.3, Batch Size = 256, Examples/Sec = 3870.22, Train LB = -327.538, Loss = 343.329
[2018-06-04 20:58] Train Step 97550, Epoch 90.3, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -366.437, Loss = 342.808
[2018-06-04 20:58] Train Step 97575, Epoch 90.3, Batch Size = 256, Examples/Sec = 3871.57, Train LB = -368.435, Loss = 344.545
[2018-06-04 20:58] Train Step 97600, Epoch 90.4, Batch Size = 256, Examples/Sec = 3857.51, Train LB = -375.759, Loss = 348.296
Performance on test set:
  Test Lower Bound = -429.831, Test Loss = 429.831
[2018-06-04 20:58] Train Step 97625, Epoch 90.4, Batch Size = 256, Examples/Sec = 3849.39, Train LB = -347.531, Loss = 347.090
[2018-06-04 20:58] Train Step 97650, Epoch 90.4, Batch Size = 256, Examples/Sec = 3871.75, Train LB = -327.284, Loss = 345.474
[2018-06-04 20:58] Train Step 97675, Epoch 90.4, Batch Size = 256, Examples/Sec = 3872.80, Train LB = -325.078, Loss = 344.379
[2018-06-04 20:58] Train Step 97700, Epoch 90.5, Batch Size = 256, Examples/Sec = 3852.80, Train LB = -349.185, Loss = 343.198
[2018-06-04 20:58] Train Step 97725, Epoch 90.5, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -338.295, Loss = 343.274
[2018-06-04 20:58] Train Step 97750, Epoch 90.5, Batch Size = 256, Examples/Sec = 3792.83, Train LB = -340.302, Loss = 343.700
[2018-06-04 20:58] Train Step 97775, Epoch 90.5, Batch Size = 256, Examples/Sec = 3875.04, Train LB = -355.357, Loss = 345.034
[2018-06-04 20:58] Train Step 97800, Epoch 90.6, Batch Size = 256, Examples/Sec = 3839.06, Train LB = -377.172, Loss = 348.864
Performance on test set:
  Test Lower Bound = -427.766, Test Loss = 427.766
[2018-06-04 20:58] Train Step 97825, Epoch 90.6, Batch Size = 256, Examples/Sec = 3847.67, Train LB = -342.169, Loss = 347.762
[2018-06-04 20:58] Train Step 97850, Epoch 90.6, Batch Size = 256, Examples/Sec = 3891.17, Train LB = -339.258, Loss = 346.843
[2018-06-04 20:58] Train Step 97875, Epoch 90.6, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -343.450, Loss = 345.411
[2018-06-04 20:58] Train Step 97900, Epoch 90.6, Batch Size = 256, Examples/Sec = 3793.94, Train LB = -329.700, Loss = 344.453
[2018-06-04 20:58] Train Step 97925, Epoch 90.7, Batch Size = 256, Examples/Sec = 3811.79, Train LB = -337.247, Loss = 343.368
[2018-06-04 20:58] Train Step 97950, Epoch 90.7, Batch Size = 256, Examples/Sec = 3855.13, Train LB = -331.488, Loss = 343.345
[2018-06-04 20:58] Train Step 97975, Epoch 90.7, Batch Size = 256, Examples/Sec = 3863.51, Train LB = -348.852, Loss = 344.675
[2018-06-04 20:58] Train Step 98000, Epoch 90.7, Batch Size = 256, Examples/Sec = 3794.56, Train LB = -373.262, Loss = 348.774
Performance on test set:
  Test Lower Bound = -425.486, Test Loss = 425.486
[2018-06-04 20:58] Train Step 98025, Epoch 90.8, Batch Size = 256, Examples/Sec = 3837.45, Train LB = -344.235, Loss = 347.669
[2018-06-04 20:58] Train Step 98050, Epoch 90.8, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -324.130, Loss = 345.714
[2018-06-04 20:58] Train Step 98075, Epoch 90.8, Batch Size = 256, Examples/Sec = 3836.35, Train LB = -347.159, Loss = 344.344
[2018-06-04 20:58] Train Step 98100, Epoch 90.8, Batch Size = 256, Examples/Sec = 3875.79, Train LB = -354.545, Loss = 343.175
[2018-06-04 20:59] Train Step 98125, Epoch 90.9, Batch Size = 256, Examples/Sec = 3850.95, Train LB = -345.693, Loss = 342.984
[2018-06-04 20:59] Train Step 98150, Epoch 90.9, Batch Size = 256, Examples/Sec = 3844.07, Train LB = -348.263, Loss = 343.457
[2018-06-04 20:59] Train Step 98175, Epoch 90.9, Batch Size = 256, Examples/Sec = 3854.33, Train LB = -345.484, Loss = 345.383
[2018-06-04 20:59] Train Step 98200, Epoch 90.9, Batch Size = 256, Examples/Sec = 3857.16, Train LB = -371.163, Loss = 349.206
Performance on test set:
  Test Lower Bound = -428.253, Test Loss = 428.253
[2018-06-04 20:59] Train Step 98225, Epoch 90.9, Batch Size = 256, Examples/Sec = 3749.60, Train LB = -355.218, Loss = 347.944
[2018-06-04 20:59] Train Step 98250, Epoch 91.0, Batch Size = 256, Examples/Sec = 3860.42, Train LB = -341.272, Loss = 346.253
[2018-06-04 20:59] Train Step 98275, Epoch 91.0, Batch Size = 256, Examples/Sec = 3841.83, Train LB = -333.117, Loss = 345.282
[2018-06-04 20:59] Train Step 98300, Epoch 91.0, Batch Size = 256, Examples/Sec = 3817.25, Train LB = -338.783, Loss = 344.067
[2018-06-04 20:59] Train Step 98325, Epoch 91.0, Batch Size = 256, Examples/Sec = 3843.03, Train LB = -366.470, Loss = 342.834
[2018-06-04 20:59] Train Step 98350, Epoch 91.1, Batch Size = 256, Examples/Sec = 3824.33, Train LB = -347.356, Loss = 343.232
[2018-06-04 20:59] Train Step 98375, Epoch 91.1, Batch Size = 256, Examples/Sec = 3869.63, Train LB = -364.333, Loss = 344.846
[2018-06-04 20:59] Train Step 98400, Epoch 91.1, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -374.858, Loss = 348.832
Performance on test set:
  Test Lower Bound = -428.631, Test Loss = 428.631
[2018-06-04 20:59] Train Step 98425, Epoch 91.1, Batch Size = 256, Examples/Sec = 3860.13, Train LB = -346.592, Loss = 348.263
[2018-06-04 20:59] Train Step 98450, Epoch 91.2, Batch Size = 256, Examples/Sec = 3845.28, Train LB = -340.487, Loss = 346.425
[2018-06-04 20:59] Train Step 98475, Epoch 91.2, Batch Size = 256, Examples/Sec = 3854.91, Train LB = -346.765, Loss = 344.314
[2018-06-04 20:59] Train Step 98500, Epoch 91.2, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -332.249, Loss = 344.157
[2018-06-04 20:59] Train Step 98525, Epoch 91.2, Batch Size = 256, Examples/Sec = 3857.27, Train LB = -333.610, Loss = 343.611
[2018-06-04 20:59] Train Step 98550, Epoch 91.2, Batch Size = 256, Examples/Sec = 3798.34, Train LB = -345.058, Loss = 343.649
[2018-06-04 20:59] Train Step 98575, Epoch 91.3, Batch Size = 256, Examples/Sec = 3876.56, Train LB = -349.697, Loss = 344.900
[2018-06-04 20:59] Train Step 98600, Epoch 91.3, Batch Size = 256, Examples/Sec = 3864.49, Train LB = -378.513, Loss = 349.229
Performance on test set:
  Test Lower Bound = -429.237, Test Loss = 429.237
[2018-06-04 20:59] Train Step 98625, Epoch 91.3, Batch Size = 256, Examples/Sec = 3840.44, Train LB = -346.189, Loss = 348.080
[2018-06-04 20:59] Train Step 98650, Epoch 91.3, Batch Size = 256, Examples/Sec = 3858.16, Train LB = -341.706, Loss = 346.145
[2018-06-04 20:59] Train Step 98675, Epoch 91.4, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -347.639, Loss = 344.441
[2018-06-04 20:59] Train Step 98700, Epoch 91.4, Batch Size = 256, Examples/Sec = 3843.44, Train LB = -333.432, Loss = 343.947
[2018-06-04 20:59] Train Step 98725, Epoch 91.4, Batch Size = 256, Examples/Sec = 3868.00, Train LB = -333.167, Loss = 343.085
[2018-06-04 20:59] Train Step 98750, Epoch 91.4, Batch Size = 256, Examples/Sec = 3857.57, Train LB = -357.909, Loss = 342.759
[2018-06-04 20:59] Train Step 98775, Epoch 91.5, Batch Size = 256, Examples/Sec = 3854.33, Train LB = -352.265, Loss = 345.406
[2018-06-04 20:59] Train Step 98800, Epoch 91.5, Batch Size = 256, Examples/Sec = 3868.22, Train LB = -370.609, Loss = 349.119
Performance on test set:
  Test Lower Bound = -429.438, Test Loss = 429.438
[2018-06-04 21:00] Train Step 98825, Epoch 91.5, Batch Size = 256, Examples/Sec = 3876.84, Train LB = -343.388, Loss = 347.836
[2018-06-04 21:00] Train Step 98850, Epoch 91.5, Batch Size = 256, Examples/Sec = 3844.77, Train LB = -335.542, Loss = 346.469
[2018-06-04 21:00] Train Step 98875, Epoch 91.6, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -353.419, Loss = 345.343
[2018-06-04 21:00] Train Step 98900, Epoch 91.6, Batch Size = 256, Examples/Sec = 3857.63, Train LB = -335.279, Loss = 344.283
[2018-06-04 21:00] Train Step 98925, Epoch 91.6, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -351.758, Loss = 343.528
[2018-06-04 21:00] Train Step 98950, Epoch 91.6, Batch Size = 256, Examples/Sec = 3822.32, Train LB = -344.866, Loss = 343.993
[2018-06-04 21:00] Train Step 98975, Epoch 91.6, Batch Size = 256, Examples/Sec = 3880.26, Train LB = -347.444, Loss = 345.223
[2018-06-04 21:00] Train Step 99000, Epoch 91.7, Batch Size = 256, Examples/Sec = 3847.14, Train LB = -379.012, Loss = 349.530
Performance on test set:
  Test Lower Bound = -428.774, Test Loss = 428.774
[2018-06-04 21:00] Train Step 99025, Epoch 91.7, Batch Size = 256, Examples/Sec = 3769.70, Train LB = -333.130, Loss = 348.152
[2018-06-04 21:00] Train Step 99050, Epoch 91.7, Batch Size = 256, Examples/Sec = 3793.32, Train LB = -347.849, Loss = 346.515
[2018-06-04 21:00] Train Step 99075, Epoch 91.7, Batch Size = 256, Examples/Sec = 3860.35, Train LB = -328.931, Loss = 345.262
[2018-06-04 21:00] Train Step 99100, Epoch 91.8, Batch Size = 256, Examples/Sec = 3737.05, Train LB = -346.671, Loss = 344.151
[2018-06-04 21:00] Train Step 99125, Epoch 91.8, Batch Size = 256, Examples/Sec = 3856.00, Train LB = -339.406, Loss = 343.806
[2018-06-04 21:00] Train Step 99150, Epoch 91.8, Batch Size = 256, Examples/Sec = 3857.86, Train LB = -345.078, Loss = 343.312
[2018-06-04 21:00] Train Step 99175, Epoch 91.8, Batch Size = 256, Examples/Sec = 3743.13, Train LB = -361.017, Loss = 344.618
[2018-06-04 21:00] Train Step 99200, Epoch 91.9, Batch Size = 256, Examples/Sec = 3871.87, Train LB = -370.842, Loss = 349.047
Performance on test set:
  Test Lower Bound = -426.908, Test Loss = 426.908
[2018-06-04 21:00] Train Step 99225, Epoch 91.9, Batch Size = 256, Examples/Sec = 3868.53, Train LB = -358.452, Loss = 347.776
[2018-06-04 21:00] Train Step 99250, Epoch 91.9, Batch Size = 256, Examples/Sec = 3861.94, Train LB = -354.275, Loss = 346.238
[2018-06-04 21:00] Train Step 99275, Epoch 91.9, Batch Size = 256, Examples/Sec = 3856.35, Train LB = -336.956, Loss = 344.951
[2018-06-04 21:00] Train Step 99300, Epoch 91.9, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -332.890, Loss = 344.110
[2018-06-04 21:00] Train Step 99325, Epoch 92.0, Batch Size = 256, Examples/Sec = 3862.10, Train LB = -342.557, Loss = 342.748
[2018-06-04 21:00] Train Step 99350, Epoch 92.0, Batch Size = 256, Examples/Sec = 3844.25, Train LB = -349.497, Loss = 342.698
[2018-06-04 21:00] Train Step 99375, Epoch 92.0, Batch Size = 256, Examples/Sec = 3870.04, Train LB = -383.042, Loss = 344.625
[2018-06-04 21:00] Train Step 99400, Epoch 92.0, Batch Size = 256, Examples/Sec = 3864.79, Train LB = -378.853, Loss = 349.675
Performance on test set:
  Test Lower Bound = -428.802, Test Loss = 428.802
[2018-06-04 21:00] Train Step 99425, Epoch 92.1, Batch Size = 256, Examples/Sec = 3864.44, Train LB = -346.580, Loss = 348.218
[2018-06-04 21:00] Train Step 99450, Epoch 92.1, Batch Size = 256, Examples/Sec = 3867.67, Train LB = -339.160, Loss = 346.711
[2018-06-04 21:00] Train Step 99475, Epoch 92.1, Batch Size = 256, Examples/Sec = 3852.35, Train LB = -343.791, Loss = 345.515
[2018-06-04 21:00] Train Step 99500, Epoch 92.1, Batch Size = 256, Examples/Sec = 3847.82, Train LB = -337.899, Loss = 343.694
[2018-06-04 21:00] Train Step 99525, Epoch 92.2, Batch Size = 256, Examples/Sec = 3855.25, Train LB = -350.138, Loss = 343.121
[2018-06-04 21:01] Train Step 99550, Epoch 92.2, Batch Size = 256, Examples/Sec = 3866.61, Train LB = -355.335, Loss = 343.811
[2018-06-04 21:01] Train Step 99575, Epoch 92.2, Batch Size = 256, Examples/Sec = 3853.11, Train LB = -330.002, Loss = 344.586
[2018-06-04 21:01] Train Step 99600, Epoch 92.2, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -382.245, Loss = 348.945
Performance on test set:
  Test Lower Bound = -429.996, Test Loss = 429.996
[2018-06-04 21:01] Train Step 99625, Epoch 92.2, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -335.101, Loss = 348.234
[2018-06-04 21:01] Train Step 99650, Epoch 92.3, Batch Size = 256, Examples/Sec = 3812.65, Train LB = -350.722, Loss = 347.236
[2018-06-04 21:01] Train Step 99675, Epoch 92.3, Batch Size = 256, Examples/Sec = 3819.07, Train LB = -348.781, Loss = 344.849
[2018-06-04 21:01] Train Step 99700, Epoch 92.3, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -342.377, Loss = 343.877
[2018-06-04 21:01] Train Step 99725, Epoch 92.3, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -348.594, Loss = 342.744
[2018-06-04 21:01] Train Step 99750, Epoch 92.4, Batch Size = 256, Examples/Sec = 3871.52, Train LB = -352.197, Loss = 342.979
[2018-06-04 21:01] Train Step 99775, Epoch 92.4, Batch Size = 256, Examples/Sec = 3864.20, Train LB = -352.216, Loss = 345.036
[2018-06-04 21:01] Train Step 99800, Epoch 92.4, Batch Size = 256, Examples/Sec = 3852.87, Train LB = -368.368, Loss = 349.486
Performance on test set:
  Test Lower Bound = -428.676, Test Loss = 428.676
[2018-06-04 21:01] Train Step 99825, Epoch 92.4, Batch Size = 256, Examples/Sec = 3836.18, Train LB = -326.564, Loss = 347.814
[2018-06-04 21:01] Train Step 99850, Epoch 92.5, Batch Size = 256, Examples/Sec = 3868.06, Train LB = -344.311, Loss = 345.902
[2018-06-04 21:01] Train Step 99875, Epoch 92.5, Batch Size = 256, Examples/Sec = 3860.60, Train LB = -343.572, Loss = 344.664
[2018-06-04 21:01] Train Step 99900, Epoch 92.5, Batch Size = 256, Examples/Sec = 3795.58, Train LB = -329.595, Loss = 343.206
[2018-06-04 21:01] Train Step 99925, Epoch 92.5, Batch Size = 256, Examples/Sec = 3863.34, Train LB = -358.773, Loss = 343.212
[2018-06-04 21:01] Train Step 99950, Epoch 92.5, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -344.328, Loss = 343.499
[2018-06-04 21:01] Train Step 99975, Epoch 92.6, Batch Size = 256, Examples/Sec = 3733.42, Train LB = -344.779, Loss = 345.347
[2018-06-04 21:01] Train Step 100000, Epoch 92.6, Batch Size = 256, Examples/Sec = 3850.79, Train LB = -361.126, Loss = 349.562
Performance on test set:
  Test Lower Bound = -431.122, Test Loss = 431.122
[2018-06-04 21:01] Train Step 100025, Epoch 92.6, Batch Size = 256, Examples/Sec = 3847.25, Train LB = -337.837, Loss = 348.563
[2018-06-04 21:01] Train Step 100050, Epoch 92.6, Batch Size = 256, Examples/Sec = 3864.20, Train LB = -346.265, Loss = 346.961
[2018-06-04 21:01] Train Step 100075, Epoch 92.7, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -336.051, Loss = 344.945
[2018-06-04 21:01] Train Step 100100, Epoch 92.7, Batch Size = 256, Examples/Sec = 3872.16, Train LB = -351.887, Loss = 343.452
[2018-06-04 21:01] Train Step 100125, Epoch 92.7, Batch Size = 256, Examples/Sec = 3856.64, Train LB = -326.330, Loss = 342.939
[2018-06-04 21:01] Train Step 100150, Epoch 92.7, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -342.888, Loss = 342.586
[2018-06-04 21:01] Train Step 100175, Epoch 92.8, Batch Size = 256, Examples/Sec = 3888.51, Train LB = -356.416, Loss = 344.118
[2018-06-04 21:01] Train Step 100200, Epoch 92.8, Batch Size = 256, Examples/Sec = 3857.93, Train LB = -373.973, Loss = 348.833
Performance on test set:
  Test Lower Bound = -431.559, Test Loss = 431.559
[2018-06-04 21:02] Train Step 100225, Epoch 92.8, Batch Size = 256, Examples/Sec = 3868.06, Train LB = -352.453, Loss = 347.916
[2018-06-04 21:02] Train Step 100250, Epoch 92.8, Batch Size = 256, Examples/Sec = 3851.42, Train LB = -335.561, Loss = 345.607
[2018-06-04 21:02] Train Step 100275, Epoch 92.8, Batch Size = 256, Examples/Sec = 3838.89, Train LB = -343.363, Loss = 344.185
[2018-06-04 21:02] Train Step 100300, Epoch 92.9, Batch Size = 256, Examples/Sec = 3816.73, Train LB = -345.781, Loss = 342.647
[2018-06-04 21:02] Train Step 100325, Epoch 92.9, Batch Size = 256, Examples/Sec = 3844.76, Train LB = -343.155, Loss = 342.442
[2018-06-04 21:02] Train Step 100350, Epoch 92.9, Batch Size = 256, Examples/Sec = 3857.93, Train LB = -336.472, Loss = 342.905
[2018-06-04 21:02] Train Step 100375, Epoch 92.9, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -349.861, Loss = 344.557
[2018-06-04 21:02] Train Step 100400, Epoch 93.0, Batch Size = 256, Examples/Sec = 3861.24, Train LB = -382.260, Loss = 348.736
Performance on test set:
  Test Lower Bound = -428.437, Test Loss = 428.437
[2018-06-04 21:02] Train Step 100425, Epoch 93.0, Batch Size = 256, Examples/Sec = 3862.52, Train LB = -335.971, Loss = 347.908
[2018-06-04 21:02] Train Step 100450, Epoch 93.0, Batch Size = 256, Examples/Sec = 3751.42, Train LB = -342.841, Loss = 346.434
[2018-06-04 21:02] Train Step 100475, Epoch 93.0, Batch Size = 256, Examples/Sec = 3836.88, Train LB = -334.378, Loss = 344.722
[2018-06-04 21:02] Train Step 100500, Epoch 93.1, Batch Size = 256, Examples/Sec = 3841.08, Train LB = -334.269, Loss = 343.501
[2018-06-04 21:02] Train Step 100525, Epoch 93.1, Batch Size = 256, Examples/Sec = 3731.89, Train LB = -351.889, Loss = 342.800
[2018-06-04 21:02] Train Step 100550, Epoch 93.1, Batch Size = 256, Examples/Sec = 3859.42, Train LB = -358.298, Loss = 343.516
[2018-06-04 21:02] Train Step 100575, Epoch 93.1, Batch Size = 256, Examples/Sec = 3853.27, Train LB = -359.110, Loss = 344.736
[2018-06-04 21:02] Train Step 100600, Epoch 93.1, Batch Size = 256, Examples/Sec = 3813.55, Train LB = -363.726, Loss = 348.971
Performance on test set:
  Test Lower Bound = -429.745, Test Loss = 429.745
[2018-06-04 21:02] Train Step 100625, Epoch 93.2, Batch Size = 256, Examples/Sec = 3833.82, Train LB = -350.487, Loss = 348.023
[2018-06-04 21:02] Train Step 100650, Epoch 93.2, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -336.143, Loss = 346.484
[2018-06-04 21:02] Train Step 100675, Epoch 93.2, Batch Size = 256, Examples/Sec = 3842.23, Train LB = -349.356, Loss = 344.479
[2018-06-04 21:02] Train Step 100700, Epoch 93.2, Batch Size = 256, Examples/Sec = 3864.09, Train LB = -336.379, Loss = 343.540
[2018-06-04 21:02] Train Step 100725, Epoch 93.3, Batch Size = 256, Examples/Sec = 3847.60, Train LB = -349.470, Loss = 342.824
[2018-06-04 21:02] Train Step 100750, Epoch 93.3, Batch Size = 256, Examples/Sec = 3852.28, Train LB = -352.458, Loss = 343.287
[2018-06-04 21:02] Train Step 100775, Epoch 93.3, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -371.835, Loss = 344.633
[2018-06-04 21:02] Train Step 100800, Epoch 93.3, Batch Size = 256, Examples/Sec = 3858.22, Train LB = -372.260, Loss = 348.904
Performance on test set:
  Test Lower Bound = -428.071, Test Loss = 428.071
[2018-06-04 21:02] Train Step 100825, Epoch 93.4, Batch Size = 256, Examples/Sec = 3855.78, Train LB = -341.774, Loss = 347.381
[2018-06-04 21:02] Train Step 100850, Epoch 93.4, Batch Size = 256, Examples/Sec = 3813.38, Train LB = -346.577, Loss = 345.898
[2018-06-04 21:02] Train Step 100875, Epoch 93.4, Batch Size = 256, Examples/Sec = 3848.00, Train LB = -342.441, Loss = 344.620
[2018-06-04 21:02] Train Step 100900, Epoch 93.4, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -339.911, Loss = 342.911
[2018-06-04 21:02] Train Step 100925, Epoch 93.4, Batch Size = 256, Examples/Sec = 3884.44, Train LB = -349.530, Loss = 342.846
[2018-06-04 21:02] Train Step 100950, Epoch 93.5, Batch Size = 256, Examples/Sec = 3848.18, Train LB = -349.286, Loss = 342.710
[2018-06-04 21:03] Train Step 100975, Epoch 93.5, Batch Size = 256, Examples/Sec = 3859.78, Train LB = -352.500, Loss = 345.221
[2018-06-04 21:03] Train Step 101000, Epoch 93.5, Batch Size = 256, Examples/Sec = 3843.67, Train LB = -389.891, Loss = 348.713
Performance on test set:
  Test Lower Bound = -429.748, Test Loss = 429.748
[2018-06-04 21:03] Train Step 101025, Epoch 93.5, Batch Size = 256, Examples/Sec = 3846.28, Train LB = -339.432, Loss = 347.683
[2018-06-04 21:03] Train Step 101050, Epoch 93.6, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -351.163, Loss = 346.604
[2018-06-04 21:03] Train Step 101075, Epoch 93.6, Batch Size = 256, Examples/Sec = 3848.12, Train LB = -348.066, Loss = 344.173
[2018-06-04 21:03] Train Step 101100, Epoch 93.6, Batch Size = 256, Examples/Sec = 3858.33, Train LB = -334.731, Loss = 343.251
[2018-06-04 21:03] Train Step 101125, Epoch 93.6, Batch Size = 256, Examples/Sec = 3875.97, Train LB = -328.228, Loss = 342.096
[2018-06-04 21:03] Train Step 101150, Epoch 93.7, Batch Size = 256, Examples/Sec = 3840.15, Train LB = -363.479, Loss = 342.473
[2018-06-04 21:03] Train Step 101175, Epoch 93.7, Batch Size = 256, Examples/Sec = 3868.59, Train LB = -350.789, Loss = 344.962
[2018-06-04 21:03] Train Step 101200, Epoch 93.7, Batch Size = 256, Examples/Sec = 3872.27, Train LB = -368.091, Loss = 348.452
Performance on test set:
  Test Lower Bound = -432.566, Test Loss = 432.566
[2018-06-04 21:03] Train Step 101225, Epoch 93.7, Batch Size = 256, Examples/Sec = 3859.20, Train LB = -359.232, Loss = 347.148
[2018-06-04 21:03] Train Step 101250, Epoch 93.8, Batch Size = 256, Examples/Sec = 3741.87, Train LB = -357.107, Loss = 345.413
[2018-06-04 21:03] Train Step 101275, Epoch 93.8, Batch Size = 256, Examples/Sec = 3859.71, Train LB = -333.651, Loss = 344.535
[2018-06-04 21:03] Train Step 101300, Epoch 93.8, Batch Size = 256, Examples/Sec = 3863.74, Train LB = -345.603, Loss = 343.901
[2018-06-04 21:03] Train Step 101325, Epoch 93.8, Batch Size = 256, Examples/Sec = 3816.96, Train LB = -339.444, Loss = 343.388
[2018-06-04 21:03] Train Step 101350, Epoch 93.8, Batch Size = 256, Examples/Sec = 3880.96, Train LB = -320.871, Loss = 343.669
[2018-06-04 21:03] Train Step 101375, Epoch 93.9, Batch Size = 256, Examples/Sec = 3861.19, Train LB = -344.172, Loss = 344.084
[2018-06-04 21:03] Train Step 101400, Epoch 93.9, Batch Size = 256, Examples/Sec = 3844.24, Train LB = -370.916, Loss = 348.591
Performance on test set:
  Test Lower Bound = -429.239, Test Loss = 429.239
[2018-06-04 21:03] Train Step 101425, Epoch 93.9, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -339.312, Loss = 347.465
[2018-06-04 21:03] Train Step 101450, Epoch 93.9, Batch Size = 256, Examples/Sec = 3842.46, Train LB = -362.742, Loss = 346.115
[2018-06-04 21:03] Train Step 101475, Epoch 94.0, Batch Size = 256, Examples/Sec = 3864.27, Train LB = -340.143, Loss = 343.878
[2018-06-04 21:03] Train Step 101500, Epoch 94.0, Batch Size = 256, Examples/Sec = 3860.95, Train LB = -339.773, Loss = 343.039
[2018-06-04 21:03] Train Step 101525, Epoch 94.0, Batch Size = 256, Examples/Sec = 3881.90, Train LB = -329.426, Loss = 342.968
[2018-06-04 21:03] Train Step 101550, Epoch 94.0, Batch Size = 256, Examples/Sec = 3851.30, Train LB = -354.414, Loss = 342.584
[2018-06-04 21:03] Train Step 101575, Epoch 94.1, Batch Size = 256, Examples/Sec = 3808.50, Train LB = -351.325, Loss = 344.708
[2018-06-04 21:03] Train Step 101600, Epoch 94.1, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -375.918, Loss = 348.870
Performance on test set:
  Test Lower Bound = -429.599, Test Loss = 429.599
[2018-06-04 21:03] Train Step 101625, Epoch 94.1, Batch Size = 256, Examples/Sec = 3834.63, Train LB = -349.647, Loss = 347.031
[2018-06-04 21:03] Train Step 101650, Epoch 94.1, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -347.651, Loss = 346.075
[2018-06-04 21:04] Train Step 101675, Epoch 94.1, Batch Size = 256, Examples/Sec = 3843.95, Train LB = -327.077, Loss = 344.436
[2018-06-04 21:04] Train Step 101700, Epoch 94.2, Batch Size = 256, Examples/Sec = 3847.49, Train LB = -352.835, Loss = 343.701
[2018-06-04 21:04] Train Step 101725, Epoch 94.2, Batch Size = 256, Examples/Sec = 3862.80, Train LB = -325.017, Loss = 342.926
[2018-06-04 21:04] Train Step 101750, Epoch 94.2, Batch Size = 256, Examples/Sec = 3858.51, Train LB = -352.540, Loss = 343.386
[2018-06-04 21:04] Train Step 101775, Epoch 94.2, Batch Size = 256, Examples/Sec = 3849.68, Train LB = -363.567, Loss = 345.195
[2018-06-04 21:04] Train Step 101800, Epoch 94.3, Batch Size = 256, Examples/Sec = 3844.71, Train LB = -374.233, Loss = 349.239
Performance on test set:
  Test Lower Bound = -430.365, Test Loss = 430.365
[2018-06-04 21:04] Train Step 101825, Epoch 94.3, Batch Size = 256, Examples/Sec = 3848.74, Train LB = -348.072, Loss = 348.468
[2018-06-04 21:04] Train Step 101850, Epoch 94.3, Batch Size = 256, Examples/Sec = 3844.13, Train LB = -345.330, Loss = 346.366
[2018-06-04 21:04] Train Step 101875, Epoch 94.3, Batch Size = 256, Examples/Sec = 3819.47, Train LB = -328.787, Loss = 344.607
[2018-06-04 21:04] Train Step 101900, Epoch 94.4, Batch Size = 256, Examples/Sec = 3844.65, Train LB = -327.251, Loss = 342.738
[2018-06-04 21:04] Train Step 101925, Epoch 94.4, Batch Size = 256, Examples/Sec = 3868.24, Train LB = -328.121, Loss = 342.073
[2018-06-04 21:04] Train Step 101950, Epoch 94.4, Batch Size = 256, Examples/Sec = 3852.64, Train LB = -343.743, Loss = 341.817
[2018-06-04 21:04] Train Step 101975, Epoch 94.4, Batch Size = 256, Examples/Sec = 3850.66, Train LB = -368.826, Loss = 344.492
[2018-06-04 21:04] Train Step 102000, Epoch 94.4, Batch Size = 256, Examples/Sec = 3816.05, Train LB = -362.322, Loss = 348.321
Performance on test set:
  Test Lower Bound = -431.458, Test Loss = 431.458
[2018-06-04 21:04] Train Step 102025, Epoch 94.5, Batch Size = 256, Examples/Sec = 3834.81, Train LB = -336.142, Loss = 346.735
[2018-06-04 21:04] Train Step 102050, Epoch 94.5, Batch Size = 256, Examples/Sec = 3735.64, Train LB = -344.440, Loss = 345.288
[2018-06-04 21:04] Train Step 102075, Epoch 94.5, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -330.259, Loss = 344.356
[2018-06-04 21:04] Train Step 102100, Epoch 94.5, Batch Size = 256, Examples/Sec = 3848.87, Train LB = -344.710, Loss = 342.758
[2018-06-04 21:04] Train Step 102125, Epoch 94.6, Batch Size = 256, Examples/Sec = 3850.73, Train LB = -353.859, Loss = 342.207
[2018-06-04 21:04] Train Step 102150, Epoch 94.6, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -354.352, Loss = 342.900
[2018-06-04 21:04] Train Step 102175, Epoch 94.6, Batch Size = 256, Examples/Sec = 3865.02, Train LB = -346.852, Loss = 344.170
[2018-06-04 21:04] Train Step 102200, Epoch 94.6, Batch Size = 256, Examples/Sec = 3861.70, Train LB = -370.652, Loss = 347.703
Performance on test set:
  Test Lower Bound = -431.624, Test Loss = 431.624
[2018-06-04 21:04] Train Step 102225, Epoch 94.7, Batch Size = 256, Examples/Sec = 3869.52, Train LB = -350.812, Loss = 346.190
[2018-06-04 21:04] Train Step 102250, Epoch 94.7, Batch Size = 256, Examples/Sec = 3857.45, Train LB = -322.556, Loss = 345.123
[2018-06-04 21:04] Train Step 102275, Epoch 94.7, Batch Size = 256, Examples/Sec = 3853.73, Train LB = -330.476, Loss = 343.681
[2018-06-04 21:04] Train Step 102300, Epoch 94.7, Batch Size = 256, Examples/Sec = 3857.05, Train LB = -327.240, Loss = 342.650
[2018-06-04 21:04] Train Step 102325, Epoch 94.7, Batch Size = 256, Examples/Sec = 3803.02, Train LB = -353.512, Loss = 341.928
[2018-06-04 21:04] Train Step 102350, Epoch 94.8, Batch Size = 256, Examples/Sec = 3857.91, Train LB = -329.088, Loss = 342.256
[2018-06-04 21:04] Train Step 102375, Epoch 94.8, Batch Size = 256, Examples/Sec = 3860.37, Train LB = -358.439, Loss = 344.218
[2018-06-04 21:04] Train Step 102400, Epoch 94.8, Batch Size = 256, Examples/Sec = 3882.62, Train LB = -373.647, Loss = 348.757
Performance on test set:
  Test Lower Bound = -429.519, Test Loss = 429.519
[2018-06-04 21:05] Train Step 102425, Epoch 94.8, Batch Size = 256, Examples/Sec = 3841.54, Train LB = -339.471, Loss = 347.555
[2018-06-04 21:05] Train Step 102450, Epoch 94.9, Batch Size = 256, Examples/Sec = 3844.47, Train LB = -337.342, Loss = 345.760
[2018-06-04 21:05] Train Step 102475, Epoch 94.9, Batch Size = 256, Examples/Sec = 3810.26, Train LB = -331.042, Loss = 343.248
[2018-06-04 21:05] Train Step 102500, Epoch 94.9, Batch Size = 256, Examples/Sec = 3851.30, Train LB = -334.022, Loss = 342.448
[2018-06-04 21:05] Train Step 102525, Epoch 94.9, Batch Size = 256, Examples/Sec = 3862.74, Train LB = -356.344, Loss = 342.076
[2018-06-04 21:05] Train Step 102550, Epoch 95.0, Batch Size = 256, Examples/Sec = 3850.44, Train LB = -329.812, Loss = 342.630
[2018-06-04 21:05] Train Step 102575, Epoch 95.0, Batch Size = 256, Examples/Sec = 3869.23, Train LB = -355.113, Loss = 344.336
[2018-06-04 21:05] Train Step 102600, Epoch 95.0, Batch Size = 256, Examples/Sec = 3843.73, Train LB = -374.940, Loss = 348.559
Performance on test set:
  Test Lower Bound = -429.554, Test Loss = 429.554
[2018-06-04 21:05] Train Step 102625, Epoch 95.0, Batch Size = 256, Examples/Sec = 3830.74, Train LB = -342.813, Loss = 347.393
[2018-06-04 21:05] Train Step 102650, Epoch 95.0, Batch Size = 256, Examples/Sec = 3838.14, Train LB = -337.913, Loss = 345.573
[2018-06-04 21:05] Train Step 102675, Epoch 95.1, Batch Size = 256, Examples/Sec = 3859.44, Train LB = -335.604, Loss = 343.707
[2018-06-04 21:05] Train Step 102700, Epoch 95.1, Batch Size = 256, Examples/Sec = 3867.36, Train LB = -327.368, Loss = 342.316
[2018-06-04 21:05] Train Step 102725, Epoch 95.1, Batch Size = 256, Examples/Sec = 3820.62, Train LB = -330.268, Loss = 341.834
[2018-06-04 21:05] Train Step 102750, Epoch 95.1, Batch Size = 256, Examples/Sec = 3854.84, Train LB = -345.078, Loss = 342.610
[2018-06-04 21:05] Train Step 102775, Epoch 95.2, Batch Size = 256, Examples/Sec = 3873.68, Train LB = -360.400, Loss = 343.660
[2018-06-04 21:05] Train Step 102800, Epoch 95.2, Batch Size = 256, Examples/Sec = 3849.05, Train LB = -380.999, Loss = 348.257
Performance on test set:
  Test Lower Bound = -431.227, Test Loss = 431.227
[2018-06-04 21:05] Train Step 102825, Epoch 95.2, Batch Size = 256, Examples/Sec = 3836.01, Train LB = -342.941, Loss = 346.992
[2018-06-04 21:05] Train Step 102850, Epoch 95.2, Batch Size = 256, Examples/Sec = 3752.01, Train LB = -334.380, Loss = 345.945
[2018-06-04 21:05] Train Step 102875, Epoch 95.3, Batch Size = 256, Examples/Sec = 3859.90, Train LB = -332.034, Loss = 344.601
[2018-06-04 21:05] Train Step 102900, Epoch 95.3, Batch Size = 256, Examples/Sec = 3845.63, Train LB = -333.594, Loss = 343.606
[2018-06-04 21:05] Train Step 102925, Epoch 95.3, Batch Size = 256, Examples/Sec = 3749.54, Train LB = -348.408, Loss = 342.114
[2018-06-04 21:05] Train Step 102950, Epoch 95.3, Batch Size = 256, Examples/Sec = 3864.56, Train LB = -366.056, Loss = 341.622
[2018-06-04 21:05] Train Step 102975, Epoch 95.3, Batch Size = 256, Examples/Sec = 3842.97, Train LB = -362.978, Loss = 344.136
[2018-06-04 21:05] Train Step 103000, Epoch 95.4, Batch Size = 256, Examples/Sec = 3806.07, Train LB = -365.741, Loss = 348.859
Performance on test set:
  Test Lower Bound = -428.523, Test Loss = 428.523
[2018-06-04 21:05] Train Step 103025, Epoch 95.4, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -340.788, Loss = 347.753
[2018-06-04 21:05] Train Step 103050, Epoch 95.4, Batch Size = 256, Examples/Sec = 3862.41, Train LB = -342.073, Loss = 345.482
[2018-06-04 21:05] Train Step 103075, Epoch 95.4, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -342.972, Loss = 343.686
[2018-06-04 21:06] Train Step 103100, Epoch 95.5, Batch Size = 256, Examples/Sec = 3836.88, Train LB = -335.258, Loss = 342.146
[2018-06-04 21:06] Train Step 103125, Epoch 95.5, Batch Size = 256, Examples/Sec = 3846.50, Train LB = -345.633, Loss = 341.866
[2018-06-04 21:06] Train Step 103150, Epoch 95.5, Batch Size = 256, Examples/Sec = 3846.80, Train LB = -360.058, Loss = 342.029
[2018-06-04 21:06] Train Step 103175, Epoch 95.5, Batch Size = 256, Examples/Sec = 3841.47, Train LB = -356.744, Loss = 344.383
[2018-06-04 21:06] Train Step 103200, Epoch 95.6, Batch Size = 256, Examples/Sec = 3847.60, Train LB = -375.042, Loss = 348.173
Performance on test set:
  Test Lower Bound = -430.432, Test Loss = 430.432
[2018-06-04 21:06] Train Step 103225, Epoch 95.6, Batch Size = 256, Examples/Sec = 3874.45, Train LB = -344.777, Loss = 346.567
[2018-06-04 21:06] Train Step 103250, Epoch 95.6, Batch Size = 256, Examples/Sec = 3853.40, Train LB = -337.706, Loss = 344.850
[2018-06-04 21:06] Train Step 103275, Epoch 95.6, Batch Size = 256, Examples/Sec = 3795.46, Train LB = -337.325, Loss = 343.693
[2018-06-04 21:06] Train Step 103300, Epoch 95.6, Batch Size = 256, Examples/Sec = 3882.25, Train LB = -325.289, Loss = 342.573
[2018-06-04 21:06] Train Step 103325, Epoch 95.7, Batch Size = 256, Examples/Sec = 3862.12, Train LB = -329.479, Loss = 342.638
[2018-06-04 21:06] Train Step 103350, Epoch 95.7, Batch Size = 256, Examples/Sec = 3857.34, Train LB = -338.514, Loss = 342.515
[2018-06-04 21:06] Train Step 103375, Epoch 95.7, Batch Size = 256, Examples/Sec = 3846.33, Train LB = -356.728, Loss = 344.485
[2018-06-04 21:06] Train Step 103400, Epoch 95.7, Batch Size = 256, Examples/Sec = 3842.23, Train LB = -360.606, Loss = 348.766
Performance on test set:
  Test Lower Bound = -431.320, Test Loss = 431.320
[2018-06-04 21:06] Train Step 103425, Epoch 95.8, Batch Size = 256, Examples/Sec = 3853.33, Train LB = -343.187, Loss = 347.605
[2018-06-04 21:06] Train Step 103450, Epoch 95.8, Batch Size = 256, Examples/Sec = 3862.34, Train LB = -327.689, Loss = 346.314
[2018-06-04 21:06] Train Step 103475, Epoch 95.8, Batch Size = 256, Examples/Sec = 3850.26, Train LB = -321.801, Loss = 343.490
[2018-06-04 21:06] Train Step 103500, Epoch 95.8, Batch Size = 256, Examples/Sec = 3853.91, Train LB = -331.334, Loss = 342.597
[2018-06-04 21:06] Train Step 103525, Epoch 95.9, Batch Size = 256, Examples/Sec = 3832.63, Train LB = -331.897, Loss = 342.141
[2018-06-04 21:06] Train Step 103550, Epoch 95.9, Batch Size = 256, Examples/Sec = 3858.27, Train LB = -343.879, Loss = 342.020
[2018-06-04 21:06] Train Step 103575, Epoch 95.9, Batch Size = 256, Examples/Sec = 3802.34, Train LB = -338.185, Loss = 343.969
[2018-06-04 21:06] Train Step 103600, Epoch 95.9, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -380.474, Loss = 348.284
Performance on test set:
  Test Lower Bound = -429.150, Test Loss = 429.150
[2018-06-04 21:06] Train Step 103625, Epoch 95.9, Batch Size = 256, Examples/Sec = 3848.01, Train LB = -340.225, Loss = 346.960
[2018-06-04 21:06] Train Step 103650, Epoch 96.0, Batch Size = 256, Examples/Sec = 3776.80, Train LB = -331.450, Loss = 345.183
[2018-06-04 21:06] Train Step 103675, Epoch 96.0, Batch Size = 256, Examples/Sec = 3859.37, Train LB = -328.866, Loss = 344.238
[2018-06-04 21:06] Train Step 103700, Epoch 96.0, Batch Size = 256, Examples/Sec = 3841.94, Train LB = -340.130, Loss = 342.686
[2018-06-04 21:06] Train Step 103725, Epoch 96.0, Batch Size = 256, Examples/Sec = 3757.19, Train LB = -331.569, Loss = 342.550
[2018-06-04 21:06] Train Step 103750, Epoch 96.1, Batch Size = 256, Examples/Sec = 3809.24, Train LB = -345.697, Loss = 342.582
[2018-06-04 21:06] Train Step 103775, Epoch 96.1, Batch Size = 256, Examples/Sec = 3859.84, Train LB = -353.811, Loss = 344.131
[2018-06-04 21:06] Train Step 103800, Epoch 96.1, Batch Size = 256, Examples/Sec = 3757.86, Train LB = -373.314, Loss = 348.786
Performance on test set:
  Test Lower Bound = -430.153, Test Loss = 430.153
[2018-06-04 21:07] Train Step 103825, Epoch 96.1, Batch Size = 256, Examples/Sec = 3808.68, Train LB = -338.887, Loss = 347.317
[2018-06-04 21:07] Train Step 103850, Epoch 96.2, Batch Size = 256, Examples/Sec = 3815.04, Train LB = -324.063, Loss = 345.596
[2018-06-04 21:07] Train Step 103875, Epoch 96.2, Batch Size = 256, Examples/Sec = 3842.81, Train LB = -357.694, Loss = 344.450
[2018-06-04 21:07] Train Step 103900, Epoch 96.2, Batch Size = 256, Examples/Sec = 3845.52, Train LB = -335.822, Loss = 342.669
[2018-06-04 21:07] Train Step 103925, Epoch 96.2, Batch Size = 256, Examples/Sec = 3878.61, Train LB = -339.111, Loss = 341.955
[2018-06-04 21:07] Train Step 103950, Epoch 96.2, Batch Size = 256, Examples/Sec = 3836.88, Train LB = -359.310, Loss = 341.821
[2018-06-04 21:07] Train Step 103975, Epoch 96.3, Batch Size = 256, Examples/Sec = 3857.40, Train LB = -367.286, Loss = 344.611
[2018-06-04 21:07] Train Step 104000, Epoch 96.3, Batch Size = 256, Examples/Sec = 3859.91, Train LB = -365.671, Loss = 348.411
Performance on test set:
  Test Lower Bound = -429.726, Test Loss = 429.726
[2018-06-04 21:07] Train Step 104025, Epoch 96.3, Batch Size = 256, Examples/Sec = 3840.50, Train LB = -354.119, Loss = 346.882
[2018-06-04 21:07] Train Step 104050, Epoch 96.3, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -324.232, Loss = 345.615
[2018-06-04 21:07] Train Step 104075, Epoch 96.4, Batch Size = 256, Examples/Sec = 3841.13, Train LB = -322.395, Loss = 343.771
[2018-06-04 21:07] Train Step 104100, Epoch 96.4, Batch Size = 256, Examples/Sec = 3839.76, Train LB = -331.623, Loss = 342.441
[2018-06-04 21:07] Train Step 104125, Epoch 96.4, Batch Size = 256, Examples/Sec = 3813.15, Train LB = -332.995, Loss = 342.667
[2018-06-04 21:07] Train Step 104150, Epoch 96.4, Batch Size = 256, Examples/Sec = 3790.23, Train LB = -355.006, Loss = 342.658
[2018-06-04 21:07] Train Step 104175, Epoch 96.5, Batch Size = 256, Examples/Sec = 3883.73, Train LB = -361.231, Loss = 343.793
[2018-06-04 21:07] Train Step 104200, Epoch 96.5, Batch Size = 256, Examples/Sec = 3860.88, Train LB = -358.252, Loss = 347.934
Performance on test set:
  Test Lower Bound = -430.613, Test Loss = 430.613
[2018-06-04 21:07] Train Step 104225, Epoch 96.5, Batch Size = 256, Examples/Sec = 3844.89, Train LB = -318.159, Loss = 346.999
[2018-06-04 21:07] Train Step 104250, Epoch 96.5, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -333.996, Loss = 344.995
[2018-06-04 21:07] Train Step 104275, Epoch 96.6, Batch Size = 256, Examples/Sec = 3816.79, Train LB = -341.405, Loss = 342.577
[2018-06-04 21:07] Train Step 104300, Epoch 96.6, Batch Size = 256, Examples/Sec = 3868.46, Train LB = -346.587, Loss = 341.598
[2018-06-04 21:07] Train Step 104325, Epoch 96.6, Batch Size = 256, Examples/Sec = 3872.69, Train LB = -372.001, Loss = 341.784
[2018-06-04 21:07] Train Step 104350, Epoch 96.6, Batch Size = 256, Examples/Sec = 3862.05, Train LB = -334.766, Loss = 342.289
[2018-06-04 21:07] Train Step 104375, Epoch 96.6, Batch Size = 256, Examples/Sec = 3867.12, Train LB = -362.012, Loss = 343.942
[2018-06-04 21:07] Train Step 104400, Epoch 96.7, Batch Size = 256, Examples/Sec = 3841.36, Train LB = -383.927, Loss = 348.034
Performance on test set:
  Test Lower Bound = -431.385, Test Loss = 431.385
[2018-06-04 21:07] Train Step 104425, Epoch 96.7, Batch Size = 256, Examples/Sec = 3848.69, Train LB = -332.187, Loss = 346.766
[2018-06-04 21:07] Train Step 104450, Epoch 96.7, Batch Size = 256, Examples/Sec = 3849.45, Train LB = -346.983, Loss = 344.843
[2018-06-04 21:07] Train Step 104475, Epoch 96.7, Batch Size = 256, Examples/Sec = 3849.10, Train LB = -328.033, Loss = 343.398
[2018-06-04 21:07] Train Step 104500, Epoch 96.8, Batch Size = 256, Examples/Sec = 3851.71, Train LB = -337.488, Loss = 342.188
[2018-06-04 21:07] Train Step 104525, Epoch 96.8, Batch Size = 256, Examples/Sec = 3771.58, Train LB = -342.675, Loss = 342.317
[2018-06-04 21:08] Train Step 104550, Epoch 96.8, Batch Size = 256, Examples/Sec = 3848.98, Train LB = -361.423, Loss = 342.056
[2018-06-04 21:08] Train Step 104575, Epoch 96.8, Batch Size = 256, Examples/Sec = 3859.02, Train LB = -361.216, Loss = 343.856
[2018-06-04 21:08] Train Step 104600, Epoch 96.9, Batch Size = 256, Examples/Sec = 3737.50, Train LB = -374.055, Loss = 347.777
Performance on test set:
  Test Lower Bound = -429.836, Test Loss = 429.836
[2018-06-04 21:08] Train Step 104625, Epoch 96.9, Batch Size = 256, Examples/Sec = 3854.09, Train LB = -349.615, Loss = 346.613
[2018-06-04 21:08] Train Step 104650, Epoch 96.9, Batch Size = 256, Examples/Sec = 3851.64, Train LB = -329.337, Loss = 345.309
[2018-06-04 21:08] Train Step 104675, Epoch 96.9, Batch Size = 256, Examples/Sec = 3841.08, Train LB = -338.736, Loss = 343.457
[2018-06-04 21:08] Train Step 104700, Epoch 96.9, Batch Size = 256, Examples/Sec = 3843.96, Train LB = -337.345, Loss = 342.294
[2018-06-04 21:08] Train Step 104725, Epoch 97.0, Batch Size = 256, Examples/Sec = 3858.91, Train LB = -340.955, Loss = 341.832
[2018-06-04 21:08] Train Step 104750, Epoch 97.0, Batch Size = 256, Examples/Sec = 3854.20, Train LB = -327.912, Loss = 341.798
[2018-06-04 21:08] Train Step 104775, Epoch 97.0, Batch Size = 256, Examples/Sec = 3802.79, Train LB = -380.470, Loss = 343.994
[2018-06-04 21:08] Train Step 104800, Epoch 97.0, Batch Size = 256, Examples/Sec = 3849.74, Train LB = -368.095, Loss = 348.221
Performance on test set:
  Test Lower Bound = -428.985, Test Loss = 428.985
[2018-06-04 21:08] Train Step 104825, Epoch 97.1, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -345.566, Loss = 347.279
[2018-06-04 21:08] Train Step 104850, Epoch 97.1, Batch Size = 256, Examples/Sec = 3876.60, Train LB = -353.742, Loss = 345.685
[2018-06-04 21:08] Train Step 104875, Epoch 97.1, Batch Size = 256, Examples/Sec = 3845.52, Train LB = -353.564, Loss = 343.732
[2018-06-04 21:08] Train Step 104900, Epoch 97.1, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -324.814, Loss = 343.032
[2018-06-04 21:08] Train Step 104925, Epoch 97.2, Batch Size = 256, Examples/Sec = 3853.73, Train LB = -338.784, Loss = 341.959
[2018-06-04 21:08] Train Step 104950, Epoch 97.2, Batch Size = 256, Examples/Sec = 3850.61, Train LB = -344.523, Loss = 342.190
[2018-06-04 21:08] Train Step 104975, Epoch 97.2, Batch Size = 256, Examples/Sec = 3848.59, Train LB = -343.357, Loss = 343.989
[2018-06-04 21:08] Train Step 105000, Epoch 97.2, Batch Size = 256, Examples/Sec = 3814.47, Train LB = -362.836, Loss = 347.650
Performance on test set:
  Test Lower Bound = -433.975, Test Loss = 433.975
[2018-06-04 21:08] Train Step 105025, Epoch 97.2, Batch Size = 256, Examples/Sec = 3860.66, Train LB = -334.790, Loss = 346.403
[2018-06-04 21:08] Train Step 105050, Epoch 97.3, Batch Size = 256, Examples/Sec = 3865.79, Train LB = -343.709, Loss = 344.505
[2018-06-04 21:08] Train Step 105075, Epoch 97.3, Batch Size = 256, Examples/Sec = 3725.37, Train LB = -331.493, Loss = 342.828
[2018-06-04 21:08] Train Step 105100, Epoch 97.3, Batch Size = 256, Examples/Sec = 3858.38, Train LB = -343.534, Loss = 341.913
[2018-06-04 21:08] Train Step 105125, Epoch 97.3, Batch Size = 256, Examples/Sec = 3867.01, Train LB = -338.021, Loss = 341.506
[2018-06-04 21:08] Train Step 105150, Epoch 97.4, Batch Size = 256, Examples/Sec = 3740.61, Train LB = -347.495, Loss = 341.861
[2018-06-04 21:08] Train Step 105175, Epoch 97.4, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -342.471, Loss = 343.994
[2018-06-04 21:08] Train Step 105200, Epoch 97.4, Batch Size = 256, Examples/Sec = 3864.38, Train LB = -369.039, Loss = 348.020
Performance on test set:
  Test Lower Bound = -431.101, Test Loss = 431.101
[2018-06-04 21:09] Train Step 105225, Epoch 97.4, Batch Size = 256, Examples/Sec = 3852.22, Train LB = -327.920, Loss = 346.545
[2018-06-04 21:09] Train Step 105250, Epoch 97.5, Batch Size = 256, Examples/Sec = 3865.55, Train LB = -340.576, Loss = 344.659
[2018-06-04 21:09] Train Step 105275, Epoch 97.5, Batch Size = 256, Examples/Sec = 3835.22, Train LB = -323.801, Loss = 343.820
[2018-06-04 21:09] Train Step 105300, Epoch 97.5, Batch Size = 256, Examples/Sec = 3849.97, Train LB = -334.060, Loss = 343.069
[2018-06-04 21:09] Train Step 105325, Epoch 97.5, Batch Size = 256, Examples/Sec = 3842.52, Train LB = -346.814, Loss = 343.061
[2018-06-04 21:09] Train Step 105350, Epoch 97.5, Batch Size = 256, Examples/Sec = 3882.97, Train LB = -332.087, Loss = 342.763
[2018-06-04 21:09] Train Step 105375, Epoch 97.6, Batch Size = 256, Examples/Sec = 3847.94, Train LB = -345.417, Loss = 343.807
[2018-06-04 21:09] Train Step 105400, Epoch 97.6, Batch Size = 256, Examples/Sec = 3811.23, Train LB = -381.906, Loss = 347.791
Performance on test set:
  Test Lower Bound = -431.664, Test Loss = 431.664
[2018-06-04 21:09] Train Step 105425, Epoch 97.6, Batch Size = 256, Examples/Sec = 3864.80, Train LB = -331.967, Loss = 346.458
[2018-06-04 21:09] Train Step 105450, Epoch 97.6, Batch Size = 256, Examples/Sec = 3846.39, Train LB = -322.272, Loss = 344.755
[2018-06-04 21:09] Train Step 105475, Epoch 97.7, Batch Size = 256, Examples/Sec = 3851.77, Train LB = -336.258, Loss = 343.304
[2018-06-04 21:09] Train Step 105500, Epoch 97.7, Batch Size = 256, Examples/Sec = 3852.62, Train LB = -347.078, Loss = 342.049
[2018-06-04 21:09] Train Step 105525, Epoch 97.7, Batch Size = 256, Examples/Sec = 3866.83, Train LB = -333.425, Loss = 340.459
[2018-06-04 21:09] Train Step 105550, Epoch 97.7, Batch Size = 256, Examples/Sec = 3866.37, Train LB = -348.921, Loss = 341.443
[2018-06-04 21:09] Train Step 105575, Epoch 97.8, Batch Size = 256, Examples/Sec = 3851.24, Train LB = -374.628, Loss = 343.580
[2018-06-04 21:09] Train Step 105600, Epoch 97.8, Batch Size = 256, Examples/Sec = 3858.67, Train LB = -371.817, Loss = 348.396
Performance on test set:
  Test Lower Bound = -428.898, Test Loss = 428.898
[2018-06-04 21:09] Train Step 105625, Epoch 97.8, Batch Size = 256, Examples/Sec = 3857.52, Train LB = -335.603, Loss = 347.426
[2018-06-04 21:09] Train Step 105650, Epoch 97.8, Batch Size = 256, Examples/Sec = 3866.96, Train LB = -349.787, Loss = 346.213
[2018-06-04 21:09] Train Step 105675, Epoch 97.8, Batch Size = 256, Examples/Sec = 3848.81, Train LB = -328.910, Loss = 344.137
[2018-06-04 21:09] Train Step 105700, Epoch 97.9, Batch Size = 256, Examples/Sec = 3866.14, Train LB = -329.655, Loss = 343.088
[2018-06-04 21:09] Train Step 105725, Epoch 97.9, Batch Size = 256, Examples/Sec = 3855.94, Train LB = -338.577, Loss = 341.894
[2018-06-04 21:09] Train Step 105750, Epoch 97.9, Batch Size = 256, Examples/Sec = 3852.46, Train LB = -357.892, Loss = 342.051
[2018-06-04 21:09] Train Step 105775, Epoch 97.9, Batch Size = 256, Examples/Sec = 3859.55, Train LB = -356.000, Loss = 344.055
[2018-06-04 21:09] Train Step 105800, Epoch 98.0, Batch Size = 256, Examples/Sec = 3864.33, Train LB = -374.396, Loss = 347.898
Performance on test set:
  Test Lower Bound = -431.430, Test Loss = 431.430
[2018-06-04 21:09] Train Step 105825, Epoch 98.0, Batch Size = 256, Examples/Sec = 3850.83, Train LB = -335.561, Loss = 346.676
[2018-06-04 21:09] Train Step 105850, Epoch 98.0, Batch Size = 256, Examples/Sec = 3870.93, Train LB = -318.378, Loss = 344.859
[2018-06-04 21:09] Train Step 105875, Epoch 98.0, Batch Size = 256, Examples/Sec = 3743.14, Train LB = -347.218, Loss = 343.038
[2018-06-04 21:09] Train Step 105900, Epoch 98.1, Batch Size = 256, Examples/Sec = 3851.01, Train LB = -344.172, Loss = 342.722
[2018-06-04 21:09] Train Step 105925, Epoch 98.1, Batch Size = 256, Examples/Sec = 3848.47, Train LB = -341.272, Loss = 341.949
[2018-06-04 21:09] Train Step 105950, Epoch 98.1, Batch Size = 256, Examples/Sec = 3709.93, Train LB = -347.745, Loss = 342.444
[2018-06-04 21:10] Train Step 105975, Epoch 98.1, Batch Size = 256, Examples/Sec = 3868.64, Train LB = -366.470, Loss = 344.503
[2018-06-04 21:10] Train Step 106000, Epoch 98.1, Batch Size = 256, Examples/Sec = 3867.65, Train LB = -372.972, Loss = 348.424
Performance on test set:
  Test Lower Bound = -431.295, Test Loss = 431.295
[2018-06-04 21:10] Train Step 106025, Epoch 98.2, Batch Size = 256, Examples/Sec = 3856.24, Train LB = -341.682, Loss = 346.637
[2018-06-04 21:10] Train Step 106050, Epoch 98.2, Batch Size = 256, Examples/Sec = 3849.50, Train LB = -330.227, Loss = 345.242
[2018-06-04 21:10] Train Step 106075, Epoch 98.2, Batch Size = 256, Examples/Sec = 3852.00, Train LB = -327.439, Loss = 343.683
[2018-06-04 21:10] Train Step 106100, Epoch 98.2, Batch Size = 256, Examples/Sec = 3855.65, Train LB = -332.440, Loss = 342.893
[2018-06-04 21:10] Train Step 106125, Epoch 98.3, Batch Size = 256, Examples/Sec = 3870.87, Train LB = -334.694, Loss = 341.953
[2018-06-04 21:10] Train Step 106150, Epoch 98.3, Batch Size = 256, Examples/Sec = 3869.23, Train LB = -333.598, Loss = 341.955
[2018-06-04 21:10] Train Step 106175, Epoch 98.3, Batch Size = 256, Examples/Sec = 3860.71, Train LB = -343.438, Loss = 343.642
[2018-06-04 21:10] Train Step 106200, Epoch 98.3, Batch Size = 256, Examples/Sec = 3848.52, Train LB = -372.737, Loss = 347.315
Performance on test set:
  Test Lower Bound = -431.374, Test Loss = 431.374
[2018-06-04 21:10] Train Step 106225, Epoch 98.4, Batch Size = 256, Examples/Sec = 3855.83, Train LB = -349.918, Loss = 346.377
[2018-06-04 21:10] Train Step 106250, Epoch 98.4, Batch Size = 256, Examples/Sec = 3844.83, Train LB = -334.300, Loss = 344.508
[2018-06-04 21:10] Train Step 106275, Epoch 98.4, Batch Size = 256, Examples/Sec = 3860.08, Train LB = -330.037, Loss = 343.074
[2018-06-04 21:10] Train Step 106300, Epoch 98.4, Batch Size = 256, Examples/Sec = 3861.64, Train LB = -343.479, Loss = 341.960
[2018-06-04 21:10] Train Step 106325, Epoch 98.4, Batch Size = 256, Examples/Sec = 3873.21, Train LB = -364.850, Loss = 340.904
[2018-06-04 21:10] Train Step 106350, Epoch 98.5, Batch Size = 256, Examples/Sec = 3842.64, Train LB = -342.613, Loss = 341.034
[2018-06-04 21:10] Train Step 106375, Epoch 98.5, Batch Size = 256, Examples/Sec = 3864.91, Train LB = -367.771, Loss = 342.774
[2018-06-04 21:10] Train Step 106400, Epoch 98.5, Batch Size = 256, Examples/Sec = 3847.31, Train LB = -370.348, Loss = 347.250
Performance on test set:
  Test Lower Bound = -431.087, Test Loss = 431.087
[2018-06-04 21:10] Train Step 106425, Epoch 98.5, Batch Size = 256, Examples/Sec = 3727.97, Train LB = -334.293, Loss = 346.295
[2018-06-04 21:10] Train Step 106450, Epoch 98.6, Batch Size = 256, Examples/Sec = 3868.11, Train LB = -335.003, Loss = 344.369
[2018-06-04 21:10] Train Step 106475, Epoch 98.6, Batch Size = 256, Examples/Sec = 3852.98, Train LB = -330.850, Loss = 342.198
[2018-06-04 21:10] Train Step 106500, Epoch 98.6, Batch Size = 256, Examples/Sec = 3811.57, Train LB = -334.061, Loss = 340.810
[2018-06-04 21:10] Train Step 106525, Epoch 98.6, Batch Size = 256, Examples/Sec = 3829.58, Train LB = -347.512, Loss = 340.027
[2018-06-04 21:10] Train Step 106550, Epoch 98.7, Batch Size = 256, Examples/Sec = 3845.86, Train LB = -346.577, Loss = 341.231
[2018-06-04 21:10] Train Step 106575, Epoch 98.7, Batch Size = 256, Examples/Sec = 3841.76, Train LB = -358.902, Loss = 343.430
[2018-06-04 21:10] Train Step 106600, Epoch 98.7, Batch Size = 256, Examples/Sec = 3870.93, Train LB = -361.326, Loss = 347.514
Performance on test set:
  Test Lower Bound = -431.996, Test Loss = 431.996
[2018-06-04 21:10] Train Step 106625, Epoch 98.7, Batch Size = 256, Examples/Sec = 3852.11, Train LB = -326.597, Loss = 345.941
[2018-06-04 21:10] Train Step 106650, Epoch 98.8, Batch Size = 256, Examples/Sec = 3854.55, Train LB = -338.520, Loss = 343.797
[2018-06-04 21:11] Train Step 106675, Epoch 98.8, Batch Size = 256, Examples/Sec = 3812.07, Train LB = -351.585, Loss = 342.533
[2018-06-04 21:11] Train Step 106700, Epoch 98.8, Batch Size = 256, Examples/Sec = 3864.73, Train LB = -342.025, Loss = 341.801
[2018-06-04 21:11] Train Step 106725, Epoch 98.8, Batch Size = 256, Examples/Sec = 3860.48, Train LB = -328.380, Loss = 341.620
[2018-06-04 21:11] Train Step 106750, Epoch 98.8, Batch Size = 256, Examples/Sec = 3739.36, Train LB = -348.374, Loss = 342.463
[2018-06-04 21:11] Train Step 106775, Epoch 98.9, Batch Size = 256, Examples/Sec = 3854.62, Train LB = -344.081, Loss = 343.112
[2018-06-04 21:11] Train Step 106800, Epoch 98.9, Batch Size = 256, Examples/Sec = 3848.99, Train LB = -380.085, Loss = 347.274
Performance on test set:
  Test Lower Bound = -430.031, Test Loss = 430.031
[2018-06-04 21:11] Train Step 106825, Epoch 98.9, Batch Size = 256, Examples/Sec = 3869.65, Train LB = -344.933, Loss = 345.792
[2018-06-04 21:11] Train Step 106850, Epoch 98.9, Batch Size = 256, Examples/Sec = 3859.31, Train LB = -349.609, Loss = 343.837
[2018-06-04 21:11] Train Step 106875, Epoch 99.0, Batch Size = 256, Examples/Sec = 3875.85, Train LB = -333.841, Loss = 344.057
[2018-06-04 21:11] Train Step 106900, Epoch 99.0, Batch Size = 256, Examples/Sec = 3858.90, Train LB = -345.295, Loss = 342.715
[2018-06-04 21:11] Train Step 106925, Epoch 99.0, Batch Size = 256, Examples/Sec = 3855.20, Train LB = -341.259, Loss = 342.235
[2018-06-04 21:11] Train Step 106950, Epoch 99.0, Batch Size = 256, Examples/Sec = 3862.87, Train LB = -346.716, Loss = 342.971
[2018-06-04 21:11] Train Step 106975, Epoch 99.1, Batch Size = 256, Examples/Sec = 3847.65, Train LB = -340.256, Loss = 344.176
[2018-06-04 21:11] Train Step 107000, Epoch 99.1, Batch Size = 256, Examples/Sec = 3856.58, Train LB = -370.434, Loss = 347.834
Performance on test set:
  Test Lower Bound = -430.787, Test Loss = 430.787
[2018-06-04 21:11] Train Step 107025, Epoch 99.1, Batch Size = 256, Examples/Sec = 3853.22, Train LB = -342.069, Loss = 347.114
[2018-06-04 21:11] Train Step 107050, Epoch 99.1, Batch Size = 256, Examples/Sec = 3853.50, Train LB = -319.505, Loss = 344.968
[2018-06-04 21:11] Train Step 107075, Epoch 99.1, Batch Size = 256, Examples/Sec = 3856.98, Train LB = -341.017, Loss = 343.430
[2018-06-04 21:11] Train Step 107100, Epoch 99.2, Batch Size = 256, Examples/Sec = 3870.23, Train LB = -337.842, Loss = 342.384
[2018-06-04 21:11] Train Step 107125, Epoch 99.2, Batch Size = 256, Examples/Sec = 3862.92, Train LB = -328.978, Loss = 341.526
[2018-06-04 21:11] Train Step 107150, Epoch 99.2, Batch Size = 256, Examples/Sec = 3873.85, Train LB = -339.506, Loss = 341.201
[2018-06-04 21:11] Train Step 107175, Epoch 99.2, Batch Size = 256, Examples/Sec = 3869.54, Train LB = -374.109, Loss = 343.029
[2018-06-04 21:11] Train Step 107200, Epoch 99.3, Batch Size = 256, Examples/Sec = 3856.18, Train LB = -365.772, Loss = 347.324
Performance on test set:
  Test Lower Bound = -430.915, Test Loss = 430.915
[2018-06-04 21:11] Train Step 107225, Epoch 99.3, Batch Size = 256, Examples/Sec = 3805.22, Train LB = -333.267, Loss = 346.351
[2018-06-04 21:11] Train Step 107250, Epoch 99.3, Batch Size = 256, Examples/Sec = 3864.62, Train LB = -347.754, Loss = 344.313
[2018-06-04 21:11] Train Step 107275, Epoch 99.3, Batch Size = 256, Examples/Sec = 3879.84, Train LB = -332.168, Loss = 343.175
[2018-06-04 21:11] Train Step 107300, Epoch 99.4, Batch Size = 256, Examples/Sec = 3843.89, Train LB = -331.906, Loss = 341.744
[2018-06-04 21:11] Train Step 107325, Epoch 99.4, Batch Size = 256, Examples/Sec = 3863.27, Train LB = -363.741, Loss = 341.735
[2018-06-04 21:11] Train Step 107350, Epoch 99.4, Batch Size = 256, Examples/Sec = 3858.97, Train LB = -345.267, Loss = 342.156
[2018-06-04 21:11] Train Step 107375, Epoch 99.4, Batch Size = 256, Examples/Sec = 3863.38, Train LB = -344.738, Loss = 343.266
[2018-06-04 21:12] Train Step 107400, Epoch 99.4, Batch Size = 256, Examples/Sec = 3857.51, Train LB = -382.449, Loss = 346.744
Performance on test set:
  Test Lower Bound = -432.714, Test Loss = 432.714
[2018-06-04 21:12] Train Step 107425, Epoch 99.5, Batch Size = 256, Examples/Sec = 3854.33, Train LB = -349.632, Loss = 346.201
[2018-06-04 21:12] Train Step 107450, Epoch 99.5, Batch Size = 256, Examples/Sec = 3858.04, Train LB = -335.312, Loss = 344.150
[2018-06-04 21:12] Train Step 107475, Epoch 99.5, Batch Size = 256, Examples/Sec = 3777.38, Train LB = -345.519, Loss = 342.682
[2018-06-04 21:12] Train Step 107500, Epoch 99.5, Batch Size = 256, Examples/Sec = 3867.31, Train LB = -329.159, Loss = 341.421
[2018-06-04 21:12] Train Step 107525, Epoch 99.6, Batch Size = 256, Examples/Sec = 3838.43, Train LB = -347.135, Loss = 341.746
[2018-06-04 21:12] Train Step 107550, Epoch 99.6, Batch Size = 256, Examples/Sec = 3744.07, Train LB = -340.780, Loss = 341.732
[2018-06-04 21:12] Train Step 107575, Epoch 99.6, Batch Size = 256, Examples/Sec = 3867.60, Train LB = -337.967, Loss = 343.308
[2018-06-04 21:12] Train Step 107600, Epoch 99.6, Batch Size = 256, Examples/Sec = 3840.50, Train LB = -367.710, Loss = 347.021
Performance on test set:
  Test Lower Bound = -430.446, Test Loss = 430.446
[2018-06-04 21:12] Train Step 107625, Epoch 99.7, Batch Size = 256, Examples/Sec = 3833.66, Train LB = -348.988, Loss = 345.466
[2018-06-04 21:12] Train Step 107650, Epoch 99.7, Batch Size = 256, Examples/Sec = 3865.62, Train LB = -341.309, Loss = 343.319
[2018-06-04 21:12] Train Step 107675, Epoch 99.7, Batch Size = 256, Examples/Sec = 3861.88, Train LB = -336.576, Loss = 342.303
[2018-06-04 21:12] Train Step 107700, Epoch 99.7, Batch Size = 256, Examples/Sec = 3882.84, Train LB = -339.411, Loss = 341.080
[2018-06-04 21:12] Train Step 107725, Epoch 99.7, Batch Size = 256, Examples/Sec = 3877.91, Train LB = -350.467, Loss = 341.071
[2018-06-04 21:12] Train Step 107750, Epoch 99.8, Batch Size = 256, Examples/Sec = 3871.15, Train LB = -317.996, Loss = 341.037
[2018-06-04 21:12] Train Step 107775, Epoch 99.8, Batch Size = 256, Examples/Sec = 3856.51, Train LB = -348.670, Loss = 342.202
[2018-06-04 21:12] Train Step 107800, Epoch 99.8, Batch Size = 256, Examples/Sec = 3842.68, Train LB = -361.840, Loss = 347.262
Performance on test set:
  Test Lower Bound = -431.317, Test Loss = 431.317
[2018-06-04 21:12] Train Step 107825, Epoch 99.8, Batch Size = 256, Examples/Sec = 3866.54, Train LB = -333.005, Loss = 345.043
[2018-06-04 21:12] Train Step 107850, Epoch 99.9, Batch Size = 256, Examples/Sec = 3869.76, Train LB = -357.386, Loss = 344.403
[2018-06-04 21:12] Train Step 107875, Epoch 99.9, Batch Size = 256, Examples/Sec = 3873.09, Train LB = -328.642, Loss = 342.825
[2018-06-04 21:12] Train Step 107900, Epoch 99.9, Batch Size = 256, Examples/Sec = 3851.13, Train LB = -348.258, Loss = 341.496
[2018-06-04 21:12] Train Step 107925, Epoch 99.9, Batch Size = 256, Examples/Sec = 3846.33, Train LB = -348.492, Loss = 340.691
[2018-06-04 21:12] Train Step 107950, Epoch 100.0, Batch Size = 256, Examples/Sec = 3834.35, Train LB = -340.367, Loss = 341.517
[2018-06-04 21:12] Train Step 107975, Epoch 100.0, Batch Size = 256, Examples/Sec = 3833.20, Train LB = -343.510, Loss = 342.446
